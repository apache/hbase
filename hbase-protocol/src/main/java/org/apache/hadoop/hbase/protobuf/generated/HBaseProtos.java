// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: hbase.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class HBaseProtos {
  private HBaseProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  /**
   * Protobuf enum {@code CellType}
   *
   * <pre>
   **
   * The type of the key in a Cell
   * </pre>
   */
  public enum CellType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>MINIMUM = 0;</code>
     */
    MINIMUM(0, 0),
    /**
     * <code>PUT = 4;</code>
     */
    PUT(1, 4),
    /**
     * <code>DELETE = 8;</code>
     */
    DELETE(2, 8),
    /**
     * <code>DELETE_COLUMN = 12;</code>
     */
    DELETE_COLUMN(3, 12),
    /**
     * <code>DELETE_FAMILY = 14;</code>
     */
    DELETE_FAMILY(4, 14),
    /**
     * <code>MAXIMUM = 255;</code>
     *
     * <pre>
     * MAXIMUM is used when searching; you look from maximum on down.
     * </pre>
     */
    MAXIMUM(5, 255),
    ;

    /**
     * <code>MINIMUM = 0;</code>
     */
    public static final int MINIMUM_VALUE = 0;
    /**
     * <code>PUT = 4;</code>
     */
    public static final int PUT_VALUE = 4;
    /**
     * <code>DELETE = 8;</code>
     */
    public static final int DELETE_VALUE = 8;
    /**
     * <code>DELETE_COLUMN = 12;</code>
     */
    public static final int DELETE_COLUMN_VALUE = 12;
    /**
     * <code>DELETE_FAMILY = 14;</code>
     */
    public static final int DELETE_FAMILY_VALUE = 14;
    /**
     * <code>MAXIMUM = 255;</code>
     *
     * <pre>
     * MAXIMUM is used when searching; you look from maximum on down.
     * </pre>
     */
    public static final int MAXIMUM_VALUE = 255;


    public final int getNumber() { return value; }

    public static CellType valueOf(int value) {
      switch (value) {
        case 0: return MINIMUM;
        case 4: return PUT;
        case 8: return DELETE;
        case 12: return DELETE_COLUMN;
        case 14: return DELETE_FAMILY;
        case 255: return MAXIMUM;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<CellType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<CellType>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<CellType>() {
            public CellType findValueByNumber(int number) {
              return CellType.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final CellType[] VALUES = values();

    public static CellType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private CellType(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:CellType)
  }

  /**
   * Protobuf enum {@code CompareType}
   *
   * <pre>
   * Comparison operators 
   * </pre>
   */
  public enum CompareType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>LESS = 0;</code>
     */
    LESS(0, 0),
    /**
     * <code>LESS_OR_EQUAL = 1;</code>
     */
    LESS_OR_EQUAL(1, 1),
    /**
     * <code>EQUAL = 2;</code>
     */
    EQUAL(2, 2),
    /**
     * <code>NOT_EQUAL = 3;</code>
     */
    NOT_EQUAL(3, 3),
    /**
     * <code>GREATER_OR_EQUAL = 4;</code>
     */
    GREATER_OR_EQUAL(4, 4),
    /**
     * <code>GREATER = 5;</code>
     */
    GREATER(5, 5),
    /**
     * <code>NO_OP = 6;</code>
     */
    NO_OP(6, 6),
    ;

    /**
     * <code>LESS = 0;</code>
     */
    public static final int LESS_VALUE = 0;
    /**
     * <code>LESS_OR_EQUAL = 1;</code>
     */
    public static final int LESS_OR_EQUAL_VALUE = 1;
    /**
     * <code>EQUAL = 2;</code>
     */
    public static final int EQUAL_VALUE = 2;
    /**
     * <code>NOT_EQUAL = 3;</code>
     */
    public static final int NOT_EQUAL_VALUE = 3;
    /**
     * <code>GREATER_OR_EQUAL = 4;</code>
     */
    public static final int GREATER_OR_EQUAL_VALUE = 4;
    /**
     * <code>GREATER = 5;</code>
     */
    public static final int GREATER_VALUE = 5;
    /**
     * <code>NO_OP = 6;</code>
     */
    public static final int NO_OP_VALUE = 6;


    public final int getNumber() { return value; }

    public static CompareType valueOf(int value) {
      switch (value) {
        case 0: return LESS;
        case 1: return LESS_OR_EQUAL;
        case 2: return EQUAL;
        case 3: return NOT_EQUAL;
        case 4: return GREATER_OR_EQUAL;
        case 5: return GREATER;
        case 6: return NO_OP;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<CompareType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static com.google.protobuf.Internal.EnumLiteMap<CompareType>
        internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<CompareType>() {
            public CompareType findValueByNumber(int number) {
              return CompareType.valueOf(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(index);
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final CompareType[] VALUES = values();

    public static CompareType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int index;
    private final int value;

    private CompareType(int index, int value) {
      this.index = index;
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:CompareType)
  }

  public interface CellOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bytes row = 1;
    /**
     * <code>optional bytes row = 1;</code>
     */
    boolean hasRow();
    /**
     * <code>optional bytes row = 1;</code>
     */
    com.google.protobuf.ByteString getRow();

    // optional bytes family = 2;
    /**
     * <code>optional bytes family = 2;</code>
     */
    boolean hasFamily();
    /**
     * <code>optional bytes family = 2;</code>
     */
    com.google.protobuf.ByteString getFamily();

    // optional bytes qualifier = 3;
    /**
     * <code>optional bytes qualifier = 3;</code>
     */
    boolean hasQualifier();
    /**
     * <code>optional bytes qualifier = 3;</code>
     */
    com.google.protobuf.ByteString getQualifier();

    // optional uint64 timestamp = 4;
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    boolean hasTimestamp();
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    long getTimestamp();

    // optional .CellType cellType = 5;
    /**
     * <code>optional .CellType cellType = 5;</code>
     */
    boolean hasCellType();
    /**
     * <code>optional .CellType cellType = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType getCellType();

    // optional bytes value = 6;
    /**
     * <code>optional bytes value = 6;</code>
     */
    boolean hasValue();
    /**
     * <code>optional bytes value = 6;</code>
     */
    com.google.protobuf.ByteString getValue();
  }
  /**
   * Protobuf type {@code Cell}
   *
   * <pre>
   **
   * Protocol buffer version of Cell.
   * </pre>
   */
  public static final class Cell extends
      com.google.protobuf.GeneratedMessage
      implements CellOrBuilder {
    // Use Cell.newBuilder() to construct.
    private Cell(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Cell(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Cell defaultInstance;
    public static Cell getDefaultInstance() {
      return defaultInstance;
    }

    public Cell getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Cell(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              family_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              qualifier_ = input.readBytes();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              timestamp_ = input.readUInt64();
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType value = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                cellType_ = value;
              }
              break;
            }
            case 50: {
              bitField0_ |= 0x00000020;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Cell_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Cell_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell.Builder.class);
    }

    public static com.google.protobuf.Parser<Cell> PARSER =
        new com.google.protobuf.AbstractParser<Cell>() {
      public Cell parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Cell(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Cell> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    /**
     * <code>optional bytes row = 1;</code>
     */
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bytes row = 1;</code>
     */
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }

    // optional bytes family = 2;
    public static final int FAMILY_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString family_;
    /**
     * <code>optional bytes family = 2;</code>
     */
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes family = 2;</code>
     */
    public com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    // optional bytes qualifier = 3;
    public static final int QUALIFIER_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString qualifier_;
    /**
     * <code>optional bytes qualifier = 3;</code>
     */
    public boolean hasQualifier() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bytes qualifier = 3;</code>
     */
    public com.google.protobuf.ByteString getQualifier() {
      return qualifier_;
    }

    // optional uint64 timestamp = 4;
    public static final int TIMESTAMP_FIELD_NUMBER = 4;
    private long timestamp_;
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    public boolean hasTimestamp() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    public long getTimestamp() {
      return timestamp_;
    }

    // optional .CellType cellType = 5;
    public static final int CELLTYPE_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType cellType_;
    /**
     * <code>optional .CellType cellType = 5;</code>
     */
    public boolean hasCellType() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .CellType cellType = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType getCellType() {
      return cellType_;
    }

    // optional bytes value = 6;
    public static final int VALUE_FIELD_NUMBER = 6;
    private com.google.protobuf.ByteString value_;
    /**
     * <code>optional bytes value = 6;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional bytes value = 6;</code>
     */
    public com.google.protobuf.ByteString getValue() {
      return value_;
    }

    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      family_ = com.google.protobuf.ByteString.EMPTY;
      qualifier_ = com.google.protobuf.ByteString.EMPTY;
      timestamp_ = 0L;
      cellType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.MINIMUM;
      value_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt64(4, timestamp_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, cellType_.getNumber());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(6, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, timestamp_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, cellType_.getNumber());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell) obj;

      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasFamily() == other.hasFamily());
      if (hasFamily()) {
        result = result && getFamily()
            .equals(other.getFamily());
      }
      result = result && (hasQualifier() == other.hasQualifier());
      if (hasQualifier()) {
        result = result && getQualifier()
            .equals(other.getQualifier());
      }
      result = result && (hasTimestamp() == other.hasTimestamp());
      if (hasTimestamp()) {
        result = result && (getTimestamp()
            == other.getTimestamp());
      }
      result = result && (hasCellType() == other.hasCellType());
      if (hasCellType()) {
        result = result &&
            (getCellType() == other.getCellType());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (hasQualifier()) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifier().hashCode();
      }
      if (hasTimestamp()) {
        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTimestamp());
      }
      if (hasCellType()) {
        hash = (37 * hash) + CELLTYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getCellType());
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code Cell}
     *
     * <pre>
     **
     * Protocol buffer version of Cell.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Cell_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Cell_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        qualifier_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        timestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        cellType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.MINIMUM;
        bitField0_ = (bitField0_ & ~0x00000010);
        value_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Cell_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.family_ = family_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.qualifier_ = qualifier_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.timestamp_ = timestamp_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.cellType_ = cellType_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (other.hasQualifier()) {
          setQualifier(other.getQualifier());
        }
        if (other.hasTimestamp()) {
          setTimestamp(other.getTimestamp());
        }
        if (other.hasCellType()) {
          setCellType(other.getCellType());
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Cell) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes row = 1;</code>
       */
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bytes row = 1;</code>
       */
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>optional bytes row = 1;</code>
       */
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes row = 1;</code>
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      // optional bytes family = 2;
      private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes family = 2;</code>
       */
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes family = 2;</code>
       */
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>optional bytes family = 2;</code>
       */
      public Builder setFamily(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        family_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes family = 2;</code>
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000002);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      // optional bytes qualifier = 3;
      private com.google.protobuf.ByteString qualifier_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes qualifier = 3;</code>
       */
      public boolean hasQualifier() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       */
      public com.google.protobuf.ByteString getQualifier() {
        return qualifier_;
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       */
      public Builder setQualifier(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        qualifier_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       */
      public Builder clearQualifier() {
        bitField0_ = (bitField0_ & ~0x00000004);
        qualifier_ = getDefaultInstance().getQualifier();
        onChanged();
        return this;
      }

      // optional uint64 timestamp = 4;
      private long timestamp_ ;
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public boolean hasTimestamp() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public long getTimestamp() {
        return timestamp_;
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public Builder setTimestamp(long value) {
        bitField0_ |= 0x00000008;
        timestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public Builder clearTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000008);
        timestamp_ = 0L;
        onChanged();
        return this;
      }

      // optional .CellType cellType = 5;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType cellType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.MINIMUM;
      /**
       * <code>optional .CellType cellType = 5;</code>
       */
      public boolean hasCellType() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .CellType cellType = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType getCellType() {
        return cellType_;
      }
      /**
       * <code>optional .CellType cellType = 5;</code>
       */
      public Builder setCellType(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        cellType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .CellType cellType = 5;</code>
       */
      public Builder clearCellType() {
        bitField0_ = (bitField0_ & ~0x00000010);
        cellType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.MINIMUM;
        onChanged();
        return this;
      }

      // optional bytes value = 6;
      private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes value = 6;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bytes value = 6;</code>
       */
      public com.google.protobuf.ByteString getValue() {
        return value_;
      }
      /**
       * <code>optional bytes value = 6;</code>
       */
      public Builder setValue(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes value = 6;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000020);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:Cell)
    }

    static {
      defaultInstance = new Cell(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:Cell)
  }

  public interface TableSchemaOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bytes name = 1;
    /**
     * <code>optional bytes name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>optional bytes name = 1;</code>
     */
    com.google.protobuf.ByteString getName();

    // repeated .BytesBytesPair attributes = 2;
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> 
        getAttributesList();
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair getAttributes(int index);
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    int getAttributesCount();
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
        getAttributesOrBuilderList();
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getAttributesOrBuilder(
        int index);

    // repeated .ColumnFamilySchema columnFamilies = 3;
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema> 
        getColumnFamiliesList();
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnFamilies(int index);
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    int getColumnFamiliesCount();
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> 
        getColumnFamiliesOrBuilderList();
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnFamiliesOrBuilder(
        int index);

    // repeated .NameStringPair configuration = 4;
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> 
        getConfigurationList();
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getConfiguration(int index);
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    int getConfigurationCount();
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
        getConfigurationOrBuilderList();
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getConfigurationOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code TableSchema}
   *
   * <pre>
   **
   * Table Schema
   * Inspired by the rest TableSchema
   * </pre>
   */
  public static final class TableSchema extends
      com.google.protobuf.GeneratedMessage
      implements TableSchemaOrBuilder {
    // Use TableSchema.newBuilder() to construct.
    private TableSchema(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private TableSchema(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final TableSchema defaultInstance;
    public static TableSchema getDefaultInstance() {
      return defaultInstance;
    }

    public TableSchema getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private TableSchema(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                attributes_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair>();
                mutable_bitField0_ |= 0x00000002;
              }
              attributes_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.PARSER, extensionRegistry));
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                columnFamilies_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema>();
                mutable_bitField0_ |= 0x00000004;
              }
              columnFamilies_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                configuration_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair>();
                mutable_bitField0_ |= 0x00000008;
              }
              configuration_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          attributes_ = java.util.Collections.unmodifiableList(attributes_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          columnFamilies_ = java.util.Collections.unmodifiableList(columnFamilies_);
        }
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          configuration_ = java.util.Collections.unmodifiableList(configuration_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TableSchema_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TableSchema_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder.class);
    }

    public static com.google.protobuf.Parser<TableSchema> PARSER =
        new com.google.protobuf.AbstractParser<TableSchema>() {
      public TableSchema parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TableSchema(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<TableSchema> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional bytes name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString name_;
    /**
     * <code>optional bytes name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bytes name = 1;</code>
     */
    public com.google.protobuf.ByteString getName() {
      return name_;
    }

    // repeated .BytesBytesPair attributes = 2;
    public static final int ATTRIBUTES_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> attributes_;
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> getAttributesList() {
      return attributes_;
    }
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
        getAttributesOrBuilderList() {
      return attributes_;
    }
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public int getAttributesCount() {
      return attributes_.size();
    }
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair getAttributes(int index) {
      return attributes_.get(index);
    }
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getAttributesOrBuilder(
        int index) {
      return attributes_.get(index);
    }

    // repeated .ColumnFamilySchema columnFamilies = 3;
    public static final int COLUMNFAMILIES_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema> columnFamilies_;
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema> getColumnFamiliesList() {
      return columnFamilies_;
    }
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> 
        getColumnFamiliesOrBuilderList() {
      return columnFamilies_;
    }
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    public int getColumnFamiliesCount() {
      return columnFamilies_.size();
    }
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnFamilies(int index) {
      return columnFamilies_.get(index);
    }
    /**
     * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnFamiliesOrBuilder(
        int index) {
      return columnFamilies_.get(index);
    }

    // repeated .NameStringPair configuration = 4;
    public static final int CONFIGURATION_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> configuration_;
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> getConfigurationList() {
      return configuration_;
    }
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
        getConfigurationOrBuilderList() {
      return configuration_;
    }
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    public int getConfigurationCount() {
      return configuration_.size();
    }
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getConfiguration(int index) {
      return configuration_.get(index);
    }
    /**
     * <code>repeated .NameStringPair configuration = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getConfigurationOrBuilder(
        int index) {
      return configuration_.get(index);
    }

    private void initFields() {
      name_ = com.google.protobuf.ByteString.EMPTY;
      attributes_ = java.util.Collections.emptyList();
      columnFamilies_ = java.util.Collections.emptyList();
      configuration_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getAttributesCount(); i++) {
        if (!getAttributes(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getColumnFamiliesCount(); i++) {
        if (!getColumnFamilies(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getConfigurationCount(); i++) {
        if (!getConfiguration(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, name_);
      }
      for (int i = 0; i < attributes_.size(); i++) {
        output.writeMessage(2, attributes_.get(i));
      }
      for (int i = 0; i < columnFamilies_.size(); i++) {
        output.writeMessage(3, columnFamilies_.get(i));
      }
      for (int i = 0; i < configuration_.size(); i++) {
        output.writeMessage(4, configuration_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, name_);
      }
      for (int i = 0; i < attributes_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, attributes_.get(i));
      }
      for (int i = 0; i < columnFamilies_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, columnFamilies_.get(i));
      }
      for (int i = 0; i < configuration_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, configuration_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && getAttributesList()
          .equals(other.getAttributesList());
      result = result && getColumnFamiliesList()
          .equals(other.getColumnFamiliesList());
      result = result && getConfigurationList()
          .equals(other.getConfigurationList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (getAttributesCount() > 0) {
        hash = (37 * hash) + ATTRIBUTES_FIELD_NUMBER;
        hash = (53 * hash) + getAttributesList().hashCode();
      }
      if (getColumnFamiliesCount() > 0) {
        hash = (37 * hash) + COLUMNFAMILIES_FIELD_NUMBER;
        hash = (53 * hash) + getColumnFamiliesList().hashCode();
      }
      if (getConfigurationCount() > 0) {
        hash = (37 * hash) + CONFIGURATION_FIELD_NUMBER;
        hash = (53 * hash) + getConfigurationList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code TableSchema}
     *
     * <pre>
     **
     * Table Schema
     * Inspired by the rest TableSchema
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchemaOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TableSchema_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TableSchema_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAttributesFieldBuilder();
          getColumnFamiliesFieldBuilder();
          getConfigurationFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (attributesBuilder_ == null) {
          attributes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          attributesBuilder_.clear();
        }
        if (columnFamiliesBuilder_ == null) {
          columnFamilies_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          columnFamiliesBuilder_.clear();
        }
        if (configurationBuilder_ == null) {
          configuration_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          configurationBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TableSchema_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (attributesBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            attributes_ = java.util.Collections.unmodifiableList(attributes_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.attributes_ = attributes_;
        } else {
          result.attributes_ = attributesBuilder_.build();
        }
        if (columnFamiliesBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            columnFamilies_ = java.util.Collections.unmodifiableList(columnFamilies_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.columnFamilies_ = columnFamilies_;
        } else {
          result.columnFamilies_ = columnFamiliesBuilder_.build();
        }
        if (configurationBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            configuration_ = java.util.Collections.unmodifiableList(configuration_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.configuration_ = configuration_;
        } else {
          result.configuration_ = configurationBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema.getDefaultInstance()) return this;
        if (other.hasName()) {
          setName(other.getName());
        }
        if (attributesBuilder_ == null) {
          if (!other.attributes_.isEmpty()) {
            if (attributes_.isEmpty()) {
              attributes_ = other.attributes_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureAttributesIsMutable();
              attributes_.addAll(other.attributes_);
            }
            onChanged();
          }
        } else {
          if (!other.attributes_.isEmpty()) {
            if (attributesBuilder_.isEmpty()) {
              attributesBuilder_.dispose();
              attributesBuilder_ = null;
              attributes_ = other.attributes_;
              bitField0_ = (bitField0_ & ~0x00000002);
              attributesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAttributesFieldBuilder() : null;
            } else {
              attributesBuilder_.addAllMessages(other.attributes_);
            }
          }
        }
        if (columnFamiliesBuilder_ == null) {
          if (!other.columnFamilies_.isEmpty()) {
            if (columnFamilies_.isEmpty()) {
              columnFamilies_ = other.columnFamilies_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureColumnFamiliesIsMutable();
              columnFamilies_.addAll(other.columnFamilies_);
            }
            onChanged();
          }
        } else {
          if (!other.columnFamilies_.isEmpty()) {
            if (columnFamiliesBuilder_.isEmpty()) {
              columnFamiliesBuilder_.dispose();
              columnFamiliesBuilder_ = null;
              columnFamilies_ = other.columnFamilies_;
              bitField0_ = (bitField0_ & ~0x00000004);
              columnFamiliesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getColumnFamiliesFieldBuilder() : null;
            } else {
              columnFamiliesBuilder_.addAllMessages(other.columnFamilies_);
            }
          }
        }
        if (configurationBuilder_ == null) {
          if (!other.configuration_.isEmpty()) {
            if (configuration_.isEmpty()) {
              configuration_ = other.configuration_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureConfigurationIsMutable();
              configuration_.addAll(other.configuration_);
            }
            onChanged();
          }
        } else {
          if (!other.configuration_.isEmpty()) {
            if (configurationBuilder_.isEmpty()) {
              configurationBuilder_.dispose();
              configurationBuilder_ = null;
              configuration_ = other.configuration_;
              bitField0_ = (bitField0_ & ~0x00000008);
              configurationBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getConfigurationFieldBuilder() : null;
            } else {
              configurationBuilder_.addAllMessages(other.configuration_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getAttributesCount(); i++) {
          if (!getAttributes(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getColumnFamiliesCount(); i++) {
          if (!getColumnFamilies(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getConfigurationCount(); i++) {
          if (!getConfiguration(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableSchema) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bytes name = 1;
      private com.google.protobuf.ByteString name_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bytes name = 1;</code>
       */
      public com.google.protobuf.ByteString getName() {
        return name_;
      }
      /**
       * <code>optional bytes name = 1;</code>
       */
      public Builder setName(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }

      // repeated .BytesBytesPair attributes = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> attributes_ =
        java.util.Collections.emptyList();
      private void ensureAttributesIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          attributes_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair>(attributes_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> attributesBuilder_;

      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> getAttributesList() {
        if (attributesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attributes_);
        } else {
          return attributesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public int getAttributesCount() {
        if (attributesBuilder_ == null) {
          return attributes_.size();
        } else {
          return attributesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair getAttributes(int index) {
        if (attributesBuilder_ == null) {
          return attributes_.get(index);
        } else {
          return attributesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder setAttributes(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (attributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributesIsMutable();
          attributes_.set(index, value);
          onChanged();
        } else {
          attributesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder setAttributes(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          attributes_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAttributes(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (attributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributesIsMutable();
          attributes_.add(value);
          onChanged();
        } else {
          attributesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAttributes(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (attributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributesIsMutable();
          attributes_.add(index, value);
          onChanged();
        } else {
          attributesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAttributes(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          attributes_.add(builderForValue.build());
          onChanged();
        } else {
          attributesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAttributes(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          attributes_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAllAttributes(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> values) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          super.addAll(values, attributes_);
          onChanged();
        } else {
          attributesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder clearAttributes() {
        if (attributesBuilder_ == null) {
          attributes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          attributesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder removeAttributes(int index) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          attributes_.remove(index);
          onChanged();
        } else {
          attributesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder getAttributesBuilder(
          int index) {
        return getAttributesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getAttributesOrBuilder(
          int index) {
        if (attributesBuilder_ == null) {
          return attributes_.get(index);  } else {
          return attributesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
           getAttributesOrBuilderList() {
        if (attributesBuilder_ != null) {
          return attributesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attributes_);
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder addAttributesBuilder() {
        return getAttributesFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder addAttributesBuilder(
          int index) {
        return getAttributesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder> 
           getAttributesBuilderList() {
        return getAttributesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
          getAttributesFieldBuilder() {
        if (attributesBuilder_ == null) {
          attributesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder>(
                  attributes_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          attributes_ = null;
        }
        return attributesBuilder_;
      }

      // repeated .ColumnFamilySchema columnFamilies = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema> columnFamilies_ =
        java.util.Collections.emptyList();
      private void ensureColumnFamiliesIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          columnFamilies_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema>(columnFamilies_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> columnFamiliesBuilder_;

      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema> getColumnFamiliesList() {
        if (columnFamiliesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(columnFamilies_);
        } else {
          return columnFamiliesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public int getColumnFamiliesCount() {
        if (columnFamiliesBuilder_ == null) {
          return columnFamilies_.size();
        } else {
          return columnFamiliesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getColumnFamilies(int index) {
        if (columnFamiliesBuilder_ == null) {
          return columnFamilies_.get(index);
        } else {
          return columnFamiliesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder setColumnFamilies(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnFamiliesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnFamiliesIsMutable();
          columnFamilies_.set(index, value);
          onChanged();
        } else {
          columnFamiliesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder setColumnFamilies(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder builderForValue) {
        if (columnFamiliesBuilder_ == null) {
          ensureColumnFamiliesIsMutable();
          columnFamilies_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnFamiliesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder addColumnFamilies(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnFamiliesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnFamiliesIsMutable();
          columnFamilies_.add(value);
          onChanged();
        } else {
          columnFamiliesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder addColumnFamilies(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema value) {
        if (columnFamiliesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnFamiliesIsMutable();
          columnFamilies_.add(index, value);
          onChanged();
        } else {
          columnFamiliesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder addColumnFamilies(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder builderForValue) {
        if (columnFamiliesBuilder_ == null) {
          ensureColumnFamiliesIsMutable();
          columnFamilies_.add(builderForValue.build());
          onChanged();
        } else {
          columnFamiliesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder addColumnFamilies(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder builderForValue) {
        if (columnFamiliesBuilder_ == null) {
          ensureColumnFamiliesIsMutable();
          columnFamilies_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnFamiliesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder addAllColumnFamilies(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema> values) {
        if (columnFamiliesBuilder_ == null) {
          ensureColumnFamiliesIsMutable();
          super.addAll(values, columnFamilies_);
          onChanged();
        } else {
          columnFamiliesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder clearColumnFamilies() {
        if (columnFamiliesBuilder_ == null) {
          columnFamilies_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          columnFamiliesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public Builder removeColumnFamilies(int index) {
        if (columnFamiliesBuilder_ == null) {
          ensureColumnFamiliesIsMutable();
          columnFamilies_.remove(index);
          onChanged();
        } else {
          columnFamiliesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder getColumnFamiliesBuilder(
          int index) {
        return getColumnFamiliesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder getColumnFamiliesOrBuilder(
          int index) {
        if (columnFamiliesBuilder_ == null) {
          return columnFamilies_.get(index);  } else {
          return columnFamiliesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> 
           getColumnFamiliesOrBuilderList() {
        if (columnFamiliesBuilder_ != null) {
          return columnFamiliesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(columnFamilies_);
        }
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder addColumnFamiliesBuilder() {
        return getColumnFamiliesFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance());
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder addColumnFamiliesBuilder(
          int index) {
        return getColumnFamiliesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance());
      }
      /**
       * <code>repeated .ColumnFamilySchema columnFamilies = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder> 
           getColumnFamiliesBuilderList() {
        return getColumnFamiliesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder> 
          getColumnFamiliesFieldBuilder() {
        if (columnFamiliesBuilder_ == null) {
          columnFamiliesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder>(
                  columnFamilies_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          columnFamilies_ = null;
        }
        return columnFamiliesBuilder_;
      }

      // repeated .NameStringPair configuration = 4;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> configuration_ =
        java.util.Collections.emptyList();
      private void ensureConfigurationIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          configuration_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair>(configuration_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> configurationBuilder_;

      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> getConfigurationList() {
        if (configurationBuilder_ == null) {
          return java.util.Collections.unmodifiableList(configuration_);
        } else {
          return configurationBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public int getConfigurationCount() {
        if (configurationBuilder_ == null) {
          return configuration_.size();
        } else {
          return configurationBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getConfiguration(int index) {
        if (configurationBuilder_ == null) {
          return configuration_.get(index);
        } else {
          return configurationBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder setConfiguration(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (configurationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureConfigurationIsMutable();
          configuration_.set(index, value);
          onChanged();
        } else {
          configurationBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder setConfiguration(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          configuration_.set(index, builderForValue.build());
          onChanged();
        } else {
          configurationBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder addConfiguration(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (configurationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureConfigurationIsMutable();
          configuration_.add(value);
          onChanged();
        } else {
          configurationBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder addConfiguration(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (configurationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureConfigurationIsMutable();
          configuration_.add(index, value);
          onChanged();
        } else {
          configurationBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder addConfiguration(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          configuration_.add(builderForValue.build());
          onChanged();
        } else {
          configurationBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder addConfiguration(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          configuration_.add(index, builderForValue.build());
          onChanged();
        } else {
          configurationBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder addAllConfiguration(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> values) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          super.addAll(values, configuration_);
          onChanged();
        } else {
          configurationBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder clearConfiguration() {
        if (configurationBuilder_ == null) {
          configuration_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          configurationBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public Builder removeConfiguration(int index) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          configuration_.remove(index);
          onChanged();
        } else {
          configurationBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder getConfigurationBuilder(
          int index) {
        return getConfigurationFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getConfigurationOrBuilder(
          int index) {
        if (configurationBuilder_ == null) {
          return configuration_.get(index);  } else {
          return configurationBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
           getConfigurationOrBuilderList() {
        if (configurationBuilder_ != null) {
          return configurationBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(configuration_);
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder addConfigurationBuilder() {
        return getConfigurationFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder addConfigurationBuilder(
          int index) {
        return getConfigurationFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameStringPair configuration = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder> 
           getConfigurationBuilderList() {
        return getConfigurationFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
          getConfigurationFieldBuilder() {
        if (configurationBuilder_ == null) {
          configurationBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder>(
                  configuration_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          configuration_ = null;
        }
        return configurationBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:TableSchema)
    }

    static {
      defaultInstance = new TableSchema(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:TableSchema)
  }

  public interface ColumnFamilySchemaOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes name = 1;
    /**
     * <code>required bytes name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>required bytes name = 1;</code>
     */
    com.google.protobuf.ByteString getName();

    // repeated .BytesBytesPair attributes = 2;
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> 
        getAttributesList();
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair getAttributes(int index);
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    int getAttributesCount();
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
        getAttributesOrBuilderList();
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getAttributesOrBuilder(
        int index);

    // repeated .NameStringPair configuration = 3;
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> 
        getConfigurationList();
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getConfiguration(int index);
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    int getConfigurationCount();
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
        getConfigurationOrBuilderList();
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getConfigurationOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code ColumnFamilySchema}
   *
   * <pre>
   **
   * Column Family Schema
   * Inspired by the rest ColumSchemaMessage
   * </pre>
   */
  public static final class ColumnFamilySchema extends
      com.google.protobuf.GeneratedMessage
      implements ColumnFamilySchemaOrBuilder {
    // Use ColumnFamilySchema.newBuilder() to construct.
    private ColumnFamilySchema(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ColumnFamilySchema(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ColumnFamilySchema defaultInstance;
    public static ColumnFamilySchema getDefaultInstance() {
      return defaultInstance;
    }

    public ColumnFamilySchema getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ColumnFamilySchema(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                attributes_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair>();
                mutable_bitField0_ |= 0x00000002;
              }
              attributes_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.PARSER, extensionRegistry));
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                configuration_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair>();
                mutable_bitField0_ |= 0x00000004;
              }
              configuration_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          attributes_ = java.util.Collections.unmodifiableList(attributes_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          configuration_ = java.util.Collections.unmodifiableList(configuration_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ColumnFamilySchema_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ColumnFamilySchema_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder.class);
    }

    public static com.google.protobuf.Parser<ColumnFamilySchema> PARSER =
        new com.google.protobuf.AbstractParser<ColumnFamilySchema>() {
      public ColumnFamilySchema parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ColumnFamilySchema(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ColumnFamilySchema> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString name_;
    /**
     * <code>required bytes name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes name = 1;</code>
     */
    public com.google.protobuf.ByteString getName() {
      return name_;
    }

    // repeated .BytesBytesPair attributes = 2;
    public static final int ATTRIBUTES_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> attributes_;
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> getAttributesList() {
      return attributes_;
    }
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
        getAttributesOrBuilderList() {
      return attributes_;
    }
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public int getAttributesCount() {
      return attributes_.size();
    }
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair getAttributes(int index) {
      return attributes_.get(index);
    }
    /**
     * <code>repeated .BytesBytesPair attributes = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getAttributesOrBuilder(
        int index) {
      return attributes_.get(index);
    }

    // repeated .NameStringPair configuration = 3;
    public static final int CONFIGURATION_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> configuration_;
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> getConfigurationList() {
      return configuration_;
    }
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
        getConfigurationOrBuilderList() {
      return configuration_;
    }
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    public int getConfigurationCount() {
      return configuration_.size();
    }
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getConfiguration(int index) {
      return configuration_.get(index);
    }
    /**
     * <code>repeated .NameStringPair configuration = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getConfigurationOrBuilder(
        int index) {
      return configuration_.get(index);
    }

    private void initFields() {
      name_ = com.google.protobuf.ByteString.EMPTY;
      attributes_ = java.util.Collections.emptyList();
      configuration_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getAttributesCount(); i++) {
        if (!getAttributes(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getConfigurationCount(); i++) {
        if (!getConfiguration(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, name_);
      }
      for (int i = 0; i < attributes_.size(); i++) {
        output.writeMessage(2, attributes_.get(i));
      }
      for (int i = 0; i < configuration_.size(); i++) {
        output.writeMessage(3, configuration_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, name_);
      }
      for (int i = 0; i < attributes_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, attributes_.get(i));
      }
      for (int i = 0; i < configuration_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, configuration_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && getAttributesList()
          .equals(other.getAttributesList());
      result = result && getConfigurationList()
          .equals(other.getConfigurationList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (getAttributesCount() > 0) {
        hash = (37 * hash) + ATTRIBUTES_FIELD_NUMBER;
        hash = (53 * hash) + getAttributesList().hashCode();
      }
      if (getConfigurationCount() > 0) {
        hash = (37 * hash) + CONFIGURATION_FIELD_NUMBER;
        hash = (53 * hash) + getConfigurationList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code ColumnFamilySchema}
     *
     * <pre>
     **
     * Column Family Schema
     * Inspired by the rest ColumSchemaMessage
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchemaOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ColumnFamilySchema_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ColumnFamilySchema_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getAttributesFieldBuilder();
          getConfigurationFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (attributesBuilder_ == null) {
          attributes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          attributesBuilder_.clear();
        }
        if (configurationBuilder_ == null) {
          configuration_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          configurationBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ColumnFamilySchema_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (attributesBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            attributes_ = java.util.Collections.unmodifiableList(attributes_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.attributes_ = attributes_;
        } else {
          result.attributes_ = attributesBuilder_.build();
        }
        if (configurationBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            configuration_ = java.util.Collections.unmodifiableList(configuration_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.configuration_ = configuration_;
        } else {
          result.configuration_ = configurationBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema.getDefaultInstance()) return this;
        if (other.hasName()) {
          setName(other.getName());
        }
        if (attributesBuilder_ == null) {
          if (!other.attributes_.isEmpty()) {
            if (attributes_.isEmpty()) {
              attributes_ = other.attributes_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureAttributesIsMutable();
              attributes_.addAll(other.attributes_);
            }
            onChanged();
          }
        } else {
          if (!other.attributes_.isEmpty()) {
            if (attributesBuilder_.isEmpty()) {
              attributesBuilder_.dispose();
              attributesBuilder_ = null;
              attributes_ = other.attributes_;
              bitField0_ = (bitField0_ & ~0x00000002);
              attributesBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAttributesFieldBuilder() : null;
            } else {
              attributesBuilder_.addAllMessages(other.attributes_);
            }
          }
        }
        if (configurationBuilder_ == null) {
          if (!other.configuration_.isEmpty()) {
            if (configuration_.isEmpty()) {
              configuration_ = other.configuration_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureConfigurationIsMutable();
              configuration_.addAll(other.configuration_);
            }
            onChanged();
          }
        } else {
          if (!other.configuration_.isEmpty()) {
            if (configurationBuilder_.isEmpty()) {
              configurationBuilder_.dispose();
              configurationBuilder_ = null;
              configuration_ = other.configuration_;
              bitField0_ = (bitField0_ & ~0x00000004);
              configurationBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getConfigurationFieldBuilder() : null;
            } else {
              configurationBuilder_.addAllMessages(other.configuration_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasName()) {
          
          return false;
        }
        for (int i = 0; i < getAttributesCount(); i++) {
          if (!getAttributes(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getConfigurationCount(); i++) {
          if (!getConfiguration(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ColumnFamilySchema) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes name = 1;
      private com.google.protobuf.ByteString name_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes name = 1;</code>
       */
      public com.google.protobuf.ByteString getName() {
        return name_;
      }
      /**
       * <code>required bytes name = 1;</code>
       */
      public Builder setName(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }

      // repeated .BytesBytesPair attributes = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> attributes_ =
        java.util.Collections.emptyList();
      private void ensureAttributesIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          attributes_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair>(attributes_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> attributesBuilder_;

      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> getAttributesList() {
        if (attributesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attributes_);
        } else {
          return attributesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public int getAttributesCount() {
        if (attributesBuilder_ == null) {
          return attributes_.size();
        } else {
          return attributesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair getAttributes(int index) {
        if (attributesBuilder_ == null) {
          return attributes_.get(index);
        } else {
          return attributesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder setAttributes(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (attributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributesIsMutable();
          attributes_.set(index, value);
          onChanged();
        } else {
          attributesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder setAttributes(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          attributes_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAttributes(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (attributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributesIsMutable();
          attributes_.add(value);
          onChanged();
        } else {
          attributesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAttributes(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair value) {
        if (attributesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributesIsMutable();
          attributes_.add(index, value);
          onChanged();
        } else {
          attributesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAttributes(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          attributes_.add(builderForValue.build());
          onChanged();
        } else {
          attributesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAttributes(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder builderForValue) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          attributes_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder addAllAttributes(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair> values) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          super.addAll(values, attributes_);
          onChanged();
        } else {
          attributesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder clearAttributes() {
        if (attributesBuilder_ == null) {
          attributes_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          attributesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public Builder removeAttributes(int index) {
        if (attributesBuilder_ == null) {
          ensureAttributesIsMutable();
          attributes_.remove(index);
          onChanged();
        } else {
          attributesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder getAttributesBuilder(
          int index) {
        return getAttributesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder getAttributesOrBuilder(
          int index) {
        if (attributesBuilder_ == null) {
          return attributes_.get(index);  } else {
          return attributesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
           getAttributesOrBuilderList() {
        if (attributesBuilder_ != null) {
          return attributesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attributes_);
        }
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder addAttributesBuilder() {
        return getAttributesFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder addAttributesBuilder(
          int index) {
        return getAttributesFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .BytesBytesPair attributes = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder> 
           getAttributesBuilderList() {
        return getAttributesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder> 
          getAttributesFieldBuilder() {
        if (attributesBuilder_ == null) {
          attributesBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder>(
                  attributes_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          attributes_ = null;
        }
        return attributesBuilder_;
      }

      // repeated .NameStringPair configuration = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> configuration_ =
        java.util.Collections.emptyList();
      private void ensureConfigurationIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          configuration_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair>(configuration_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> configurationBuilder_;

      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> getConfigurationList() {
        if (configurationBuilder_ == null) {
          return java.util.Collections.unmodifiableList(configuration_);
        } else {
          return configurationBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public int getConfigurationCount() {
        if (configurationBuilder_ == null) {
          return configuration_.size();
        } else {
          return configurationBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getConfiguration(int index) {
        if (configurationBuilder_ == null) {
          return configuration_.get(index);
        } else {
          return configurationBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder setConfiguration(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (configurationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureConfigurationIsMutable();
          configuration_.set(index, value);
          onChanged();
        } else {
          configurationBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder setConfiguration(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          configuration_.set(index, builderForValue.build());
          onChanged();
        } else {
          configurationBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder addConfiguration(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (configurationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureConfigurationIsMutable();
          configuration_.add(value);
          onChanged();
        } else {
          configurationBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder addConfiguration(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (configurationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureConfigurationIsMutable();
          configuration_.add(index, value);
          onChanged();
        } else {
          configurationBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder addConfiguration(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          configuration_.add(builderForValue.build());
          onChanged();
        } else {
          configurationBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder addConfiguration(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          configuration_.add(index, builderForValue.build());
          onChanged();
        } else {
          configurationBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder addAllConfiguration(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> values) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          super.addAll(values, configuration_);
          onChanged();
        } else {
          configurationBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder clearConfiguration() {
        if (configurationBuilder_ == null) {
          configuration_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          configurationBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public Builder removeConfiguration(int index) {
        if (configurationBuilder_ == null) {
          ensureConfigurationIsMutable();
          configuration_.remove(index);
          onChanged();
        } else {
          configurationBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder getConfigurationBuilder(
          int index) {
        return getConfigurationFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getConfigurationOrBuilder(
          int index) {
        if (configurationBuilder_ == null) {
          return configuration_.get(index);  } else {
          return configurationBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
           getConfigurationOrBuilderList() {
        if (configurationBuilder_ != null) {
          return configurationBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(configuration_);
        }
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder addConfigurationBuilder() {
        return getConfigurationFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder addConfigurationBuilder(
          int index) {
        return getConfigurationFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameStringPair configuration = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder> 
           getConfigurationBuilderList() {
        return getConfigurationFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
          getConfigurationFieldBuilder() {
        if (configurationBuilder_ == null) {
          configurationBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder>(
                  configuration_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          configuration_ = null;
        }
        return configurationBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:ColumnFamilySchema)
    }

    static {
      defaultInstance = new ColumnFamilySchema(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:ColumnFamilySchema)
  }

  public interface RegionInfoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required uint64 regionId = 1;
    /**
     * <code>required uint64 regionId = 1;</code>
     */
    boolean hasRegionId();
    /**
     * <code>required uint64 regionId = 1;</code>
     */
    long getRegionId();

    // required bytes tableName = 2;
    /**
     * <code>required bytes tableName = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>required bytes tableName = 2;</code>
     */
    com.google.protobuf.ByteString getTableName();

    // optional bytes startKey = 3;
    /**
     * <code>optional bytes startKey = 3;</code>
     */
    boolean hasStartKey();
    /**
     * <code>optional bytes startKey = 3;</code>
     */
    com.google.protobuf.ByteString getStartKey();

    // optional bytes endKey = 4;
    /**
     * <code>optional bytes endKey = 4;</code>
     */
    boolean hasEndKey();
    /**
     * <code>optional bytes endKey = 4;</code>
     */
    com.google.protobuf.ByteString getEndKey();

    // optional bool offline = 5;
    /**
     * <code>optional bool offline = 5;</code>
     */
    boolean hasOffline();
    /**
     * <code>optional bool offline = 5;</code>
     */
    boolean getOffline();

    // optional bool split = 6;
    /**
     * <code>optional bool split = 6;</code>
     */
    boolean hasSplit();
    /**
     * <code>optional bool split = 6;</code>
     */
    boolean getSplit();
  }
  /**
   * Protobuf type {@code RegionInfo}
   *
   * <pre>
   **
   * Protocol buffer version of HRegionInfo.
   * </pre>
   */
  public static final class RegionInfo extends
      com.google.protobuf.GeneratedMessage
      implements RegionInfoOrBuilder {
    // Use RegionInfo.newBuilder() to construct.
    private RegionInfo(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private RegionInfo(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final RegionInfo defaultInstance;
    public static RegionInfo getDefaultInstance() {
      return defaultInstance;
    }

    public RegionInfo getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private RegionInfo(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              regionId_ = input.readUInt64();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              tableName_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              startKey_ = input.readBytes();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              endKey_ = input.readBytes();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              offline_ = input.readBool();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              split_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionInfo_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionInfo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder.class);
    }

    public static com.google.protobuf.Parser<RegionInfo> PARSER =
        new com.google.protobuf.AbstractParser<RegionInfo>() {
      public RegionInfo parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RegionInfo(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<RegionInfo> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required uint64 regionId = 1;
    public static final int REGIONID_FIELD_NUMBER = 1;
    private long regionId_;
    /**
     * <code>required uint64 regionId = 1;</code>
     */
    public boolean hasRegionId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required uint64 regionId = 1;</code>
     */
    public long getRegionId() {
      return regionId_;
    }

    // required bytes tableName = 2;
    public static final int TABLENAME_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString tableName_;
    /**
     * <code>required bytes tableName = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bytes tableName = 2;</code>
     */
    public com.google.protobuf.ByteString getTableName() {
      return tableName_;
    }

    // optional bytes startKey = 3;
    public static final int STARTKEY_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString startKey_;
    /**
     * <code>optional bytes startKey = 3;</code>
     */
    public boolean hasStartKey() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bytes startKey = 3;</code>
     */
    public com.google.protobuf.ByteString getStartKey() {
      return startKey_;
    }

    // optional bytes endKey = 4;
    public static final int ENDKEY_FIELD_NUMBER = 4;
    private com.google.protobuf.ByteString endKey_;
    /**
     * <code>optional bytes endKey = 4;</code>
     */
    public boolean hasEndKey() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional bytes endKey = 4;</code>
     */
    public com.google.protobuf.ByteString getEndKey() {
      return endKey_;
    }

    // optional bool offline = 5;
    public static final int OFFLINE_FIELD_NUMBER = 5;
    private boolean offline_;
    /**
     * <code>optional bool offline = 5;</code>
     */
    public boolean hasOffline() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool offline = 5;</code>
     */
    public boolean getOffline() {
      return offline_;
    }

    // optional bool split = 6;
    public static final int SPLIT_FIELD_NUMBER = 6;
    private boolean split_;
    /**
     * <code>optional bool split = 6;</code>
     */
    public boolean hasSplit() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional bool split = 6;</code>
     */
    public boolean getSplit() {
      return split_;
    }

    private void initFields() {
      regionId_ = 0L;
      tableName_ = com.google.protobuf.ByteString.EMPTY;
      startKey_ = com.google.protobuf.ByteString.EMPTY;
      endKey_ = com.google.protobuf.ByteString.EMPTY;
      offline_ = false;
      split_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegionId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasTableName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(1, regionId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, startKey_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, endKey_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(5, offline_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBool(6, split_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, regionId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, startKey_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, endKey_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, offline_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, split_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo) obj;

      boolean result = true;
      result = result && (hasRegionId() == other.hasRegionId());
      if (hasRegionId()) {
        result = result && (getRegionId()
            == other.getRegionId());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasStartKey() == other.hasStartKey());
      if (hasStartKey()) {
        result = result && getStartKey()
            .equals(other.getStartKey());
      }
      result = result && (hasEndKey() == other.hasEndKey());
      if (hasEndKey()) {
        result = result && getEndKey()
            .equals(other.getEndKey());
      }
      result = result && (hasOffline() == other.hasOffline());
      if (hasOffline()) {
        result = result && (getOffline()
            == other.getOffline());
      }
      result = result && (hasSplit() == other.hasSplit());
      if (hasSplit()) {
        result = result && (getSplit()
            == other.getSplit());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegionId()) {
        hash = (37 * hash) + REGIONID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getRegionId());
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLENAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasStartKey()) {
        hash = (37 * hash) + STARTKEY_FIELD_NUMBER;
        hash = (53 * hash) + getStartKey().hashCode();
      }
      if (hasEndKey()) {
        hash = (37 * hash) + ENDKEY_FIELD_NUMBER;
        hash = (53 * hash) + getEndKey().hashCode();
      }
      if (hasOffline()) {
        hash = (37 * hash) + OFFLINE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getOffline());
      }
      if (hasSplit()) {
        hash = (37 * hash) + SPLIT_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getSplit());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code RegionInfo}
     *
     * <pre>
     **
     * Protocol buffer version of HRegionInfo.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionInfo_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        regionId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        tableName_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        startKey_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        endKey_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        offline_ = false;
        bitField0_ = (bitField0_ & ~0x00000010);
        split_ = false;
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionInfo_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.regionId_ = regionId_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.tableName_ = tableName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.startKey_ = startKey_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.endKey_ = endKey_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.offline_ = offline_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.split_ = split_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo.getDefaultInstance()) return this;
        if (other.hasRegionId()) {
          setRegionId(other.getRegionId());
        }
        if (other.hasTableName()) {
          setTableName(other.getTableName());
        }
        if (other.hasStartKey()) {
          setStartKey(other.getStartKey());
        }
        if (other.hasEndKey()) {
          setEndKey(other.getEndKey());
        }
        if (other.hasOffline()) {
          setOffline(other.getOffline());
        }
        if (other.hasSplit()) {
          setSplit(other.getSplit());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegionId()) {
          
          return false;
        }
        if (!hasTableName()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionInfo) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required uint64 regionId = 1;
      private long regionId_ ;
      /**
       * <code>required uint64 regionId = 1;</code>
       */
      public boolean hasRegionId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required uint64 regionId = 1;</code>
       */
      public long getRegionId() {
        return regionId_;
      }
      /**
       * <code>required uint64 regionId = 1;</code>
       */
      public Builder setRegionId(long value) {
        bitField0_ |= 0x00000001;
        regionId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required uint64 regionId = 1;</code>
       */
      public Builder clearRegionId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        regionId_ = 0L;
        onChanged();
        return this;
      }

      // required bytes tableName = 2;
      private com.google.protobuf.ByteString tableName_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes tableName = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bytes tableName = 2;</code>
       */
      public com.google.protobuf.ByteString getTableName() {
        return tableName_;
      }
      /**
       * <code>required bytes tableName = 2;</code>
       */
      public Builder setTableName(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        tableName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes tableName = 2;</code>
       */
      public Builder clearTableName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tableName_ = getDefaultInstance().getTableName();
        onChanged();
        return this;
      }

      // optional bytes startKey = 3;
      private com.google.protobuf.ByteString startKey_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes startKey = 3;</code>
       */
      public boolean hasStartKey() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bytes startKey = 3;</code>
       */
      public com.google.protobuf.ByteString getStartKey() {
        return startKey_;
      }
      /**
       * <code>optional bytes startKey = 3;</code>
       */
      public Builder setStartKey(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        startKey_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes startKey = 3;</code>
       */
      public Builder clearStartKey() {
        bitField0_ = (bitField0_ & ~0x00000004);
        startKey_ = getDefaultInstance().getStartKey();
        onChanged();
        return this;
      }

      // optional bytes endKey = 4;
      private com.google.protobuf.ByteString endKey_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes endKey = 4;</code>
       */
      public boolean hasEndKey() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional bytes endKey = 4;</code>
       */
      public com.google.protobuf.ByteString getEndKey() {
        return endKey_;
      }
      /**
       * <code>optional bytes endKey = 4;</code>
       */
      public Builder setEndKey(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        endKey_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes endKey = 4;</code>
       */
      public Builder clearEndKey() {
        bitField0_ = (bitField0_ & ~0x00000008);
        endKey_ = getDefaultInstance().getEndKey();
        onChanged();
        return this;
      }

      // optional bool offline = 5;
      private boolean offline_ ;
      /**
       * <code>optional bool offline = 5;</code>
       */
      public boolean hasOffline() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool offline = 5;</code>
       */
      public boolean getOffline() {
        return offline_;
      }
      /**
       * <code>optional bool offline = 5;</code>
       */
      public Builder setOffline(boolean value) {
        bitField0_ |= 0x00000010;
        offline_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool offline = 5;</code>
       */
      public Builder clearOffline() {
        bitField0_ = (bitField0_ & ~0x00000010);
        offline_ = false;
        onChanged();
        return this;
      }

      // optional bool split = 6;
      private boolean split_ ;
      /**
       * <code>optional bool split = 6;</code>
       */
      public boolean hasSplit() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bool split = 6;</code>
       */
      public boolean getSplit() {
        return split_;
      }
      /**
       * <code>optional bool split = 6;</code>
       */
      public Builder setSplit(boolean value) {
        bitField0_ |= 0x00000020;
        split_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool split = 6;</code>
       */
      public Builder clearSplit() {
        bitField0_ = (bitField0_ & ~0x00000020);
        split_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:RegionInfo)
    }

    static {
      defaultInstance = new RegionInfo(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:RegionInfo)
  }

  public interface RegionSpecifierOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier.RegionSpecifierType type = 1;
    /**
     * <code>required .RegionSpecifier.RegionSpecifierType type = 1;</code>
     */
    boolean hasType();
    /**
     * <code>required .RegionSpecifier.RegionSpecifierType type = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType getType();

    // required bytes value = 2;
    /**
     * <code>required bytes value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>required bytes value = 2;</code>
     */
    com.google.protobuf.ByteString getValue();
  }
  /**
   * Protobuf type {@code RegionSpecifier}
   *
   * <pre>
   **
   * Container protocol buffer to specify a region.
   * You can specify region by region name, or the hash
   * of the region name, which is known as encoded
   * region name.
   * </pre>
   */
  public static final class RegionSpecifier extends
      com.google.protobuf.GeneratedMessage
      implements RegionSpecifierOrBuilder {
    // Use RegionSpecifier.newBuilder() to construct.
    private RegionSpecifier(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private RegionSpecifier(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final RegionSpecifier defaultInstance;
    public static RegionSpecifier getDefaultInstance() {
      return defaultInstance;
    }

    public RegionSpecifier getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private RegionSpecifier(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType value = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                type_ = value;
              }
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionSpecifier_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionSpecifier_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder.class);
    }

    public static com.google.protobuf.Parser<RegionSpecifier> PARSER =
        new com.google.protobuf.AbstractParser<RegionSpecifier>() {
      public RegionSpecifier parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RegionSpecifier(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<RegionSpecifier> getParserForType() {
      return PARSER;
    }

    /**
     * Protobuf enum {@code RegionSpecifier.RegionSpecifierType}
     */
    public enum RegionSpecifierType
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>REGION_NAME = 1;</code>
       *
       * <pre>
       * &lt;tablename&gt;,&lt;startkey&gt;,&lt;regionId&gt;.&lt;encodedName&gt;
       * </pre>
       */
      REGION_NAME(0, 1),
      /**
       * <code>ENCODED_REGION_NAME = 2;</code>
       *
       * <pre>
       * hash of &lt;tablename&gt;,&lt;startkey&gt;,&lt;regionId&gt;
       * </pre>
       */
      ENCODED_REGION_NAME(1, 2),
      ;

      /**
       * <code>REGION_NAME = 1;</code>
       *
       * <pre>
       * &lt;tablename&gt;,&lt;startkey&gt;,&lt;regionId&gt;.&lt;encodedName&gt;
       * </pre>
       */
      public static final int REGION_NAME_VALUE = 1;
      /**
       * <code>ENCODED_REGION_NAME = 2;</code>
       *
       * <pre>
       * hash of &lt;tablename&gt;,&lt;startkey&gt;,&lt;regionId&gt;
       * </pre>
       */
      public static final int ENCODED_REGION_NAME_VALUE = 2;


      public final int getNumber() { return value; }

      public static RegionSpecifierType valueOf(int value) {
        switch (value) {
          case 1: return REGION_NAME;
          case 2: return ENCODED_REGION_NAME;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<RegionSpecifierType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<RegionSpecifierType>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<RegionSpecifierType>() {
              public RegionSpecifierType findValueByNumber(int number) {
                return RegionSpecifierType.valueOf(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDescriptor().getEnumTypes().get(0);
      }

      private static final RegionSpecifierType[] VALUES = values();

      public static RegionSpecifierType valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int index;
      private final int value;

      private RegionSpecifierType(int index, int value) {
        this.index = index;
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:RegionSpecifier.RegionSpecifierType)
    }

    private int bitField0_;
    // required .RegionSpecifier.RegionSpecifierType type = 1;
    public static final int TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType type_;
    /**
     * <code>required .RegionSpecifier.RegionSpecifierType type = 1;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier.RegionSpecifierType type = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType getType() {
      return type_;
    }

    // required bytes value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString value_;
    /**
     * <code>required bytes value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bytes value = 2;</code>
     */
    public com.google.protobuf.ByteString getValue() {
      return value_;
    }

    private void initFields() {
      type_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType.REGION_NAME;
      value_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, type_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, type_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier) obj;

      boolean result = true;
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result &&
            (getType() == other.getType());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getType());
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code RegionSpecifier}
     *
     * <pre>
     **
     * Container protocol buffer to specify a region.
     * You can specify region by region name, or the hash
     * of the region name, which is known as encoded
     * region name.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionSpecifier_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionSpecifier_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        type_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType.REGION_NAME;
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionSpecifier_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) return this;
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasType()) {
          
          return false;
        }
        if (!hasValue()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier.RegionSpecifierType type = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType type_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType.REGION_NAME;
      /**
       * <code>required .RegionSpecifier.RegionSpecifierType type = 1;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier.RegionSpecifierType type = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType getType() {
        return type_;
      }
      /**
       * <code>required .RegionSpecifier.RegionSpecifierType type = 1;</code>
       */
      public Builder setType(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        type_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required .RegionSpecifier.RegionSpecifierType type = 1;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.RegionSpecifierType.REGION_NAME;
        onChanged();
        return this;
      }

      // required bytes value = 2;
      private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bytes value = 2;</code>
       */
      public com.google.protobuf.ByteString getValue() {
        return value_;
      }
      /**
       * <code>required bytes value = 2;</code>
       */
      public Builder setValue(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:RegionSpecifier)
    }

    static {
      defaultInstance = new RegionSpecifier(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:RegionSpecifier)
  }

  public interface RegionLoadOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier regionSpecifier = 1;
    /**
     * <code>required .RegionSpecifier regionSpecifier = 1;</code>
     *
     * <pre>
     ** the region specifier 
     * </pre>
     */
    boolean hasRegionSpecifier();
    /**
     * <code>required .RegionSpecifier regionSpecifier = 1;</code>
     *
     * <pre>
     ** the region specifier 
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegionSpecifier();
    /**
     * <code>required .RegionSpecifier regionSpecifier = 1;</code>
     *
     * <pre>
     ** the region specifier 
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionSpecifierOrBuilder();

    // optional uint32 stores = 2;
    /**
     * <code>optional uint32 stores = 2;</code>
     *
     * <pre>
     ** the number of stores for the region 
     * </pre>
     */
    boolean hasStores();
    /**
     * <code>optional uint32 stores = 2;</code>
     *
     * <pre>
     ** the number of stores for the region 
     * </pre>
     */
    int getStores();

    // optional uint32 storefiles = 3;
    /**
     * <code>optional uint32 storefiles = 3;</code>
     *
     * <pre>
     ** the number of storefiles for the region 
     * </pre>
     */
    boolean hasStorefiles();
    /**
     * <code>optional uint32 storefiles = 3;</code>
     *
     * <pre>
     ** the number of storefiles for the region 
     * </pre>
     */
    int getStorefiles();

    // optional uint32 storeUncompressedSizeMB = 4;
    /**
     * <code>optional uint32 storeUncompressedSizeMB = 4;</code>
     *
     * <pre>
     ** the total size of the store files for the region, uncompressed, in MB 
     * </pre>
     */
    boolean hasStoreUncompressedSizeMB();
    /**
     * <code>optional uint32 storeUncompressedSizeMB = 4;</code>
     *
     * <pre>
     ** the total size of the store files for the region, uncompressed, in MB 
     * </pre>
     */
    int getStoreUncompressedSizeMB();

    // optional uint32 storefileSizeMB = 5;
    /**
     * <code>optional uint32 storefileSizeMB = 5;</code>
     *
     * <pre>
     ** the current total size of the store files for the region, in MB 
     * </pre>
     */
    boolean hasStorefileSizeMB();
    /**
     * <code>optional uint32 storefileSizeMB = 5;</code>
     *
     * <pre>
     ** the current total size of the store files for the region, in MB 
     * </pre>
     */
    int getStorefileSizeMB();

    // optional uint32 memstoreSizeMB = 6;
    /**
     * <code>optional uint32 memstoreSizeMB = 6;</code>
     *
     * <pre>
     ** the current size of the memstore for the region, in MB 
     * </pre>
     */
    boolean hasMemstoreSizeMB();
    /**
     * <code>optional uint32 memstoreSizeMB = 6;</code>
     *
     * <pre>
     ** the current size of the memstore for the region, in MB 
     * </pre>
     */
    int getMemstoreSizeMB();

    // optional uint32 storefileIndexSizeMB = 7;
    /**
     * <code>optional uint32 storefileIndexSizeMB = 7;</code>
     *
     * <pre>
     **
     * The current total size of root-level store file indexes for the region,
     * in MB. The same as {&#64;link #rootIndexSizeKB} but in MB.
     * </pre>
     */
    boolean hasStorefileIndexSizeMB();
    /**
     * <code>optional uint32 storefileIndexSizeMB = 7;</code>
     *
     * <pre>
     **
     * The current total size of root-level store file indexes for the region,
     * in MB. The same as {&#64;link #rootIndexSizeKB} but in MB.
     * </pre>
     */
    int getStorefileIndexSizeMB();

    // optional uint64 readRequestsCount = 8;
    /**
     * <code>optional uint64 readRequestsCount = 8;</code>
     *
     * <pre>
     ** the current total read requests made to region 
     * </pre>
     */
    boolean hasReadRequestsCount();
    /**
     * <code>optional uint64 readRequestsCount = 8;</code>
     *
     * <pre>
     ** the current total read requests made to region 
     * </pre>
     */
    long getReadRequestsCount();

    // optional uint64 writeRequestsCount = 9;
    /**
     * <code>optional uint64 writeRequestsCount = 9;</code>
     *
     * <pre>
     ** the current total write requests made to region 
     * </pre>
     */
    boolean hasWriteRequestsCount();
    /**
     * <code>optional uint64 writeRequestsCount = 9;</code>
     *
     * <pre>
     ** the current total write requests made to region 
     * </pre>
     */
    long getWriteRequestsCount();

    // optional uint64 totalCompactingKVs = 10;
    /**
     * <code>optional uint64 totalCompactingKVs = 10;</code>
     *
     * <pre>
     ** the total compacting key values in currently running compaction 
     * </pre>
     */
    boolean hasTotalCompactingKVs();
    /**
     * <code>optional uint64 totalCompactingKVs = 10;</code>
     *
     * <pre>
     ** the total compacting key values in currently running compaction 
     * </pre>
     */
    long getTotalCompactingKVs();

    // optional uint64 currentCompactedKVs = 11;
    /**
     * <code>optional uint64 currentCompactedKVs = 11;</code>
     *
     * <pre>
     ** the completed count of key values in currently running compaction 
     * </pre>
     */
    boolean hasCurrentCompactedKVs();
    /**
     * <code>optional uint64 currentCompactedKVs = 11;</code>
     *
     * <pre>
     ** the completed count of key values in currently running compaction 
     * </pre>
     */
    long getCurrentCompactedKVs();

    // optional uint32 rootIndexSizeKB = 12;
    /**
     * <code>optional uint32 rootIndexSizeKB = 12;</code>
     *
     * <pre>
     ** The current total size of root-level indexes for the region, in KB. 
     * </pre>
     */
    boolean hasRootIndexSizeKB();
    /**
     * <code>optional uint32 rootIndexSizeKB = 12;</code>
     *
     * <pre>
     ** The current total size of root-level indexes for the region, in KB. 
     * </pre>
     */
    int getRootIndexSizeKB();

    // optional uint32 totalStaticIndexSizeKB = 13;
    /**
     * <code>optional uint32 totalStaticIndexSizeKB = 13;</code>
     *
     * <pre>
     ** The total size of all index blocks, not just the root level, in KB. 
     * </pre>
     */
    boolean hasTotalStaticIndexSizeKB();
    /**
     * <code>optional uint32 totalStaticIndexSizeKB = 13;</code>
     *
     * <pre>
     ** The total size of all index blocks, not just the root level, in KB. 
     * </pre>
     */
    int getTotalStaticIndexSizeKB();

    // optional uint32 totalStaticBloomSizeKB = 14;
    /**
     * <code>optional uint32 totalStaticBloomSizeKB = 14;</code>
     *
     * <pre>
     **
     * The total size of all Bloom filter blocks, not just loaded into the
     * block cache, in KB.
     * </pre>
     */
    boolean hasTotalStaticBloomSizeKB();
    /**
     * <code>optional uint32 totalStaticBloomSizeKB = 14;</code>
     *
     * <pre>
     **
     * The total size of all Bloom filter blocks, not just loaded into the
     * block cache, in KB.
     * </pre>
     */
    int getTotalStaticBloomSizeKB();

    // optional uint64 completeSequenceId = 15;
    /**
     * <code>optional uint64 completeSequenceId = 15;</code>
     *
     * <pre>
     ** the most recent sequence Id from cache flush 
     * </pre>
     */
    boolean hasCompleteSequenceId();
    /**
     * <code>optional uint64 completeSequenceId = 15;</code>
     *
     * <pre>
     ** the most recent sequence Id from cache flush 
     * </pre>
     */
    long getCompleteSequenceId();
  }
  /**
   * Protobuf type {@code RegionLoad}
   */
  public static final class RegionLoad extends
      com.google.protobuf.GeneratedMessage
      implements RegionLoadOrBuilder {
    // Use RegionLoad.newBuilder() to construct.
    private RegionLoad(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private RegionLoad(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final RegionLoad defaultInstance;
    public static RegionLoad getDefaultInstance() {
      return defaultInstance;
    }

    public RegionLoad getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private RegionLoad(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = regionSpecifier_.toBuilder();
              }
              regionSpecifier_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(regionSpecifier_);
                regionSpecifier_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              stores_ = input.readUInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              storefiles_ = input.readUInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              storeUncompressedSizeMB_ = input.readUInt32();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              storefileSizeMB_ = input.readUInt32();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              memstoreSizeMB_ = input.readUInt32();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              storefileIndexSizeMB_ = input.readUInt32();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              readRequestsCount_ = input.readUInt64();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              writeRequestsCount_ = input.readUInt64();
              break;
            }
            case 80: {
              bitField0_ |= 0x00000200;
              totalCompactingKVs_ = input.readUInt64();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              currentCompactedKVs_ = input.readUInt64();
              break;
            }
            case 96: {
              bitField0_ |= 0x00000800;
              rootIndexSizeKB_ = input.readUInt32();
              break;
            }
            case 104: {
              bitField0_ |= 0x00001000;
              totalStaticIndexSizeKB_ = input.readUInt32();
              break;
            }
            case 112: {
              bitField0_ |= 0x00002000;
              totalStaticBloomSizeKB_ = input.readUInt32();
              break;
            }
            case 120: {
              bitField0_ |= 0x00004000;
              completeSequenceId_ = input.readUInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionLoad_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionLoad_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder.class);
    }

    public static com.google.protobuf.Parser<RegionLoad> PARSER =
        new com.google.protobuf.AbstractParser<RegionLoad>() {
      public RegionLoad parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RegionLoad(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<RegionLoad> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .RegionSpecifier regionSpecifier = 1;
    public static final int REGIONSPECIFIER_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier regionSpecifier_;
    /**
     * <code>required .RegionSpecifier regionSpecifier = 1;</code>
     *
     * <pre>
     ** the region specifier 
     * </pre>
     */
    public boolean hasRegionSpecifier() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier regionSpecifier = 1;</code>
     *
     * <pre>
     ** the region specifier 
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegionSpecifier() {
      return regionSpecifier_;
    }
    /**
     * <code>required .RegionSpecifier regionSpecifier = 1;</code>
     *
     * <pre>
     ** the region specifier 
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionSpecifierOrBuilder() {
      return regionSpecifier_;
    }

    // optional uint32 stores = 2;
    public static final int STORES_FIELD_NUMBER = 2;
    private int stores_;
    /**
     * <code>optional uint32 stores = 2;</code>
     *
     * <pre>
     ** the number of stores for the region 
     * </pre>
     */
    public boolean hasStores() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional uint32 stores = 2;</code>
     *
     * <pre>
     ** the number of stores for the region 
     * </pre>
     */
    public int getStores() {
      return stores_;
    }

    // optional uint32 storefiles = 3;
    public static final int STOREFILES_FIELD_NUMBER = 3;
    private int storefiles_;
    /**
     * <code>optional uint32 storefiles = 3;</code>
     *
     * <pre>
     ** the number of storefiles for the region 
     * </pre>
     */
    public boolean hasStorefiles() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional uint32 storefiles = 3;</code>
     *
     * <pre>
     ** the number of storefiles for the region 
     * </pre>
     */
    public int getStorefiles() {
      return storefiles_;
    }

    // optional uint32 storeUncompressedSizeMB = 4;
    public static final int STOREUNCOMPRESSEDSIZEMB_FIELD_NUMBER = 4;
    private int storeUncompressedSizeMB_;
    /**
     * <code>optional uint32 storeUncompressedSizeMB = 4;</code>
     *
     * <pre>
     ** the total size of the store files for the region, uncompressed, in MB 
     * </pre>
     */
    public boolean hasStoreUncompressedSizeMB() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional uint32 storeUncompressedSizeMB = 4;</code>
     *
     * <pre>
     ** the total size of the store files for the region, uncompressed, in MB 
     * </pre>
     */
    public int getStoreUncompressedSizeMB() {
      return storeUncompressedSizeMB_;
    }

    // optional uint32 storefileSizeMB = 5;
    public static final int STOREFILESIZEMB_FIELD_NUMBER = 5;
    private int storefileSizeMB_;
    /**
     * <code>optional uint32 storefileSizeMB = 5;</code>
     *
     * <pre>
     ** the current total size of the store files for the region, in MB 
     * </pre>
     */
    public boolean hasStorefileSizeMB() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional uint32 storefileSizeMB = 5;</code>
     *
     * <pre>
     ** the current total size of the store files for the region, in MB 
     * </pre>
     */
    public int getStorefileSizeMB() {
      return storefileSizeMB_;
    }

    // optional uint32 memstoreSizeMB = 6;
    public static final int MEMSTORESIZEMB_FIELD_NUMBER = 6;
    private int memstoreSizeMB_;
    /**
     * <code>optional uint32 memstoreSizeMB = 6;</code>
     *
     * <pre>
     ** the current size of the memstore for the region, in MB 
     * </pre>
     */
    public boolean hasMemstoreSizeMB() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional uint32 memstoreSizeMB = 6;</code>
     *
     * <pre>
     ** the current size of the memstore for the region, in MB 
     * </pre>
     */
    public int getMemstoreSizeMB() {
      return memstoreSizeMB_;
    }

    // optional uint32 storefileIndexSizeMB = 7;
    public static final int STOREFILEINDEXSIZEMB_FIELD_NUMBER = 7;
    private int storefileIndexSizeMB_;
    /**
     * <code>optional uint32 storefileIndexSizeMB = 7;</code>
     *
     * <pre>
     **
     * The current total size of root-level store file indexes for the region,
     * in MB. The same as {&#64;link #rootIndexSizeKB} but in MB.
     * </pre>
     */
    public boolean hasStorefileIndexSizeMB() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional uint32 storefileIndexSizeMB = 7;</code>
     *
     * <pre>
     **
     * The current total size of root-level store file indexes for the region,
     * in MB. The same as {&#64;link #rootIndexSizeKB} but in MB.
     * </pre>
     */
    public int getStorefileIndexSizeMB() {
      return storefileIndexSizeMB_;
    }

    // optional uint64 readRequestsCount = 8;
    public static final int READREQUESTSCOUNT_FIELD_NUMBER = 8;
    private long readRequestsCount_;
    /**
     * <code>optional uint64 readRequestsCount = 8;</code>
     *
     * <pre>
     ** the current total read requests made to region 
     * </pre>
     */
    public boolean hasReadRequestsCount() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional uint64 readRequestsCount = 8;</code>
     *
     * <pre>
     ** the current total read requests made to region 
     * </pre>
     */
    public long getReadRequestsCount() {
      return readRequestsCount_;
    }

    // optional uint64 writeRequestsCount = 9;
    public static final int WRITEREQUESTSCOUNT_FIELD_NUMBER = 9;
    private long writeRequestsCount_;
    /**
     * <code>optional uint64 writeRequestsCount = 9;</code>
     *
     * <pre>
     ** the current total write requests made to region 
     * </pre>
     */
    public boolean hasWriteRequestsCount() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional uint64 writeRequestsCount = 9;</code>
     *
     * <pre>
     ** the current total write requests made to region 
     * </pre>
     */
    public long getWriteRequestsCount() {
      return writeRequestsCount_;
    }

    // optional uint64 totalCompactingKVs = 10;
    public static final int TOTALCOMPACTINGKVS_FIELD_NUMBER = 10;
    private long totalCompactingKVs_;
    /**
     * <code>optional uint64 totalCompactingKVs = 10;</code>
     *
     * <pre>
     ** the total compacting key values in currently running compaction 
     * </pre>
     */
    public boolean hasTotalCompactingKVs() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional uint64 totalCompactingKVs = 10;</code>
     *
     * <pre>
     ** the total compacting key values in currently running compaction 
     * </pre>
     */
    public long getTotalCompactingKVs() {
      return totalCompactingKVs_;
    }

    // optional uint64 currentCompactedKVs = 11;
    public static final int CURRENTCOMPACTEDKVS_FIELD_NUMBER = 11;
    private long currentCompactedKVs_;
    /**
     * <code>optional uint64 currentCompactedKVs = 11;</code>
     *
     * <pre>
     ** the completed count of key values in currently running compaction 
     * </pre>
     */
    public boolean hasCurrentCompactedKVs() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional uint64 currentCompactedKVs = 11;</code>
     *
     * <pre>
     ** the completed count of key values in currently running compaction 
     * </pre>
     */
    public long getCurrentCompactedKVs() {
      return currentCompactedKVs_;
    }

    // optional uint32 rootIndexSizeKB = 12;
    public static final int ROOTINDEXSIZEKB_FIELD_NUMBER = 12;
    private int rootIndexSizeKB_;
    /**
     * <code>optional uint32 rootIndexSizeKB = 12;</code>
     *
     * <pre>
     ** The current total size of root-level indexes for the region, in KB. 
     * </pre>
     */
    public boolean hasRootIndexSizeKB() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    /**
     * <code>optional uint32 rootIndexSizeKB = 12;</code>
     *
     * <pre>
     ** The current total size of root-level indexes for the region, in KB. 
     * </pre>
     */
    public int getRootIndexSizeKB() {
      return rootIndexSizeKB_;
    }

    // optional uint32 totalStaticIndexSizeKB = 13;
    public static final int TOTALSTATICINDEXSIZEKB_FIELD_NUMBER = 13;
    private int totalStaticIndexSizeKB_;
    /**
     * <code>optional uint32 totalStaticIndexSizeKB = 13;</code>
     *
     * <pre>
     ** The total size of all index blocks, not just the root level, in KB. 
     * </pre>
     */
    public boolean hasTotalStaticIndexSizeKB() {
      return ((bitField0_ & 0x00001000) == 0x00001000);
    }
    /**
     * <code>optional uint32 totalStaticIndexSizeKB = 13;</code>
     *
     * <pre>
     ** The total size of all index blocks, not just the root level, in KB. 
     * </pre>
     */
    public int getTotalStaticIndexSizeKB() {
      return totalStaticIndexSizeKB_;
    }

    // optional uint32 totalStaticBloomSizeKB = 14;
    public static final int TOTALSTATICBLOOMSIZEKB_FIELD_NUMBER = 14;
    private int totalStaticBloomSizeKB_;
    /**
     * <code>optional uint32 totalStaticBloomSizeKB = 14;</code>
     *
     * <pre>
     **
     * The total size of all Bloom filter blocks, not just loaded into the
     * block cache, in KB.
     * </pre>
     */
    public boolean hasTotalStaticBloomSizeKB() {
      return ((bitField0_ & 0x00002000) == 0x00002000);
    }
    /**
     * <code>optional uint32 totalStaticBloomSizeKB = 14;</code>
     *
     * <pre>
     **
     * The total size of all Bloom filter blocks, not just loaded into the
     * block cache, in KB.
     * </pre>
     */
    public int getTotalStaticBloomSizeKB() {
      return totalStaticBloomSizeKB_;
    }

    // optional uint64 completeSequenceId = 15;
    public static final int COMPLETESEQUENCEID_FIELD_NUMBER = 15;
    private long completeSequenceId_;
    /**
     * <code>optional uint64 completeSequenceId = 15;</code>
     *
     * <pre>
     ** the most recent sequence Id from cache flush 
     * </pre>
     */
    public boolean hasCompleteSequenceId() {
      return ((bitField0_ & 0x00004000) == 0x00004000);
    }
    /**
     * <code>optional uint64 completeSequenceId = 15;</code>
     *
     * <pre>
     ** the most recent sequence Id from cache flush 
     * </pre>
     */
    public long getCompleteSequenceId() {
      return completeSequenceId_;
    }

    private void initFields() {
      regionSpecifier_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      stores_ = 0;
      storefiles_ = 0;
      storeUncompressedSizeMB_ = 0;
      storefileSizeMB_ = 0;
      memstoreSizeMB_ = 0;
      storefileIndexSizeMB_ = 0;
      readRequestsCount_ = 0L;
      writeRequestsCount_ = 0L;
      totalCompactingKVs_ = 0L;
      currentCompactedKVs_ = 0L;
      rootIndexSizeKB_ = 0;
      totalStaticIndexSizeKB_ = 0;
      totalStaticBloomSizeKB_ = 0;
      completeSequenceId_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegionSpecifier()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegionSpecifier().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, regionSpecifier_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt32(2, stores_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt32(3, storefiles_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(4, storeUncompressedSizeMB_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeUInt32(5, storefileSizeMB_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeUInt32(6, memstoreSizeMB_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeUInt32(7, storefileIndexSizeMB_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeUInt64(8, readRequestsCount_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeUInt64(9, writeRequestsCount_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeUInt64(10, totalCompactingKVs_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeUInt64(11, currentCompactedKVs_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeUInt32(12, rootIndexSizeKB_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        output.writeUInt32(13, totalStaticIndexSizeKB_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        output.writeUInt32(14, totalStaticBloomSizeKB_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        output.writeUInt64(15, completeSequenceId_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, regionSpecifier_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, stores_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(3, storefiles_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, storeUncompressedSizeMB_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(5, storefileSizeMB_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(6, memstoreSizeMB_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(7, storefileIndexSizeMB_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(8, readRequestsCount_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(9, writeRequestsCount_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(10, totalCompactingKVs_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(11, currentCompactedKVs_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(12, rootIndexSizeKB_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(13, totalStaticIndexSizeKB_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(14, totalStaticBloomSizeKB_);
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(15, completeSequenceId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad) obj;

      boolean result = true;
      result = result && (hasRegionSpecifier() == other.hasRegionSpecifier());
      if (hasRegionSpecifier()) {
        result = result && getRegionSpecifier()
            .equals(other.getRegionSpecifier());
      }
      result = result && (hasStores() == other.hasStores());
      if (hasStores()) {
        result = result && (getStores()
            == other.getStores());
      }
      result = result && (hasStorefiles() == other.hasStorefiles());
      if (hasStorefiles()) {
        result = result && (getStorefiles()
            == other.getStorefiles());
      }
      result = result && (hasStoreUncompressedSizeMB() == other.hasStoreUncompressedSizeMB());
      if (hasStoreUncompressedSizeMB()) {
        result = result && (getStoreUncompressedSizeMB()
            == other.getStoreUncompressedSizeMB());
      }
      result = result && (hasStorefileSizeMB() == other.hasStorefileSizeMB());
      if (hasStorefileSizeMB()) {
        result = result && (getStorefileSizeMB()
            == other.getStorefileSizeMB());
      }
      result = result && (hasMemstoreSizeMB() == other.hasMemstoreSizeMB());
      if (hasMemstoreSizeMB()) {
        result = result && (getMemstoreSizeMB()
            == other.getMemstoreSizeMB());
      }
      result = result && (hasStorefileIndexSizeMB() == other.hasStorefileIndexSizeMB());
      if (hasStorefileIndexSizeMB()) {
        result = result && (getStorefileIndexSizeMB()
            == other.getStorefileIndexSizeMB());
      }
      result = result && (hasReadRequestsCount() == other.hasReadRequestsCount());
      if (hasReadRequestsCount()) {
        result = result && (getReadRequestsCount()
            == other.getReadRequestsCount());
      }
      result = result && (hasWriteRequestsCount() == other.hasWriteRequestsCount());
      if (hasWriteRequestsCount()) {
        result = result && (getWriteRequestsCount()
            == other.getWriteRequestsCount());
      }
      result = result && (hasTotalCompactingKVs() == other.hasTotalCompactingKVs());
      if (hasTotalCompactingKVs()) {
        result = result && (getTotalCompactingKVs()
            == other.getTotalCompactingKVs());
      }
      result = result && (hasCurrentCompactedKVs() == other.hasCurrentCompactedKVs());
      if (hasCurrentCompactedKVs()) {
        result = result && (getCurrentCompactedKVs()
            == other.getCurrentCompactedKVs());
      }
      result = result && (hasRootIndexSizeKB() == other.hasRootIndexSizeKB());
      if (hasRootIndexSizeKB()) {
        result = result && (getRootIndexSizeKB()
            == other.getRootIndexSizeKB());
      }
      result = result && (hasTotalStaticIndexSizeKB() == other.hasTotalStaticIndexSizeKB());
      if (hasTotalStaticIndexSizeKB()) {
        result = result && (getTotalStaticIndexSizeKB()
            == other.getTotalStaticIndexSizeKB());
      }
      result = result && (hasTotalStaticBloomSizeKB() == other.hasTotalStaticBloomSizeKB());
      if (hasTotalStaticBloomSizeKB()) {
        result = result && (getTotalStaticBloomSizeKB()
            == other.getTotalStaticBloomSizeKB());
      }
      result = result && (hasCompleteSequenceId() == other.hasCompleteSequenceId());
      if (hasCompleteSequenceId()) {
        result = result && (getCompleteSequenceId()
            == other.getCompleteSequenceId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegionSpecifier()) {
        hash = (37 * hash) + REGIONSPECIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getRegionSpecifier().hashCode();
      }
      if (hasStores()) {
        hash = (37 * hash) + STORES_FIELD_NUMBER;
        hash = (53 * hash) + getStores();
      }
      if (hasStorefiles()) {
        hash = (37 * hash) + STOREFILES_FIELD_NUMBER;
        hash = (53 * hash) + getStorefiles();
      }
      if (hasStoreUncompressedSizeMB()) {
        hash = (37 * hash) + STOREUNCOMPRESSEDSIZEMB_FIELD_NUMBER;
        hash = (53 * hash) + getStoreUncompressedSizeMB();
      }
      if (hasStorefileSizeMB()) {
        hash = (37 * hash) + STOREFILESIZEMB_FIELD_NUMBER;
        hash = (53 * hash) + getStorefileSizeMB();
      }
      if (hasMemstoreSizeMB()) {
        hash = (37 * hash) + MEMSTORESIZEMB_FIELD_NUMBER;
        hash = (53 * hash) + getMemstoreSizeMB();
      }
      if (hasStorefileIndexSizeMB()) {
        hash = (37 * hash) + STOREFILEINDEXSIZEMB_FIELD_NUMBER;
        hash = (53 * hash) + getStorefileIndexSizeMB();
      }
      if (hasReadRequestsCount()) {
        hash = (37 * hash) + READREQUESTSCOUNT_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReadRequestsCount());
      }
      if (hasWriteRequestsCount()) {
        hash = (37 * hash) + WRITEREQUESTSCOUNT_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getWriteRequestsCount());
      }
      if (hasTotalCompactingKVs()) {
        hash = (37 * hash) + TOTALCOMPACTINGKVS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTotalCompactingKVs());
      }
      if (hasCurrentCompactedKVs()) {
        hash = (37 * hash) + CURRENTCOMPACTEDKVS_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getCurrentCompactedKVs());
      }
      if (hasRootIndexSizeKB()) {
        hash = (37 * hash) + ROOTINDEXSIZEKB_FIELD_NUMBER;
        hash = (53 * hash) + getRootIndexSizeKB();
      }
      if (hasTotalStaticIndexSizeKB()) {
        hash = (37 * hash) + TOTALSTATICINDEXSIZEKB_FIELD_NUMBER;
        hash = (53 * hash) + getTotalStaticIndexSizeKB();
      }
      if (hasTotalStaticBloomSizeKB()) {
        hash = (37 * hash) + TOTALSTATICBLOOMSIZEKB_FIELD_NUMBER;
        hash = (53 * hash) + getTotalStaticBloomSizeKB();
      }
      if (hasCompleteSequenceId()) {
        hash = (37 * hash) + COMPLETESEQUENCEID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getCompleteSequenceId());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code RegionLoad}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionLoad_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionLoad_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionSpecifierFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionSpecifierBuilder_ == null) {
          regionSpecifier_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionSpecifierBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        stores_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        storefiles_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        storeUncompressedSizeMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        storefileSizeMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        memstoreSizeMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        storefileIndexSizeMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000040);
        readRequestsCount_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000080);
        writeRequestsCount_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000100);
        totalCompactingKVs_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000200);
        currentCompactedKVs_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000400);
        rootIndexSizeKB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000800);
        totalStaticIndexSizeKB_ = 0;
        bitField0_ = (bitField0_ & ~0x00001000);
        totalStaticBloomSizeKB_ = 0;
        bitField0_ = (bitField0_ & ~0x00002000);
        completeSequenceId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00004000);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_RegionLoad_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionSpecifierBuilder_ == null) {
          result.regionSpecifier_ = regionSpecifier_;
        } else {
          result.regionSpecifier_ = regionSpecifierBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.stores_ = stores_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.storefiles_ = storefiles_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.storeUncompressedSizeMB_ = storeUncompressedSizeMB_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.storefileSizeMB_ = storefileSizeMB_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.memstoreSizeMB_ = memstoreSizeMB_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.storefileIndexSizeMB_ = storefileIndexSizeMB_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.readRequestsCount_ = readRequestsCount_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.writeRequestsCount_ = writeRequestsCount_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.totalCompactingKVs_ = totalCompactingKVs_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.currentCompactedKVs_ = currentCompactedKVs_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000800;
        }
        result.rootIndexSizeKB_ = rootIndexSizeKB_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00001000;
        }
        result.totalStaticIndexSizeKB_ = totalStaticIndexSizeKB_;
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00002000;
        }
        result.totalStaticBloomSizeKB_ = totalStaticBloomSizeKB_;
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00004000;
        }
        result.completeSequenceId_ = completeSequenceId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.getDefaultInstance()) return this;
        if (other.hasRegionSpecifier()) {
          mergeRegionSpecifier(other.getRegionSpecifier());
        }
        if (other.hasStores()) {
          setStores(other.getStores());
        }
        if (other.hasStorefiles()) {
          setStorefiles(other.getStorefiles());
        }
        if (other.hasStoreUncompressedSizeMB()) {
          setStoreUncompressedSizeMB(other.getStoreUncompressedSizeMB());
        }
        if (other.hasStorefileSizeMB()) {
          setStorefileSizeMB(other.getStorefileSizeMB());
        }
        if (other.hasMemstoreSizeMB()) {
          setMemstoreSizeMB(other.getMemstoreSizeMB());
        }
        if (other.hasStorefileIndexSizeMB()) {
          setStorefileIndexSizeMB(other.getStorefileIndexSizeMB());
        }
        if (other.hasReadRequestsCount()) {
          setReadRequestsCount(other.getReadRequestsCount());
        }
        if (other.hasWriteRequestsCount()) {
          setWriteRequestsCount(other.getWriteRequestsCount());
        }
        if (other.hasTotalCompactingKVs()) {
          setTotalCompactingKVs(other.getTotalCompactingKVs());
        }
        if (other.hasCurrentCompactedKVs()) {
          setCurrentCompactedKVs(other.getCurrentCompactedKVs());
        }
        if (other.hasRootIndexSizeKB()) {
          setRootIndexSizeKB(other.getRootIndexSizeKB());
        }
        if (other.hasTotalStaticIndexSizeKB()) {
          setTotalStaticIndexSizeKB(other.getTotalStaticIndexSizeKB());
        }
        if (other.hasTotalStaticBloomSizeKB()) {
          setTotalStaticBloomSizeKB(other.getTotalStaticBloomSizeKB());
        }
        if (other.hasCompleteSequenceId()) {
          setCompleteSequenceId(other.getCompleteSequenceId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegionSpecifier()) {
          
          return false;
        }
        if (!getRegionSpecifier().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier regionSpecifier = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier regionSpecifier_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionSpecifierBuilder_;
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      public boolean hasRegionSpecifier() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegionSpecifier() {
        if (regionSpecifierBuilder_ == null) {
          return regionSpecifier_;
        } else {
          return regionSpecifierBuilder_.getMessage();
        }
      }
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      public Builder setRegionSpecifier(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionSpecifierBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          regionSpecifier_ = value;
          onChanged();
        } else {
          regionSpecifierBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      public Builder setRegionSpecifier(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionSpecifierBuilder_ == null) {
          regionSpecifier_ = builderForValue.build();
          onChanged();
        } else {
          regionSpecifierBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      public Builder mergeRegionSpecifier(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionSpecifierBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              regionSpecifier_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            regionSpecifier_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(regionSpecifier_).mergeFrom(value).buildPartial();
          } else {
            regionSpecifier_ = value;
          }
          onChanged();
        } else {
          regionSpecifierBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      public Builder clearRegionSpecifier() {
        if (regionSpecifierBuilder_ == null) {
          regionSpecifier_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionSpecifierBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionSpecifierBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionSpecifierFieldBuilder().getBuilder();
      }
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionSpecifierOrBuilder() {
        if (regionSpecifierBuilder_ != null) {
          return regionSpecifierBuilder_.getMessageOrBuilder();
        } else {
          return regionSpecifier_;
        }
      }
      /**
       * <code>required .RegionSpecifier regionSpecifier = 1;</code>
       *
       * <pre>
       ** the region specifier 
       * </pre>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionSpecifierFieldBuilder() {
        if (regionSpecifierBuilder_ == null) {
          regionSpecifierBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  regionSpecifier_,
                  getParentForChildren(),
                  isClean());
          regionSpecifier_ = null;
        }
        return regionSpecifierBuilder_;
      }

      // optional uint32 stores = 2;
      private int stores_ ;
      /**
       * <code>optional uint32 stores = 2;</code>
       *
       * <pre>
       ** the number of stores for the region 
       * </pre>
       */
      public boolean hasStores() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional uint32 stores = 2;</code>
       *
       * <pre>
       ** the number of stores for the region 
       * </pre>
       */
      public int getStores() {
        return stores_;
      }
      /**
       * <code>optional uint32 stores = 2;</code>
       *
       * <pre>
       ** the number of stores for the region 
       * </pre>
       */
      public Builder setStores(int value) {
        bitField0_ |= 0x00000002;
        stores_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 stores = 2;</code>
       *
       * <pre>
       ** the number of stores for the region 
       * </pre>
       */
      public Builder clearStores() {
        bitField0_ = (bitField0_ & ~0x00000002);
        stores_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 storefiles = 3;
      private int storefiles_ ;
      /**
       * <code>optional uint32 storefiles = 3;</code>
       *
       * <pre>
       ** the number of storefiles for the region 
       * </pre>
       */
      public boolean hasStorefiles() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional uint32 storefiles = 3;</code>
       *
       * <pre>
       ** the number of storefiles for the region 
       * </pre>
       */
      public int getStorefiles() {
        return storefiles_;
      }
      /**
       * <code>optional uint32 storefiles = 3;</code>
       *
       * <pre>
       ** the number of storefiles for the region 
       * </pre>
       */
      public Builder setStorefiles(int value) {
        bitField0_ |= 0x00000004;
        storefiles_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 storefiles = 3;</code>
       *
       * <pre>
       ** the number of storefiles for the region 
       * </pre>
       */
      public Builder clearStorefiles() {
        bitField0_ = (bitField0_ & ~0x00000004);
        storefiles_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 storeUncompressedSizeMB = 4;
      private int storeUncompressedSizeMB_ ;
      /**
       * <code>optional uint32 storeUncompressedSizeMB = 4;</code>
       *
       * <pre>
       ** the total size of the store files for the region, uncompressed, in MB 
       * </pre>
       */
      public boolean hasStoreUncompressedSizeMB() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional uint32 storeUncompressedSizeMB = 4;</code>
       *
       * <pre>
       ** the total size of the store files for the region, uncompressed, in MB 
       * </pre>
       */
      public int getStoreUncompressedSizeMB() {
        return storeUncompressedSizeMB_;
      }
      /**
       * <code>optional uint32 storeUncompressedSizeMB = 4;</code>
       *
       * <pre>
       ** the total size of the store files for the region, uncompressed, in MB 
       * </pre>
       */
      public Builder setStoreUncompressedSizeMB(int value) {
        bitField0_ |= 0x00000008;
        storeUncompressedSizeMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 storeUncompressedSizeMB = 4;</code>
       *
       * <pre>
       ** the total size of the store files for the region, uncompressed, in MB 
       * </pre>
       */
      public Builder clearStoreUncompressedSizeMB() {
        bitField0_ = (bitField0_ & ~0x00000008);
        storeUncompressedSizeMB_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 storefileSizeMB = 5;
      private int storefileSizeMB_ ;
      /**
       * <code>optional uint32 storefileSizeMB = 5;</code>
       *
       * <pre>
       ** the current total size of the store files for the region, in MB 
       * </pre>
       */
      public boolean hasStorefileSizeMB() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional uint32 storefileSizeMB = 5;</code>
       *
       * <pre>
       ** the current total size of the store files for the region, in MB 
       * </pre>
       */
      public int getStorefileSizeMB() {
        return storefileSizeMB_;
      }
      /**
       * <code>optional uint32 storefileSizeMB = 5;</code>
       *
       * <pre>
       ** the current total size of the store files for the region, in MB 
       * </pre>
       */
      public Builder setStorefileSizeMB(int value) {
        bitField0_ |= 0x00000010;
        storefileSizeMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 storefileSizeMB = 5;</code>
       *
       * <pre>
       ** the current total size of the store files for the region, in MB 
       * </pre>
       */
      public Builder clearStorefileSizeMB() {
        bitField0_ = (bitField0_ & ~0x00000010);
        storefileSizeMB_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 memstoreSizeMB = 6;
      private int memstoreSizeMB_ ;
      /**
       * <code>optional uint32 memstoreSizeMB = 6;</code>
       *
       * <pre>
       ** the current size of the memstore for the region, in MB 
       * </pre>
       */
      public boolean hasMemstoreSizeMB() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional uint32 memstoreSizeMB = 6;</code>
       *
       * <pre>
       ** the current size of the memstore for the region, in MB 
       * </pre>
       */
      public int getMemstoreSizeMB() {
        return memstoreSizeMB_;
      }
      /**
       * <code>optional uint32 memstoreSizeMB = 6;</code>
       *
       * <pre>
       ** the current size of the memstore for the region, in MB 
       * </pre>
       */
      public Builder setMemstoreSizeMB(int value) {
        bitField0_ |= 0x00000020;
        memstoreSizeMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 memstoreSizeMB = 6;</code>
       *
       * <pre>
       ** the current size of the memstore for the region, in MB 
       * </pre>
       */
      public Builder clearMemstoreSizeMB() {
        bitField0_ = (bitField0_ & ~0x00000020);
        memstoreSizeMB_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 storefileIndexSizeMB = 7;
      private int storefileIndexSizeMB_ ;
      /**
       * <code>optional uint32 storefileIndexSizeMB = 7;</code>
       *
       * <pre>
       **
       * The current total size of root-level store file indexes for the region,
       * in MB. The same as {&#64;link #rootIndexSizeKB} but in MB.
       * </pre>
       */
      public boolean hasStorefileIndexSizeMB() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional uint32 storefileIndexSizeMB = 7;</code>
       *
       * <pre>
       **
       * The current total size of root-level store file indexes for the region,
       * in MB. The same as {&#64;link #rootIndexSizeKB} but in MB.
       * </pre>
       */
      public int getStorefileIndexSizeMB() {
        return storefileIndexSizeMB_;
      }
      /**
       * <code>optional uint32 storefileIndexSizeMB = 7;</code>
       *
       * <pre>
       **
       * The current total size of root-level store file indexes for the region,
       * in MB. The same as {&#64;link #rootIndexSizeKB} but in MB.
       * </pre>
       */
      public Builder setStorefileIndexSizeMB(int value) {
        bitField0_ |= 0x00000040;
        storefileIndexSizeMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 storefileIndexSizeMB = 7;</code>
       *
       * <pre>
       **
       * The current total size of root-level store file indexes for the region,
       * in MB. The same as {&#64;link #rootIndexSizeKB} but in MB.
       * </pre>
       */
      public Builder clearStorefileIndexSizeMB() {
        bitField0_ = (bitField0_ & ~0x00000040);
        storefileIndexSizeMB_ = 0;
        onChanged();
        return this;
      }

      // optional uint64 readRequestsCount = 8;
      private long readRequestsCount_ ;
      /**
       * <code>optional uint64 readRequestsCount = 8;</code>
       *
       * <pre>
       ** the current total read requests made to region 
       * </pre>
       */
      public boolean hasReadRequestsCount() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional uint64 readRequestsCount = 8;</code>
       *
       * <pre>
       ** the current total read requests made to region 
       * </pre>
       */
      public long getReadRequestsCount() {
        return readRequestsCount_;
      }
      /**
       * <code>optional uint64 readRequestsCount = 8;</code>
       *
       * <pre>
       ** the current total read requests made to region 
       * </pre>
       */
      public Builder setReadRequestsCount(long value) {
        bitField0_ |= 0x00000080;
        readRequestsCount_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 readRequestsCount = 8;</code>
       *
       * <pre>
       ** the current total read requests made to region 
       * </pre>
       */
      public Builder clearReadRequestsCount() {
        bitField0_ = (bitField0_ & ~0x00000080);
        readRequestsCount_ = 0L;
        onChanged();
        return this;
      }

      // optional uint64 writeRequestsCount = 9;
      private long writeRequestsCount_ ;
      /**
       * <code>optional uint64 writeRequestsCount = 9;</code>
       *
       * <pre>
       ** the current total write requests made to region 
       * </pre>
       */
      public boolean hasWriteRequestsCount() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional uint64 writeRequestsCount = 9;</code>
       *
       * <pre>
       ** the current total write requests made to region 
       * </pre>
       */
      public long getWriteRequestsCount() {
        return writeRequestsCount_;
      }
      /**
       * <code>optional uint64 writeRequestsCount = 9;</code>
       *
       * <pre>
       ** the current total write requests made to region 
       * </pre>
       */
      public Builder setWriteRequestsCount(long value) {
        bitField0_ |= 0x00000100;
        writeRequestsCount_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 writeRequestsCount = 9;</code>
       *
       * <pre>
       ** the current total write requests made to region 
       * </pre>
       */
      public Builder clearWriteRequestsCount() {
        bitField0_ = (bitField0_ & ~0x00000100);
        writeRequestsCount_ = 0L;
        onChanged();
        return this;
      }

      // optional uint64 totalCompactingKVs = 10;
      private long totalCompactingKVs_ ;
      /**
       * <code>optional uint64 totalCompactingKVs = 10;</code>
       *
       * <pre>
       ** the total compacting key values in currently running compaction 
       * </pre>
       */
      public boolean hasTotalCompactingKVs() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional uint64 totalCompactingKVs = 10;</code>
       *
       * <pre>
       ** the total compacting key values in currently running compaction 
       * </pre>
       */
      public long getTotalCompactingKVs() {
        return totalCompactingKVs_;
      }
      /**
       * <code>optional uint64 totalCompactingKVs = 10;</code>
       *
       * <pre>
       ** the total compacting key values in currently running compaction 
       * </pre>
       */
      public Builder setTotalCompactingKVs(long value) {
        bitField0_ |= 0x00000200;
        totalCompactingKVs_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 totalCompactingKVs = 10;</code>
       *
       * <pre>
       ** the total compacting key values in currently running compaction 
       * </pre>
       */
      public Builder clearTotalCompactingKVs() {
        bitField0_ = (bitField0_ & ~0x00000200);
        totalCompactingKVs_ = 0L;
        onChanged();
        return this;
      }

      // optional uint64 currentCompactedKVs = 11;
      private long currentCompactedKVs_ ;
      /**
       * <code>optional uint64 currentCompactedKVs = 11;</code>
       *
       * <pre>
       ** the completed count of key values in currently running compaction 
       * </pre>
       */
      public boolean hasCurrentCompactedKVs() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional uint64 currentCompactedKVs = 11;</code>
       *
       * <pre>
       ** the completed count of key values in currently running compaction 
       * </pre>
       */
      public long getCurrentCompactedKVs() {
        return currentCompactedKVs_;
      }
      /**
       * <code>optional uint64 currentCompactedKVs = 11;</code>
       *
       * <pre>
       ** the completed count of key values in currently running compaction 
       * </pre>
       */
      public Builder setCurrentCompactedKVs(long value) {
        bitField0_ |= 0x00000400;
        currentCompactedKVs_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 currentCompactedKVs = 11;</code>
       *
       * <pre>
       ** the completed count of key values in currently running compaction 
       * </pre>
       */
      public Builder clearCurrentCompactedKVs() {
        bitField0_ = (bitField0_ & ~0x00000400);
        currentCompactedKVs_ = 0L;
        onChanged();
        return this;
      }

      // optional uint32 rootIndexSizeKB = 12;
      private int rootIndexSizeKB_ ;
      /**
       * <code>optional uint32 rootIndexSizeKB = 12;</code>
       *
       * <pre>
       ** The current total size of root-level indexes for the region, in KB. 
       * </pre>
       */
      public boolean hasRootIndexSizeKB() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional uint32 rootIndexSizeKB = 12;</code>
       *
       * <pre>
       ** The current total size of root-level indexes for the region, in KB. 
       * </pre>
       */
      public int getRootIndexSizeKB() {
        return rootIndexSizeKB_;
      }
      /**
       * <code>optional uint32 rootIndexSizeKB = 12;</code>
       *
       * <pre>
       ** The current total size of root-level indexes for the region, in KB. 
       * </pre>
       */
      public Builder setRootIndexSizeKB(int value) {
        bitField0_ |= 0x00000800;
        rootIndexSizeKB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 rootIndexSizeKB = 12;</code>
       *
       * <pre>
       ** The current total size of root-level indexes for the region, in KB. 
       * </pre>
       */
      public Builder clearRootIndexSizeKB() {
        bitField0_ = (bitField0_ & ~0x00000800);
        rootIndexSizeKB_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 totalStaticIndexSizeKB = 13;
      private int totalStaticIndexSizeKB_ ;
      /**
       * <code>optional uint32 totalStaticIndexSizeKB = 13;</code>
       *
       * <pre>
       ** The total size of all index blocks, not just the root level, in KB. 
       * </pre>
       */
      public boolean hasTotalStaticIndexSizeKB() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional uint32 totalStaticIndexSizeKB = 13;</code>
       *
       * <pre>
       ** The total size of all index blocks, not just the root level, in KB. 
       * </pre>
       */
      public int getTotalStaticIndexSizeKB() {
        return totalStaticIndexSizeKB_;
      }
      /**
       * <code>optional uint32 totalStaticIndexSizeKB = 13;</code>
       *
       * <pre>
       ** The total size of all index blocks, not just the root level, in KB. 
       * </pre>
       */
      public Builder setTotalStaticIndexSizeKB(int value) {
        bitField0_ |= 0x00001000;
        totalStaticIndexSizeKB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 totalStaticIndexSizeKB = 13;</code>
       *
       * <pre>
       ** The total size of all index blocks, not just the root level, in KB. 
       * </pre>
       */
      public Builder clearTotalStaticIndexSizeKB() {
        bitField0_ = (bitField0_ & ~0x00001000);
        totalStaticIndexSizeKB_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 totalStaticBloomSizeKB = 14;
      private int totalStaticBloomSizeKB_ ;
      /**
       * <code>optional uint32 totalStaticBloomSizeKB = 14;</code>
       *
       * <pre>
       **
       * The total size of all Bloom filter blocks, not just loaded into the
       * block cache, in KB.
       * </pre>
       */
      public boolean hasTotalStaticBloomSizeKB() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional uint32 totalStaticBloomSizeKB = 14;</code>
       *
       * <pre>
       **
       * The total size of all Bloom filter blocks, not just loaded into the
       * block cache, in KB.
       * </pre>
       */
      public int getTotalStaticBloomSizeKB() {
        return totalStaticBloomSizeKB_;
      }
      /**
       * <code>optional uint32 totalStaticBloomSizeKB = 14;</code>
       *
       * <pre>
       **
       * The total size of all Bloom filter blocks, not just loaded into the
       * block cache, in KB.
       * </pre>
       */
      public Builder setTotalStaticBloomSizeKB(int value) {
        bitField0_ |= 0x00002000;
        totalStaticBloomSizeKB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 totalStaticBloomSizeKB = 14;</code>
       *
       * <pre>
       **
       * The total size of all Bloom filter blocks, not just loaded into the
       * block cache, in KB.
       * </pre>
       */
      public Builder clearTotalStaticBloomSizeKB() {
        bitField0_ = (bitField0_ & ~0x00002000);
        totalStaticBloomSizeKB_ = 0;
        onChanged();
        return this;
      }

      // optional uint64 completeSequenceId = 15;
      private long completeSequenceId_ ;
      /**
       * <code>optional uint64 completeSequenceId = 15;</code>
       *
       * <pre>
       ** the most recent sequence Id from cache flush 
       * </pre>
       */
      public boolean hasCompleteSequenceId() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      /**
       * <code>optional uint64 completeSequenceId = 15;</code>
       *
       * <pre>
       ** the most recent sequence Id from cache flush 
       * </pre>
       */
      public long getCompleteSequenceId() {
        return completeSequenceId_;
      }
      /**
       * <code>optional uint64 completeSequenceId = 15;</code>
       *
       * <pre>
       ** the most recent sequence Id from cache flush 
       * </pre>
       */
      public Builder setCompleteSequenceId(long value) {
        bitField0_ |= 0x00004000;
        completeSequenceId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 completeSequenceId = 15;</code>
       *
       * <pre>
       ** the most recent sequence Id from cache flush 
       * </pre>
       */
      public Builder clearCompleteSequenceId() {
        bitField0_ = (bitField0_ & ~0x00004000);
        completeSequenceId_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:RegionLoad)
    }

    static {
      defaultInstance = new RegionLoad(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:RegionLoad)
  }

  public interface ServerLoadOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional uint32 numberOfRequests = 1;
    /**
     * <code>optional uint32 numberOfRequests = 1;</code>
     *
     * <pre>
     ** Number of requests since last report. 
     * </pre>
     */
    boolean hasNumberOfRequests();
    /**
     * <code>optional uint32 numberOfRequests = 1;</code>
     *
     * <pre>
     ** Number of requests since last report. 
     * </pre>
     */
    int getNumberOfRequests();

    // optional uint32 totalNumberOfRequests = 2;
    /**
     * <code>optional uint32 totalNumberOfRequests = 2;</code>
     *
     * <pre>
     ** Total Number of requests from the start of the region server. 
     * </pre>
     */
    boolean hasTotalNumberOfRequests();
    /**
     * <code>optional uint32 totalNumberOfRequests = 2;</code>
     *
     * <pre>
     ** Total Number of requests from the start of the region server. 
     * </pre>
     */
    int getTotalNumberOfRequests();

    // optional uint32 usedHeapMB = 3;
    /**
     * <code>optional uint32 usedHeapMB = 3;</code>
     *
     * <pre>
     ** the amount of used heap, in MB. 
     * </pre>
     */
    boolean hasUsedHeapMB();
    /**
     * <code>optional uint32 usedHeapMB = 3;</code>
     *
     * <pre>
     ** the amount of used heap, in MB. 
     * </pre>
     */
    int getUsedHeapMB();

    // optional uint32 maxHeapMB = 4;
    /**
     * <code>optional uint32 maxHeapMB = 4;</code>
     *
     * <pre>
     ** the maximum allowable size of the heap, in MB. 
     * </pre>
     */
    boolean hasMaxHeapMB();
    /**
     * <code>optional uint32 maxHeapMB = 4;</code>
     *
     * <pre>
     ** the maximum allowable size of the heap, in MB. 
     * </pre>
     */
    int getMaxHeapMB();

    // repeated .RegionLoad regionLoads = 5;
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad> 
        getRegionLoadsList();
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad getRegionLoads(int index);
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    int getRegionLoadsCount();
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder> 
        getRegionLoadsOrBuilderList();
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
        int index);

    // repeated .Coprocessor coprocessors = 6;
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> 
        getCoprocessorsList();
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getCoprocessors(int index);
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    int getCoprocessorsCount();
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
        getCoprocessorsOrBuilderList();
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getCoprocessorsOrBuilder(
        int index);

    // optional uint64 reportStartTime = 7;
    /**
     * <code>optional uint64 reportStartTime = 7;</code>
     *
     * <pre>
     **
     * Time when incremental (non-total) counts began being calculated (e.g. numberOfRequests)
     * time is measured as the difference, measured in milliseconds, between the current time
     * and midnight, January 1, 1970 UTC.
     * </pre>
     */
    boolean hasReportStartTime();
    /**
     * <code>optional uint64 reportStartTime = 7;</code>
     *
     * <pre>
     **
     * Time when incremental (non-total) counts began being calculated (e.g. numberOfRequests)
     * time is measured as the difference, measured in milliseconds, between the current time
     * and midnight, January 1, 1970 UTC.
     * </pre>
     */
    long getReportStartTime();

    // optional uint64 reportEndTime = 8;
    /**
     * <code>optional uint64 reportEndTime = 8;</code>
     *
     * <pre>
     **
     * Time when report was generated.
     * time is measured as the difference, measured in milliseconds, between the current time
     * and midnight, January 1, 1970 UTC.
     * </pre>
     */
    boolean hasReportEndTime();
    /**
     * <code>optional uint64 reportEndTime = 8;</code>
     *
     * <pre>
     **
     * Time when report was generated.
     * time is measured as the difference, measured in milliseconds, between the current time
     * and midnight, January 1, 1970 UTC.
     * </pre>
     */
    long getReportEndTime();

    // optional uint32 infoServerPort = 9;
    /**
     * <code>optional uint32 infoServerPort = 9;</code>
     *
     * <pre>
     **
     * The port number that this region server is hosing an info server on.
     * </pre>
     */
    boolean hasInfoServerPort();
    /**
     * <code>optional uint32 infoServerPort = 9;</code>
     *
     * <pre>
     **
     * The port number that this region server is hosing an info server on.
     * </pre>
     */
    int getInfoServerPort();
  }
  /**
   * Protobuf type {@code ServerLoad}
   */
  public static final class ServerLoad extends
      com.google.protobuf.GeneratedMessage
      implements ServerLoadOrBuilder {
    // Use ServerLoad.newBuilder() to construct.
    private ServerLoad(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ServerLoad(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ServerLoad defaultInstance;
    public static ServerLoad getDefaultInstance() {
      return defaultInstance;
    }

    public ServerLoad getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ServerLoad(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numberOfRequests_ = input.readUInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              totalNumberOfRequests_ = input.readUInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              usedHeapMB_ = input.readUInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              maxHeapMB_ = input.readUInt32();
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                regionLoads_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad>();
                mutable_bitField0_ |= 0x00000010;
              }
              regionLoads_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.PARSER, extensionRegistry));
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                coprocessors_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor>();
                mutable_bitField0_ |= 0x00000020;
              }
              coprocessors_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.PARSER, extensionRegistry));
              break;
            }
            case 56: {
              bitField0_ |= 0x00000010;
              reportStartTime_ = input.readUInt64();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000020;
              reportEndTime_ = input.readUInt64();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000040;
              infoServerPort_ = input.readUInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          regionLoads_ = java.util.Collections.unmodifiableList(regionLoads_);
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          coprocessors_ = java.util.Collections.unmodifiableList(coprocessors_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerLoad_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerLoad_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad.Builder.class);
    }

    public static com.google.protobuf.Parser<ServerLoad> PARSER =
        new com.google.protobuf.AbstractParser<ServerLoad>() {
      public ServerLoad parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ServerLoad(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ServerLoad> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional uint32 numberOfRequests = 1;
    public static final int NUMBEROFREQUESTS_FIELD_NUMBER = 1;
    private int numberOfRequests_;
    /**
     * <code>optional uint32 numberOfRequests = 1;</code>
     *
     * <pre>
     ** Number of requests since last report. 
     * </pre>
     */
    public boolean hasNumberOfRequests() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional uint32 numberOfRequests = 1;</code>
     *
     * <pre>
     ** Number of requests since last report. 
     * </pre>
     */
    public int getNumberOfRequests() {
      return numberOfRequests_;
    }

    // optional uint32 totalNumberOfRequests = 2;
    public static final int TOTALNUMBEROFREQUESTS_FIELD_NUMBER = 2;
    private int totalNumberOfRequests_;
    /**
     * <code>optional uint32 totalNumberOfRequests = 2;</code>
     *
     * <pre>
     ** Total Number of requests from the start of the region server. 
     * </pre>
     */
    public boolean hasTotalNumberOfRequests() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional uint32 totalNumberOfRequests = 2;</code>
     *
     * <pre>
     ** Total Number of requests from the start of the region server. 
     * </pre>
     */
    public int getTotalNumberOfRequests() {
      return totalNumberOfRequests_;
    }

    // optional uint32 usedHeapMB = 3;
    public static final int USEDHEAPMB_FIELD_NUMBER = 3;
    private int usedHeapMB_;
    /**
     * <code>optional uint32 usedHeapMB = 3;</code>
     *
     * <pre>
     ** the amount of used heap, in MB. 
     * </pre>
     */
    public boolean hasUsedHeapMB() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional uint32 usedHeapMB = 3;</code>
     *
     * <pre>
     ** the amount of used heap, in MB. 
     * </pre>
     */
    public int getUsedHeapMB() {
      return usedHeapMB_;
    }

    // optional uint32 maxHeapMB = 4;
    public static final int MAXHEAPMB_FIELD_NUMBER = 4;
    private int maxHeapMB_;
    /**
     * <code>optional uint32 maxHeapMB = 4;</code>
     *
     * <pre>
     ** the maximum allowable size of the heap, in MB. 
     * </pre>
     */
    public boolean hasMaxHeapMB() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional uint32 maxHeapMB = 4;</code>
     *
     * <pre>
     ** the maximum allowable size of the heap, in MB. 
     * </pre>
     */
    public int getMaxHeapMB() {
      return maxHeapMB_;
    }

    // repeated .RegionLoad regionLoads = 5;
    public static final int REGIONLOADS_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad> regionLoads_;
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad> getRegionLoadsList() {
      return regionLoads_;
    }
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder> 
        getRegionLoadsOrBuilderList() {
      return regionLoads_;
    }
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    public int getRegionLoadsCount() {
      return regionLoads_.size();
    }
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad getRegionLoads(int index) {
      return regionLoads_.get(index);
    }
    /**
     * <code>repeated .RegionLoad regionLoads = 5;</code>
     *
     * <pre>
     ** Information on the load of individual regions. 
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
        int index) {
      return regionLoads_.get(index);
    }

    // repeated .Coprocessor coprocessors = 6;
    public static final int COPROCESSORS_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> coprocessors_;
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> getCoprocessorsList() {
      return coprocessors_;
    }
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
        getCoprocessorsOrBuilderList() {
      return coprocessors_;
    }
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    public int getCoprocessorsCount() {
      return coprocessors_.size();
    }
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getCoprocessors(int index) {
      return coprocessors_.get(index);
    }
    /**
     * <code>repeated .Coprocessor coprocessors = 6;</code>
     *
     * <pre>
     **
     * Regionserver-level coprocessors, e.g., WALObserver implementations.
     * Region-level coprocessors, on the other hand, are stored inside RegionLoad
     * objects.
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getCoprocessorsOrBuilder(
        int index) {
      return coprocessors_.get(index);
    }

    // optional uint64 reportStartTime = 7;
    public static final int REPORTSTARTTIME_FIELD_NUMBER = 7;
    private long reportStartTime_;
    /**
     * <code>optional uint64 reportStartTime = 7;</code>
     *
     * <pre>
     **
     * Time when incremental (non-total) counts began being calculated (e.g. numberOfRequests)
     * time is measured as the difference, measured in milliseconds, between the current time
     * and midnight, January 1, 1970 UTC.
     * </pre>
     */
    public boolean hasReportStartTime() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional uint64 reportStartTime = 7;</code>
     *
     * <pre>
     **
     * Time when incremental (non-total) counts began being calculated (e.g. numberOfRequests)
     * time is measured as the difference, measured in milliseconds, between the current time
     * and midnight, January 1, 1970 UTC.
     * </pre>
     */
    public long getReportStartTime() {
      return reportStartTime_;
    }

    // optional uint64 reportEndTime = 8;
    public static final int REPORTENDTIME_FIELD_NUMBER = 8;
    private long reportEndTime_;
    /**
     * <code>optional uint64 reportEndTime = 8;</code>
     *
     * <pre>
     **
     * Time when report was generated.
     * time is measured as the difference, measured in milliseconds, between the current time
     * and midnight, January 1, 1970 UTC.
     * </pre>
     */
    public boolean hasReportEndTime() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional uint64 reportEndTime = 8;</code>
     *
     * <pre>
     **
     * Time when report was generated.
     * time is measured as the difference, measured in milliseconds, between the current time
     * and midnight, January 1, 1970 UTC.
     * </pre>
     */
    public long getReportEndTime() {
      return reportEndTime_;
    }

    // optional uint32 infoServerPort = 9;
    public static final int INFOSERVERPORT_FIELD_NUMBER = 9;
    private int infoServerPort_;
    /**
     * <code>optional uint32 infoServerPort = 9;</code>
     *
     * <pre>
     **
     * The port number that this region server is hosing an info server on.
     * </pre>
     */
    public boolean hasInfoServerPort() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional uint32 infoServerPort = 9;</code>
     *
     * <pre>
     **
     * The port number that this region server is hosing an info server on.
     * </pre>
     */
    public int getInfoServerPort() {
      return infoServerPort_;
    }

    private void initFields() {
      numberOfRequests_ = 0;
      totalNumberOfRequests_ = 0;
      usedHeapMB_ = 0;
      maxHeapMB_ = 0;
      regionLoads_ = java.util.Collections.emptyList();
      coprocessors_ = java.util.Collections.emptyList();
      reportStartTime_ = 0L;
      reportEndTime_ = 0L;
      infoServerPort_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getRegionLoadsCount(); i++) {
        if (!getRegionLoads(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getCoprocessorsCount(); i++) {
        if (!getCoprocessors(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt32(1, numberOfRequests_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt32(2, totalNumberOfRequests_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt32(3, usedHeapMB_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(4, maxHeapMB_);
      }
      for (int i = 0; i < regionLoads_.size(); i++) {
        output.writeMessage(5, regionLoads_.get(i));
      }
      for (int i = 0; i < coprocessors_.size(); i++) {
        output.writeMessage(6, coprocessors_.get(i));
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeUInt64(7, reportStartTime_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeUInt64(8, reportEndTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeUInt32(9, infoServerPort_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(1, numberOfRequests_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, totalNumberOfRequests_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(3, usedHeapMB_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, maxHeapMB_);
      }
      for (int i = 0; i < regionLoads_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, regionLoads_.get(i));
      }
      for (int i = 0; i < coprocessors_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, coprocessors_.get(i));
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(7, reportStartTime_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(8, reportEndTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(9, infoServerPort_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad) obj;

      boolean result = true;
      result = result && (hasNumberOfRequests() == other.hasNumberOfRequests());
      if (hasNumberOfRequests()) {
        result = result && (getNumberOfRequests()
            == other.getNumberOfRequests());
      }
      result = result && (hasTotalNumberOfRequests() == other.hasTotalNumberOfRequests());
      if (hasTotalNumberOfRequests()) {
        result = result && (getTotalNumberOfRequests()
            == other.getTotalNumberOfRequests());
      }
      result = result && (hasUsedHeapMB() == other.hasUsedHeapMB());
      if (hasUsedHeapMB()) {
        result = result && (getUsedHeapMB()
            == other.getUsedHeapMB());
      }
      result = result && (hasMaxHeapMB() == other.hasMaxHeapMB());
      if (hasMaxHeapMB()) {
        result = result && (getMaxHeapMB()
            == other.getMaxHeapMB());
      }
      result = result && getRegionLoadsList()
          .equals(other.getRegionLoadsList());
      result = result && getCoprocessorsList()
          .equals(other.getCoprocessorsList());
      result = result && (hasReportStartTime() == other.hasReportStartTime());
      if (hasReportStartTime()) {
        result = result && (getReportStartTime()
            == other.getReportStartTime());
      }
      result = result && (hasReportEndTime() == other.hasReportEndTime());
      if (hasReportEndTime()) {
        result = result && (getReportEndTime()
            == other.getReportEndTime());
      }
      result = result && (hasInfoServerPort() == other.hasInfoServerPort());
      if (hasInfoServerPort()) {
        result = result && (getInfoServerPort()
            == other.getInfoServerPort());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNumberOfRequests()) {
        hash = (37 * hash) + NUMBEROFREQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getNumberOfRequests();
      }
      if (hasTotalNumberOfRequests()) {
        hash = (37 * hash) + TOTALNUMBEROFREQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getTotalNumberOfRequests();
      }
      if (hasUsedHeapMB()) {
        hash = (37 * hash) + USEDHEAPMB_FIELD_NUMBER;
        hash = (53 * hash) + getUsedHeapMB();
      }
      if (hasMaxHeapMB()) {
        hash = (37 * hash) + MAXHEAPMB_FIELD_NUMBER;
        hash = (53 * hash) + getMaxHeapMB();
      }
      if (getRegionLoadsCount() > 0) {
        hash = (37 * hash) + REGIONLOADS_FIELD_NUMBER;
        hash = (53 * hash) + getRegionLoadsList().hashCode();
      }
      if (getCoprocessorsCount() > 0) {
        hash = (37 * hash) + COPROCESSORS_FIELD_NUMBER;
        hash = (53 * hash) + getCoprocessorsList().hashCode();
      }
      if (hasReportStartTime()) {
        hash = (37 * hash) + REPORTSTARTTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReportStartTime());
      }
      if (hasReportEndTime()) {
        hash = (37 * hash) + REPORTENDTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getReportEndTime());
      }
      if (hasInfoServerPort()) {
        hash = (37 * hash) + INFOSERVERPORT_FIELD_NUMBER;
        hash = (53 * hash) + getInfoServerPort();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code ServerLoad}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoadOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerLoad_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerLoad_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionLoadsFieldBuilder();
          getCoprocessorsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        numberOfRequests_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        totalNumberOfRequests_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        usedHeapMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        maxHeapMB_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (regionLoadsBuilder_ == null) {
          regionLoads_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          regionLoadsBuilder_.clear();
        }
        if (coprocessorsBuilder_ == null) {
          coprocessors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          coprocessorsBuilder_.clear();
        }
        reportStartTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        reportEndTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000080);
        infoServerPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerLoad_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numberOfRequests_ = numberOfRequests_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.totalNumberOfRequests_ = totalNumberOfRequests_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.usedHeapMB_ = usedHeapMB_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.maxHeapMB_ = maxHeapMB_;
        if (regionLoadsBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            regionLoads_ = java.util.Collections.unmodifiableList(regionLoads_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.regionLoads_ = regionLoads_;
        } else {
          result.regionLoads_ = regionLoadsBuilder_.build();
        }
        if (coprocessorsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            coprocessors_ = java.util.Collections.unmodifiableList(coprocessors_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.coprocessors_ = coprocessors_;
        } else {
          result.coprocessors_ = coprocessorsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        result.reportStartTime_ = reportStartTime_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        result.reportEndTime_ = reportEndTime_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000040;
        }
        result.infoServerPort_ = infoServerPort_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad.getDefaultInstance()) return this;
        if (other.hasNumberOfRequests()) {
          setNumberOfRequests(other.getNumberOfRequests());
        }
        if (other.hasTotalNumberOfRequests()) {
          setTotalNumberOfRequests(other.getTotalNumberOfRequests());
        }
        if (other.hasUsedHeapMB()) {
          setUsedHeapMB(other.getUsedHeapMB());
        }
        if (other.hasMaxHeapMB()) {
          setMaxHeapMB(other.getMaxHeapMB());
        }
        if (regionLoadsBuilder_ == null) {
          if (!other.regionLoads_.isEmpty()) {
            if (regionLoads_.isEmpty()) {
              regionLoads_ = other.regionLoads_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureRegionLoadsIsMutable();
              regionLoads_.addAll(other.regionLoads_);
            }
            onChanged();
          }
        } else {
          if (!other.regionLoads_.isEmpty()) {
            if (regionLoadsBuilder_.isEmpty()) {
              regionLoadsBuilder_.dispose();
              regionLoadsBuilder_ = null;
              regionLoads_ = other.regionLoads_;
              bitField0_ = (bitField0_ & ~0x00000010);
              regionLoadsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getRegionLoadsFieldBuilder() : null;
            } else {
              regionLoadsBuilder_.addAllMessages(other.regionLoads_);
            }
          }
        }
        if (coprocessorsBuilder_ == null) {
          if (!other.coprocessors_.isEmpty()) {
            if (coprocessors_.isEmpty()) {
              coprocessors_ = other.coprocessors_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureCoprocessorsIsMutable();
              coprocessors_.addAll(other.coprocessors_);
            }
            onChanged();
          }
        } else {
          if (!other.coprocessors_.isEmpty()) {
            if (coprocessorsBuilder_.isEmpty()) {
              coprocessorsBuilder_.dispose();
              coprocessorsBuilder_ = null;
              coprocessors_ = other.coprocessors_;
              bitField0_ = (bitField0_ & ~0x00000020);
              coprocessorsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getCoprocessorsFieldBuilder() : null;
            } else {
              coprocessorsBuilder_.addAllMessages(other.coprocessors_);
            }
          }
        }
        if (other.hasReportStartTime()) {
          setReportStartTime(other.getReportStartTime());
        }
        if (other.hasReportEndTime()) {
          setReportEndTime(other.getReportEndTime());
        }
        if (other.hasInfoServerPort()) {
          setInfoServerPort(other.getInfoServerPort());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getRegionLoadsCount(); i++) {
          if (!getRegionLoads(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getCoprocessorsCount(); i++) {
          if (!getCoprocessors(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerLoad) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional uint32 numberOfRequests = 1;
      private int numberOfRequests_ ;
      /**
       * <code>optional uint32 numberOfRequests = 1;</code>
       *
       * <pre>
       ** Number of requests since last report. 
       * </pre>
       */
      public boolean hasNumberOfRequests() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional uint32 numberOfRequests = 1;</code>
       *
       * <pre>
       ** Number of requests since last report. 
       * </pre>
       */
      public int getNumberOfRequests() {
        return numberOfRequests_;
      }
      /**
       * <code>optional uint32 numberOfRequests = 1;</code>
       *
       * <pre>
       ** Number of requests since last report. 
       * </pre>
       */
      public Builder setNumberOfRequests(int value) {
        bitField0_ |= 0x00000001;
        numberOfRequests_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 numberOfRequests = 1;</code>
       *
       * <pre>
       ** Number of requests since last report. 
       * </pre>
       */
      public Builder clearNumberOfRequests() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numberOfRequests_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 totalNumberOfRequests = 2;
      private int totalNumberOfRequests_ ;
      /**
       * <code>optional uint32 totalNumberOfRequests = 2;</code>
       *
       * <pre>
       ** Total Number of requests from the start of the region server. 
       * </pre>
       */
      public boolean hasTotalNumberOfRequests() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional uint32 totalNumberOfRequests = 2;</code>
       *
       * <pre>
       ** Total Number of requests from the start of the region server. 
       * </pre>
       */
      public int getTotalNumberOfRequests() {
        return totalNumberOfRequests_;
      }
      /**
       * <code>optional uint32 totalNumberOfRequests = 2;</code>
       *
       * <pre>
       ** Total Number of requests from the start of the region server. 
       * </pre>
       */
      public Builder setTotalNumberOfRequests(int value) {
        bitField0_ |= 0x00000002;
        totalNumberOfRequests_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 totalNumberOfRequests = 2;</code>
       *
       * <pre>
       ** Total Number of requests from the start of the region server. 
       * </pre>
       */
      public Builder clearTotalNumberOfRequests() {
        bitField0_ = (bitField0_ & ~0x00000002);
        totalNumberOfRequests_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 usedHeapMB = 3;
      private int usedHeapMB_ ;
      /**
       * <code>optional uint32 usedHeapMB = 3;</code>
       *
       * <pre>
       ** the amount of used heap, in MB. 
       * </pre>
       */
      public boolean hasUsedHeapMB() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional uint32 usedHeapMB = 3;</code>
       *
       * <pre>
       ** the amount of used heap, in MB. 
       * </pre>
       */
      public int getUsedHeapMB() {
        return usedHeapMB_;
      }
      /**
       * <code>optional uint32 usedHeapMB = 3;</code>
       *
       * <pre>
       ** the amount of used heap, in MB. 
       * </pre>
       */
      public Builder setUsedHeapMB(int value) {
        bitField0_ |= 0x00000004;
        usedHeapMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 usedHeapMB = 3;</code>
       *
       * <pre>
       ** the amount of used heap, in MB. 
       * </pre>
       */
      public Builder clearUsedHeapMB() {
        bitField0_ = (bitField0_ & ~0x00000004);
        usedHeapMB_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 maxHeapMB = 4;
      private int maxHeapMB_ ;
      /**
       * <code>optional uint32 maxHeapMB = 4;</code>
       *
       * <pre>
       ** the maximum allowable size of the heap, in MB. 
       * </pre>
       */
      public boolean hasMaxHeapMB() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional uint32 maxHeapMB = 4;</code>
       *
       * <pre>
       ** the maximum allowable size of the heap, in MB. 
       * </pre>
       */
      public int getMaxHeapMB() {
        return maxHeapMB_;
      }
      /**
       * <code>optional uint32 maxHeapMB = 4;</code>
       *
       * <pre>
       ** the maximum allowable size of the heap, in MB. 
       * </pre>
       */
      public Builder setMaxHeapMB(int value) {
        bitField0_ |= 0x00000008;
        maxHeapMB_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 maxHeapMB = 4;</code>
       *
       * <pre>
       ** the maximum allowable size of the heap, in MB. 
       * </pre>
       */
      public Builder clearMaxHeapMB() {
        bitField0_ = (bitField0_ & ~0x00000008);
        maxHeapMB_ = 0;
        onChanged();
        return this;
      }

      // repeated .RegionLoad regionLoads = 5;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad> regionLoads_ =
        java.util.Collections.emptyList();
      private void ensureRegionLoadsIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          regionLoads_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad>(regionLoads_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder> regionLoadsBuilder_;

      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad> getRegionLoadsList() {
        if (regionLoadsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(regionLoads_);
        } else {
          return regionLoadsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public int getRegionLoadsCount() {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.size();
        } else {
          return regionLoadsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad getRegionLoads(int index) {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.get(index);
        } else {
          return regionLoadsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder setRegionLoads(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.set(index, value);
          onChanged();
        } else {
          regionLoadsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder setRegionLoads(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.set(index, builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder addRegionLoads(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.add(value);
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder addRegionLoads(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad value) {
        if (regionLoadsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureRegionLoadsIsMutable();
          regionLoads_.add(index, value);
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder addRegionLoads(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.add(builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder addRegionLoads(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder builderForValue) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.add(index, builderForValue.build());
          onChanged();
        } else {
          regionLoadsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder addAllRegionLoads(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad> values) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          super.addAll(values, regionLoads_);
          onChanged();
        } else {
          regionLoadsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder clearRegionLoads() {
        if (regionLoadsBuilder_ == null) {
          regionLoads_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          regionLoadsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public Builder removeRegionLoads(int index) {
        if (regionLoadsBuilder_ == null) {
          ensureRegionLoadsIsMutable();
          regionLoads_.remove(index);
          onChanged();
        } else {
          regionLoadsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder getRegionLoadsBuilder(
          int index) {
        return getRegionLoadsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder getRegionLoadsOrBuilder(
          int index) {
        if (regionLoadsBuilder_ == null) {
          return regionLoads_.get(index);  } else {
          return regionLoadsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder> 
           getRegionLoadsOrBuilderList() {
        if (regionLoadsBuilder_ != null) {
          return regionLoadsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(regionLoads_);
        }
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder addRegionLoadsBuilder() {
        return getRegionLoadsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.getDefaultInstance());
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder addRegionLoadsBuilder(
          int index) {
        return getRegionLoadsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.getDefaultInstance());
      }
      /**
       * <code>repeated .RegionLoad regionLoads = 5;</code>
       *
       * <pre>
       ** Information on the load of individual regions. 
       * </pre>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder> 
           getRegionLoadsBuilderList() {
        return getRegionLoadsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder> 
          getRegionLoadsFieldBuilder() {
        if (regionLoadsBuilder_ == null) {
          regionLoadsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoad.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionLoadOrBuilder>(
                  regionLoads_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          regionLoads_ = null;
        }
        return regionLoadsBuilder_;
      }

      // repeated .Coprocessor coprocessors = 6;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> coprocessors_ =
        java.util.Collections.emptyList();
      private void ensureCoprocessorsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          coprocessors_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor>(coprocessors_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> coprocessorsBuilder_;

      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> getCoprocessorsList() {
        if (coprocessorsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(coprocessors_);
        } else {
          return coprocessorsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public int getCoprocessorsCount() {
        if (coprocessorsBuilder_ == null) {
          return coprocessors_.size();
        } else {
          return coprocessorsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getCoprocessors(int index) {
        if (coprocessorsBuilder_ == null) {
          return coprocessors_.get(index);
        } else {
          return coprocessorsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder setCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (coprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCoprocessorsIsMutable();
          coprocessors_.set(index, value);
          onChanged();
        } else {
          coprocessorsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder setCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          coprocessors_.set(index, builderForValue.build());
          onChanged();
        } else {
          coprocessorsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder addCoprocessors(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (coprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCoprocessorsIsMutable();
          coprocessors_.add(value);
          onChanged();
        } else {
          coprocessorsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder addCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor value) {
        if (coprocessorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCoprocessorsIsMutable();
          coprocessors_.add(index, value);
          onChanged();
        } else {
          coprocessorsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder addCoprocessors(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          coprocessors_.add(builderForValue.build());
          onChanged();
        } else {
          coprocessorsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder addCoprocessors(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder builderForValue) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          coprocessors_.add(index, builderForValue.build());
          onChanged();
        } else {
          coprocessorsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder addAllCoprocessors(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor> values) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          super.addAll(values, coprocessors_);
          onChanged();
        } else {
          coprocessorsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder clearCoprocessors() {
        if (coprocessorsBuilder_ == null) {
          coprocessors_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          coprocessorsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public Builder removeCoprocessors(int index) {
        if (coprocessorsBuilder_ == null) {
          ensureCoprocessorsIsMutable();
          coprocessors_.remove(index);
          onChanged();
        } else {
          coprocessorsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder getCoprocessorsBuilder(
          int index) {
        return getCoprocessorsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder getCoprocessorsOrBuilder(
          int index) {
        if (coprocessorsBuilder_ == null) {
          return coprocessors_.get(index);  } else {
          return coprocessorsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
           getCoprocessorsOrBuilderList() {
        if (coprocessorsBuilder_ != null) {
          return coprocessorsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(coprocessors_);
        }
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder addCoprocessorsBuilder() {
        return getCoprocessorsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.getDefaultInstance());
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder addCoprocessorsBuilder(
          int index) {
        return getCoprocessorsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.getDefaultInstance());
      }
      /**
       * <code>repeated .Coprocessor coprocessors = 6;</code>
       *
       * <pre>
       **
       * Regionserver-level coprocessors, e.g., WALObserver implementations.
       * Region-level coprocessors, on the other hand, are stored inside RegionLoad
       * objects.
       * </pre>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder> 
           getCoprocessorsBuilderList() {
        return getCoprocessorsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder> 
          getCoprocessorsFieldBuilder() {
        if (coprocessorsBuilder_ == null) {
          coprocessorsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder>(
                  coprocessors_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          coprocessors_ = null;
        }
        return coprocessorsBuilder_;
      }

      // optional uint64 reportStartTime = 7;
      private long reportStartTime_ ;
      /**
       * <code>optional uint64 reportStartTime = 7;</code>
       *
       * <pre>
       **
       * Time when incremental (non-total) counts began being calculated (e.g. numberOfRequests)
       * time is measured as the difference, measured in milliseconds, between the current time
       * and midnight, January 1, 1970 UTC.
       * </pre>
       */
      public boolean hasReportStartTime() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional uint64 reportStartTime = 7;</code>
       *
       * <pre>
       **
       * Time when incremental (non-total) counts began being calculated (e.g. numberOfRequests)
       * time is measured as the difference, measured in milliseconds, between the current time
       * and midnight, January 1, 1970 UTC.
       * </pre>
       */
      public long getReportStartTime() {
        return reportStartTime_;
      }
      /**
       * <code>optional uint64 reportStartTime = 7;</code>
       *
       * <pre>
       **
       * Time when incremental (non-total) counts began being calculated (e.g. numberOfRequests)
       * time is measured as the difference, measured in milliseconds, between the current time
       * and midnight, January 1, 1970 UTC.
       * </pre>
       */
      public Builder setReportStartTime(long value) {
        bitField0_ |= 0x00000040;
        reportStartTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 reportStartTime = 7;</code>
       *
       * <pre>
       **
       * Time when incremental (non-total) counts began being calculated (e.g. numberOfRequests)
       * time is measured as the difference, measured in milliseconds, between the current time
       * and midnight, January 1, 1970 UTC.
       * </pre>
       */
      public Builder clearReportStartTime() {
        bitField0_ = (bitField0_ & ~0x00000040);
        reportStartTime_ = 0L;
        onChanged();
        return this;
      }

      // optional uint64 reportEndTime = 8;
      private long reportEndTime_ ;
      /**
       * <code>optional uint64 reportEndTime = 8;</code>
       *
       * <pre>
       **
       * Time when report was generated.
       * time is measured as the difference, measured in milliseconds, between the current time
       * and midnight, January 1, 1970 UTC.
       * </pre>
       */
      public boolean hasReportEndTime() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional uint64 reportEndTime = 8;</code>
       *
       * <pre>
       **
       * Time when report was generated.
       * time is measured as the difference, measured in milliseconds, between the current time
       * and midnight, January 1, 1970 UTC.
       * </pre>
       */
      public long getReportEndTime() {
        return reportEndTime_;
      }
      /**
       * <code>optional uint64 reportEndTime = 8;</code>
       *
       * <pre>
       **
       * Time when report was generated.
       * time is measured as the difference, measured in milliseconds, between the current time
       * and midnight, January 1, 1970 UTC.
       * </pre>
       */
      public Builder setReportEndTime(long value) {
        bitField0_ |= 0x00000080;
        reportEndTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 reportEndTime = 8;</code>
       *
       * <pre>
       **
       * Time when report was generated.
       * time is measured as the difference, measured in milliseconds, between the current time
       * and midnight, January 1, 1970 UTC.
       * </pre>
       */
      public Builder clearReportEndTime() {
        bitField0_ = (bitField0_ & ~0x00000080);
        reportEndTime_ = 0L;
        onChanged();
        return this;
      }

      // optional uint32 infoServerPort = 9;
      private int infoServerPort_ ;
      /**
       * <code>optional uint32 infoServerPort = 9;</code>
       *
       * <pre>
       **
       * The port number that this region server is hosing an info server on.
       * </pre>
       */
      public boolean hasInfoServerPort() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional uint32 infoServerPort = 9;</code>
       *
       * <pre>
       **
       * The port number that this region server is hosing an info server on.
       * </pre>
       */
      public int getInfoServerPort() {
        return infoServerPort_;
      }
      /**
       * <code>optional uint32 infoServerPort = 9;</code>
       *
       * <pre>
       **
       * The port number that this region server is hosing an info server on.
       * </pre>
       */
      public Builder setInfoServerPort(int value) {
        bitField0_ |= 0x00000100;
        infoServerPort_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 infoServerPort = 9;</code>
       *
       * <pre>
       **
       * The port number that this region server is hosing an info server on.
       * </pre>
       */
      public Builder clearInfoServerPort() {
        bitField0_ = (bitField0_ & ~0x00000100);
        infoServerPort_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:ServerLoad)
    }

    static {
      defaultInstance = new ServerLoad(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:ServerLoad)
  }

  public interface TimeRangeOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional uint64 from = 1;
    /**
     * <code>optional uint64 from = 1;</code>
     */
    boolean hasFrom();
    /**
     * <code>optional uint64 from = 1;</code>
     */
    long getFrom();

    // optional uint64 to = 2;
    /**
     * <code>optional uint64 to = 2;</code>
     */
    boolean hasTo();
    /**
     * <code>optional uint64 to = 2;</code>
     */
    long getTo();
  }
  /**
   * Protobuf type {@code TimeRange}
   *
   * <pre>
   **
   * A range of time. Both from and to are Java time
   * stamp in milliseconds. If you don't specify a time
   * range, it means all time.  By default, if not
   * specified, from = 0, and to = Long.MAX_VALUE
   * </pre>
   */
  public static final class TimeRange extends
      com.google.protobuf.GeneratedMessage
      implements TimeRangeOrBuilder {
    // Use TimeRange.newBuilder() to construct.
    private TimeRange(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private TimeRange(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final TimeRange defaultInstance;
    public static TimeRange getDefaultInstance() {
      return defaultInstance;
    }

    public TimeRange getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private TimeRange(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              from_ = input.readUInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              to_ = input.readUInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TimeRange_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TimeRange_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder.class);
    }

    public static com.google.protobuf.Parser<TimeRange> PARSER =
        new com.google.protobuf.AbstractParser<TimeRange>() {
      public TimeRange parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TimeRange(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<TimeRange> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional uint64 from = 1;
    public static final int FROM_FIELD_NUMBER = 1;
    private long from_;
    /**
     * <code>optional uint64 from = 1;</code>
     */
    public boolean hasFrom() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional uint64 from = 1;</code>
     */
    public long getFrom() {
      return from_;
    }

    // optional uint64 to = 2;
    public static final int TO_FIELD_NUMBER = 2;
    private long to_;
    /**
     * <code>optional uint64 to = 2;</code>
     */
    public boolean hasTo() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional uint64 to = 2;</code>
     */
    public long getTo() {
      return to_;
    }

    private void initFields() {
      from_ = 0L;
      to_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(1, from_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt64(2, to_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, from_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, to_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange) obj;

      boolean result = true;
      result = result && (hasFrom() == other.hasFrom());
      if (hasFrom()) {
        result = result && (getFrom()
            == other.getFrom());
      }
      result = result && (hasTo() == other.hasTo());
      if (hasTo()) {
        result = result && (getTo()
            == other.getTo());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasFrom()) {
        hash = (37 * hash) + FROM_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getFrom());
      }
      if (hasTo()) {
        hash = (37 * hash) + TO_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTo());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code TimeRange}
     *
     * <pre>
     **
     * A range of time. Both from and to are Java time
     * stamp in milliseconds. If you don't specify a time
     * range, it means all time.  By default, if not
     * specified, from = 0, and to = Long.MAX_VALUE
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TimeRange_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TimeRange_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        from_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        to_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_TimeRange_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.from_ = from_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.to_ = to_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) return this;
        if (other.hasFrom()) {
          setFrom(other.getFrom());
        }
        if (other.hasTo()) {
          setTo(other.getTo());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional uint64 from = 1;
      private long from_ ;
      /**
       * <code>optional uint64 from = 1;</code>
       */
      public boolean hasFrom() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional uint64 from = 1;</code>
       */
      public long getFrom() {
        return from_;
      }
      /**
       * <code>optional uint64 from = 1;</code>
       */
      public Builder setFrom(long value) {
        bitField0_ |= 0x00000001;
        from_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 from = 1;</code>
       */
      public Builder clearFrom() {
        bitField0_ = (bitField0_ & ~0x00000001);
        from_ = 0L;
        onChanged();
        return this;
      }

      // optional uint64 to = 2;
      private long to_ ;
      /**
       * <code>optional uint64 to = 2;</code>
       */
      public boolean hasTo() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional uint64 to = 2;</code>
       */
      public long getTo() {
        return to_;
      }
      /**
       * <code>optional uint64 to = 2;</code>
       */
      public Builder setTo(long value) {
        bitField0_ |= 0x00000002;
        to_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 to = 2;</code>
       */
      public Builder clearTo() {
        bitField0_ = (bitField0_ & ~0x00000002);
        to_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:TimeRange)
    }

    static {
      defaultInstance = new TimeRange(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:TimeRange)
  }

  public interface FilterOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string name = 1;
    /**
     * <code>required string name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>required string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <code>required string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    // optional bytes serializedFilter = 2;
    /**
     * <code>optional bytes serializedFilter = 2;</code>
     */
    boolean hasSerializedFilter();
    /**
     * <code>optional bytes serializedFilter = 2;</code>
     */
    com.google.protobuf.ByteString getSerializedFilter();
  }
  /**
   * Protobuf type {@code Filter}
   */
  public static final class Filter extends
      com.google.protobuf.GeneratedMessage
      implements FilterOrBuilder {
    // Use Filter.newBuilder() to construct.
    private Filter(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Filter(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Filter defaultInstance;
    public static Filter getDefaultInstance() {
      return defaultInstance;
    }

    public Filter getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Filter(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              serializedFilter_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Filter_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Filter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder.class);
    }

    public static com.google.protobuf.Parser<Filter> PARSER =
        new com.google.protobuf.AbstractParser<Filter>() {
      public Filter parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Filter(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Filter> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private java.lang.Object name_;
    /**
     * <code>required string name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bytes serializedFilter = 2;
    public static final int SERIALIZEDFILTER_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString serializedFilter_;
    /**
     * <code>optional bytes serializedFilter = 2;</code>
     */
    public boolean hasSerializedFilter() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes serializedFilter = 2;</code>
     */
    public com.google.protobuf.ByteString getSerializedFilter() {
      return serializedFilter_;
    }

    private void initFields() {
      name_ = "";
      serializedFilter_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, serializedFilter_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, serializedFilter_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasSerializedFilter() == other.hasSerializedFilter());
      if (hasSerializedFilter()) {
        result = result && getSerializedFilter()
            .equals(other.getSerializedFilter());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasSerializedFilter()) {
        hash = (37 * hash) + SERIALIZEDFILTER_FIELD_NUMBER;
        hash = (53 * hash) + getSerializedFilter().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code Filter}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Filter_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Filter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        serializedFilter_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Filter_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.serializedFilter_ = serializedFilter_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance()) return this;
        if (other.hasName()) {
          bitField0_ |= 0x00000001;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasSerializedFilter()) {
          setSerializedFilter(other.getSerializedFilter());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasName()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string name = 1;
      private java.lang.Object name_ = "";
      /**
       * <code>required string name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }

      // optional bytes serializedFilter = 2;
      private com.google.protobuf.ByteString serializedFilter_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes serializedFilter = 2;</code>
       */
      public boolean hasSerializedFilter() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes serializedFilter = 2;</code>
       */
      public com.google.protobuf.ByteString getSerializedFilter() {
        return serializedFilter_;
      }
      /**
       * <code>optional bytes serializedFilter = 2;</code>
       */
      public Builder setSerializedFilter(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        serializedFilter_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes serializedFilter = 2;</code>
       */
      public Builder clearSerializedFilter() {
        bitField0_ = (bitField0_ & ~0x00000002);
        serializedFilter_ = getDefaultInstance().getSerializedFilter();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:Filter)
    }

    static {
      defaultInstance = new Filter(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:Filter)
  }

  public interface KeyValueOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes row = 1;
    /**
     * <code>required bytes row = 1;</code>
     */
    boolean hasRow();
    /**
     * <code>required bytes row = 1;</code>
     */
    com.google.protobuf.ByteString getRow();

    // required bytes family = 2;
    /**
     * <code>required bytes family = 2;</code>
     */
    boolean hasFamily();
    /**
     * <code>required bytes family = 2;</code>
     */
    com.google.protobuf.ByteString getFamily();

    // required bytes qualifier = 3;
    /**
     * <code>required bytes qualifier = 3;</code>
     */
    boolean hasQualifier();
    /**
     * <code>required bytes qualifier = 3;</code>
     */
    com.google.protobuf.ByteString getQualifier();

    // optional uint64 timestamp = 4;
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    boolean hasTimestamp();
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    long getTimestamp();

    // optional .CellType keyType = 5;
    /**
     * <code>optional .CellType keyType = 5;</code>
     */
    boolean hasKeyType();
    /**
     * <code>optional .CellType keyType = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType getKeyType();

    // optional bytes value = 6;
    /**
     * <code>optional bytes value = 6;</code>
     */
    boolean hasValue();
    /**
     * <code>optional bytes value = 6;</code>
     */
    com.google.protobuf.ByteString getValue();
  }
  /**
   * Protobuf type {@code KeyValue}
   *
   * <pre>
   **
   * Protocol buffer version of KeyValue.
   * It doesn't have those transient parameters
   * </pre>
   */
  public static final class KeyValue extends
      com.google.protobuf.GeneratedMessage
      implements KeyValueOrBuilder {
    // Use KeyValue.newBuilder() to construct.
    private KeyValue(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private KeyValue(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final KeyValue defaultInstance;
    public static KeyValue getDefaultInstance() {
      return defaultInstance;
    }

    public KeyValue getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private KeyValue(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              family_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              qualifier_ = input.readBytes();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              timestamp_ = input.readUInt64();
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType value = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                keyType_ = value;
              }
              break;
            }
            case 50: {
              bitField0_ |= 0x00000020;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_KeyValue_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_KeyValue_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue.Builder.class);
    }

    public static com.google.protobuf.Parser<KeyValue> PARSER =
        new com.google.protobuf.AbstractParser<KeyValue>() {
      public KeyValue parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new KeyValue(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<KeyValue> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    /**
     * <code>required bytes row = 1;</code>
     */
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes row = 1;</code>
     */
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }

    // required bytes family = 2;
    public static final int FAMILY_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString family_;
    /**
     * <code>required bytes family = 2;</code>
     */
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bytes family = 2;</code>
     */
    public com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    // required bytes qualifier = 3;
    public static final int QUALIFIER_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString qualifier_;
    /**
     * <code>required bytes qualifier = 3;</code>
     */
    public boolean hasQualifier() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bytes qualifier = 3;</code>
     */
    public com.google.protobuf.ByteString getQualifier() {
      return qualifier_;
    }

    // optional uint64 timestamp = 4;
    public static final int TIMESTAMP_FIELD_NUMBER = 4;
    private long timestamp_;
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    public boolean hasTimestamp() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    public long getTimestamp() {
      return timestamp_;
    }

    // optional .CellType keyType = 5;
    public static final int KEYTYPE_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType keyType_;
    /**
     * <code>optional .CellType keyType = 5;</code>
     */
    public boolean hasKeyType() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .CellType keyType = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType getKeyType() {
      return keyType_;
    }

    // optional bytes value = 6;
    public static final int VALUE_FIELD_NUMBER = 6;
    private com.google.protobuf.ByteString value_;
    /**
     * <code>optional bytes value = 6;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional bytes value = 6;</code>
     */
    public com.google.protobuf.ByteString getValue() {
      return value_;
    }

    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      family_ = com.google.protobuf.ByteString.EMPTY;
      qualifier_ = com.google.protobuf.ByteString.EMPTY;
      timestamp_ = 0L;
      keyType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.MINIMUM;
      value_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasQualifier()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt64(4, timestamp_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, keyType_.getNumber());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBytes(6, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, timestamp_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, keyType_.getNumber());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(6, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue) obj;

      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasFamily() == other.hasFamily());
      if (hasFamily()) {
        result = result && getFamily()
            .equals(other.getFamily());
      }
      result = result && (hasQualifier() == other.hasQualifier());
      if (hasQualifier()) {
        result = result && getQualifier()
            .equals(other.getQualifier());
      }
      result = result && (hasTimestamp() == other.hasTimestamp());
      if (hasTimestamp()) {
        result = result && (getTimestamp()
            == other.getTimestamp());
      }
      result = result && (hasKeyType() == other.hasKeyType());
      if (hasKeyType()) {
        result = result &&
            (getKeyType() == other.getKeyType());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (hasQualifier()) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifier().hashCode();
      }
      if (hasTimestamp()) {
        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTimestamp());
      }
      if (hasKeyType()) {
        hash = (37 * hash) + KEYTYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getKeyType());
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code KeyValue}
     *
     * <pre>
     **
     * Protocol buffer version of KeyValue.
     * It doesn't have those transient parameters
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValueOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_KeyValue_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_KeyValue_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        qualifier_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        timestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        keyType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.MINIMUM;
        bitField0_ = (bitField0_ & ~0x00000010);
        value_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_KeyValue_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.family_ = family_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.qualifier_ = qualifier_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.timestamp_ = timestamp_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.keyType_ = keyType_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (other.hasQualifier()) {
          setQualifier(other.getQualifier());
        }
        if (other.hasTimestamp()) {
          setTimestamp(other.getTimestamp());
        }
        if (other.hasKeyType()) {
          setKeyType(other.getKeyType());
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        if (!hasFamily()) {
          
          return false;
        }
        if (!hasQualifier()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.KeyValue) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes row = 1;</code>
       */
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      // required bytes family = 2;
      private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 2;</code>
       */
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bytes family = 2;</code>
       */
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>required bytes family = 2;</code>
       */
      public Builder setFamily(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        family_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family = 2;</code>
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000002);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      // required bytes qualifier = 3;
      private com.google.protobuf.ByteString qualifier_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes qualifier = 3;</code>
       */
      public boolean hasQualifier() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bytes qualifier = 3;</code>
       */
      public com.google.protobuf.ByteString getQualifier() {
        return qualifier_;
      }
      /**
       * <code>required bytes qualifier = 3;</code>
       */
      public Builder setQualifier(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        qualifier_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes qualifier = 3;</code>
       */
      public Builder clearQualifier() {
        bitField0_ = (bitField0_ & ~0x00000004);
        qualifier_ = getDefaultInstance().getQualifier();
        onChanged();
        return this;
      }

      // optional uint64 timestamp = 4;
      private long timestamp_ ;
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public boolean hasTimestamp() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public long getTimestamp() {
        return timestamp_;
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public Builder setTimestamp(long value) {
        bitField0_ |= 0x00000008;
        timestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public Builder clearTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000008);
        timestamp_ = 0L;
        onChanged();
        return this;
      }

      // optional .CellType keyType = 5;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType keyType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.MINIMUM;
      /**
       * <code>optional .CellType keyType = 5;</code>
       */
      public boolean hasKeyType() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .CellType keyType = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType getKeyType() {
        return keyType_;
      }
      /**
       * <code>optional .CellType keyType = 5;</code>
       */
      public Builder setKeyType(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        keyType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .CellType keyType = 5;</code>
       */
      public Builder clearKeyType() {
        bitField0_ = (bitField0_ & ~0x00000010);
        keyType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CellType.MINIMUM;
        onChanged();
        return this;
      }

      // optional bytes value = 6;
      private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes value = 6;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bytes value = 6;</code>
       */
      public com.google.protobuf.ByteString getValue() {
        return value_;
      }
      /**
       * <code>optional bytes value = 6;</code>
       */
      public Builder setValue(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes value = 6;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000020);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:KeyValue)
    }

    static {
      defaultInstance = new KeyValue(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:KeyValue)
  }

  public interface ServerNameOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string hostName = 1;
    /**
     * <code>required string hostName = 1;</code>
     */
    boolean hasHostName();
    /**
     * <code>required string hostName = 1;</code>
     */
    java.lang.String getHostName();
    /**
     * <code>required string hostName = 1;</code>
     */
    com.google.protobuf.ByteString
        getHostNameBytes();

    // optional uint32 port = 2;
    /**
     * <code>optional uint32 port = 2;</code>
     */
    boolean hasPort();
    /**
     * <code>optional uint32 port = 2;</code>
     */
    int getPort();

    // optional uint64 startCode = 3;
    /**
     * <code>optional uint64 startCode = 3;</code>
     */
    boolean hasStartCode();
    /**
     * <code>optional uint64 startCode = 3;</code>
     */
    long getStartCode();
  }
  /**
   * Protobuf type {@code ServerName}
   *
   * <pre>
   **
   * Protocol buffer version of ServerName
   * </pre>
   */
  public static final class ServerName extends
      com.google.protobuf.GeneratedMessage
      implements ServerNameOrBuilder {
    // Use ServerName.newBuilder() to construct.
    private ServerName(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ServerName(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ServerName defaultInstance;
    public static ServerName getDefaultInstance() {
      return defaultInstance;
    }

    public ServerName getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ServerName(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              hostName_ = input.readBytes();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              port_ = input.readUInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              startCode_ = input.readUInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerName_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerName_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder.class);
    }

    public static com.google.protobuf.Parser<ServerName> PARSER =
        new com.google.protobuf.AbstractParser<ServerName>() {
      public ServerName parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ServerName(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ServerName> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required string hostName = 1;
    public static final int HOSTNAME_FIELD_NUMBER = 1;
    private java.lang.Object hostName_;
    /**
     * <code>required string hostName = 1;</code>
     */
    public boolean hasHostName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string hostName = 1;</code>
     */
    public java.lang.String getHostName() {
      java.lang.Object ref = hostName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          hostName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string hostName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getHostNameBytes() {
      java.lang.Object ref = hostName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        hostName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional uint32 port = 2;
    public static final int PORT_FIELD_NUMBER = 2;
    private int port_;
    /**
     * <code>optional uint32 port = 2;</code>
     */
    public boolean hasPort() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional uint32 port = 2;</code>
     */
    public int getPort() {
      return port_;
    }

    // optional uint64 startCode = 3;
    public static final int STARTCODE_FIELD_NUMBER = 3;
    private long startCode_;
    /**
     * <code>optional uint64 startCode = 3;</code>
     */
    public boolean hasStartCode() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional uint64 startCode = 3;</code>
     */
    public long getStartCode() {
      return startCode_;
    }

    private void initFields() {
      hostName_ = "";
      port_ = 0;
      startCode_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasHostName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getHostNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt32(2, port_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(3, startCode_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getHostNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, port_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, startCode_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName) obj;

      boolean result = true;
      result = result && (hasHostName() == other.hasHostName());
      if (hasHostName()) {
        result = result && getHostName()
            .equals(other.getHostName());
      }
      result = result && (hasPort() == other.hasPort());
      if (hasPort()) {
        result = result && (getPort()
            == other.getPort());
      }
      result = result && (hasStartCode() == other.hasStartCode());
      if (hasStartCode()) {
        result = result && (getStartCode()
            == other.getStartCode());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasHostName()) {
        hash = (37 * hash) + HOSTNAME_FIELD_NUMBER;
        hash = (53 * hash) + getHostName().hashCode();
      }
      if (hasPort()) {
        hash = (37 * hash) + PORT_FIELD_NUMBER;
        hash = (53 * hash) + getPort();
      }
      if (hasStartCode()) {
        hash = (37 * hash) + STARTCODE_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getStartCode());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code ServerName}
     *
     * <pre>
     **
     * Protocol buffer version of ServerName
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerNameOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerName_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerName_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        hostName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        port_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        startCode_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_ServerName_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.hostName_ = hostName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.port_ = port_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.startCode_ = startCode_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName.getDefaultInstance()) return this;
        if (other.hasHostName()) {
          bitField0_ |= 0x00000001;
          hostName_ = other.hostName_;
          onChanged();
        }
        if (other.hasPort()) {
          setPort(other.getPort());
        }
        if (other.hasStartCode()) {
          setStartCode(other.getStartCode());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasHostName()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.ServerName) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string hostName = 1;
      private java.lang.Object hostName_ = "";
      /**
       * <code>required string hostName = 1;</code>
       */
      public boolean hasHostName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string hostName = 1;</code>
       */
      public java.lang.String getHostName() {
        java.lang.Object ref = hostName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          hostName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string hostName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getHostNameBytes() {
        java.lang.Object ref = hostName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          hostName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string hostName = 1;</code>
       */
      public Builder setHostName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        hostName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string hostName = 1;</code>
       */
      public Builder clearHostName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        hostName_ = getDefaultInstance().getHostName();
        onChanged();
        return this;
      }
      /**
       * <code>required string hostName = 1;</code>
       */
      public Builder setHostNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        hostName_ = value;
        onChanged();
        return this;
      }

      // optional uint32 port = 2;
      private int port_ ;
      /**
       * <code>optional uint32 port = 2;</code>
       */
      public boolean hasPort() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional uint32 port = 2;</code>
       */
      public int getPort() {
        return port_;
      }
      /**
       * <code>optional uint32 port = 2;</code>
       */
      public Builder setPort(int value) {
        bitField0_ |= 0x00000002;
        port_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 port = 2;</code>
       */
      public Builder clearPort() {
        bitField0_ = (bitField0_ & ~0x00000002);
        port_ = 0;
        onChanged();
        return this;
      }

      // optional uint64 startCode = 3;
      private long startCode_ ;
      /**
       * <code>optional uint64 startCode = 3;</code>
       */
      public boolean hasStartCode() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional uint64 startCode = 3;</code>
       */
      public long getStartCode() {
        return startCode_;
      }
      /**
       * <code>optional uint64 startCode = 3;</code>
       */
      public Builder setStartCode(long value) {
        bitField0_ |= 0x00000004;
        startCode_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 startCode = 3;</code>
       */
      public Builder clearStartCode() {
        bitField0_ = (bitField0_ & ~0x00000004);
        startCode_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:ServerName)
    }

    static {
      defaultInstance = new ServerName(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:ServerName)
  }

  public interface CoprocessorOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string name = 1;
    /**
     * <code>required string name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>required string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <code>required string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();
  }
  /**
   * Protobuf type {@code Coprocessor}
   */
  public static final class Coprocessor extends
      com.google.protobuf.GeneratedMessage
      implements CoprocessorOrBuilder {
    // Use Coprocessor.newBuilder() to construct.
    private Coprocessor(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Coprocessor(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Coprocessor defaultInstance;
    public static Coprocessor getDefaultInstance() {
      return defaultInstance;
    }

    public Coprocessor getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Coprocessor(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Coprocessor_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Coprocessor_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder.class);
    }

    public static com.google.protobuf.Parser<Coprocessor> PARSER =
        new com.google.protobuf.AbstractParser<Coprocessor>() {
      public Coprocessor parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Coprocessor(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Coprocessor> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private java.lang.Object name_;
    /**
     * <code>required string name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      name_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNameBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNameBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code Coprocessor}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CoprocessorOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Coprocessor_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Coprocessor_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_Coprocessor_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor.getDefaultInstance()) return this;
        if (other.hasName()) {
          bitField0_ |= 0x00000001;
          name_ = other.name_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasName()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Coprocessor) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string name = 1;
      private java.lang.Object name_ = "";
      /**
       * <code>required string name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:Coprocessor)
    }

    static {
      defaultInstance = new Coprocessor(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:Coprocessor)
  }

  public interface NameStringPairOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string name = 1;
    /**
     * <code>required string name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>required string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <code>required string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    // required string value = 2;
    /**
     * <code>required string value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>required string value = 2;</code>
     */
    java.lang.String getValue();
    /**
     * <code>required string value = 2;</code>
     */
    com.google.protobuf.ByteString
        getValueBytes();
  }
  /**
   * Protobuf type {@code NameStringPair}
   */
  public static final class NameStringPair extends
      com.google.protobuf.GeneratedMessage
      implements NameStringPairOrBuilder {
    // Use NameStringPair.newBuilder() to construct.
    private NameStringPair(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NameStringPair(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NameStringPair defaultInstance;
    public static NameStringPair getDefaultInstance() {
      return defaultInstance;
    }

    public NameStringPair getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NameStringPair(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameStringPair_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameStringPair_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder.class);
    }

    public static com.google.protobuf.Parser<NameStringPair> PARSER =
        new com.google.protobuf.AbstractParser<NameStringPair>() {
      public NameStringPair parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NameStringPair(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NameStringPair> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private java.lang.Object name_;
    /**
     * <code>required string name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // required string value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private java.lang.Object value_;
    /**
     * <code>required string value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required string value = 2;</code>
     */
    public java.lang.String getValue() {
      java.lang.Object ref = value_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          value_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string value = 2;</code>
     */
    public com.google.protobuf.ByteString
        getValueBytes() {
      java.lang.Object ref = value_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        value_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private void initFields() {
      name_ = "";
      value_ = "";
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getValueBytes());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getValueBytes());
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code NameStringPair}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameStringPair_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameStringPair_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameStringPair_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.getDefaultInstance()) return this;
        if (other.hasName()) {
          bitField0_ |= 0x00000001;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasValue()) {
          bitField0_ |= 0x00000002;
          value_ = other.value_;
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasName()) {
          
          return false;
        }
        if (!hasValue()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string name = 1;
      private java.lang.Object name_ = "";
      /**
       * <code>required string name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }

      // required string value = 2;
      private java.lang.Object value_ = "";
      /**
       * <code>required string value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required string value = 2;</code>
       */
      public java.lang.String getValue() {
        java.lang.Object ref = value_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          value_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string value = 2;</code>
       */
      public com.google.protobuf.ByteString
          getValueBytes() {
        java.lang.Object ref = value_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          value_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string value = 2;</code>
       */
      public Builder setValue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }
      /**
       * <code>required string value = 2;</code>
       */
      public Builder setValueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:NameStringPair)
    }

    static {
      defaultInstance = new NameStringPair(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:NameStringPair)
  }

  public interface NameBytesPairOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string name = 1;
    /**
     * <code>required string name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>required string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <code>required string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    // optional bytes value = 2;
    /**
     * <code>optional bytes value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional bytes value = 2;</code>
     */
    com.google.protobuf.ByteString getValue();
  }
  /**
   * Protobuf type {@code NameBytesPair}
   */
  public static final class NameBytesPair extends
      com.google.protobuf.GeneratedMessage
      implements NameBytesPairOrBuilder {
    // Use NameBytesPair.newBuilder() to construct.
    private NameBytesPair(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NameBytesPair(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NameBytesPair defaultInstance;
    public static NameBytesPair getDefaultInstance() {
      return defaultInstance;
    }

    public NameBytesPair getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NameBytesPair(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameBytesPair_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameBytesPair_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder.class);
    }

    public static com.google.protobuf.Parser<NameBytesPair> PARSER =
        new com.google.protobuf.AbstractParser<NameBytesPair>() {
      public NameBytesPair parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NameBytesPair(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NameBytesPair> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private java.lang.Object name_;
    /**
     * <code>required string name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional bytes value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString value_;
    /**
     * <code>optional bytes value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes value = 2;</code>
     */
    public com.google.protobuf.ByteString getValue() {
      return value_;
    }

    private void initFields() {
      name_ = "";
      value_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code NameBytesPair}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameBytesPair_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameBytesPair_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameBytesPair_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) return this;
        if (other.hasName()) {
          bitField0_ |= 0x00000001;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasName()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string name = 1;
      private java.lang.Object name_ = "";
      /**
       * <code>required string name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }

      // optional bytes value = 2;
      private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public com.google.protobuf.ByteString getValue() {
        return value_;
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public Builder setValue(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:NameBytesPair)
    }

    static {
      defaultInstance = new NameBytesPair(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:NameBytesPair)
  }

  public interface BytesBytesPairOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes first = 1;
    /**
     * <code>required bytes first = 1;</code>
     */
    boolean hasFirst();
    /**
     * <code>required bytes first = 1;</code>
     */
    com.google.protobuf.ByteString getFirst();

    // required bytes second = 2;
    /**
     * <code>required bytes second = 2;</code>
     */
    boolean hasSecond();
    /**
     * <code>required bytes second = 2;</code>
     */
    com.google.protobuf.ByteString getSecond();
  }
  /**
   * Protobuf type {@code BytesBytesPair}
   */
  public static final class BytesBytesPair extends
      com.google.protobuf.GeneratedMessage
      implements BytesBytesPairOrBuilder {
    // Use BytesBytesPair.newBuilder() to construct.
    private BytesBytesPair(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private BytesBytesPair(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final BytesBytesPair defaultInstance;
    public static BytesBytesPair getDefaultInstance() {
      return defaultInstance;
    }

    public BytesBytesPair getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private BytesBytesPair(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              first_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              second_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BytesBytesPair_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BytesBytesPair_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder.class);
    }

    public static com.google.protobuf.Parser<BytesBytesPair> PARSER =
        new com.google.protobuf.AbstractParser<BytesBytesPair>() {
      public BytesBytesPair parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BytesBytesPair(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<BytesBytesPair> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes first = 1;
    public static final int FIRST_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString first_;
    /**
     * <code>required bytes first = 1;</code>
     */
    public boolean hasFirst() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes first = 1;</code>
     */
    public com.google.protobuf.ByteString getFirst() {
      return first_;
    }

    // required bytes second = 2;
    public static final int SECOND_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString second_;
    /**
     * <code>required bytes second = 2;</code>
     */
    public boolean hasSecond() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bytes second = 2;</code>
     */
    public com.google.protobuf.ByteString getSecond() {
      return second_;
    }

    private void initFields() {
      first_ = com.google.protobuf.ByteString.EMPTY;
      second_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasFirst()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasSecond()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, first_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, second_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, first_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, second_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair) obj;

      boolean result = true;
      result = result && (hasFirst() == other.hasFirst());
      if (hasFirst()) {
        result = result && getFirst()
            .equals(other.getFirst());
      }
      result = result && (hasSecond() == other.hasSecond());
      if (hasSecond()) {
        result = result && getSecond()
            .equals(other.getSecond());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasFirst()) {
        hash = (37 * hash) + FIRST_FIELD_NUMBER;
        hash = (53 * hash) + getFirst().hashCode();
      }
      if (hasSecond()) {
        hash = (37 * hash) + SECOND_FIELD_NUMBER;
        hash = (53 * hash) + getSecond().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code BytesBytesPair}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPairOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BytesBytesPair_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BytesBytesPair_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        first_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        second_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BytesBytesPair_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.first_ = first_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.second_ = second_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair.getDefaultInstance()) return this;
        if (other.hasFirst()) {
          setFirst(other.getFirst());
        }
        if (other.hasSecond()) {
          setSecond(other.getSecond());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasFirst()) {
          
          return false;
        }
        if (!hasSecond()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BytesBytesPair) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes first = 1;
      private com.google.protobuf.ByteString first_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes first = 1;</code>
       */
      public boolean hasFirst() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes first = 1;</code>
       */
      public com.google.protobuf.ByteString getFirst() {
        return first_;
      }
      /**
       * <code>required bytes first = 1;</code>
       */
      public Builder setFirst(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        first_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes first = 1;</code>
       */
      public Builder clearFirst() {
        bitField0_ = (bitField0_ & ~0x00000001);
        first_ = getDefaultInstance().getFirst();
        onChanged();
        return this;
      }

      // required bytes second = 2;
      private com.google.protobuf.ByteString second_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes second = 2;</code>
       */
      public boolean hasSecond() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bytes second = 2;</code>
       */
      public com.google.protobuf.ByteString getSecond() {
        return second_;
      }
      /**
       * <code>required bytes second = 2;</code>
       */
      public Builder setSecond(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        second_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes second = 2;</code>
       */
      public Builder clearSecond() {
        bitField0_ = (bitField0_ & ~0x00000002);
        second_ = getDefaultInstance().getSecond();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:BytesBytesPair)
    }

    static {
      defaultInstance = new BytesBytesPair(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:BytesBytesPair)
  }

  public interface NameInt64PairOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional string name = 1;
    /**
     * <code>optional string name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>optional string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <code>optional string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    // optional int64 value = 2;
    /**
     * <code>optional int64 value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional int64 value = 2;</code>
     */
    long getValue();
  }
  /**
   * Protobuf type {@code NameInt64Pair}
   */
  public static final class NameInt64Pair extends
      com.google.protobuf.GeneratedMessage
      implements NameInt64PairOrBuilder {
    // Use NameInt64Pair.newBuilder() to construct.
    private NameInt64Pair(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NameInt64Pair(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NameInt64Pair defaultInstance;
    public static NameInt64Pair getDefaultInstance() {
      return defaultInstance;
    }

    public NameInt64Pair getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NameInt64Pair(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              value_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameInt64Pair_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameInt64Pair_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair.Builder.class);
    }

    public static com.google.protobuf.Parser<NameInt64Pair> PARSER =
        new com.google.protobuf.AbstractParser<NameInt64Pair>() {
      public NameInt64Pair parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NameInt64Pair(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NameInt64Pair> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private java.lang.Object name_;
    /**
     * <code>optional string name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private long value_;
    /**
     * <code>optional int64 value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 value = 2;</code>
     */
    public long getValue() {
      return value_;
    }

    private void initFields() {
      name_ = "";
      value_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && (getValue()
            == other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getValue());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code NameInt64Pair}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64PairOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameInt64Pair_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameInt64Pair_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_NameInt64Pair_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair.getDefaultInstance()) return this;
        if (other.hasName()) {
          bitField0_ |= 0x00000001;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameInt64Pair) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional string name = 1;
      private java.lang.Object name_ = "";
      /**
       * <code>optional string name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }

      // optional int64 value = 2;
      private long value_ ;
      /**
       * <code>optional int64 value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 value = 2;</code>
       */
      public long getValue() {
        return value_;
      }
      /**
       * <code>optional int64 value = 2;</code>
       */
      public Builder setValue(long value) {
        bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:NameInt64Pair)
    }

    static {
      defaultInstance = new NameInt64Pair(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:NameInt64Pair)
  }

  public interface SnapshotDescriptionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required string name = 1;
    /**
     * <code>required string name = 1;</code>
     */
    boolean hasName();
    /**
     * <code>required string name = 1;</code>
     */
    java.lang.String getName();
    /**
     * <code>required string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    // optional string table = 2;
    /**
     * <code>optional string table = 2;</code>
     *
     * <pre>
     * not needed for delete, but checked for in taking snapshot
     * </pre>
     */
    boolean hasTable();
    /**
     * <code>optional string table = 2;</code>
     *
     * <pre>
     * not needed for delete, but checked for in taking snapshot
     * </pre>
     */
    java.lang.String getTable();
    /**
     * <code>optional string table = 2;</code>
     *
     * <pre>
     * not needed for delete, but checked for in taking snapshot
     * </pre>
     */
    com.google.protobuf.ByteString
        getTableBytes();

    // optional int64 creationTime = 3 [default = 0];
    /**
     * <code>optional int64 creationTime = 3 [default = 0];</code>
     */
    boolean hasCreationTime();
    /**
     * <code>optional int64 creationTime = 3 [default = 0];</code>
     */
    long getCreationTime();

    // optional .SnapshotDescription.Type type = 4 [default = FLUSH];
    /**
     * <code>optional .SnapshotDescription.Type type = 4 [default = FLUSH];</code>
     */
    boolean hasType();
    /**
     * <code>optional .SnapshotDescription.Type type = 4 [default = FLUSH];</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type getType();

    // optional int32 version = 5;
    /**
     * <code>optional int32 version = 5;</code>
     */
    boolean hasVersion();
    /**
     * <code>optional int32 version = 5;</code>
     */
    int getVersion();
  }
  /**
   * Protobuf type {@code SnapshotDescription}
   *
   * <pre>
   **
   * Description of the snapshot to take
   * </pre>
   */
  public static final class SnapshotDescription extends
      com.google.protobuf.GeneratedMessage
      implements SnapshotDescriptionOrBuilder {
    // Use SnapshotDescription.newBuilder() to construct.
    private SnapshotDescription(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private SnapshotDescription(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final SnapshotDescription defaultInstance;
    public static SnapshotDescription getDefaultInstance() {
      return defaultInstance;
    }

    public SnapshotDescription getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private SnapshotDescription(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              name_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              table_ = input.readBytes();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              creationTime_ = input.readInt64();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type value = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                type_ = value;
              }
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              version_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_SnapshotDescription_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_SnapshotDescription_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Builder.class);
    }

    public static com.google.protobuf.Parser<SnapshotDescription> PARSER =
        new com.google.protobuf.AbstractParser<SnapshotDescription>() {
      public SnapshotDescription parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new SnapshotDescription(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<SnapshotDescription> getParserForType() {
      return PARSER;
    }

    /**
     * Protobuf enum {@code SnapshotDescription.Type}
     */
    public enum Type
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>DISABLED = 0;</code>
       */
      DISABLED(0, 0),
      /**
       * <code>FLUSH = 1;</code>
       */
      FLUSH(1, 1),
      ;

      /**
       * <code>DISABLED = 0;</code>
       */
      public static final int DISABLED_VALUE = 0;
      /**
       * <code>FLUSH = 1;</code>
       */
      public static final int FLUSH_VALUE = 1;


      public final int getNumber() { return value; }

      public static Type valueOf(int value) {
        switch (value) {
          case 0: return DISABLED;
          case 1: return FLUSH;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Type>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<Type>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Type>() {
              public Type findValueByNumber(int number) {
                return Type.valueOf(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.getDescriptor().getEnumTypes().get(0);
      }

      private static final Type[] VALUES = values();

      public static Type valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int index;
      private final int value;

      private Type(int index, int value) {
        this.index = index;
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:SnapshotDescription.Type)
    }

    private int bitField0_;
    // required string name = 1;
    public static final int NAME_FIELD_NUMBER = 1;
    private java.lang.Object name_;
    /**
     * <code>required string name = 1;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required string name = 1;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional string table = 2;
    public static final int TABLE_FIELD_NUMBER = 2;
    private java.lang.Object table_;
    /**
     * <code>optional string table = 2;</code>
     *
     * <pre>
     * not needed for delete, but checked for in taking snapshot
     * </pre>
     */
    public boolean hasTable() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string table = 2;</code>
     *
     * <pre>
     * not needed for delete, but checked for in taking snapshot
     * </pre>
     */
    public java.lang.String getTable() {
      java.lang.Object ref = table_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          table_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string table = 2;</code>
     *
     * <pre>
     * not needed for delete, but checked for in taking snapshot
     * </pre>
     */
    public com.google.protobuf.ByteString
        getTableBytes() {
      java.lang.Object ref = table_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        table_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // optional int64 creationTime = 3 [default = 0];
    public static final int CREATIONTIME_FIELD_NUMBER = 3;
    private long creationTime_;
    /**
     * <code>optional int64 creationTime = 3 [default = 0];</code>
     */
    public boolean hasCreationTime() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 creationTime = 3 [default = 0];</code>
     */
    public long getCreationTime() {
      return creationTime_;
    }

    // optional .SnapshotDescription.Type type = 4 [default = FLUSH];
    public static final int TYPE_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type type_;
    /**
     * <code>optional .SnapshotDescription.Type type = 4 [default = FLUSH];</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .SnapshotDescription.Type type = 4 [default = FLUSH];</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type getType() {
      return type_;
    }

    // optional int32 version = 5;
    public static final int VERSION_FIELD_NUMBER = 5;
    private int version_;
    /**
     * <code>optional int32 version = 5;</code>
     */
    public boolean hasVersion() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int32 version = 5;</code>
     */
    public int getVersion() {
      return version_;
    }

    private void initFields() {
      name_ = "";
      table_ = "";
      creationTime_ = 0L;
      type_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type.FLUSH;
      version_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getTableBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, creationTime_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, type_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt32(5, version_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, getNameBytes());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getTableBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, creationTime_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, type_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, version_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription) obj;

      boolean result = true;
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasTable() == other.hasTable());
      if (hasTable()) {
        result = result && getTable()
            .equals(other.getTable());
      }
      result = result && (hasCreationTime() == other.hasCreationTime());
      if (hasCreationTime()) {
        result = result && (getCreationTime()
            == other.getCreationTime());
      }
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result &&
            (getType() == other.getType());
      }
      result = result && (hasVersion() == other.hasVersion());
      if (hasVersion()) {
        result = result && (getVersion()
            == other.getVersion());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasTable()) {
        hash = (37 * hash) + TABLE_FIELD_NUMBER;
        hash = (53 * hash) + getTable().hashCode();
      }
      if (hasCreationTime()) {
        hash = (37 * hash) + CREATIONTIME_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getCreationTime());
      }
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getType());
      }
      if (hasVersion()) {
        hash = (37 * hash) + VERSION_FIELD_NUMBER;
        hash = (53 * hash) + getVersion();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code SnapshotDescription}
     *
     * <pre>
     **
     * Description of the snapshot to take
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescriptionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_SnapshotDescription_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_SnapshotDescription_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        table_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        creationTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        type_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type.FLUSH;
        bitField0_ = (bitField0_ & ~0x00000008);
        version_ = 0;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_SnapshotDescription_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.table_ = table_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.creationTime_ = creationTime_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.version_ = version_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.getDefaultInstance()) return this;
        if (other.hasName()) {
          bitField0_ |= 0x00000001;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasTable()) {
          bitField0_ |= 0x00000002;
          table_ = other.table_;
          onChanged();
        }
        if (other.hasCreationTime()) {
          setCreationTime(other.getCreationTime());
        }
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasVersion()) {
          setVersion(other.getVersion());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasName()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required string name = 1;
      private java.lang.Object name_ = "";
      /**
       * <code>required string name = 1;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required string name = 1;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>required string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        name_ = value;
        onChanged();
        return this;
      }

      // optional string table = 2;
      private java.lang.Object table_ = "";
      /**
       * <code>optional string table = 2;</code>
       *
       * <pre>
       * not needed for delete, but checked for in taking snapshot
       * </pre>
       */
      public boolean hasTable() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string table = 2;</code>
       *
       * <pre>
       * not needed for delete, but checked for in taking snapshot
       * </pre>
       */
      public java.lang.String getTable() {
        java.lang.Object ref = table_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          table_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string table = 2;</code>
       *
       * <pre>
       * not needed for delete, but checked for in taking snapshot
       * </pre>
       */
      public com.google.protobuf.ByteString
          getTableBytes() {
        java.lang.Object ref = table_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          table_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string table = 2;</code>
       *
       * <pre>
       * not needed for delete, but checked for in taking snapshot
       * </pre>
       */
      public Builder setTable(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        table_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string table = 2;</code>
       *
       * <pre>
       * not needed for delete, but checked for in taking snapshot
       * </pre>
       */
      public Builder clearTable() {
        bitField0_ = (bitField0_ & ~0x00000002);
        table_ = getDefaultInstance().getTable();
        onChanged();
        return this;
      }
      /**
       * <code>optional string table = 2;</code>
       *
       * <pre>
       * not needed for delete, but checked for in taking snapshot
       * </pre>
       */
      public Builder setTableBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        table_ = value;
        onChanged();
        return this;
      }

      // optional int64 creationTime = 3 [default = 0];
      private long creationTime_ ;
      /**
       * <code>optional int64 creationTime = 3 [default = 0];</code>
       */
      public boolean hasCreationTime() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 creationTime = 3 [default = 0];</code>
       */
      public long getCreationTime() {
        return creationTime_;
      }
      /**
       * <code>optional int64 creationTime = 3 [default = 0];</code>
       */
      public Builder setCreationTime(long value) {
        bitField0_ |= 0x00000004;
        creationTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 creationTime = 3 [default = 0];</code>
       */
      public Builder clearCreationTime() {
        bitField0_ = (bitField0_ & ~0x00000004);
        creationTime_ = 0L;
        onChanged();
        return this;
      }

      // optional .SnapshotDescription.Type type = 4 [default = FLUSH];
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type type_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type.FLUSH;
      /**
       * <code>optional .SnapshotDescription.Type type = 4 [default = FLUSH];</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .SnapshotDescription.Type type = 4 [default = FLUSH];</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type getType() {
        return type_;
      }
      /**
       * <code>optional .SnapshotDescription.Type type = 4 [default = FLUSH];</code>
       */
      public Builder setType(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        type_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .SnapshotDescription.Type type = 4 [default = FLUSH];</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000008);
        type_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.SnapshotDescription.Type.FLUSH;
        onChanged();
        return this;
      }

      // optional int32 version = 5;
      private int version_ ;
      /**
       * <code>optional int32 version = 5;</code>
       */
      public boolean hasVersion() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional int32 version = 5;</code>
       */
      public int getVersion() {
        return version_;
      }
      /**
       * <code>optional int32 version = 5;</code>
       */
      public Builder setVersion(int value) {
        bitField0_ |= 0x00000010;
        version_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 version = 5;</code>
       */
      public Builder clearVersion() {
        bitField0_ = (bitField0_ & ~0x00000010);
        version_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:SnapshotDescription)
    }

    static {
      defaultInstance = new SnapshotDescription(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:SnapshotDescription)
  }

  public interface EmptyMsgOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code EmptyMsg}
   */
  public static final class EmptyMsg extends
      com.google.protobuf.GeneratedMessage
      implements EmptyMsgOrBuilder {
    // Use EmptyMsg.newBuilder() to construct.
    private EmptyMsg(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private EmptyMsg(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final EmptyMsg defaultInstance;
    public static EmptyMsg getDefaultInstance() {
      return defaultInstance;
    }

    public EmptyMsg getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private EmptyMsg(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_EmptyMsg_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_EmptyMsg_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg.Builder.class);
    }

    public static com.google.protobuf.Parser<EmptyMsg> PARSER =
        new com.google.protobuf.AbstractParser<EmptyMsg>() {
      public EmptyMsg parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new EmptyMsg(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<EmptyMsg> getParserForType() {
      return PARSER;
    }

    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg) obj;

      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code EmptyMsg}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsgOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_EmptyMsg_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_EmptyMsg_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_EmptyMsg_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg(this);
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.EmptyMsg) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      // @@protoc_insertion_point(builder_scope:EmptyMsg)
    }

    static {
      defaultInstance = new EmptyMsg(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:EmptyMsg)
  }

  public interface LongMsgOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required int64 longMsg = 1;
    /**
     * <code>required int64 longMsg = 1;</code>
     */
    boolean hasLongMsg();
    /**
     * <code>required int64 longMsg = 1;</code>
     */
    long getLongMsg();
  }
  /**
   * Protobuf type {@code LongMsg}
   */
  public static final class LongMsg extends
      com.google.protobuf.GeneratedMessage
      implements LongMsgOrBuilder {
    // Use LongMsg.newBuilder() to construct.
    private LongMsg(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private LongMsg(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final LongMsg defaultInstance;
    public static LongMsg getDefaultInstance() {
      return defaultInstance;
    }

    public LongMsg getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private LongMsg(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              longMsg_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_LongMsg_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_LongMsg_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg.Builder.class);
    }

    public static com.google.protobuf.Parser<LongMsg> PARSER =
        new com.google.protobuf.AbstractParser<LongMsg>() {
      public LongMsg parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new LongMsg(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<LongMsg> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required int64 longMsg = 1;
    public static final int LONGMSG_FIELD_NUMBER = 1;
    private long longMsg_;
    /**
     * <code>required int64 longMsg = 1;</code>
     */
    public boolean hasLongMsg() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required int64 longMsg = 1;</code>
     */
    public long getLongMsg() {
      return longMsg_;
    }

    private void initFields() {
      longMsg_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasLongMsg()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, longMsg_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, longMsg_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg) obj;

      boolean result = true;
      result = result && (hasLongMsg() == other.hasLongMsg());
      if (hasLongMsg()) {
        result = result && (getLongMsg()
            == other.getLongMsg());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasLongMsg()) {
        hash = (37 * hash) + LONGMSG_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getLongMsg());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code LongMsg}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsgOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_LongMsg_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_LongMsg_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        longMsg_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_LongMsg_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.longMsg_ = longMsg_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg.getDefaultInstance()) return this;
        if (other.hasLongMsg()) {
          setLongMsg(other.getLongMsg());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasLongMsg()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.LongMsg) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required int64 longMsg = 1;
      private long longMsg_ ;
      /**
       * <code>required int64 longMsg = 1;</code>
       */
      public boolean hasLongMsg() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required int64 longMsg = 1;</code>
       */
      public long getLongMsg() {
        return longMsg_;
      }
      /**
       * <code>required int64 longMsg = 1;</code>
       */
      public Builder setLongMsg(long value) {
        bitField0_ |= 0x00000001;
        longMsg_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required int64 longMsg = 1;</code>
       */
      public Builder clearLongMsg() {
        bitField0_ = (bitField0_ & ~0x00000001);
        longMsg_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:LongMsg)
    }

    static {
      defaultInstance = new LongMsg(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:LongMsg)
  }

  public interface BigDecimalMsgOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes bigdecimalMsg = 1;
    /**
     * <code>required bytes bigdecimalMsg = 1;</code>
     */
    boolean hasBigdecimalMsg();
    /**
     * <code>required bytes bigdecimalMsg = 1;</code>
     */
    com.google.protobuf.ByteString getBigdecimalMsg();
  }
  /**
   * Protobuf type {@code BigDecimalMsg}
   */
  public static final class BigDecimalMsg extends
      com.google.protobuf.GeneratedMessage
      implements BigDecimalMsgOrBuilder {
    // Use BigDecimalMsg.newBuilder() to construct.
    private BigDecimalMsg(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private BigDecimalMsg(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final BigDecimalMsg defaultInstance;
    public static BigDecimalMsg getDefaultInstance() {
      return defaultInstance;
    }

    public BigDecimalMsg getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private BigDecimalMsg(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              bigdecimalMsg_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BigDecimalMsg_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BigDecimalMsg_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg.Builder.class);
    }

    public static com.google.protobuf.Parser<BigDecimalMsg> PARSER =
        new com.google.protobuf.AbstractParser<BigDecimalMsg>() {
      public BigDecimalMsg parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BigDecimalMsg(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<BigDecimalMsg> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes bigdecimalMsg = 1;
    public static final int BIGDECIMALMSG_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString bigdecimalMsg_;
    /**
     * <code>required bytes bigdecimalMsg = 1;</code>
     */
    public boolean hasBigdecimalMsg() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes bigdecimalMsg = 1;</code>
     */
    public com.google.protobuf.ByteString getBigdecimalMsg() {
      return bigdecimalMsg_;
    }

    private void initFields() {
      bigdecimalMsg_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasBigdecimalMsg()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, bigdecimalMsg_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, bigdecimalMsg_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg other = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg) obj;

      boolean result = true;
      result = result && (hasBigdecimalMsg() == other.hasBigdecimalMsg());
      if (hasBigdecimalMsg()) {
        result = result && getBigdecimalMsg()
            .equals(other.getBigdecimalMsg());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasBigdecimalMsg()) {
        hash = (37 * hash) + BIGDECIMALMSG_FIELD_NUMBER;
        hash = (53 * hash) + getBigdecimalMsg().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code BigDecimalMsg}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsgOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BigDecimalMsg_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BigDecimalMsg_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg.class, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        bigdecimalMsg_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.internal_static_BigDecimalMsg_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg build() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg result = new org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.bigdecimalMsg_ = bigdecimalMsg_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg.getDefaultInstance()) return this;
        if (other.hasBigdecimalMsg()) {
          setBigdecimalMsg(other.getBigdecimalMsg());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasBigdecimalMsg()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.BigDecimalMsg) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes bigdecimalMsg = 1;
      private com.google.protobuf.ByteString bigdecimalMsg_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes bigdecimalMsg = 1;</code>
       */
      public boolean hasBigdecimalMsg() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes bigdecimalMsg = 1;</code>
       */
      public com.google.protobuf.ByteString getBigdecimalMsg() {
        return bigdecimalMsg_;
      }
      /**
       * <code>required bytes bigdecimalMsg = 1;</code>
       */
      public Builder setBigdecimalMsg(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        bigdecimalMsg_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes bigdecimalMsg = 1;</code>
       */
      public Builder clearBigdecimalMsg() {
        bitField0_ = (bitField0_ & ~0x00000001);
        bigdecimalMsg_ = getDefaultInstance().getBigdecimalMsg();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:BigDecimalMsg)
    }

    static {
      defaultInstance = new BigDecimalMsg(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:BigDecimalMsg)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Cell_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Cell_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_TableSchema_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_TableSchema_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ColumnFamilySchema_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ColumnFamilySchema_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_RegionInfo_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_RegionInfo_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_RegionSpecifier_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_RegionSpecifier_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_RegionLoad_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_RegionLoad_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ServerLoad_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ServerLoad_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_TimeRange_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_TimeRange_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Filter_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Filter_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_KeyValue_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_KeyValue_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ServerName_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ServerName_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Coprocessor_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Coprocessor_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_NameStringPair_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_NameStringPair_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_NameBytesPair_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_NameBytesPair_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_BytesBytesPair_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_BytesBytesPair_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_NameInt64Pair_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_NameInt64Pair_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_SnapshotDescription_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_SnapshotDescription_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_EmptyMsg_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_EmptyMsg_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_LongMsg_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_LongMsg_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_BigDecimalMsg_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_BigDecimalMsg_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\013hbase.proto\"u\n\004Cell\022\013\n\003row\030\001 \001(\014\022\016\n\006fa" +
      "mily\030\002 \001(\014\022\021\n\tqualifier\030\003 \001(\014\022\021\n\ttimesta" +
      "mp\030\004 \001(\004\022\033\n\010cellType\030\005 \001(\0162\t.CellType\022\r\n" +
      "\005value\030\006 \001(\014\"\225\001\n\013TableSchema\022\014\n\004name\030\001 \001" +
      "(\014\022#\n\nattributes\030\002 \003(\0132\017.BytesBytesPair\022" +
      "+\n\016columnFamilies\030\003 \003(\0132\023.ColumnFamilySc" +
      "hema\022&\n\rconfiguration\030\004 \003(\0132\017.NameString" +
      "Pair\"o\n\022ColumnFamilySchema\022\014\n\004name\030\001 \002(\014" +
      "\022#\n\nattributes\030\002 \003(\0132\017.BytesBytesPair\022&\n" +
      "\rconfiguration\030\003 \003(\0132\017.NameStringPair\"s\n",
      "\nRegionInfo\022\020\n\010regionId\030\001 \002(\004\022\021\n\ttableNa" +
      "me\030\002 \002(\014\022\020\n\010startKey\030\003 \001(\014\022\016\n\006endKey\030\004 \001" +
      "(\014\022\017\n\007offline\030\005 \001(\010\022\r\n\005split\030\006 \001(\010\"\225\001\n\017R" +
      "egionSpecifier\0222\n\004type\030\001 \002(\0162$.RegionSpe" +
      "cifier.RegionSpecifierType\022\r\n\005value\030\002 \002(" +
      "\014\"?\n\023RegionSpecifierType\022\017\n\013REGION_NAME\020" +
      "\001\022\027\n\023ENCODED_REGION_NAME\020\002\"\260\003\n\nRegionLoa" +
      "d\022)\n\017regionSpecifier\030\001 \002(\0132\020.RegionSpeci" +
      "fier\022\016\n\006stores\030\002 \001(\r\022\022\n\nstorefiles\030\003 \001(\r" +
      "\022\037\n\027storeUncompressedSizeMB\030\004 \001(\r\022\027\n\017sto",
      "refileSizeMB\030\005 \001(\r\022\026\n\016memstoreSizeMB\030\006 \001" +
      "(\r\022\034\n\024storefileIndexSizeMB\030\007 \001(\r\022\031\n\021read" +
      "RequestsCount\030\010 \001(\004\022\032\n\022writeRequestsCoun" +
      "t\030\t \001(\004\022\032\n\022totalCompactingKVs\030\n \001(\004\022\033\n\023c" +
      "urrentCompactedKVs\030\013 \001(\004\022\027\n\017rootIndexSiz" +
      "eKB\030\014 \001(\r\022\036\n\026totalStaticIndexSizeKB\030\r \001(" +
      "\r\022\036\n\026totalStaticBloomSizeKB\030\016 \001(\r\022\032\n\022com" +
      "pleteSequenceId\030\017 \001(\004\"\372\001\n\nServerLoad\022\030\n\020" +
      "numberOfRequests\030\001 \001(\r\022\035\n\025totalNumberOfR" +
      "equests\030\002 \001(\r\022\022\n\nusedHeapMB\030\003 \001(\r\022\021\n\tmax",
      "HeapMB\030\004 \001(\r\022 \n\013regionLoads\030\005 \003(\0132\013.Regi" +
      "onLoad\022\"\n\014coprocessors\030\006 \003(\0132\014.Coprocess" +
      "or\022\027\n\017reportStartTime\030\007 \001(\004\022\025\n\rreportEnd" +
      "Time\030\010 \001(\004\022\026\n\016infoServerPort\030\t \001(\r\"%\n\tTi" +
      "meRange\022\014\n\004from\030\001 \001(\004\022\n\n\002to\030\002 \001(\004\"0\n\006Fil" +
      "ter\022\014\n\004name\030\001 \002(\t\022\030\n\020serializedFilter\030\002 " +
      "\001(\014\"x\n\010KeyValue\022\013\n\003row\030\001 \002(\014\022\016\n\006family\030\002" +
      " \002(\014\022\021\n\tqualifier\030\003 \002(\014\022\021\n\ttimestamp\030\004 \001" +
      "(\004\022\032\n\007keyType\030\005 \001(\0162\t.CellType\022\r\n\005value\030" +
      "\006 \001(\014\"?\n\nServerName\022\020\n\010hostName\030\001 \002(\t\022\014\n",
      "\004port\030\002 \001(\r\022\021\n\tstartCode\030\003 \001(\004\"\033\n\013Coproc" +
      "essor\022\014\n\004name\030\001 \002(\t\"-\n\016NameStringPair\022\014\n" +
      "\004name\030\001 \002(\t\022\r\n\005value\030\002 \002(\t\",\n\rNameBytesP" +
      "air\022\014\n\004name\030\001 \002(\t\022\r\n\005value\030\002 \001(\014\"/\n\016Byte" +
      "sBytesPair\022\r\n\005first\030\001 \002(\014\022\016\n\006second\030\002 \002(" +
      "\014\",\n\rNameInt64Pair\022\014\n\004name\030\001 \001(\t\022\r\n\005valu" +
      "e\030\002 \001(\003\"\255\001\n\023SnapshotDescription\022\014\n\004name\030" +
      "\001 \002(\t\022\r\n\005table\030\002 \001(\t\022\027\n\014creationTime\030\003 \001" +
      "(\003:\0010\022.\n\004type\030\004 \001(\0162\031.SnapshotDescriptio" +
      "n.Type:\005FLUSH\022\017\n\007version\030\005 \001(\005\"\037\n\004Type\022\014",
      "\n\010DISABLED\020\000\022\t\n\005FLUSH\020\001\"\n\n\010EmptyMsg\"\032\n\007L" +
      "ongMsg\022\017\n\007longMsg\030\001 \002(\003\"&\n\rBigDecimalMsg" +
      "\022\025\n\rbigdecimalMsg\030\001 \002(\014*`\n\010CellType\022\013\n\007M" +
      "INIMUM\020\000\022\007\n\003PUT\020\004\022\n\n\006DELETE\020\010\022\021\n\rDELETE_" +
      "COLUMN\020\014\022\021\n\rDELETE_FAMILY\020\016\022\014\n\007MAXIMUM\020\377" +
      "\001*r\n\013CompareType\022\010\n\004LESS\020\000\022\021\n\rLESS_OR_EQ" +
      "UAL\020\001\022\t\n\005EQUAL\020\002\022\r\n\tNOT_EQUAL\020\003\022\024\n\020GREAT" +
      "ER_OR_EQUAL\020\004\022\013\n\007GREATER\020\005\022\t\n\005NO_OP\020\006B>\n" +
      "*org.apache.hadoop.hbase.protobuf.genera" +
      "tedB\013HBaseProtosH\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_Cell_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_Cell_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Cell_descriptor,
              new java.lang.String[] { "Row", "Family", "Qualifier", "Timestamp", "CellType", "Value", });
          internal_static_TableSchema_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_TableSchema_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_TableSchema_descriptor,
              new java.lang.String[] { "Name", "Attributes", "ColumnFamilies", "Configuration", });
          internal_static_ColumnFamilySchema_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_ColumnFamilySchema_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ColumnFamilySchema_descriptor,
              new java.lang.String[] { "Name", "Attributes", "Configuration", });
          internal_static_RegionInfo_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_RegionInfo_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_RegionInfo_descriptor,
              new java.lang.String[] { "RegionId", "TableName", "StartKey", "EndKey", "Offline", "Split", });
          internal_static_RegionSpecifier_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_RegionSpecifier_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_RegionSpecifier_descriptor,
              new java.lang.String[] { "Type", "Value", });
          internal_static_RegionLoad_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_RegionLoad_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_RegionLoad_descriptor,
              new java.lang.String[] { "RegionSpecifier", "Stores", "Storefiles", "StoreUncompressedSizeMB", "StorefileSizeMB", "MemstoreSizeMB", "StorefileIndexSizeMB", "ReadRequestsCount", "WriteRequestsCount", "TotalCompactingKVs", "CurrentCompactedKVs", "RootIndexSizeKB", "TotalStaticIndexSizeKB", "TotalStaticBloomSizeKB", "CompleteSequenceId", });
          internal_static_ServerLoad_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_ServerLoad_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ServerLoad_descriptor,
              new java.lang.String[] { "NumberOfRequests", "TotalNumberOfRequests", "UsedHeapMB", "MaxHeapMB", "RegionLoads", "Coprocessors", "ReportStartTime", "ReportEndTime", "InfoServerPort", });
          internal_static_TimeRange_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_TimeRange_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_TimeRange_descriptor,
              new java.lang.String[] { "From", "To", });
          internal_static_Filter_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_Filter_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Filter_descriptor,
              new java.lang.String[] { "Name", "SerializedFilter", });
          internal_static_KeyValue_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_KeyValue_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_KeyValue_descriptor,
              new java.lang.String[] { "Row", "Family", "Qualifier", "Timestamp", "KeyType", "Value", });
          internal_static_ServerName_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_ServerName_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ServerName_descriptor,
              new java.lang.String[] { "HostName", "Port", "StartCode", });
          internal_static_Coprocessor_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_Coprocessor_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Coprocessor_descriptor,
              new java.lang.String[] { "Name", });
          internal_static_NameStringPair_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_NameStringPair_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_NameStringPair_descriptor,
              new java.lang.String[] { "Name", "Value", });
          internal_static_NameBytesPair_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_NameBytesPair_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_NameBytesPair_descriptor,
              new java.lang.String[] { "Name", "Value", });
          internal_static_BytesBytesPair_descriptor =
            getDescriptor().getMessageTypes().get(14);
          internal_static_BytesBytesPair_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_BytesBytesPair_descriptor,
              new java.lang.String[] { "First", "Second", });
          internal_static_NameInt64Pair_descriptor =
            getDescriptor().getMessageTypes().get(15);
          internal_static_NameInt64Pair_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_NameInt64Pair_descriptor,
              new java.lang.String[] { "Name", "Value", });
          internal_static_SnapshotDescription_descriptor =
            getDescriptor().getMessageTypes().get(16);
          internal_static_SnapshotDescription_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_SnapshotDescription_descriptor,
              new java.lang.String[] { "Name", "Table", "CreationTime", "Type", "Version", });
          internal_static_EmptyMsg_descriptor =
            getDescriptor().getMessageTypes().get(17);
          internal_static_EmptyMsg_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_EmptyMsg_descriptor,
              new java.lang.String[] { });
          internal_static_LongMsg_descriptor =
            getDescriptor().getMessageTypes().get(18);
          internal_static_LongMsg_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_LongMsg_descriptor,
              new java.lang.String[] { "LongMsg", });
          internal_static_BigDecimalMsg_descriptor =
            getDescriptor().getMessageTypes().get(19);
          internal_static_BigDecimalMsg_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_BigDecimalMsg_descriptor,
              new java.lang.String[] { "BigdecimalMsg", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}

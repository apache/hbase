// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: AccessControl.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class AccessControlProtos {
  private AccessControlProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public interface PermissionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.Permission.Type type = 1;
    /**
     * <code>required .hbase.pb.Permission.Type type = 1;</code>
     */
    boolean hasType();
    /**
     * <code>required .hbase.pb.Permission.Type type = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type getType();

    // optional .hbase.pb.GlobalPermission global_permission = 2;
    /**
     * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
     */
    boolean hasGlobalPermission();
    /**
     * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission getGlobalPermission();
    /**
     * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermissionOrBuilder getGlobalPermissionOrBuilder();

    // optional .hbase.pb.NamespacePermission namespace_permission = 3;
    /**
     * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
     */
    boolean hasNamespacePermission();
    /**
     * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission getNamespacePermission();
    /**
     * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermissionOrBuilder getNamespacePermissionOrBuilder();

    // optional .hbase.pb.TablePermission table_permission = 4;
    /**
     * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
     */
    boolean hasTablePermission();
    /**
     * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission getTablePermission();
    /**
     * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermissionOrBuilder getTablePermissionOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.Permission}
   */
  public static final class Permission extends
      com.google.protobuf.GeneratedMessage
      implements PermissionOrBuilder {
    // Use Permission.newBuilder() to construct.
    private Permission(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Permission(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Permission defaultInstance;
    public static Permission getDefaultInstance() {
      return defaultInstance;
    }

    public Permission getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Permission(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type value = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                type_ = value;
              }
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = globalPermission_.toBuilder();
              }
              globalPermission_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(globalPermission_);
                globalPermission_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = namespacePermission_.toBuilder();
              }
              namespacePermission_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(namespacePermission_);
                namespacePermission_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = tablePermission_.toBuilder();
              }
              tablePermission_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tablePermission_);
                tablePermission_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_Permission_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_Permission_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder.class);
    }

    public static com.google.protobuf.Parser<Permission> PARSER =
        new com.google.protobuf.AbstractParser<Permission>() {
      public Permission parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Permission(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Permission> getParserForType() {
      return PARSER;
    }

    /**
     * Protobuf enum {@code hbase.pb.Permission.Action}
     */
    public enum Action
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>READ = 0;</code>
       */
      READ(0, 0),
      /**
       * <code>WRITE = 1;</code>
       */
      WRITE(1, 1),
      /**
       * <code>EXEC = 2;</code>
       */
      EXEC(2, 2),
      /**
       * <code>CREATE = 3;</code>
       */
      CREATE(3, 3),
      /**
       * <code>ADMIN = 4;</code>
       */
      ADMIN(4, 4),
      ;

      /**
       * <code>READ = 0;</code>
       */
      public static final int READ_VALUE = 0;
      /**
       * <code>WRITE = 1;</code>
       */
      public static final int WRITE_VALUE = 1;
      /**
       * <code>EXEC = 2;</code>
       */
      public static final int EXEC_VALUE = 2;
      /**
       * <code>CREATE = 3;</code>
       */
      public static final int CREATE_VALUE = 3;
      /**
       * <code>ADMIN = 4;</code>
       */
      public static final int ADMIN_VALUE = 4;


      public final int getNumber() { return value; }

      public static Action valueOf(int value) {
        switch (value) {
          case 0: return READ;
          case 1: return WRITE;
          case 2: return EXEC;
          case 3: return CREATE;
          case 4: return ADMIN;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Action>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<Action>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Action>() {
              public Action findValueByNumber(int number) {
                return Action.valueOf(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDescriptor().getEnumTypes().get(0);
      }

      private static final Action[] VALUES = values();

      public static Action valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int index;
      private final int value;

      private Action(int index, int value) {
        this.index = index;
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.Permission.Action)
    }

    /**
     * Protobuf enum {@code hbase.pb.Permission.Type}
     */
    public enum Type
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>Global = 1;</code>
       */
      Global(0, 1),
      /**
       * <code>Namespace = 2;</code>
       */
      Namespace(1, 2),
      /**
       * <code>Table = 3;</code>
       */
      Table(2, 3),
      ;

      /**
       * <code>Global = 1;</code>
       */
      public static final int Global_VALUE = 1;
      /**
       * <code>Namespace = 2;</code>
       */
      public static final int Namespace_VALUE = 2;
      /**
       * <code>Table = 3;</code>
       */
      public static final int Table_VALUE = 3;


      public final int getNumber() { return value; }

      public static Type valueOf(int value) {
        switch (value) {
          case 1: return Global;
          case 2: return Namespace;
          case 3: return Table;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Type>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<Type>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Type>() {
              public Type findValueByNumber(int number) {
                return Type.valueOf(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDescriptor().getEnumTypes().get(1);
      }

      private static final Type[] VALUES = values();

      public static Type valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int index;
      private final int value;

      private Type(int index, int value) {
        this.index = index;
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:hbase.pb.Permission.Type)
    }

    private int bitField0_;
    // required .hbase.pb.Permission.Type type = 1;
    public static final int TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type type_;
    /**
     * <code>required .hbase.pb.Permission.Type type = 1;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.Permission.Type type = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type getType() {
      return type_;
    }

    // optional .hbase.pb.GlobalPermission global_permission = 2;
    public static final int GLOBAL_PERMISSION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission globalPermission_;
    /**
     * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
     */
    public boolean hasGlobalPermission() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission getGlobalPermission() {
      return globalPermission_;
    }
    /**
     * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermissionOrBuilder getGlobalPermissionOrBuilder() {
      return globalPermission_;
    }

    // optional .hbase.pb.NamespacePermission namespace_permission = 3;
    public static final int NAMESPACE_PERMISSION_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission namespacePermission_;
    /**
     * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
     */
    public boolean hasNamespacePermission() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission getNamespacePermission() {
      return namespacePermission_;
    }
    /**
     * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermissionOrBuilder getNamespacePermissionOrBuilder() {
      return namespacePermission_;
    }

    // optional .hbase.pb.TablePermission table_permission = 4;
    public static final int TABLE_PERMISSION_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission tablePermission_;
    /**
     * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
     */
    public boolean hasTablePermission() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission getTablePermission() {
      return tablePermission_;
    }
    /**
     * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermissionOrBuilder getTablePermissionOrBuilder() {
      return tablePermission_;
    }

    private void initFields() {
      type_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.Global;
      globalPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.getDefaultInstance();
      namespacePermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.getDefaultInstance();
      tablePermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasTablePermission()) {
        if (!getTablePermission().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, type_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, globalPermission_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, namespacePermission_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, tablePermission_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, type_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, globalPermission_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, namespacePermission_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, tablePermission_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission) obj;

      boolean result = true;
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result &&
            (getType() == other.getType());
      }
      result = result && (hasGlobalPermission() == other.hasGlobalPermission());
      if (hasGlobalPermission()) {
        result = result && getGlobalPermission()
            .equals(other.getGlobalPermission());
      }
      result = result && (hasNamespacePermission() == other.hasNamespacePermission());
      if (hasNamespacePermission()) {
        result = result && getNamespacePermission()
            .equals(other.getNamespacePermission());
      }
      result = result && (hasTablePermission() == other.hasTablePermission());
      if (hasTablePermission()) {
        result = result && getTablePermission()
            .equals(other.getTablePermission());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getType());
      }
      if (hasGlobalPermission()) {
        hash = (37 * hash) + GLOBAL_PERMISSION_FIELD_NUMBER;
        hash = (53 * hash) + getGlobalPermission().hashCode();
      }
      if (hasNamespacePermission()) {
        hash = (37 * hash) + NAMESPACE_PERMISSION_FIELD_NUMBER;
        hash = (53 * hash) + getNamespacePermission().hashCode();
      }
      if (hasTablePermission()) {
        hash = (37 * hash) + TABLE_PERMISSION_FIELD_NUMBER;
        hash = (53 * hash) + getTablePermission().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.Permission}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_Permission_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_Permission_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getGlobalPermissionFieldBuilder();
          getNamespacePermissionFieldBuilder();
          getTablePermissionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        type_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.Global;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (globalPermissionBuilder_ == null) {
          globalPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.getDefaultInstance();
        } else {
          globalPermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (namespacePermissionBuilder_ == null) {
          namespacePermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.getDefaultInstance();
        } else {
          namespacePermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (tablePermissionBuilder_ == null) {
          tablePermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.getDefaultInstance();
        } else {
          tablePermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_Permission_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (globalPermissionBuilder_ == null) {
          result.globalPermission_ = globalPermission_;
        } else {
          result.globalPermission_ = globalPermissionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (namespacePermissionBuilder_ == null) {
          result.namespacePermission_ = namespacePermission_;
        } else {
          result.namespacePermission_ = namespacePermissionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (tablePermissionBuilder_ == null) {
          result.tablePermission_ = tablePermission_;
        } else {
          result.tablePermission_ = tablePermissionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance()) return this;
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasGlobalPermission()) {
          mergeGlobalPermission(other.getGlobalPermission());
        }
        if (other.hasNamespacePermission()) {
          mergeNamespacePermission(other.getNamespacePermission());
        }
        if (other.hasTablePermission()) {
          mergeTablePermission(other.getTablePermission());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasType()) {
          
          return false;
        }
        if (hasTablePermission()) {
          if (!getTablePermission().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.Permission.Type type = 1;
      private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type type_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.Global;
      /**
       * <code>required .hbase.pb.Permission.Type type = 1;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.Permission.Type type = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type getType() {
        return type_;
      }
      /**
       * <code>required .hbase.pb.Permission.Type type = 1;</code>
       */
      public Builder setType(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        type_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required .hbase.pb.Permission.Type type = 1;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.Global;
        onChanged();
        return this;
      }

      // optional .hbase.pb.GlobalPermission global_permission = 2;
      private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission globalPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermissionOrBuilder> globalPermissionBuilder_;
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      public boolean hasGlobalPermission() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission getGlobalPermission() {
        if (globalPermissionBuilder_ == null) {
          return globalPermission_;
        } else {
          return globalPermissionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      public Builder setGlobalPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission value) {
        if (globalPermissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          globalPermission_ = value;
          onChanged();
        } else {
          globalPermissionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      public Builder setGlobalPermission(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.Builder builderForValue) {
        if (globalPermissionBuilder_ == null) {
          globalPermission_ = builderForValue.build();
          onChanged();
        } else {
          globalPermissionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      public Builder mergeGlobalPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission value) {
        if (globalPermissionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              globalPermission_ != org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.getDefaultInstance()) {
            globalPermission_ =
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.newBuilder(globalPermission_).mergeFrom(value).buildPartial();
          } else {
            globalPermission_ = value;
          }
          onChanged();
        } else {
          globalPermissionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      public Builder clearGlobalPermission() {
        if (globalPermissionBuilder_ == null) {
          globalPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.getDefaultInstance();
          onChanged();
        } else {
          globalPermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.Builder getGlobalPermissionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getGlobalPermissionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermissionOrBuilder getGlobalPermissionOrBuilder() {
        if (globalPermissionBuilder_ != null) {
          return globalPermissionBuilder_.getMessageOrBuilder();
        } else {
          return globalPermission_;
        }
      }
      /**
       * <code>optional .hbase.pb.GlobalPermission global_permission = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermissionOrBuilder> 
          getGlobalPermissionFieldBuilder() {
        if (globalPermissionBuilder_ == null) {
          globalPermissionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermissionOrBuilder>(
                  globalPermission_,
                  getParentForChildren(),
                  isClean());
          globalPermission_ = null;
        }
        return globalPermissionBuilder_;
      }

      // optional .hbase.pb.NamespacePermission namespace_permission = 3;
      private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission namespacePermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermissionOrBuilder> namespacePermissionBuilder_;
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      public boolean hasNamespacePermission() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission getNamespacePermission() {
        if (namespacePermissionBuilder_ == null) {
          return namespacePermission_;
        } else {
          return namespacePermissionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      public Builder setNamespacePermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission value) {
        if (namespacePermissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          namespacePermission_ = value;
          onChanged();
        } else {
          namespacePermissionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      public Builder setNamespacePermission(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.Builder builderForValue) {
        if (namespacePermissionBuilder_ == null) {
          namespacePermission_ = builderForValue.build();
          onChanged();
        } else {
          namespacePermissionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      public Builder mergeNamespacePermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission value) {
        if (namespacePermissionBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              namespacePermission_ != org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.getDefaultInstance()) {
            namespacePermission_ =
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.newBuilder(namespacePermission_).mergeFrom(value).buildPartial();
          } else {
            namespacePermission_ = value;
          }
          onChanged();
        } else {
          namespacePermissionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      public Builder clearNamespacePermission() {
        if (namespacePermissionBuilder_ == null) {
          namespacePermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.getDefaultInstance();
          onChanged();
        } else {
          namespacePermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.Builder getNamespacePermissionBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getNamespacePermissionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermissionOrBuilder getNamespacePermissionOrBuilder() {
        if (namespacePermissionBuilder_ != null) {
          return namespacePermissionBuilder_.getMessageOrBuilder();
        } else {
          return namespacePermission_;
        }
      }
      /**
       * <code>optional .hbase.pb.NamespacePermission namespace_permission = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermissionOrBuilder> 
          getNamespacePermissionFieldBuilder() {
        if (namespacePermissionBuilder_ == null) {
          namespacePermissionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermissionOrBuilder>(
                  namespacePermission_,
                  getParentForChildren(),
                  isClean());
          namespacePermission_ = null;
        }
        return namespacePermissionBuilder_;
      }

      // optional .hbase.pb.TablePermission table_permission = 4;
      private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission tablePermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermissionOrBuilder> tablePermissionBuilder_;
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      public boolean hasTablePermission() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission getTablePermission() {
        if (tablePermissionBuilder_ == null) {
          return tablePermission_;
        } else {
          return tablePermissionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      public Builder setTablePermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission value) {
        if (tablePermissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tablePermission_ = value;
          onChanged();
        } else {
          tablePermissionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      public Builder setTablePermission(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.Builder builderForValue) {
        if (tablePermissionBuilder_ == null) {
          tablePermission_ = builderForValue.build();
          onChanged();
        } else {
          tablePermissionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      public Builder mergeTablePermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission value) {
        if (tablePermissionBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              tablePermission_ != org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.getDefaultInstance()) {
            tablePermission_ =
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.newBuilder(tablePermission_).mergeFrom(value).buildPartial();
          } else {
            tablePermission_ = value;
          }
          onChanged();
        } else {
          tablePermissionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      public Builder clearTablePermission() {
        if (tablePermissionBuilder_ == null) {
          tablePermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.getDefaultInstance();
          onChanged();
        } else {
          tablePermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.Builder getTablePermissionBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getTablePermissionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermissionOrBuilder getTablePermissionOrBuilder() {
        if (tablePermissionBuilder_ != null) {
          return tablePermissionBuilder_.getMessageOrBuilder();
        } else {
          return tablePermission_;
        }
      }
      /**
       * <code>optional .hbase.pb.TablePermission table_permission = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermissionOrBuilder> 
          getTablePermissionFieldBuilder() {
        if (tablePermissionBuilder_ == null) {
          tablePermissionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermissionOrBuilder>(
                  tablePermission_,
                  getParentForChildren(),
                  isClean());
          tablePermission_ = null;
        }
        return tablePermissionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.Permission)
    }

    static {
      defaultInstance = new Permission(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.Permission)
  }

  public interface TablePermissionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hbase.pb.TableName table_name = 1;
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     */
    boolean hasTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // optional bytes family = 2;
    /**
     * <code>optional bytes family = 2;</code>
     */
    boolean hasFamily();
    /**
     * <code>optional bytes family = 2;</code>
     */
    com.google.protobuf.ByteString getFamily();

    // optional bytes qualifier = 3;
    /**
     * <code>optional bytes qualifier = 3;</code>
     */
    boolean hasQualifier();
    /**
     * <code>optional bytes qualifier = 3;</code>
     */
    com.google.protobuf.ByteString getQualifier();

    // repeated .hbase.pb.Permission.Action action = 4;
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList();
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
     */
    int getActionCount();
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.TablePermission}
   */
  public static final class TablePermission extends
      com.google.protobuf.GeneratedMessage
      implements TablePermissionOrBuilder {
    // Use TablePermission.newBuilder() to construct.
    private TablePermission(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private TablePermission(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final TablePermission defaultInstance;
    public static TablePermission getDefaultInstance() {
      return defaultInstance;
    }

    public TablePermission getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private TablePermission(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              family_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              qualifier_ = input.readBytes();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                  action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>();
                  mutable_bitField0_ |= 0x00000008;
                }
                action_.add(value);
              }
              break;
            }
            case 34: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(4, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                    action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>();
                    mutable_bitField0_ |= 0x00000008;
                  }
                  action_.add(value);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          action_ = java.util.Collections.unmodifiableList(action_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_TablePermission_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_TablePermission_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.Builder.class);
    }

    public static com.google.protobuf.Parser<TablePermission> PARSER =
        new com.google.protobuf.AbstractParser<TablePermission>() {
      public TablePermission parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new TablePermission(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<TablePermission> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hbase.pb.TableName table_name = 1;
    public static final int TABLE_NAME_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // optional bytes family = 2;
    public static final int FAMILY_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString family_;
    /**
     * <code>optional bytes family = 2;</code>
     */
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes family = 2;</code>
     */
    public com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    // optional bytes qualifier = 3;
    public static final int QUALIFIER_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString qualifier_;
    /**
     * <code>optional bytes qualifier = 3;</code>
     */
    public boolean hasQualifier() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bytes qualifier = 3;</code>
     */
    public com.google.protobuf.ByteString getQualifier() {
      return qualifier_;
    }

    // repeated .hbase.pb.Permission.Action action = 4;
    public static final int ACTION_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> action_;
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList() {
      return action_;
    }
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
     */
    public int getActionCount() {
      return action_.size();
    }
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index) {
      return action_.get(index);
    }

    private void initFields() {
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      family_ = com.google.protobuf.ByteString.EMPTY;
      qualifier_ = com.google.protobuf.ByteString.EMPTY;
      action_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasTableName()) {
        if (!getTableName().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, tableName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, qualifier_);
      }
      for (int i = 0; i < action_.size(); i++) {
        output.writeEnum(4, action_.get(i).getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, tableName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, qualifier_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < action_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(action_.get(i).getNumber());
        }
        size += dataSize;
        size += 1 * action_.size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission) obj;

      boolean result = true;
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasFamily() == other.hasFamily());
      if (hasFamily()) {
        result = result && getFamily()
            .equals(other.getFamily());
      }
      result = result && (hasQualifier() == other.hasQualifier());
      if (hasQualifier()) {
        result = result && getQualifier()
            .equals(other.getQualifier());
      }
      result = result && getActionList()
          .equals(other.getActionList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (hasQualifier()) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifier().hashCode();
      }
      if (getActionCount() > 0) {
        hash = (37 * hash) + ACTION_FIELD_NUMBER;
        hash = (53 * hash) + hashEnumList(getActionList());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.TablePermission}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermissionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_TablePermission_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_TablePermission_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        qualifier_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        action_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_TablePermission_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.family_ = family_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.qualifier_ = qualifier_;
        if (((bitField0_ & 0x00000008) == 0x00000008)) {
          action_ = java.util.Collections.unmodifiableList(action_);
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.action_ = action_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission.getDefaultInstance()) return this;
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (other.hasQualifier()) {
          setQualifier(other.getQualifier());
        }
        if (!other.action_.isEmpty()) {
          if (action_.isEmpty()) {
            action_ = other.action_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureActionIsMutable();
            action_.addAll(other.action_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasTableName()) {
          if (!getTableName().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.TablePermission) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hbase.pb.TableName table_name = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // optional bytes family = 2;
      private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes family = 2;</code>
       */
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes family = 2;</code>
       */
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>optional bytes family = 2;</code>
       */
      public Builder setFamily(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        family_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes family = 2;</code>
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000002);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      // optional bytes qualifier = 3;
      private com.google.protobuf.ByteString qualifier_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes qualifier = 3;</code>
       */
      public boolean hasQualifier() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       */
      public com.google.protobuf.ByteString getQualifier() {
        return qualifier_;
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       */
      public Builder setQualifier(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        qualifier_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes qualifier = 3;</code>
       */
      public Builder clearQualifier() {
        bitField0_ = (bitField0_ & ~0x00000004);
        qualifier_ = getDefaultInstance().getQualifier();
        onChanged();
        return this;
      }

      // repeated .hbase.pb.Permission.Action action = 4;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> action_ =
        java.util.Collections.emptyList();
      private void ensureActionIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>(action_);
          bitField0_ |= 0x00000008;
        }
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList() {
        return java.util.Collections.unmodifiableList(action_);
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
       */
      public int getActionCount() {
        return action_.size();
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index) {
        return action_.get(index);
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
       */
      public Builder setAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureActionIsMutable();
        action_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
       */
      public Builder addAction(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureActionIsMutable();
        action_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
       */
      public Builder addAllAction(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> values) {
        ensureActionIsMutable();
        super.addAll(values, action_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 4;</code>
       */
      public Builder clearAction() {
        action_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.TablePermission)
    }

    static {
      defaultInstance = new TablePermission(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.TablePermission)
  }

  public interface NamespacePermissionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bytes namespace_name = 1;
    /**
     * <code>optional bytes namespace_name = 1;</code>
     */
    boolean hasNamespaceName();
    /**
     * <code>optional bytes namespace_name = 1;</code>
     */
    com.google.protobuf.ByteString getNamespaceName();

    // repeated .hbase.pb.Permission.Action action = 2;
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList();
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
     */
    int getActionCount();
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.NamespacePermission}
   */
  public static final class NamespacePermission extends
      com.google.protobuf.GeneratedMessage
      implements NamespacePermissionOrBuilder {
    // Use NamespacePermission.newBuilder() to construct.
    private NamespacePermission(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private NamespacePermission(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final NamespacePermission defaultInstance;
    public static NamespacePermission getDefaultInstance() {
      return defaultInstance;
    }

    public NamespacePermission getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private NamespacePermission(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              namespaceName_ = input.readBytes();
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>();
                  mutable_bitField0_ |= 0x00000002;
                }
                action_.add(value);
              }
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(2, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                    action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>();
                    mutable_bitField0_ |= 0x00000002;
                  }
                  action_.add(value);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          action_ = java.util.Collections.unmodifiableList(action_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_NamespacePermission_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_NamespacePermission_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.Builder.class);
    }

    public static com.google.protobuf.Parser<NamespacePermission> PARSER =
        new com.google.protobuf.AbstractParser<NamespacePermission>() {
      public NamespacePermission parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new NamespacePermission(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<NamespacePermission> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional bytes namespace_name = 1;
    public static final int NAMESPACE_NAME_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString namespaceName_;
    /**
     * <code>optional bytes namespace_name = 1;</code>
     */
    public boolean hasNamespaceName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bytes namespace_name = 1;</code>
     */
    public com.google.protobuf.ByteString getNamespaceName() {
      return namespaceName_;
    }

    // repeated .hbase.pb.Permission.Action action = 2;
    public static final int ACTION_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> action_;
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList() {
      return action_;
    }
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
     */
    public int getActionCount() {
      return action_.size();
    }
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index) {
      return action_.get(index);
    }

    private void initFields() {
      namespaceName_ = com.google.protobuf.ByteString.EMPTY;
      action_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, namespaceName_);
      }
      for (int i = 0; i < action_.size(); i++) {
        output.writeEnum(2, action_.get(i).getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, namespaceName_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < action_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(action_.get(i).getNumber());
        }
        size += dataSize;
        size += 1 * action_.size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission) obj;

      boolean result = true;
      result = result && (hasNamespaceName() == other.hasNamespaceName());
      if (hasNamespaceName()) {
        result = result && getNamespaceName()
            .equals(other.getNamespaceName());
      }
      result = result && getActionList()
          .equals(other.getActionList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasNamespaceName()) {
        hash = (37 * hash) + NAMESPACE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceName().hashCode();
      }
      if (getActionCount() > 0) {
        hash = (37 * hash) + ACTION_FIELD_NUMBER;
        hash = (53 * hash) + hashEnumList(getActionList());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.NamespacePermission}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermissionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_NamespacePermission_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_NamespacePermission_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        namespaceName_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        action_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_NamespacePermission_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.namespaceName_ = namespaceName_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          action_ = java.util.Collections.unmodifiableList(action_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.action_ = action_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission.getDefaultInstance()) return this;
        if (other.hasNamespaceName()) {
          setNamespaceName(other.getNamespaceName());
        }
        if (!other.action_.isEmpty()) {
          if (action_.isEmpty()) {
            action_ = other.action_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureActionIsMutable();
            action_.addAll(other.action_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.NamespacePermission) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bytes namespace_name = 1;
      private com.google.protobuf.ByteString namespaceName_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes namespace_name = 1;</code>
       */
      public boolean hasNamespaceName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bytes namespace_name = 1;</code>
       */
      public com.google.protobuf.ByteString getNamespaceName() {
        return namespaceName_;
      }
      /**
       * <code>optional bytes namespace_name = 1;</code>
       */
      public Builder setNamespaceName(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        namespaceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes namespace_name = 1;</code>
       */
      public Builder clearNamespaceName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        namespaceName_ = getDefaultInstance().getNamespaceName();
        onChanged();
        return this;
      }

      // repeated .hbase.pb.Permission.Action action = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> action_ =
        java.util.Collections.emptyList();
      private void ensureActionIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>(action_);
          bitField0_ |= 0x00000002;
        }
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList() {
        return java.util.Collections.unmodifiableList(action_);
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
       */
      public int getActionCount() {
        return action_.size();
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index) {
        return action_.get(index);
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
       */
      public Builder setAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureActionIsMutable();
        action_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
       */
      public Builder addAction(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureActionIsMutable();
        action_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
       */
      public Builder addAllAction(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> values) {
        ensureActionIsMutable();
        super.addAll(values, action_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 2;</code>
       */
      public Builder clearAction() {
        action_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.NamespacePermission)
    }

    static {
      defaultInstance = new NamespacePermission(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.NamespacePermission)
  }

  public interface GlobalPermissionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hbase.pb.Permission.Action action = 1;
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList();
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
     */
    int getActionCount();
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index);
  }
  /**
   * Protobuf type {@code hbase.pb.GlobalPermission}
   */
  public static final class GlobalPermission extends
      com.google.protobuf.GeneratedMessage
      implements GlobalPermissionOrBuilder {
    // Use GlobalPermission.newBuilder() to construct.
    private GlobalPermission(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GlobalPermission(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GlobalPermission defaultInstance;
    public static GlobalPermission getDefaultInstance() {
      return defaultInstance;
    }

    public GlobalPermission getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GlobalPermission(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                  action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>();
                  mutable_bitField0_ |= 0x00000001;
                }
                action_.add(value);
              }
              break;
            }
            case 10: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(1, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                    action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>();
                    mutable_bitField0_ |= 0x00000001;
                  }
                  action_.add(value);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          action_ = java.util.Collections.unmodifiableList(action_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GlobalPermission_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GlobalPermission_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.Builder.class);
    }

    public static com.google.protobuf.Parser<GlobalPermission> PARSER =
        new com.google.protobuf.AbstractParser<GlobalPermission>() {
      public GlobalPermission parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GlobalPermission(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GlobalPermission> getParserForType() {
      return PARSER;
    }

    // repeated .hbase.pb.Permission.Action action = 1;
    public static final int ACTION_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> action_;
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList() {
      return action_;
    }
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
     */
    public int getActionCount() {
      return action_.size();
    }
    /**
     * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index) {
      return action_.get(index);
    }

    private void initFields() {
      action_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < action_.size(); i++) {
        output.writeEnum(1, action_.get(i).getNumber());
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < action_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(action_.get(i).getNumber());
        }
        size += dataSize;
        size += 1 * action_.size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission) obj;

      boolean result = true;
      result = result && getActionList()
          .equals(other.getActionList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getActionCount() > 0) {
        hash = (37 * hash) + ACTION_FIELD_NUMBER;
        hash = (53 * hash) + hashEnumList(getActionList());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GlobalPermission}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermissionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GlobalPermission_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GlobalPermission_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        action_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GlobalPermission_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          action_ = java.util.Collections.unmodifiableList(action_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.action_ = action_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission.getDefaultInstance()) return this;
        if (!other.action_.isEmpty()) {
          if (action_.isEmpty()) {
            action_ = other.action_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureActionIsMutable();
            action_.addAll(other.action_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GlobalPermission) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hbase.pb.Permission.Action action = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> action_ =
        java.util.Collections.emptyList();
      private void ensureActionIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action>(action_);
          bitField0_ |= 0x00000001;
        }
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> getActionList() {
        return java.util.Collections.unmodifiableList(action_);
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
       */
      public int getActionCount() {
        return action_.size();
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action getAction(int index) {
        return action_.get(index);
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
       */
      public Builder setAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureActionIsMutable();
        action_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
       */
      public Builder addAction(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureActionIsMutable();
        action_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
       */
      public Builder addAllAction(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Action> values) {
        ensureActionIsMutable();
        super.addAll(values, action_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission.Action action = 1;</code>
       */
      public Builder clearAction() {
        action_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.GlobalPermission)
    }

    static {
      defaultInstance = new GlobalPermission(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GlobalPermission)
  }

  public interface UserPermissionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes user = 1;
    /**
     * <code>required bytes user = 1;</code>
     */
    boolean hasUser();
    /**
     * <code>required bytes user = 1;</code>
     */
    com.google.protobuf.ByteString getUser();

    // required .hbase.pb.Permission permission = 3;
    /**
     * <code>required .hbase.pb.Permission permission = 3;</code>
     */
    boolean hasPermission();
    /**
     * <code>required .hbase.pb.Permission permission = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermission();
    /**
     * <code>required .hbase.pb.Permission permission = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.UserPermission}
   */
  public static final class UserPermission extends
      com.google.protobuf.GeneratedMessage
      implements UserPermissionOrBuilder {
    // Use UserPermission.newBuilder() to construct.
    private UserPermission(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private UserPermission(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final UserPermission defaultInstance;
    public static UserPermission getDefaultInstance() {
      return defaultInstance;
    }

    public UserPermission getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private UserPermission(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              user_ = input.readBytes();
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = permission_.toBuilder();
              }
              permission_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(permission_);
                permission_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UserPermission_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UserPermission_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder.class);
    }

    public static com.google.protobuf.Parser<UserPermission> PARSER =
        new com.google.protobuf.AbstractParser<UserPermission>() {
      public UserPermission parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new UserPermission(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<UserPermission> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes user = 1;
    public static final int USER_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString user_;
    /**
     * <code>required bytes user = 1;</code>
     */
    public boolean hasUser() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes user = 1;</code>
     */
    public com.google.protobuf.ByteString getUser() {
      return user_;
    }

    // required .hbase.pb.Permission permission = 3;
    public static final int PERMISSION_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission permission_;
    /**
     * <code>required .hbase.pb.Permission permission = 3;</code>
     */
    public boolean hasPermission() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .hbase.pb.Permission permission = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermission() {
      return permission_;
    }
    /**
     * <code>required .hbase.pb.Permission permission = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionOrBuilder() {
      return permission_;
    }

    private void initFields() {
      user_ = com.google.protobuf.ByteString.EMPTY;
      permission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUser()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasPermission()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getPermission().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, user_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(3, permission_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, user_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, permission_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission) obj;

      boolean result = true;
      result = result && (hasUser() == other.hasUser());
      if (hasUser()) {
        result = result && getUser()
            .equals(other.getUser());
      }
      result = result && (hasPermission() == other.hasPermission());
      if (hasPermission()) {
        result = result && getPermission()
            .equals(other.getPermission());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUser()) {
        hash = (37 * hash) + USER_FIELD_NUMBER;
        hash = (53 * hash) + getUser().hashCode();
      }
      if (hasPermission()) {
        hash = (37 * hash) + PERMISSION_FIELD_NUMBER;
        hash = (53 * hash) + getPermission().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UserPermission}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UserPermission_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UserPermission_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getPermissionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        user_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (permissionBuilder_ == null) {
          permission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance();
        } else {
          permissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UserPermission_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.user_ = user_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (permissionBuilder_ == null) {
          result.permission_ = permission_;
        } else {
          result.permission_ = permissionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance()) return this;
        if (other.hasUser()) {
          setUser(other.getUser());
        }
        if (other.hasPermission()) {
          mergePermission(other.getPermission());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUser()) {
          
          return false;
        }
        if (!hasPermission()) {
          
          return false;
        }
        if (!getPermission().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes user = 1;
      private com.google.protobuf.ByteString user_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes user = 1;</code>
       */
      public boolean hasUser() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes user = 1;</code>
       */
      public com.google.protobuf.ByteString getUser() {
        return user_;
      }
      /**
       * <code>required bytes user = 1;</code>
       */
      public Builder setUser(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        user_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes user = 1;</code>
       */
      public Builder clearUser() {
        bitField0_ = (bitField0_ & ~0x00000001);
        user_ = getDefaultInstance().getUser();
        onChanged();
        return this;
      }

      // required .hbase.pb.Permission permission = 3;
      private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission permission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> permissionBuilder_;
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      public boolean hasPermission() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermission() {
        if (permissionBuilder_ == null) {
          return permission_;
        } else {
          return permissionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      public Builder setPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission value) {
        if (permissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          permission_ = value;
          onChanged();
        } else {
          permissionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      public Builder setPermission(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder builderForValue) {
        if (permissionBuilder_ == null) {
          permission_ = builderForValue.build();
          onChanged();
        } else {
          permissionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      public Builder mergePermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission value) {
        if (permissionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              permission_ != org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance()) {
            permission_ =
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.newBuilder(permission_).mergeFrom(value).buildPartial();
          } else {
            permission_ = value;
          }
          onChanged();
        } else {
          permissionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      public Builder clearPermission() {
        if (permissionBuilder_ == null) {
          permission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance();
          onChanged();
        } else {
          permissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder getPermissionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getPermissionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionOrBuilder() {
        if (permissionBuilder_ != null) {
          return permissionBuilder_.getMessageOrBuilder();
        } else {
          return permission_;
        }
      }
      /**
       * <code>required .hbase.pb.Permission permission = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
          getPermissionFieldBuilder() {
        if (permissionBuilder_ == null) {
          permissionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder>(
                  permission_,
                  getParentForChildren(),
                  isClean());
          permission_ = null;
        }
        return permissionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.UserPermission)
    }

    static {
      defaultInstance = new UserPermission(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UserPermission)
  }

  public interface UsersAndPermissionsOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions> 
        getUserPermissionsList();
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions getUserPermissions(int index);
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    int getUserPermissionsCount();
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder> 
        getUserPermissionsOrBuilderList();
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder getUserPermissionsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.UsersAndPermissions}
   *
   * <pre>
   **
   * Content of the /hbase/acl/&lt;table or namespace&gt; znode.
   * </pre>
   */
  public static final class UsersAndPermissions extends
      com.google.protobuf.GeneratedMessage
      implements UsersAndPermissionsOrBuilder {
    // Use UsersAndPermissions.newBuilder() to construct.
    private UsersAndPermissions(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private UsersAndPermissions(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final UsersAndPermissions defaultInstance;
    public static UsersAndPermissions getDefaultInstance() {
      return defaultInstance;
    }

    public UsersAndPermissions getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private UsersAndPermissions(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                userPermissions_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions>();
                mutable_bitField0_ |= 0x00000001;
              }
              userPermissions_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          userPermissions_ = java.util.Collections.unmodifiableList(userPermissions_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.Builder.class);
    }

    public static com.google.protobuf.Parser<UsersAndPermissions> PARSER =
        new com.google.protobuf.AbstractParser<UsersAndPermissions>() {
      public UsersAndPermissions parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new UsersAndPermissions(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<UsersAndPermissions> getParserForType() {
      return PARSER;
    }

    public interface UserPermissionsOrBuilder
        extends com.google.protobuf.MessageOrBuilder {

      // required bytes user = 1;
      /**
       * <code>required bytes user = 1;</code>
       */
      boolean hasUser();
      /**
       * <code>required bytes user = 1;</code>
       */
      com.google.protobuf.ByteString getUser();

      // repeated .hbase.pb.Permission permissions = 2;
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> 
          getPermissionsList();
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermissions(int index);
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      int getPermissionsCount();
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
          getPermissionsOrBuilderList();
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionsOrBuilder(
          int index);
    }
    /**
     * Protobuf type {@code hbase.pb.UsersAndPermissions.UserPermissions}
     */
    public static final class UserPermissions extends
        com.google.protobuf.GeneratedMessage
        implements UserPermissionsOrBuilder {
      // Use UserPermissions.newBuilder() to construct.
      private UserPermissions(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
        super(builder);
        this.unknownFields = builder.getUnknownFields();
      }
      private UserPermissions(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

      private static final UserPermissions defaultInstance;
      public static UserPermissions getDefaultInstance() {
        return defaultInstance;
      }

      public UserPermissions getDefaultInstanceForType() {
        return defaultInstance;
      }

      private final com.google.protobuf.UnknownFieldSet unknownFields;
      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
          getUnknownFields() {
        return this.unknownFields;
      }
      private UserPermissions(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        initFields();
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!parseUnknownField(input, unknownFields,
                                       extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                bitField0_ |= 0x00000001;
                user_ = input.readBytes();
                break;
              }
              case 18: {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  permissions_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission>();
                  mutable_bitField0_ |= 0x00000002;
                }
                permissions_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.PARSER, extensionRegistry));
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e.getMessage()).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
            permissions_ = java.util.Collections.unmodifiableList(permissions_);
          }
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_UserPermissions_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_UserPermissions_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder.class);
      }

      public static com.google.protobuf.Parser<UserPermissions> PARSER =
          new com.google.protobuf.AbstractParser<UserPermissions>() {
        public UserPermissions parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new UserPermissions(input, extensionRegistry);
        }
      };

      @java.lang.Override
      public com.google.protobuf.Parser<UserPermissions> getParserForType() {
        return PARSER;
      }

      private int bitField0_;
      // required bytes user = 1;
      public static final int USER_FIELD_NUMBER = 1;
      private com.google.protobuf.ByteString user_;
      /**
       * <code>required bytes user = 1;</code>
       */
      public boolean hasUser() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes user = 1;</code>
       */
      public com.google.protobuf.ByteString getUser() {
        return user_;
      }

      // repeated .hbase.pb.Permission permissions = 2;
      public static final int PERMISSIONS_FIELD_NUMBER = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> permissions_;
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> getPermissionsList() {
        return permissions_;
      }
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
          getPermissionsOrBuilderList() {
        return permissions_;
      }
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      public int getPermissionsCount() {
        return permissions_.size();
      }
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermissions(int index) {
        return permissions_.get(index);
      }
      /**
       * <code>repeated .hbase.pb.Permission permissions = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionsOrBuilder(
          int index) {
        return permissions_.get(index);
      }

      private void initFields() {
        user_ = com.google.protobuf.ByteString.EMPTY;
        permissions_ = java.util.Collections.emptyList();
      }
      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized != -1) return isInitialized == 1;

        if (!hasUser()) {
          memoizedIsInitialized = 0;
          return false;
        }
        for (int i = 0; i < getPermissionsCount(); i++) {
          if (!getPermissions(i).isInitialized()) {
            memoizedIsInitialized = 0;
            return false;
          }
        }
        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          output.writeBytes(1, user_);
        }
        for (int i = 0; i < permissions_.size(); i++) {
          output.writeMessage(2, permissions_.get(i));
        }
        getUnknownFields().writeTo(output);
      }

      private int memoizedSerializedSize = -1;
      public int getSerializedSize() {
        int size = memoizedSerializedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, user_);
        }
        for (int i = 0; i < permissions_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, permissions_.get(i));
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSerializedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @java.lang.Override
      protected java.lang.Object writeReplace()
          throws java.io.ObjectStreamException {
        return super.writeReplace();
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions) obj;

        boolean result = true;
        result = result && (hasUser() == other.hasUser());
        if (hasUser()) {
          result = result && getUser()
              .equals(other.getUser());
        }
        result = result && getPermissionsList()
            .equals(other.getPermissionsList());
        result = result &&
            getUnknownFields().equals(other.getUnknownFields());
        return result;
      }

      private int memoizedHashCode = 0;
      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        if (hasUser()) {
          hash = (37 * hash) + USER_FIELD_NUMBER;
          hash = (53 * hash) + getUser().hashCode();
        }
        if (getPermissionsCount() > 0) {
          hash = (37 * hash) + PERMISSIONS_FIELD_NUMBER;
          hash = (53 * hash) + getPermissionsList().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return PARSER.parseFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseFrom(input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return PARSER.parseDelimitedFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseDelimitedFrom(input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return PARSER.parseFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseFrom(input, extensionRegistry);
      }

      public static Builder newBuilder() { return Builder.create(); }
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions prototype) {
        return newBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() { return newBuilder(this); }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code hbase.pb.UsersAndPermissions.UserPermissions}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessage.Builder<Builder>
         implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_UserPermissions_descriptor;
        }

        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_UserPermissions_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessage.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
            getPermissionsFieldBuilder();
          }
        }
        private static Builder create() {
          return new Builder();
        }

        public Builder clear() {
          super.clear();
          user_ = com.google.protobuf.ByteString.EMPTY;
          bitField0_ = (bitField0_ & ~0x00000001);
          if (permissionsBuilder_ == null) {
            permissions_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            permissionsBuilder_.clear();
          }
          return this;
        }

        public Builder clone() {
          return create().mergeFrom(buildPartial());
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_UserPermissions_descriptor;
        }

        public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.getDefaultInstance();
        }

        public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions build() {
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions buildPartial() {
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
            to_bitField0_ |= 0x00000001;
          }
          result.user_ = user_;
          if (permissionsBuilder_ == null) {
            if (((bitField0_ & 0x00000002) == 0x00000002)) {
              permissions_ = java.util.Collections.unmodifiableList(permissions_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.permissions_ = permissions_;
          } else {
            result.permissions_ = permissionsBuilder_.build();
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions) {
            return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions other) {
          if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.getDefaultInstance()) return this;
          if (other.hasUser()) {
            setUser(other.getUser());
          }
          if (permissionsBuilder_ == null) {
            if (!other.permissions_.isEmpty()) {
              if (permissions_.isEmpty()) {
                permissions_ = other.permissions_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensurePermissionsIsMutable();
                permissions_.addAll(other.permissions_);
              }
              onChanged();
            }
          } else {
            if (!other.permissions_.isEmpty()) {
              if (permissionsBuilder_.isEmpty()) {
                permissionsBuilder_.dispose();
                permissionsBuilder_ = null;
                permissions_ = other.permissions_;
                bitField0_ = (bitField0_ & ~0x00000002);
                permissionsBuilder_ = 
                  com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                     getPermissionsFieldBuilder() : null;
              } else {
                permissionsBuilder_.addAllMessages(other.permissions_);
              }
            }
          }
          this.mergeUnknownFields(other.getUnknownFields());
          return this;
        }

        public final boolean isInitialized() {
          if (!hasUser()) {
            
            return false;
          }
          for (int i = 0; i < getPermissionsCount(); i++) {
            if (!getPermissions(i).isInitialized()) {
              
              return false;
            }
          }
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions) e.getUnfinishedMessage();
            throw e;
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        // required bytes user = 1;
        private com.google.protobuf.ByteString user_ = com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>required bytes user = 1;</code>
         */
        public boolean hasUser() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        /**
         * <code>required bytes user = 1;</code>
         */
        public com.google.protobuf.ByteString getUser() {
          return user_;
        }
        /**
         * <code>required bytes user = 1;</code>
         */
        public Builder setUser(com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          user_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>required bytes user = 1;</code>
         */
        public Builder clearUser() {
          bitField0_ = (bitField0_ & ~0x00000001);
          user_ = getDefaultInstance().getUser();
          onChanged();
          return this;
        }

        // repeated .hbase.pb.Permission permissions = 2;
        private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> permissions_ =
          java.util.Collections.emptyList();
        private void ensurePermissionsIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            permissions_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission>(permissions_);
            bitField0_ |= 0x00000002;
           }
        }

        private com.google.protobuf.RepeatedFieldBuilder<
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> permissionsBuilder_;

        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> getPermissionsList() {
          if (permissionsBuilder_ == null) {
            return java.util.Collections.unmodifiableList(permissions_);
          } else {
            return permissionsBuilder_.getMessageList();
          }
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public int getPermissionsCount() {
          if (permissionsBuilder_ == null) {
            return permissions_.size();
          } else {
            return permissionsBuilder_.getCount();
          }
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermissions(int index) {
          if (permissionsBuilder_ == null) {
            return permissions_.get(index);
          } else {
            return permissionsBuilder_.getMessage(index);
          }
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder setPermissions(
            int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission value) {
          if (permissionsBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensurePermissionsIsMutable();
            permissions_.set(index, value);
            onChanged();
          } else {
            permissionsBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder setPermissions(
            int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder builderForValue) {
          if (permissionsBuilder_ == null) {
            ensurePermissionsIsMutable();
            permissions_.set(index, builderForValue.build());
            onChanged();
          } else {
            permissionsBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder addPermissions(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission value) {
          if (permissionsBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensurePermissionsIsMutable();
            permissions_.add(value);
            onChanged();
          } else {
            permissionsBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder addPermissions(
            int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission value) {
          if (permissionsBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensurePermissionsIsMutable();
            permissions_.add(index, value);
            onChanged();
          } else {
            permissionsBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder addPermissions(
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder builderForValue) {
          if (permissionsBuilder_ == null) {
            ensurePermissionsIsMutable();
            permissions_.add(builderForValue.build());
            onChanged();
          } else {
            permissionsBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder addPermissions(
            int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder builderForValue) {
          if (permissionsBuilder_ == null) {
            ensurePermissionsIsMutable();
            permissions_.add(index, builderForValue.build());
            onChanged();
          } else {
            permissionsBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder addAllPermissions(
            java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> values) {
          if (permissionsBuilder_ == null) {
            ensurePermissionsIsMutable();
            super.addAll(values, permissions_);
            onChanged();
          } else {
            permissionsBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder clearPermissions() {
          if (permissionsBuilder_ == null) {
            permissions_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            permissionsBuilder_.clear();
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public Builder removePermissions(int index) {
          if (permissionsBuilder_ == null) {
            ensurePermissionsIsMutable();
            permissions_.remove(index);
            onChanged();
          } else {
            permissionsBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder getPermissionsBuilder(
            int index) {
          return getPermissionsFieldBuilder().getBuilder(index);
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionsOrBuilder(
            int index) {
          if (permissionsBuilder_ == null) {
            return permissions_.get(index);  } else {
            return permissionsBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
             getPermissionsOrBuilderList() {
          if (permissionsBuilder_ != null) {
            return permissionsBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(permissions_);
          }
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder addPermissionsBuilder() {
          return getPermissionsFieldBuilder().addBuilder(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance());
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder addPermissionsBuilder(
            int index) {
          return getPermissionsFieldBuilder().addBuilder(
              index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance());
        }
        /**
         * <code>repeated .hbase.pb.Permission permissions = 2;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder> 
             getPermissionsBuilderList() {
          return getPermissionsFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilder<
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
            getPermissionsFieldBuilder() {
          if (permissionsBuilder_ == null) {
            permissionsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder>(
                    permissions_,
                    ((bitField0_ & 0x00000002) == 0x00000002),
                    getParentForChildren(),
                    isClean());
            permissions_ = null;
          }
          return permissionsBuilder_;
        }

        // @@protoc_insertion_point(builder_scope:hbase.pb.UsersAndPermissions.UserPermissions)
      }

      static {
        defaultInstance = new UserPermissions(true);
        defaultInstance.initFields();
      }

      // @@protoc_insertion_point(class_scope:hbase.pb.UsersAndPermissions.UserPermissions)
    }

    // repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;
    public static final int USER_PERMISSIONS_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions> userPermissions_;
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions> getUserPermissionsList() {
      return userPermissions_;
    }
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder> 
        getUserPermissionsOrBuilderList() {
      return userPermissions_;
    }
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    public int getUserPermissionsCount() {
      return userPermissions_.size();
    }
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions getUserPermissions(int index) {
      return userPermissions_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder getUserPermissionsOrBuilder(
        int index) {
      return userPermissions_.get(index);
    }

    private void initFields() {
      userPermissions_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getUserPermissionsCount(); i++) {
        if (!getUserPermissions(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < userPermissions_.size(); i++) {
        output.writeMessage(1, userPermissions_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < userPermissions_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userPermissions_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions) obj;

      boolean result = true;
      result = result && getUserPermissionsList()
          .equals(other.getUserPermissionsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getUserPermissionsCount() > 0) {
        hash = (37 * hash) + USER_PERMISSIONS_FIELD_NUMBER;
        hash = (53 * hash) + getUserPermissionsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.UsersAndPermissions}
     *
     * <pre>
     **
     * Content of the /hbase/acl/&lt;table or namespace&gt; znode.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissionsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserPermissionsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userPermissionsBuilder_ == null) {
          userPermissions_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          userPermissionsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_UsersAndPermissions_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions(this);
        int from_bitField0_ = bitField0_;
        if (userPermissionsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            userPermissions_ = java.util.Collections.unmodifiableList(userPermissions_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.userPermissions_ = userPermissions_;
        } else {
          result.userPermissions_ = userPermissionsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.getDefaultInstance()) return this;
        if (userPermissionsBuilder_ == null) {
          if (!other.userPermissions_.isEmpty()) {
            if (userPermissions_.isEmpty()) {
              userPermissions_ = other.userPermissions_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureUserPermissionsIsMutable();
              userPermissions_.addAll(other.userPermissions_);
            }
            onChanged();
          }
        } else {
          if (!other.userPermissions_.isEmpty()) {
            if (userPermissionsBuilder_.isEmpty()) {
              userPermissionsBuilder_.dispose();
              userPermissionsBuilder_ = null;
              userPermissions_ = other.userPermissions_;
              bitField0_ = (bitField0_ & ~0x00000001);
              userPermissionsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getUserPermissionsFieldBuilder() : null;
            } else {
              userPermissionsBuilder_.addAllMessages(other.userPermissions_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getUserPermissionsCount(); i++) {
          if (!getUserPermissions(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions> userPermissions_ =
        java.util.Collections.emptyList();
      private void ensureUserPermissionsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          userPermissions_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions>(userPermissions_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder> userPermissionsBuilder_;

      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions> getUserPermissionsList() {
        if (userPermissionsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(userPermissions_);
        } else {
          return userPermissionsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public int getUserPermissionsCount() {
        if (userPermissionsBuilder_ == null) {
          return userPermissions_.size();
        } else {
          return userPermissionsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions getUserPermissions(int index) {
        if (userPermissionsBuilder_ == null) {
          return userPermissions_.get(index);
        } else {
          return userPermissionsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder setUserPermissions(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions value) {
        if (userPermissionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUserPermissionsIsMutable();
          userPermissions_.set(index, value);
          onChanged();
        } else {
          userPermissionsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder setUserPermissions(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder builderForValue) {
        if (userPermissionsBuilder_ == null) {
          ensureUserPermissionsIsMutable();
          userPermissions_.set(index, builderForValue.build());
          onChanged();
        } else {
          userPermissionsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder addUserPermissions(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions value) {
        if (userPermissionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUserPermissionsIsMutable();
          userPermissions_.add(value);
          onChanged();
        } else {
          userPermissionsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder addUserPermissions(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions value) {
        if (userPermissionsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUserPermissionsIsMutable();
          userPermissions_.add(index, value);
          onChanged();
        } else {
          userPermissionsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder addUserPermissions(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder builderForValue) {
        if (userPermissionsBuilder_ == null) {
          ensureUserPermissionsIsMutable();
          userPermissions_.add(builderForValue.build());
          onChanged();
        } else {
          userPermissionsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder addUserPermissions(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder builderForValue) {
        if (userPermissionsBuilder_ == null) {
          ensureUserPermissionsIsMutable();
          userPermissions_.add(index, builderForValue.build());
          onChanged();
        } else {
          userPermissionsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder addAllUserPermissions(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions> values) {
        if (userPermissionsBuilder_ == null) {
          ensureUserPermissionsIsMutable();
          super.addAll(values, userPermissions_);
          onChanged();
        } else {
          userPermissionsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder clearUserPermissions() {
        if (userPermissionsBuilder_ == null) {
          userPermissions_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          userPermissionsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public Builder removeUserPermissions(int index) {
        if (userPermissionsBuilder_ == null) {
          ensureUserPermissionsIsMutable();
          userPermissions_.remove(index);
          onChanged();
        } else {
          userPermissionsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder getUserPermissionsBuilder(
          int index) {
        return getUserPermissionsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder getUserPermissionsOrBuilder(
          int index) {
        if (userPermissionsBuilder_ == null) {
          return userPermissions_.get(index);  } else {
          return userPermissionsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder> 
           getUserPermissionsOrBuilderList() {
        if (userPermissionsBuilder_ != null) {
          return userPermissionsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(userPermissions_);
        }
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder addUserPermissionsBuilder() {
        return getUserPermissionsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder addUserPermissionsBuilder(
          int index) {
        return getUserPermissionsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.UsersAndPermissions.UserPermissions user_permissions = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder> 
           getUserPermissionsBuilderList() {
        return getUserPermissionsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder> 
          getUserPermissionsFieldBuilder() {
        if (userPermissionsBuilder_ == null) {
          userPermissionsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissions.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UsersAndPermissions.UserPermissionsOrBuilder>(
                  userPermissions_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          userPermissions_ = null;
        }
        return userPermissionsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.UsersAndPermissions)
    }

    static {
      defaultInstance = new UsersAndPermissions(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.UsersAndPermissions)
  }

  public interface GrantRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserPermission user_permission = 1;
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    boolean hasUserPermission();
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission();
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder();

    // optional bool merge_existing_permissions = 2 [default = false];
    /**
     * <code>optional bool merge_existing_permissions = 2 [default = false];</code>
     */
    boolean hasMergeExistingPermissions();
    /**
     * <code>optional bool merge_existing_permissions = 2 [default = false];</code>
     */
    boolean getMergeExistingPermissions();
  }
  /**
   * Protobuf type {@code hbase.pb.GrantRequest}
   */
  public static final class GrantRequest extends
      com.google.protobuf.GeneratedMessage
      implements GrantRequestOrBuilder {
    // Use GrantRequest.newBuilder() to construct.
    private GrantRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GrantRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GrantRequest defaultInstance;
    public static GrantRequest getDefaultInstance() {
      return defaultInstance;
    }

    public GrantRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GrantRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userPermission_.toBuilder();
              }
              userPermission_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userPermission_);
                userPermission_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              mergeExistingPermissions_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<GrantRequest> PARSER =
        new com.google.protobuf.AbstractParser<GrantRequest>() {
      public GrantRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GrantRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GrantRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserPermission user_permission = 1;
    public static final int USER_PERMISSION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission userPermission_;
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public boolean hasUserPermission() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission() {
      return userPermission_;
    }
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder() {
      return userPermission_;
    }

    // optional bool merge_existing_permissions = 2 [default = false];
    public static final int MERGE_EXISTING_PERMISSIONS_FIELD_NUMBER = 2;
    private boolean mergeExistingPermissions_;
    /**
     * <code>optional bool merge_existing_permissions = 2 [default = false];</code>
     */
    public boolean hasMergeExistingPermissions() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool merge_existing_permissions = 2 [default = false];</code>
     */
    public boolean getMergeExistingPermissions() {
      return mergeExistingPermissions_;
    }

    private void initFields() {
      userPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
      mergeExistingPermissions_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserPermission()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserPermission().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userPermission_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, mergeExistingPermissions_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userPermission_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, mergeExistingPermissions_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest) obj;

      boolean result = true;
      result = result && (hasUserPermission() == other.hasUserPermission());
      if (hasUserPermission()) {
        result = result && getUserPermission()
            .equals(other.getUserPermission());
      }
      result = result && (hasMergeExistingPermissions() == other.hasMergeExistingPermissions());
      if (hasMergeExistingPermissions()) {
        result = result && (getMergeExistingPermissions()
            == other.getMergeExistingPermissions());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserPermission()) {
        hash = (37 * hash) + USER_PERMISSION_FIELD_NUMBER;
        hash = (53 * hash) + getUserPermission().hashCode();
      }
      if (hasMergeExistingPermissions()) {
        hash = (37 * hash) + MERGE_EXISTING_PERMISSIONS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getMergeExistingPermissions());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GrantRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserPermissionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userPermissionBuilder_ == null) {
          userPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
        } else {
          userPermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        mergeExistingPermissions_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userPermissionBuilder_ == null) {
          result.userPermission_ = userPermission_;
        } else {
          result.userPermission_ = userPermissionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.mergeExistingPermissions_ = mergeExistingPermissions_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.getDefaultInstance()) return this;
        if (other.hasUserPermission()) {
          mergeUserPermission(other.getUserPermission());
        }
        if (other.hasMergeExistingPermissions()) {
          setMergeExistingPermissions(other.getMergeExistingPermissions());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserPermission()) {
          
          return false;
        }
        if (!getUserPermission().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserPermission user_permission = 1;
      private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission userPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> userPermissionBuilder_;
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public boolean hasUserPermission() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission() {
        if (userPermissionBuilder_ == null) {
          return userPermission_;
        } else {
          return userPermissionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder setUserPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission value) {
        if (userPermissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userPermission_ = value;
          onChanged();
        } else {
          userPermissionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder setUserPermission(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder builderForValue) {
        if (userPermissionBuilder_ == null) {
          userPermission_ = builderForValue.build();
          onChanged();
        } else {
          userPermissionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder mergeUserPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission value) {
        if (userPermissionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userPermission_ != org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance()) {
            userPermission_ =
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.newBuilder(userPermission_).mergeFrom(value).buildPartial();
          } else {
            userPermission_ = value;
          }
          onChanged();
        } else {
          userPermissionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder clearUserPermission() {
        if (userPermissionBuilder_ == null) {
          userPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
          onChanged();
        } else {
          userPermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder getUserPermissionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserPermissionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder() {
        if (userPermissionBuilder_ != null) {
          return userPermissionBuilder_.getMessageOrBuilder();
        } else {
          return userPermission_;
        }
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> 
          getUserPermissionFieldBuilder() {
        if (userPermissionBuilder_ == null) {
          userPermissionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder>(
                  userPermission_,
                  getParentForChildren(),
                  isClean());
          userPermission_ = null;
        }
        return userPermissionBuilder_;
      }

      // optional bool merge_existing_permissions = 2 [default = false];
      private boolean mergeExistingPermissions_ ;
      /**
       * <code>optional bool merge_existing_permissions = 2 [default = false];</code>
       */
      public boolean hasMergeExistingPermissions() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool merge_existing_permissions = 2 [default = false];</code>
       */
      public boolean getMergeExistingPermissions() {
        return mergeExistingPermissions_;
      }
      /**
       * <code>optional bool merge_existing_permissions = 2 [default = false];</code>
       */
      public Builder setMergeExistingPermissions(boolean value) {
        bitField0_ |= 0x00000002;
        mergeExistingPermissions_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool merge_existing_permissions = 2 [default = false];</code>
       */
      public Builder clearMergeExistingPermissions() {
        bitField0_ = (bitField0_ & ~0x00000002);
        mergeExistingPermissions_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.GrantRequest)
    }

    static {
      defaultInstance = new GrantRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GrantRequest)
  }

  public interface GrantResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.GrantResponse}
   */
  public static final class GrantResponse extends
      com.google.protobuf.GeneratedMessage
      implements GrantResponseOrBuilder {
    // Use GrantResponse.newBuilder() to construct.
    private GrantResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GrantResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GrantResponse defaultInstance;
    public static GrantResponse getDefaultInstance() {
      return defaultInstance;
    }

    public GrantResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GrantResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<GrantResponse> PARSER =
        new com.google.protobuf.AbstractParser<GrantResponse>() {
      public GrantResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GrantResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GrantResponse> getParserForType() {
      return PARSER;
    }

    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse) obj;

      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GrantResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GrantResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse(this);
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.GrantResponse)
    }

    static {
      defaultInstance = new GrantResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GrantResponse)
  }

  public interface RevokeRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .hbase.pb.UserPermission user_permission = 1;
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    boolean hasUserPermission();
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission();
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder();
  }
  /**
   * Protobuf type {@code hbase.pb.RevokeRequest}
   */
  public static final class RevokeRequest extends
      com.google.protobuf.GeneratedMessage
      implements RevokeRequestOrBuilder {
    // Use RevokeRequest.newBuilder() to construct.
    private RevokeRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private RevokeRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final RevokeRequest defaultInstance;
    public static RevokeRequest getDefaultInstance() {
      return defaultInstance;
    }

    public RevokeRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private RevokeRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = userPermission_.toBuilder();
              }
              userPermission_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(userPermission_);
                userPermission_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<RevokeRequest> PARSER =
        new com.google.protobuf.AbstractParser<RevokeRequest>() {
      public RevokeRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RevokeRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<RevokeRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .hbase.pb.UserPermission user_permission = 1;
    public static final int USER_PERMISSION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission userPermission_;
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public boolean hasUserPermission() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission() {
      return userPermission_;
    }
    /**
     * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder() {
      return userPermission_;
    }

    private void initFields() {
      userPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasUserPermission()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getUserPermission().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, userPermission_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userPermission_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest) obj;

      boolean result = true;
      result = result && (hasUserPermission() == other.hasUserPermission());
      if (hasUserPermission()) {
        result = result && getUserPermission()
            .equals(other.getUserPermission());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasUserPermission()) {
        hash = (37 * hash) + USER_PERMISSION_FIELD_NUMBER;
        hash = (53 * hash) + getUserPermission().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RevokeRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserPermissionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userPermissionBuilder_ == null) {
          userPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
        } else {
          userPermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (userPermissionBuilder_ == null) {
          result.userPermission_ = userPermission_;
        } else {
          result.userPermission_ = userPermissionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.getDefaultInstance()) return this;
        if (other.hasUserPermission()) {
          mergeUserPermission(other.getUserPermission());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasUserPermission()) {
          
          return false;
        }
        if (!getUserPermission().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .hbase.pb.UserPermission user_permission = 1;
      private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission userPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> userPermissionBuilder_;
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public boolean hasUserPermission() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission() {
        if (userPermissionBuilder_ == null) {
          return userPermission_;
        } else {
          return userPermissionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder setUserPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission value) {
        if (userPermissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          userPermission_ = value;
          onChanged();
        } else {
          userPermissionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder setUserPermission(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder builderForValue) {
        if (userPermissionBuilder_ == null) {
          userPermission_ = builderForValue.build();
          onChanged();
        } else {
          userPermissionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder mergeUserPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission value) {
        if (userPermissionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              userPermission_ != org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance()) {
            userPermission_ =
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.newBuilder(userPermission_).mergeFrom(value).buildPartial();
          } else {
            userPermission_ = value;
          }
          onChanged();
        } else {
          userPermissionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder clearUserPermission() {
        if (userPermissionBuilder_ == null) {
          userPermission_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance();
          onChanged();
        } else {
          userPermissionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder getUserPermissionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getUserPermissionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder() {
        if (userPermissionBuilder_ != null) {
          return userPermissionBuilder_.getMessageOrBuilder();
        } else {
          return userPermission_;
        }
      }
      /**
       * <code>required .hbase.pb.UserPermission user_permission = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> 
          getUserPermissionFieldBuilder() {
        if (userPermissionBuilder_ == null) {
          userPermissionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder>(
                  userPermission_,
                  getParentForChildren(),
                  isClean());
          userPermission_ = null;
        }
        return userPermissionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.RevokeRequest)
    }

    static {
      defaultInstance = new RevokeRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RevokeRequest)
  }

  public interface RevokeResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.RevokeResponse}
   */
  public static final class RevokeResponse extends
      com.google.protobuf.GeneratedMessage
      implements RevokeResponseOrBuilder {
    // Use RevokeResponse.newBuilder() to construct.
    private RevokeResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private RevokeResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final RevokeResponse defaultInstance;
    public static RevokeResponse getDefaultInstance() {
      return defaultInstance;
    }

    public RevokeResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private RevokeResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<RevokeResponse> PARSER =
        new com.google.protobuf.AbstractParser<RevokeResponse>() {
      public RevokeResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new RevokeResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<RevokeResponse> getParserForType() {
      return PARSER;
    }

    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse) obj;

      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.RevokeResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_RevokeResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse(this);
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.RevokeResponse)
    }

    static {
      defaultInstance = new RevokeResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.RevokeResponse)
  }

  public interface GetUserPermissionsRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .hbase.pb.Permission.Type type = 1;
    /**
     * <code>optional .hbase.pb.Permission.Type type = 1;</code>
     */
    boolean hasType();
    /**
     * <code>optional .hbase.pb.Permission.Type type = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type getType();

    // optional .hbase.pb.TableName table_name = 2;
    /**
     * <code>optional .hbase.pb.TableName table_name = 2;</code>
     */
    boolean hasTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName();
    /**
     * <code>optional .hbase.pb.TableName table_name = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder();

    // optional bytes namespace_name = 3;
    /**
     * <code>optional bytes namespace_name = 3;</code>
     */
    boolean hasNamespaceName();
    /**
     * <code>optional bytes namespace_name = 3;</code>
     */
    com.google.protobuf.ByteString getNamespaceName();
  }
  /**
   * Protobuf type {@code hbase.pb.GetUserPermissionsRequest}
   */
  public static final class GetUserPermissionsRequest extends
      com.google.protobuf.GeneratedMessage
      implements GetUserPermissionsRequestOrBuilder {
    // Use GetUserPermissionsRequest.newBuilder() to construct.
    private GetUserPermissionsRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GetUserPermissionsRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GetUserPermissionsRequest defaultInstance;
    public static GetUserPermissionsRequest getDefaultInstance() {
      return defaultInstance;
    }

    public GetUserPermissionsRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GetUserPermissionsRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type value = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                type_ = value;
              }
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = tableName_.toBuilder();
              }
              tableName_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(tableName_);
                tableName_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              namespaceName_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<GetUserPermissionsRequest> PARSER =
        new com.google.protobuf.AbstractParser<GetUserPermissionsRequest>() {
      public GetUserPermissionsRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GetUserPermissionsRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GetUserPermissionsRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .hbase.pb.Permission.Type type = 1;
    public static final int TYPE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type type_;
    /**
     * <code>optional .hbase.pb.Permission.Type type = 1;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hbase.pb.Permission.Type type = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type getType() {
      return type_;
    }

    // optional .hbase.pb.TableName table_name = 2;
    public static final int TABLE_NAME_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_;
    /**
     * <code>optional .hbase.pb.TableName table_name = 2;</code>
     */
    public boolean hasTableName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
      return tableName_;
    }
    /**
     * <code>optional .hbase.pb.TableName table_name = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
      return tableName_;
    }

    // optional bytes namespace_name = 3;
    public static final int NAMESPACE_NAME_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString namespaceName_;
    /**
     * <code>optional bytes namespace_name = 3;</code>
     */
    public boolean hasNamespaceName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bytes namespace_name = 3;</code>
     */
    public com.google.protobuf.ByteString getNamespaceName() {
      return namespaceName_;
    }

    private void initFields() {
      type_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.Global;
      tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      namespaceName_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasTableName()) {
        if (!getTableName().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, type_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, namespaceName_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, type_.getNumber());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, tableName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, namespaceName_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest) obj;

      boolean result = true;
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result &&
            (getType() == other.getType());
      }
      result = result && (hasTableName() == other.hasTableName());
      if (hasTableName()) {
        result = result && getTableName()
            .equals(other.getTableName());
      }
      result = result && (hasNamespaceName() == other.hasNamespaceName());
      if (hasNamespaceName()) {
        result = result && getNamespaceName()
            .equals(other.getNamespaceName());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getType());
      }
      if (hasTableName()) {
        hash = (37 * hash) + TABLE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getTableName().hashCode();
      }
      if (hasNamespaceName()) {
        hash = (37 * hash) + NAMESPACE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getNamespaceName().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetUserPermissionsRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getTableNameFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        type_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.Global;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        namespaceName_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (tableNameBuilder_ == null) {
          result.tableName_ = tableName_;
        } else {
          result.tableName_ = tableNameBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.namespaceName_ = namespaceName_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.getDefaultInstance()) return this;
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasTableName()) {
          mergeTableName(other.getTableName());
        }
        if (other.hasNamespaceName()) {
          setNamespaceName(other.getNamespaceName());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasTableName()) {
          if (!getTableName().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .hbase.pb.Permission.Type type = 1;
      private org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type type_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.Global;
      /**
       * <code>optional .hbase.pb.Permission.Type type = 1;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hbase.pb.Permission.Type type = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type getType() {
        return type_;
      }
      /**
       * <code>optional .hbase.pb.Permission.Type type = 1;</code>
       */
      public Builder setType(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        type_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .hbase.pb.Permission.Type type = 1;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        type_ = org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Type.Global;
        onChanged();
        return this;
      }

      // optional .hbase.pb.TableName table_name = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> tableNameBuilder_;
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      public boolean hasTableName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName getTableName() {
        if (tableNameBuilder_ == null) {
          return tableName_;
        } else {
          return tableNameBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          tableName_ = value;
          onChanged();
        } else {
          tableNameBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder setTableName(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder builderForValue) {
        if (tableNameBuilder_ == null) {
          tableName_ = builderForValue.build();
          onChanged();
        } else {
          tableNameBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder mergeTableName(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName value) {
        if (tableNameBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              tableName_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance()) {
            tableName_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.newBuilder(tableName_).mergeFrom(value).buildPartial();
          } else {
            tableName_ = value;
          }
          onChanged();
        } else {
          tableNameBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      public Builder clearTableName() {
        if (tableNameBuilder_ == null) {
          tableName_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.getDefaultInstance();
          onChanged();
        } else {
          tableNameBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder getTableNameBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getTableNameFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder getTableNameOrBuilder() {
        if (tableNameBuilder_ != null) {
          return tableNameBuilder_.getMessageOrBuilder();
        } else {
          return tableName_;
        }
      }
      /**
       * <code>optional .hbase.pb.TableName table_name = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder> 
          getTableNameFieldBuilder() {
        if (tableNameBuilder_ == null) {
          tableNameBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableName.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TableNameOrBuilder>(
                  tableName_,
                  getParentForChildren(),
                  isClean());
          tableName_ = null;
        }
        return tableNameBuilder_;
      }

      // optional bytes namespace_name = 3;
      private com.google.protobuf.ByteString namespaceName_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes namespace_name = 3;</code>
       */
      public boolean hasNamespaceName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bytes namespace_name = 3;</code>
       */
      public com.google.protobuf.ByteString getNamespaceName() {
        return namespaceName_;
      }
      /**
       * <code>optional bytes namespace_name = 3;</code>
       */
      public Builder setNamespaceName(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        namespaceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes namespace_name = 3;</code>
       */
      public Builder clearNamespaceName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        namespaceName_ = getDefaultInstance().getNamespaceName();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.GetUserPermissionsRequest)
    }

    static {
      defaultInstance = new GetUserPermissionsRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetUserPermissionsRequest)
  }

  public interface GetUserPermissionsResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hbase.pb.UserPermission user_permission = 1;
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission> 
        getUserPermissionList();
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission(int index);
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    int getUserPermissionCount();
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> 
        getUserPermissionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.GetUserPermissionsResponse}
   */
  public static final class GetUserPermissionsResponse extends
      com.google.protobuf.GeneratedMessage
      implements GetUserPermissionsResponseOrBuilder {
    // Use GetUserPermissionsResponse.newBuilder() to construct.
    private GetUserPermissionsResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GetUserPermissionsResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GetUserPermissionsResponse defaultInstance;
    public static GetUserPermissionsResponse getDefaultInstance() {
      return defaultInstance;
    }

    public GetUserPermissionsResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GetUserPermissionsResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                userPermission_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission>();
                mutable_bitField0_ |= 0x00000001;
              }
              userPermission_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          userPermission_ = java.util.Collections.unmodifiableList(userPermission_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<GetUserPermissionsResponse> PARSER =
        new com.google.protobuf.AbstractParser<GetUserPermissionsResponse>() {
      public GetUserPermissionsResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GetUserPermissionsResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GetUserPermissionsResponse> getParserForType() {
      return PARSER;
    }

    // repeated .hbase.pb.UserPermission user_permission = 1;
    public static final int USER_PERMISSION_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission> userPermission_;
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission> getUserPermissionList() {
      return userPermission_;
    }
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> 
        getUserPermissionOrBuilderList() {
      return userPermission_;
    }
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public int getUserPermissionCount() {
      return userPermission_.size();
    }
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission(int index) {
      return userPermission_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder(
        int index) {
      return userPermission_.get(index);
    }

    private void initFields() {
      userPermission_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getUserPermissionCount(); i++) {
        if (!getUserPermission(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < userPermission_.size(); i++) {
        output.writeMessage(1, userPermission_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < userPermission_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, userPermission_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse) obj;

      boolean result = true;
      result = result && getUserPermissionList()
          .equals(other.getUserPermissionList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getUserPermissionCount() > 0) {
        hash = (37 * hash) + USER_PERMISSION_FIELD_NUMBER;
        hash = (53 * hash) + getUserPermissionList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.GetUserPermissionsResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getUserPermissionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (userPermissionBuilder_ == null) {
          userPermission_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          userPermissionBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_GetUserPermissionsResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse(this);
        int from_bitField0_ = bitField0_;
        if (userPermissionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            userPermission_ = java.util.Collections.unmodifiableList(userPermission_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.userPermission_ = userPermission_;
        } else {
          result.userPermission_ = userPermissionBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.getDefaultInstance()) return this;
        if (userPermissionBuilder_ == null) {
          if (!other.userPermission_.isEmpty()) {
            if (userPermission_.isEmpty()) {
              userPermission_ = other.userPermission_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureUserPermissionIsMutable();
              userPermission_.addAll(other.userPermission_);
            }
            onChanged();
          }
        } else {
          if (!other.userPermission_.isEmpty()) {
            if (userPermissionBuilder_.isEmpty()) {
              userPermissionBuilder_.dispose();
              userPermissionBuilder_ = null;
              userPermission_ = other.userPermission_;
              bitField0_ = (bitField0_ & ~0x00000001);
              userPermissionBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getUserPermissionFieldBuilder() : null;
            } else {
              userPermissionBuilder_.addAllMessages(other.userPermission_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getUserPermissionCount(); i++) {
          if (!getUserPermission(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hbase.pb.UserPermission user_permission = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission> userPermission_ =
        java.util.Collections.emptyList();
      private void ensureUserPermissionIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          userPermission_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission>(userPermission_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> userPermissionBuilder_;

      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission> getUserPermissionList() {
        if (userPermissionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(userPermission_);
        } else {
          return userPermissionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public int getUserPermissionCount() {
        if (userPermissionBuilder_ == null) {
          return userPermission_.size();
        } else {
          return userPermissionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission getUserPermission(int index) {
        if (userPermissionBuilder_ == null) {
          return userPermission_.get(index);
        } else {
          return userPermissionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder setUserPermission(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission value) {
        if (userPermissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUserPermissionIsMutable();
          userPermission_.set(index, value);
          onChanged();
        } else {
          userPermissionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder setUserPermission(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder builderForValue) {
        if (userPermissionBuilder_ == null) {
          ensureUserPermissionIsMutable();
          userPermission_.set(index, builderForValue.build());
          onChanged();
        } else {
          userPermissionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder addUserPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission value) {
        if (userPermissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUserPermissionIsMutable();
          userPermission_.add(value);
          onChanged();
        } else {
          userPermissionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder addUserPermission(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission value) {
        if (userPermissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureUserPermissionIsMutable();
          userPermission_.add(index, value);
          onChanged();
        } else {
          userPermissionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder addUserPermission(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder builderForValue) {
        if (userPermissionBuilder_ == null) {
          ensureUserPermissionIsMutable();
          userPermission_.add(builderForValue.build());
          onChanged();
        } else {
          userPermissionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder addUserPermission(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder builderForValue) {
        if (userPermissionBuilder_ == null) {
          ensureUserPermissionIsMutable();
          userPermission_.add(index, builderForValue.build());
          onChanged();
        } else {
          userPermissionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder addAllUserPermission(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission> values) {
        if (userPermissionBuilder_ == null) {
          ensureUserPermissionIsMutable();
          super.addAll(values, userPermission_);
          onChanged();
        } else {
          userPermissionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder clearUserPermission() {
        if (userPermissionBuilder_ == null) {
          userPermission_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          userPermissionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public Builder removeUserPermission(int index) {
        if (userPermissionBuilder_ == null) {
          ensureUserPermissionIsMutable();
          userPermission_.remove(index);
          onChanged();
        } else {
          userPermissionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder getUserPermissionBuilder(
          int index) {
        return getUserPermissionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder getUserPermissionOrBuilder(
          int index) {
        if (userPermissionBuilder_ == null) {
          return userPermission_.get(index);  } else {
          return userPermissionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> 
           getUserPermissionOrBuilderList() {
        if (userPermissionBuilder_ != null) {
          return userPermissionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(userPermission_);
        }
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder addUserPermissionBuilder() {
        return getUserPermissionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder addUserPermissionBuilder(
          int index) {
        return getUserPermissionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.UserPermission user_permission = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder> 
           getUserPermissionBuilderList() {
        return getUserPermissionFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder> 
          getUserPermissionFieldBuilder() {
        if (userPermissionBuilder_ == null) {
          userPermissionBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.UserPermissionOrBuilder>(
                  userPermission_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          userPermission_ = null;
        }
        return userPermissionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.GetUserPermissionsResponse)
    }

    static {
      defaultInstance = new GetUserPermissionsResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.GetUserPermissionsResponse)
  }

  public interface CheckPermissionsRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .hbase.pb.Permission permission = 1;
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> 
        getPermissionList();
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermission(int index);
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    int getPermissionCount();
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
        getPermissionOrBuilderList();
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hbase.pb.CheckPermissionsRequest}
   */
  public static final class CheckPermissionsRequest extends
      com.google.protobuf.GeneratedMessage
      implements CheckPermissionsRequestOrBuilder {
    // Use CheckPermissionsRequest.newBuilder() to construct.
    private CheckPermissionsRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private CheckPermissionsRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final CheckPermissionsRequest defaultInstance;
    public static CheckPermissionsRequest getDefaultInstance() {
      return defaultInstance;
    }

    public CheckPermissionsRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private CheckPermissionsRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                permission_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission>();
                mutable_bitField0_ |= 0x00000001;
              }
              permission_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          permission_ = java.util.Collections.unmodifiableList(permission_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<CheckPermissionsRequest> PARSER =
        new com.google.protobuf.AbstractParser<CheckPermissionsRequest>() {
      public CheckPermissionsRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CheckPermissionsRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<CheckPermissionsRequest> getParserForType() {
      return PARSER;
    }

    // repeated .hbase.pb.Permission permission = 1;
    public static final int PERMISSION_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> permission_;
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> getPermissionList() {
      return permission_;
    }
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
        getPermissionOrBuilderList() {
      return permission_;
    }
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    public int getPermissionCount() {
      return permission_.size();
    }
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermission(int index) {
      return permission_.get(index);
    }
    /**
     * <code>repeated .hbase.pb.Permission permission = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionOrBuilder(
        int index) {
      return permission_.get(index);
    }

    private void initFields() {
      permission_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getPermissionCount(); i++) {
        if (!getPermission(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < permission_.size(); i++) {
        output.writeMessage(1, permission_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < permission_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, permission_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest) obj;

      boolean result = true;
      result = result && getPermissionList()
          .equals(other.getPermissionList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getPermissionCount() > 0) {
        hash = (37 * hash) + PERMISSION_FIELD_NUMBER;
        hash = (53 * hash) + getPermissionList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CheckPermissionsRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getPermissionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (permissionBuilder_ == null) {
          permission_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          permissionBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest(this);
        int from_bitField0_ = bitField0_;
        if (permissionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            permission_ = java.util.Collections.unmodifiableList(permission_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.permission_ = permission_;
        } else {
          result.permission_ = permissionBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.getDefaultInstance()) return this;
        if (permissionBuilder_ == null) {
          if (!other.permission_.isEmpty()) {
            if (permission_.isEmpty()) {
              permission_ = other.permission_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensurePermissionIsMutable();
              permission_.addAll(other.permission_);
            }
            onChanged();
          }
        } else {
          if (!other.permission_.isEmpty()) {
            if (permissionBuilder_.isEmpty()) {
              permissionBuilder_.dispose();
              permissionBuilder_ = null;
              permission_ = other.permission_;
              bitField0_ = (bitField0_ & ~0x00000001);
              permissionBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getPermissionFieldBuilder() : null;
            } else {
              permissionBuilder_.addAllMessages(other.permission_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getPermissionCount(); i++) {
          if (!getPermission(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .hbase.pb.Permission permission = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> permission_ =
        java.util.Collections.emptyList();
      private void ensurePermissionIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          permission_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission>(permission_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> permissionBuilder_;

      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> getPermissionList() {
        if (permissionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(permission_);
        } else {
          return permissionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public int getPermissionCount() {
        if (permissionBuilder_ == null) {
          return permission_.size();
        } else {
          return permissionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission getPermission(int index) {
        if (permissionBuilder_ == null) {
          return permission_.get(index);
        } else {
          return permissionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder setPermission(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission value) {
        if (permissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePermissionIsMutable();
          permission_.set(index, value);
          onChanged();
        } else {
          permissionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder setPermission(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder builderForValue) {
        if (permissionBuilder_ == null) {
          ensurePermissionIsMutable();
          permission_.set(index, builderForValue.build());
          onChanged();
        } else {
          permissionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder addPermission(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission value) {
        if (permissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePermissionIsMutable();
          permission_.add(value);
          onChanged();
        } else {
          permissionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder addPermission(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission value) {
        if (permissionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePermissionIsMutable();
          permission_.add(index, value);
          onChanged();
        } else {
          permissionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder addPermission(
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder builderForValue) {
        if (permissionBuilder_ == null) {
          ensurePermissionIsMutable();
          permission_.add(builderForValue.build());
          onChanged();
        } else {
          permissionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder addPermission(
          int index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder builderForValue) {
        if (permissionBuilder_ == null) {
          ensurePermissionIsMutable();
          permission_.add(index, builderForValue.build());
          onChanged();
        } else {
          permissionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder addAllPermission(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission> values) {
        if (permissionBuilder_ == null) {
          ensurePermissionIsMutable();
          super.addAll(values, permission_);
          onChanged();
        } else {
          permissionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder clearPermission() {
        if (permissionBuilder_ == null) {
          permission_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          permissionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public Builder removePermission(int index) {
        if (permissionBuilder_ == null) {
          ensurePermissionIsMutable();
          permission_.remove(index);
          onChanged();
        } else {
          permissionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder getPermissionBuilder(
          int index) {
        return getPermissionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder getPermissionOrBuilder(
          int index) {
        if (permissionBuilder_ == null) {
          return permission_.get(index);  } else {
          return permissionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
           getPermissionOrBuilderList() {
        if (permissionBuilder_ != null) {
          return permissionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(permission_);
        }
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder addPermissionBuilder() {
        return getPermissionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder addPermissionBuilder(
          int index) {
        return getPermissionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.getDefaultInstance());
      }
      /**
       * <code>repeated .hbase.pb.Permission permission = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder> 
           getPermissionBuilderList() {
        return getPermissionFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder> 
          getPermissionFieldBuilder() {
        if (permissionBuilder_ == null) {
          permissionBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.Permission.Builder, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.PermissionOrBuilder>(
                  permission_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          permission_ = null;
        }
        return permissionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.CheckPermissionsRequest)
    }

    static {
      defaultInstance = new CheckPermissionsRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CheckPermissionsRequest)
  }

  public interface CheckPermissionsResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  /**
   * Protobuf type {@code hbase.pb.CheckPermissionsResponse}
   */
  public static final class CheckPermissionsResponse extends
      com.google.protobuf.GeneratedMessage
      implements CheckPermissionsResponseOrBuilder {
    // Use CheckPermissionsResponse.newBuilder() to construct.
    private CheckPermissionsResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private CheckPermissionsResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final CheckPermissionsResponse defaultInstance;
    public static CheckPermissionsResponse getDefaultInstance() {
      return defaultInstance;
    }

    public CheckPermissionsResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private CheckPermissionsResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<CheckPermissionsResponse> PARSER =
        new com.google.protobuf.AbstractParser<CheckPermissionsResponse>() {
      public CheckPermissionsResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CheckPermissionsResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<CheckPermissionsResponse> getParserForType() {
      return PARSER;
    }

    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse other = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse) obj;

      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hbase.pb.CheckPermissionsResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.class, org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.internal_static_hbase_pb_CheckPermissionsResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse result = new org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse(this);
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      // @@protoc_insertion_point(builder_scope:hbase.pb.CheckPermissionsResponse)
    }

    static {
      defaultInstance = new CheckPermissionsResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:hbase.pb.CheckPermissionsResponse)
  }

  /**
   * Protobuf service {@code hbase.pb.AccessControlService}
   */
  public static abstract class AccessControlService
      implements com.google.protobuf.Service {
    protected AccessControlService() {}

    public interface Interface {
      /**
       * <code>rpc Grant(.hbase.pb.GrantRequest) returns (.hbase.pb.GrantResponse);</code>
       */
      public abstract void grant(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse> done);

      /**
       * <code>rpc Revoke(.hbase.pb.RevokeRequest) returns (.hbase.pb.RevokeResponse);</code>
       */
      public abstract void revoke(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse> done);

      /**
       * <code>rpc GetUserPermissions(.hbase.pb.GetUserPermissionsRequest) returns (.hbase.pb.GetUserPermissionsResponse);</code>
       */
      public abstract void getUserPermissions(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse> done);

      /**
       * <code>rpc CheckPermissions(.hbase.pb.CheckPermissionsRequest) returns (.hbase.pb.CheckPermissionsResponse);</code>
       */
      public abstract void checkPermissions(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse> done);

    }

    public static com.google.protobuf.Service newReflectiveService(
        final Interface impl) {
      return new AccessControlService() {
        @java.lang.Override
        public  void grant(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse> done) {
          impl.grant(controller, request, done);
        }

        @java.lang.Override
        public  void revoke(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse> done) {
          impl.revoke(controller, request, done);
        }

        @java.lang.Override
        public  void getUserPermissions(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse> done) {
          impl.getUserPermissions(controller, request, done);
        }

        @java.lang.Override
        public  void checkPermissions(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse> done) {
          impl.checkPermissions(controller, request, done);
        }

      };
    }

    public static com.google.protobuf.BlockingService
        newReflectiveBlockingService(final BlockingInterface impl) {
      return new com.google.protobuf.BlockingService() {
        public final com.google.protobuf.Descriptors.ServiceDescriptor
            getDescriptorForType() {
          return getDescriptor();
        }

        public final com.google.protobuf.Message callBlockingMethod(
            com.google.protobuf.Descriptors.MethodDescriptor method,
            com.google.protobuf.RpcController controller,
            com.google.protobuf.Message request)
            throws com.google.protobuf.ServiceException {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.callBlockingMethod() given method descriptor for " +
              "wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return impl.grant(controller, (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest)request);
            case 1:
              return impl.revoke(controller, (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest)request);
            case 2:
              return impl.getUserPermissions(controller, (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest)request);
            case 3:
              return impl.checkPermissions(controller, (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest)request);
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final com.google.protobuf.Message
            getRequestPrototype(
            com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getRequestPrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final com.google.protobuf.Message
            getResponsePrototype(
            com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getResponsePrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

      };
    }

    /**
     * <code>rpc Grant(.hbase.pb.GrantRequest) returns (.hbase.pb.GrantResponse);</code>
     */
    public abstract void grant(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse> done);

    /**
     * <code>rpc Revoke(.hbase.pb.RevokeRequest) returns (.hbase.pb.RevokeResponse);</code>
     */
    public abstract void revoke(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse> done);

    /**
     * <code>rpc GetUserPermissions(.hbase.pb.GetUserPermissionsRequest) returns (.hbase.pb.GetUserPermissionsResponse);</code>
     */
    public abstract void getUserPermissions(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse> done);

    /**
     * <code>rpc CheckPermissions(.hbase.pb.CheckPermissionsRequest) returns (.hbase.pb.CheckPermissionsResponse);</code>
     */
    public abstract void checkPermissions(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse> done);

    public static final
        com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.getDescriptor().getServices().get(0);
    }
    public final com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }

    public final void callMethod(
        com.google.protobuf.Descriptors.MethodDescriptor method,
        com.google.protobuf.RpcController controller,
        com.google.protobuf.Message request,
        com.google.protobuf.RpcCallback<
          com.google.protobuf.Message> done) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.callMethod() given method descriptor for wrong " +
          "service type.");
      }
      switch(method.getIndex()) {
        case 0:
          this.grant(controller, (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse>specializeCallback(
              done));
          return;
        case 1:
          this.revoke(controller, (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse>specializeCallback(
              done));
          return;
        case 2:
          this.getUserPermissions(controller, (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse>specializeCallback(
              done));
          return;
        case 3:
          this.checkPermissions(controller, (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse>specializeCallback(
              done));
          return;
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final com.google.protobuf.Message
        getRequestPrototype(
        com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getRequestPrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final com.google.protobuf.Message
        getResponsePrototype(
        com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getResponsePrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public static Stub newStub(
        com.google.protobuf.RpcChannel channel) {
      return new Stub(channel);
    }

    public static final class Stub extends org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.AccessControlService implements Interface {
      private Stub(com.google.protobuf.RpcChannel channel) {
        this.channel = channel;
      }

      private final com.google.protobuf.RpcChannel channel;

      public com.google.protobuf.RpcChannel getChannel() {
        return channel;
      }

      public  void grant(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.getDefaultInstance()));
      }

      public  void revoke(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.getDefaultInstance()));
      }

      public  void getUserPermissions(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.getDefaultInstance()));
      }

      public  void checkPermissions(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.getDefaultInstance()));
      }
    }

    public static BlockingInterface newBlockingStub(
        com.google.protobuf.BlockingRpcChannel channel) {
      return new BlockingStub(channel);
    }

    public interface BlockingInterface {
      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse grant(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse revoke(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse getUserPermissions(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse checkPermissions(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest request)
          throws com.google.protobuf.ServiceException;
    }

    private static final class BlockingStub implements BlockingInterface {
      private BlockingStub(com.google.protobuf.BlockingRpcChannel channel) {
        this.channel = channel;
      }

      private final com.google.protobuf.BlockingRpcChannel channel;

      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse grant(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GrantResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse revoke(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.RevokeResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse getUserPermissions(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.GetUserPermissionsResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse checkPermissions(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.AccessControlProtos.CheckPermissionsResponse.getDefaultInstance());
      }

    }

    // @@protoc_insertion_point(class_scope:hbase.pb.AccessControlService)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_Permission_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_Permission_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_TablePermission_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_TablePermission_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_NamespacePermission_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_NamespacePermission_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GlobalPermission_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_GlobalPermission_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UserPermission_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_UserPermission_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UsersAndPermissions_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_UsersAndPermissions_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_UsersAndPermissions_UserPermissions_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_UsersAndPermissions_UserPermissions_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GrantRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_GrantRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GrantResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_GrantResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RevokeRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_RevokeRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_RevokeResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_RevokeResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetUserPermissionsRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_GetUserPermissionsRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_GetUserPermissionsResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_GetUserPermissionsResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CheckPermissionsRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_CheckPermissionsRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_hbase_pb_CheckPermissionsResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_hbase_pb_CheckPermissionsResponse_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\023AccessControl.proto\022\010hbase.pb\032\013HBase.p" +
      "roto\"\314\002\n\nPermission\022\'\n\004type\030\001 \002(\0162\031.hbas" +
      "e.pb.Permission.Type\0225\n\021global_permissio" +
      "n\030\002 \001(\0132\032.hbase.pb.GlobalPermission\022;\n\024n" +
      "amespace_permission\030\003 \001(\0132\035.hbase.pb.Nam" +
      "espacePermission\0223\n\020table_permission\030\004 \001" +
      "(\0132\031.hbase.pb.TablePermission\">\n\006Action\022" +
      "\010\n\004READ\020\000\022\t\n\005WRITE\020\001\022\010\n\004EXEC\020\002\022\n\n\006CREATE" +
      "\020\003\022\t\n\005ADMIN\020\004\",\n\004Type\022\n\n\006Global\020\001\022\r\n\tNam" +
      "espace\020\002\022\t\n\005Table\020\003\"\212\001\n\017TablePermission\022",
      "\'\n\ntable_name\030\001 \001(\0132\023.hbase.pb.TableName" +
      "\022\016\n\006family\030\002 \001(\014\022\021\n\tqualifier\030\003 \001(\014\022+\n\006a" +
      "ction\030\004 \003(\0162\033.hbase.pb.Permission.Action" +
      "\"Z\n\023NamespacePermission\022\026\n\016namespace_nam" +
      "e\030\001 \001(\014\022+\n\006action\030\002 \003(\0162\033.hbase.pb.Permi" +
      "ssion.Action\"?\n\020GlobalPermission\022+\n\006acti" +
      "on\030\001 \003(\0162\033.hbase.pb.Permission.Action\"H\n" +
      "\016UserPermission\022\014\n\004user\030\001 \002(\014\022(\n\npermiss" +
      "ion\030\003 \002(\0132\024.hbase.pb.Permission\"\252\001\n\023User" +
      "sAndPermissions\022G\n\020user_permissions\030\001 \003(",
      "\0132-.hbase.pb.UsersAndPermissions.UserPer" +
      "missions\032J\n\017UserPermissions\022\014\n\004user\030\001 \002(" +
      "\014\022)\n\013permissions\030\002 \003(\0132\024.hbase.pb.Permis" +
      "sion\"l\n\014GrantRequest\0221\n\017user_permission\030" +
      "\001 \002(\0132\030.hbase.pb.UserPermission\022)\n\032merge" +
      "_existing_permissions\030\002 \001(\010:\005false\"\017\n\rGr" +
      "antResponse\"B\n\rRevokeRequest\0221\n\017user_per" +
      "mission\030\001 \002(\0132\030.hbase.pb.UserPermission\"" +
      "\020\n\016RevokeResponse\"\205\001\n\031GetUserPermissions" +
      "Request\022\'\n\004type\030\001 \001(\0162\031.hbase.pb.Permiss",
      "ion.Type\022\'\n\ntable_name\030\002 \001(\0132\023.hbase.pb." +
      "TableName\022\026\n\016namespace_name\030\003 \001(\014\"O\n\032Get" +
      "UserPermissionsResponse\0221\n\017user_permissi" +
      "on\030\001 \003(\0132\030.hbase.pb.UserPermission\"C\n\027Ch" +
      "eckPermissionsRequest\022(\n\npermission\030\001 \003(" +
      "\0132\024.hbase.pb.Permission\"\032\n\030CheckPermissi" +
      "onsResponse2\311\002\n\024AccessControlService\0228\n\005" +
      "Grant\022\026.hbase.pb.GrantRequest\032\027.hbase.pb" +
      ".GrantResponse\022;\n\006Revoke\022\027.hbase.pb.Revo" +
      "keRequest\032\030.hbase.pb.RevokeResponse\022_\n\022G",
      "etUserPermissions\022#.hbase.pb.GetUserPerm" +
      "issionsRequest\032$.hbase.pb.GetUserPermiss" +
      "ionsResponse\022Y\n\020CheckPermissions\022!.hbase" +
      ".pb.CheckPermissionsRequest\032\".hbase.pb.C" +
      "heckPermissionsResponseBI\n*org.apache.ha" +
      "doop.hbase.protobuf.generatedB\023AccessCon" +
      "trolProtosH\001\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_hbase_pb_Permission_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_hbase_pb_Permission_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_Permission_descriptor,
              new java.lang.String[] { "Type", "GlobalPermission", "NamespacePermission", "TablePermission", });
          internal_static_hbase_pb_TablePermission_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_hbase_pb_TablePermission_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_TablePermission_descriptor,
              new java.lang.String[] { "TableName", "Family", "Qualifier", "Action", });
          internal_static_hbase_pb_NamespacePermission_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_hbase_pb_NamespacePermission_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_NamespacePermission_descriptor,
              new java.lang.String[] { "NamespaceName", "Action", });
          internal_static_hbase_pb_GlobalPermission_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_hbase_pb_GlobalPermission_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_GlobalPermission_descriptor,
              new java.lang.String[] { "Action", });
          internal_static_hbase_pb_UserPermission_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_hbase_pb_UserPermission_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_UserPermission_descriptor,
              new java.lang.String[] { "User", "Permission", });
          internal_static_hbase_pb_UsersAndPermissions_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_hbase_pb_UsersAndPermissions_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_UsersAndPermissions_descriptor,
              new java.lang.String[] { "UserPermissions", });
          internal_static_hbase_pb_UsersAndPermissions_UserPermissions_descriptor =
            internal_static_hbase_pb_UsersAndPermissions_descriptor.getNestedTypes().get(0);
          internal_static_hbase_pb_UsersAndPermissions_UserPermissions_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_UsersAndPermissions_UserPermissions_descriptor,
              new java.lang.String[] { "User", "Permissions", });
          internal_static_hbase_pb_GrantRequest_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_hbase_pb_GrantRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_GrantRequest_descriptor,
              new java.lang.String[] { "UserPermission", "MergeExistingPermissions", });
          internal_static_hbase_pb_GrantResponse_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_hbase_pb_GrantResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_GrantResponse_descriptor,
              new java.lang.String[] { });
          internal_static_hbase_pb_RevokeRequest_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_hbase_pb_RevokeRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_RevokeRequest_descriptor,
              new java.lang.String[] { "UserPermission", });
          internal_static_hbase_pb_RevokeResponse_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_hbase_pb_RevokeResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_RevokeResponse_descriptor,
              new java.lang.String[] { });
          internal_static_hbase_pb_GetUserPermissionsRequest_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_hbase_pb_GetUserPermissionsRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_GetUserPermissionsRequest_descriptor,
              new java.lang.String[] { "Type", "TableName", "NamespaceName", });
          internal_static_hbase_pb_GetUserPermissionsResponse_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_hbase_pb_GetUserPermissionsResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_GetUserPermissionsResponse_descriptor,
              new java.lang.String[] { "UserPermission", });
          internal_static_hbase_pb_CheckPermissionsRequest_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_hbase_pb_CheckPermissionsRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_CheckPermissionsRequest_descriptor,
              new java.lang.String[] { "Permission", });
          internal_static_hbase_pb_CheckPermissionsResponse_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_hbase_pb_CheckPermissionsResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_hbase_pb_CheckPermissionsResponse_descriptor,
              new java.lang.String[] { });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor(),
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}

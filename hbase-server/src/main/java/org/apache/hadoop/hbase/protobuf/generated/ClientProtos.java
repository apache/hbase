// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: Client.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class ClientProtos {
  private ClientProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public interface ColumnOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required bytes family = 1;
    boolean hasFamily();
    com.google.protobuf.ByteString getFamily();
    
    // repeated bytes qualifier = 2;
    java.util.List<com.google.protobuf.ByteString> getQualifierList();
    int getQualifierCount();
    com.google.protobuf.ByteString getQualifier(int index);
  }
  public static final class Column extends
      com.google.protobuf.GeneratedMessage
      implements ColumnOrBuilder {
    // Use Column.newBuilder() to construct.
    private Column(Builder builder) {
      super(builder);
    }
    private Column(boolean noInit) {}
    
    private static final Column defaultInstance;
    public static Column getDefaultInstance() {
      return defaultInstance;
    }
    
    public Column getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required bytes family = 1;
    public static final int FAMILY_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString family_;
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public com.google.protobuf.ByteString getFamily() {
      return family_;
    }
    
    // repeated bytes qualifier = 2;
    public static final int QUALIFIER_FIELD_NUMBER = 2;
    private java.util.List<com.google.protobuf.ByteString> qualifier_;
    public java.util.List<com.google.protobuf.ByteString>
        getQualifierList() {
      return qualifier_;
    }
    public int getQualifierCount() {
      return qualifier_.size();
    }
    public com.google.protobuf.ByteString getQualifier(int index) {
      return qualifier_.get(index);
    }
    
    private void initFields() {
      family_ = com.google.protobuf.ByteString.EMPTY;
      qualifier_ = java.util.Collections.emptyList();;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, family_);
      }
      for (int i = 0; i < qualifier_.size(); i++) {
        output.writeBytes(2, qualifier_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, family_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < qualifier_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(qualifier_.get(i));
        }
        size += dataSize;
        size += 1 * getQualifierList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column) obj;
      
      boolean result = true;
      result = result && (hasFamily() == other.hasFamily());
      if (hasFamily()) {
        result = result && getFamily()
            .equals(other.getFamily());
      }
      result = result && getQualifierList()
          .equals(other.getQualifierList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (getQualifierCount() > 0) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifierList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        family_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        qualifier_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.family_ = family_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          qualifier_ = java.util.Collections.unmodifiableList(qualifier_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.qualifier_ = qualifier_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance()) return this;
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (!other.qualifier_.isEmpty()) {
          if (qualifier_.isEmpty()) {
            qualifier_ = other.qualifier_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureQualifierIsMutable();
            qualifier_.addAll(other.qualifier_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasFamily()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              family_ = input.readBytes();
              break;
            }
            case 18: {
              ensureQualifierIsMutable();
              qualifier_.add(input.readBytes());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required bytes family = 1;
      private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      public Builder setFamily(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        family_ = value;
        onChanged();
        return this;
      }
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }
      
      // repeated bytes qualifier = 2;
      private java.util.List<com.google.protobuf.ByteString> qualifier_ = java.util.Collections.emptyList();;
      private void ensureQualifierIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          qualifier_ = new java.util.ArrayList<com.google.protobuf.ByteString>(qualifier_);
          bitField0_ |= 0x00000002;
         }
      }
      public java.util.List<com.google.protobuf.ByteString>
          getQualifierList() {
        return java.util.Collections.unmodifiableList(qualifier_);
      }
      public int getQualifierCount() {
        return qualifier_.size();
      }
      public com.google.protobuf.ByteString getQualifier(int index) {
        return qualifier_.get(index);
      }
      public Builder setQualifier(
          int index, com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureQualifierIsMutable();
        qualifier_.set(index, value);
        onChanged();
        return this;
      }
      public Builder addQualifier(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureQualifierIsMutable();
        qualifier_.add(value);
        onChanged();
        return this;
      }
      public Builder addAllQualifier(
          java.lang.Iterable<? extends com.google.protobuf.ByteString> values) {
        ensureQualifierIsMutable();
        super.addAll(values, qualifier_);
        onChanged();
        return this;
      }
      public Builder clearQualifier() {
        qualifier_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:Column)
    }
    
    static {
      defaultInstance = new Column(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:Column)
  }
  
  public interface GetOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required bytes row = 1;
    boolean hasRow();
    com.google.protobuf.ByteString getRow();
    
    // repeated .Column column = 2;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> 
        getColumnList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index);
    int getColumnCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index);
    
    // repeated .NameBytesPair attribute = 3;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    int getAttributeCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);
    
    // optional uint64 lockId = 4;
    boolean hasLockId();
    long getLockId();
    
    // optional .Filter filter = 5;
    boolean hasFilter();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter getFilter();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder getFilterOrBuilder();
    
    // optional .TimeRange timeRange = 6;
    boolean hasTimeRange();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();
    
    // optional uint32 maxVersions = 7 [default = 1];
    boolean hasMaxVersions();
    int getMaxVersions();
    
    // optional bool cacheBlocks = 8 [default = true];
    boolean hasCacheBlocks();
    boolean getCacheBlocks();
    
    // optional uint32 storeLimit = 9;
    boolean hasStoreLimit();
    int getStoreLimit();
    
    // optional uint32 storeOffset = 10;
    boolean hasStoreOffset();
    int getStoreOffset();
  }
  public static final class Get extends
      com.google.protobuf.GeneratedMessage
      implements GetOrBuilder {
    // Use Get.newBuilder() to construct.
    private Get(Builder builder) {
      super(builder);
    }
    private Get(boolean noInit) {}
    
    private static final Get defaultInstance;
    public static Get getDefaultInstance() {
      return defaultInstance;
    }
    
    public Get getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }
    
    // repeated .Column column = 2;
    public static final int COLUMN_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> column_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> getColumnList() {
      return column_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList() {
      return column_;
    }
    public int getColumnCount() {
      return column_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index) {
      return column_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index) {
      return column_.get(index);
    }
    
    // repeated .NameBytesPair attribute = 3;
    public static final int ATTRIBUTE_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    public int getAttributeCount() {
      return attribute_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }
    
    // optional uint64 lockId = 4;
    public static final int LOCKID_FIELD_NUMBER = 4;
    private long lockId_;
    public boolean hasLockId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public long getLockId() {
      return lockId_;
    }
    
    // optional .Filter filter = 5;
    public static final int FILTER_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter filter_;
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter getFilter() {
      return filter_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_;
    }
    
    // optional .TimeRange timeRange = 6;
    public static final int TIMERANGE_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_;
    }
    
    // optional uint32 maxVersions = 7 [default = 1];
    public static final int MAXVERSIONS_FIELD_NUMBER = 7;
    private int maxVersions_;
    public boolean hasMaxVersions() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public int getMaxVersions() {
      return maxVersions_;
    }
    
    // optional bool cacheBlocks = 8 [default = true];
    public static final int CACHEBLOCKS_FIELD_NUMBER = 8;
    private boolean cacheBlocks_;
    public boolean hasCacheBlocks() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    public boolean getCacheBlocks() {
      return cacheBlocks_;
    }
    
    // optional uint32 storeLimit = 9;
    public static final int STORELIMIT_FIELD_NUMBER = 9;
    private int storeLimit_;
    public boolean hasStoreLimit() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    public int getStoreLimit() {
      return storeLimit_;
    }
    
    // optional uint32 storeOffset = 10;
    public static final int STOREOFFSET_FIELD_NUMBER = 10;
    private int storeOffset_;
    public boolean hasStoreOffset() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    public int getStoreOffset() {
      return storeOffset_;
    }
    
    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      column_ = java.util.Collections.emptyList();
      attribute_ = java.util.Collections.emptyList();
      lockId_ = 0L;
      filter_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
      timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      maxVersions_ = 1;
      cacheBlocks_ = true;
      storeLimit_ = 0;
      storeOffset_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getColumnCount(); i++) {
        if (!getColumn(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasFilter()) {
        if (!getFilter().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      for (int i = 0; i < column_.size(); i++) {
        output.writeMessage(2, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(3, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt64(4, lockId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(5, filter_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(6, timeRange_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeUInt32(7, maxVersions_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBool(8, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeUInt32(9, storeLimit_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeUInt32(10, storeOffset_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      for (int i = 0; i < column_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, lockId_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, filter_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, timeRange_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(7, maxVersions_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(9, storeLimit_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(10, storeOffset_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get) obj;
      
      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && getColumnList()
          .equals(other.getColumnList());
      result = result && getAttributeList()
          .equals(other.getAttributeList());
      result = result && (hasLockId() == other.hasLockId());
      if (hasLockId()) {
        result = result && (getLockId()
            == other.getLockId());
      }
      result = result && (hasFilter() == other.hasFilter());
      if (hasFilter()) {
        result = result && getFilter()
            .equals(other.getFilter());
      }
      result = result && (hasTimeRange() == other.hasTimeRange());
      if (hasTimeRange()) {
        result = result && getTimeRange()
            .equals(other.getTimeRange());
      }
      result = result && (hasMaxVersions() == other.hasMaxVersions());
      if (hasMaxVersions()) {
        result = result && (getMaxVersions()
            == other.getMaxVersions());
      }
      result = result && (hasCacheBlocks() == other.hasCacheBlocks());
      if (hasCacheBlocks()) {
        result = result && (getCacheBlocks()
            == other.getCacheBlocks());
      }
      result = result && (hasStoreLimit() == other.hasStoreLimit());
      if (hasStoreLimit()) {
        result = result && (getStoreLimit()
            == other.getStoreLimit());
      }
      result = result && (hasStoreOffset() == other.hasStoreOffset());
      if (hasStoreOffset()) {
        result = result && (getStoreOffset()
            == other.getStoreOffset());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (getColumnCount() > 0) {
        hash = (37 * hash) + COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + getColumnList().hashCode();
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasLockId()) {
        hash = (37 * hash) + LOCKID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getLockId());
      }
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIMERANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasMaxVersions()) {
        hash = (37 * hash) + MAXVERSIONS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxVersions();
      }
      if (hasCacheBlocks()) {
        hash = (37 * hash) + CACHEBLOCKS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCacheBlocks());
      }
      if (hasStoreLimit()) {
        hash = (37 * hash) + STORELIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getStoreLimit();
      }
      if (hasStoreOffset()) {
        hash = (37 * hash) + STOREOFFSET_FIELD_NUMBER;
        hash = (53 * hash) + getStoreOffset();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getColumnFieldBuilder();
          getAttributeFieldBuilder();
          getFilterFieldBuilder();
          getTimeRangeFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          columnBuilder_.clear();
        }
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          attributeBuilder_.clear();
        }
        lockId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (filterBuilder_ == null) {
          filter_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
        } else {
          filterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        maxVersions_ = 1;
        bitField0_ = (bitField0_ & ~0x00000040);
        cacheBlocks_ = true;
        bitField0_ = (bitField0_ & ~0x00000080);
        storeLimit_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        storeOffset_ = 0;
        bitField0_ = (bitField0_ & ~0x00000200);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (columnBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            column_ = java.util.Collections.unmodifiableList(column_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.column_ = column_;
        } else {
          result.column_ = columnBuilder_.build();
        }
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000002;
        }
        result.lockId_ = lockId_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        if (filterBuilder_ == null) {
          result.filter_ = filter_;
        } else {
          result.filter_ = filterBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000008;
        }
        if (timeRangeBuilder_ == null) {
          result.timeRange_ = timeRange_;
        } else {
          result.timeRange_ = timeRangeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        result.maxVersions_ = maxVersions_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        result.cacheBlocks_ = cacheBlocks_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000040;
        }
        result.storeLimit_ = storeLimit_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000080;
        }
        result.storeOffset_ = storeOffset_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (columnBuilder_ == null) {
          if (!other.column_.isEmpty()) {
            if (column_.isEmpty()) {
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureColumnIsMutable();
              column_.addAll(other.column_);
            }
            onChanged();
          }
        } else {
          if (!other.column_.isEmpty()) {
            if (columnBuilder_.isEmpty()) {
              columnBuilder_.dispose();
              columnBuilder_ = null;
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000002);
              columnBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getColumnFieldBuilder() : null;
            } else {
              columnBuilder_.addAllMessages(other.column_);
            }
          }
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000004);
              attributeBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasLockId()) {
          setLockId(other.getLockId());
        }
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasMaxVersions()) {
          setMaxVersions(other.getMaxVersions());
        }
        if (other.hasCacheBlocks()) {
          setCacheBlocks(other.getCacheBlocks());
        }
        if (other.hasStoreLimit()) {
          setStoreLimit(other.getStoreLimit());
        }
        if (other.hasStoreOffset()) {
          setStoreOffset(other.getStoreOffset());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        for (int i = 0; i < getColumnCount(); i++) {
          if (!getColumn(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            
            return false;
          }
        }
        if (hasFilter()) {
          if (!getFilter().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addColumn(subBuilder.buildPartial());
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addAttribute(subBuilder.buildPartial());
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              lockId_ = input.readUInt64();
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.newBuilder();
              if (hasFilter()) {
                subBuilder.mergeFrom(getFilter());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setFilter(subBuilder.buildPartial());
              break;
            }
            case 50: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder();
              if (hasTimeRange()) {
                subBuilder.mergeFrom(getTimeRange());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setTimeRange(subBuilder.buildPartial());
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              maxVersions_ = input.readUInt32();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              cacheBlocks_ = input.readBool();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              storeLimit_ = input.readUInt32();
              break;
            }
            case 80: {
              bitField0_ |= 0x00000200;
              storeOffset_ = input.readUInt32();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }
      
      // repeated .Column column = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> column_ =
        java.util.Collections.emptyList();
      private void ensureColumnIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          column_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column>(column_);
          bitField0_ |= 0x00000002;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> columnBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> getColumnList() {
        if (columnBuilder_ == null) {
          return java.util.Collections.unmodifiableList(column_);
        } else {
          return columnBuilder_.getMessageList();
        }
      }
      public int getColumnCount() {
        if (columnBuilder_ == null) {
          return column_.size();
        } else {
          return columnBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);
        } else {
          return columnBuilder_.getMessage(index);
        }
      }
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.set(index, value);
          onChanged();
        } else {
          columnBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addColumn(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(value);
          onChanged();
        } else {
          columnBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(index, value);
          onChanged();
        } else {
          columnBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addColumn(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllColumn(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> values) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          super.addAll(values, column_);
          onChanged();
        } else {
          columnBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearColumn() {
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          columnBuilder_.clear();
        }
        return this;
      }
      public Builder removeColumn(int index) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.remove(index);
          onChanged();
        } else {
          columnBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder getColumnBuilder(
          int index) {
        return getColumnFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
          int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);  } else {
          return columnBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
           getColumnOrBuilderList() {
        if (columnBuilder_ != null) {
          return columnBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(column_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder() {
        return getColumnFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder(
          int index) {
        return getColumnFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder> 
           getColumnBuilderList() {
        return getColumnFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
          getColumnFieldBuilder() {
        if (columnBuilder_ == null) {
          columnBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder>(
                  column_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          column_ = null;
        }
        return columnBuilder_;
      }
      
      // repeated .NameBytesPair attribute = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000004;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAttribute(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addAttribute(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          super.addAll(values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }
      
      // optional uint64 lockId = 4;
      private long lockId_ ;
      public boolean hasLockId() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public long getLockId() {
        return lockId_;
      }
      public Builder setLockId(long value) {
        bitField0_ |= 0x00000008;
        lockId_ = value;
        onChanged();
        return this;
      }
      public Builder clearLockId() {
        bitField0_ = (bitField0_ & ~0x00000008);
        lockId_ = 0L;
        onChanged();
        return this;
      }
      
      // optional .Filter filter = 5;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter filter_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder> filterBuilder_;
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      public Builder setFilter(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
          onChanged();
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder setFilter(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
          onChanged();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder mergeFilter(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              filter_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance()) {
            filter_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.newBuilder(filter_).mergeFrom(value).buildPartial();
          } else {
            filter_ = value;
          }
          onChanged();
        } else {
          filterBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder clearFilter() {
        if (filterBuilder_ == null) {
          filter_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
          onChanged();
        } else {
          filterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder>(
                  filter_,
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }
      
      // optional .TimeRange timeRange = 6;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      public Builder setTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      public Builder setTimeRange(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      public Builder mergeTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              timeRange_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            timeRange_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder(timeRange_).mergeFrom(value).buildPartial();
          } else {
            timeRange_ = value;
          }
          onChanged();
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      public Builder clearTimeRange() {
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
          onChanged();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  timeRange_,
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }
      
      // optional uint32 maxVersions = 7 [default = 1];
      private int maxVersions_ = 1;
      public boolean hasMaxVersions() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      public int getMaxVersions() {
        return maxVersions_;
      }
      public Builder setMaxVersions(int value) {
        bitField0_ |= 0x00000040;
        maxVersions_ = value;
        onChanged();
        return this;
      }
      public Builder clearMaxVersions() {
        bitField0_ = (bitField0_ & ~0x00000040);
        maxVersions_ = 1;
        onChanged();
        return this;
      }
      
      // optional bool cacheBlocks = 8 [default = true];
      private boolean cacheBlocks_ = true;
      public boolean hasCacheBlocks() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      public boolean getCacheBlocks() {
        return cacheBlocks_;
      }
      public Builder setCacheBlocks(boolean value) {
        bitField0_ |= 0x00000080;
        cacheBlocks_ = value;
        onChanged();
        return this;
      }
      public Builder clearCacheBlocks() {
        bitField0_ = (bitField0_ & ~0x00000080);
        cacheBlocks_ = true;
        onChanged();
        return this;
      }
      
      // optional uint32 storeLimit = 9;
      private int storeLimit_ ;
      public boolean hasStoreLimit() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      public int getStoreLimit() {
        return storeLimit_;
      }
      public Builder setStoreLimit(int value) {
        bitField0_ |= 0x00000100;
        storeLimit_ = value;
        onChanged();
        return this;
      }
      public Builder clearStoreLimit() {
        bitField0_ = (bitField0_ & ~0x00000100);
        storeLimit_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 storeOffset = 10;
      private int storeOffset_ ;
      public boolean hasStoreOffset() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      public int getStoreOffset() {
        return storeOffset_;
      }
      public Builder setStoreOffset(int value) {
        bitField0_ |= 0x00000200;
        storeOffset_ = value;
        onChanged();
        return this;
      }
      public Builder clearStoreOffset() {
        bitField0_ = (bitField0_ & ~0x00000200);
        storeOffset_ = 0;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:Get)
    }
    
    static {
      defaultInstance = new Get(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:Get)
  }
  
  public interface ResultOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated bytes keyValueBytes = 1;
    java.util.List<com.google.protobuf.ByteString> getKeyValueBytesList();
    int getKeyValueBytesCount();
    com.google.protobuf.ByteString getKeyValueBytes(int index);
  }
  public static final class Result extends
      com.google.protobuf.GeneratedMessage
      implements ResultOrBuilder {
    // Use Result.newBuilder() to construct.
    private Result(Builder builder) {
      super(builder);
    }
    private Result(boolean noInit) {}
    
    private static final Result defaultInstance;
    public static Result getDefaultInstance() {
      return defaultInstance;
    }
    
    public Result getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_fieldAccessorTable;
    }
    
    // repeated bytes keyValueBytes = 1;
    public static final int KEYVALUEBYTES_FIELD_NUMBER = 1;
    private java.util.List<com.google.protobuf.ByteString> keyValueBytes_;
    public java.util.List<com.google.protobuf.ByteString>
        getKeyValueBytesList() {
      return keyValueBytes_;
    }
    public int getKeyValueBytesCount() {
      return keyValueBytes_.size();
    }
    public com.google.protobuf.ByteString getKeyValueBytes(int index) {
      return keyValueBytes_.get(index);
    }
    
    private void initFields() {
      keyValueBytes_ = java.util.Collections.emptyList();;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < keyValueBytes_.size(); i++) {
        output.writeBytes(1, keyValueBytes_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < keyValueBytes_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(keyValueBytes_.get(i));
        }
        size += dataSize;
        size += 1 * getKeyValueBytesList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result) obj;
      
      boolean result = true;
      result = result && getKeyValueBytesList()
          .equals(other.getKeyValueBytesList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getKeyValueBytesCount() > 0) {
        hash = (37 * hash) + KEYVALUEBYTES_FIELD_NUMBER;
        hash = (53 * hash) + getKeyValueBytesList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        keyValueBytes_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          keyValueBytes_ = java.util.Collections.unmodifiableList(keyValueBytes_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.keyValueBytes_ = keyValueBytes_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance()) return this;
        if (!other.keyValueBytes_.isEmpty()) {
          if (keyValueBytes_.isEmpty()) {
            keyValueBytes_ = other.keyValueBytes_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureKeyValueBytesIsMutable();
            keyValueBytes_.addAll(other.keyValueBytes_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              ensureKeyValueBytesIsMutable();
              keyValueBytes_.add(input.readBytes());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated bytes keyValueBytes = 1;
      private java.util.List<com.google.protobuf.ByteString> keyValueBytes_ = java.util.Collections.emptyList();;
      private void ensureKeyValueBytesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          keyValueBytes_ = new java.util.ArrayList<com.google.protobuf.ByteString>(keyValueBytes_);
          bitField0_ |= 0x00000001;
         }
      }
      public java.util.List<com.google.protobuf.ByteString>
          getKeyValueBytesList() {
        return java.util.Collections.unmodifiableList(keyValueBytes_);
      }
      public int getKeyValueBytesCount() {
        return keyValueBytes_.size();
      }
      public com.google.protobuf.ByteString getKeyValueBytes(int index) {
        return keyValueBytes_.get(index);
      }
      public Builder setKeyValueBytes(
          int index, com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureKeyValueBytesIsMutable();
        keyValueBytes_.set(index, value);
        onChanged();
        return this;
      }
      public Builder addKeyValueBytes(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureKeyValueBytesIsMutable();
        keyValueBytes_.add(value);
        onChanged();
        return this;
      }
      public Builder addAllKeyValueBytes(
          java.lang.Iterable<? extends com.google.protobuf.ByteString> values) {
        ensureKeyValueBytesIsMutable();
        super.addAll(values, keyValueBytes_);
        onChanged();
        return this;
      }
      public Builder clearKeyValueBytes() {
        keyValueBytes_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:Result)
    }
    
    static {
      defaultInstance = new Result(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:Result)
  }
  
  public interface GetRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // required .Get get = 2;
    boolean hasGet();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder();
    
    // optional bool closestRowBefore = 3;
    boolean hasClosestRowBefore();
    boolean getClosestRowBefore();
    
    // optional bool existenceOnly = 4;
    boolean hasExistenceOnly();
    boolean getExistenceOnly();
  }
  public static final class GetRequest extends
      com.google.protobuf.GeneratedMessage
      implements GetRequestOrBuilder {
    // Use GetRequest.newBuilder() to construct.
    private GetRequest(Builder builder) {
      super(builder);
    }
    private GetRequest(boolean noInit) {}
    
    private static final GetRequest defaultInstance;
    public static GetRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // required .Get get = 2;
    public static final int GET_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get get_;
    public boolean hasGet() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet() {
      return get_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
      return get_;
    }
    
    // optional bool closestRowBefore = 3;
    public static final int CLOSESTROWBEFORE_FIELD_NUMBER = 3;
    private boolean closestRowBefore_;
    public boolean hasClosestRowBefore() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public boolean getClosestRowBefore() {
      return closestRowBefore_;
    }
    
    // optional bool existenceOnly = 4;
    public static final int EXISTENCEONLY_FIELD_NUMBER = 4;
    private boolean existenceOnly_;
    public boolean hasExistenceOnly() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public boolean getExistenceOnly() {
      return existenceOnly_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      closestRowBefore_ = false;
      existenceOnly_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasGet()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getGet().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, get_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, closestRowBefore_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBool(4, existenceOnly_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, get_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, closestRowBefore_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, existenceOnly_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasGet() == other.hasGet());
      if (hasGet()) {
        result = result && getGet()
            .equals(other.getGet());
      }
      result = result && (hasClosestRowBefore() == other.hasClosestRowBefore());
      if (hasClosestRowBefore()) {
        result = result && (getClosestRowBefore()
            == other.getClosestRowBefore());
      }
      result = result && (hasExistenceOnly() == other.hasExistenceOnly());
      if (hasExistenceOnly()) {
        result = result && (getExistenceOnly()
            == other.getExistenceOnly());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasGet()) {
        hash = (37 * hash) + GET_FIELD_NUMBER;
        hash = (53 * hash) + getGet().hashCode();
      }
      if (hasClosestRowBefore()) {
        hash = (37 * hash) + CLOSESTROWBEFORE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getClosestRowBefore());
      }
      if (hasExistenceOnly()) {
        hash = (37 * hash) + EXISTENCEONLY_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getExistenceOnly());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getGetFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (getBuilder_ == null) {
          get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
        } else {
          getBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        closestRowBefore_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        existenceOnly_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (getBuilder_ == null) {
          result.get_ = get_;
        } else {
          result.get_ = getBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.closestRowBefore_ = closestRowBefore_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.existenceOnly_ = existenceOnly_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasGet()) {
          mergeGet(other.getGet());
        }
        if (other.hasClosestRowBefore()) {
          setClosestRowBefore(other.getClosestRowBefore());
        }
        if (other.hasExistenceOnly()) {
          setExistenceOnly(other.getExistenceOnly());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasGet()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getGet().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.newBuilder();
              if (hasGet()) {
                subBuilder.mergeFrom(getGet());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setGet(subBuilder.buildPartial());
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              closestRowBefore_ = input.readBool();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              existenceOnly_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // required .Get get = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> getBuilder_;
      public boolean hasGet() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet() {
        if (getBuilder_ == null) {
          return get_;
        } else {
          return getBuilder_.getMessage();
        }
      }
      public Builder setGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          get_ = value;
          onChanged();
        } else {
          getBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setGet(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          get_ = builderForValue.build();
          onChanged();
        } else {
          getBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              get_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance()) {
            get_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.newBuilder(get_).mergeFrom(value).buildPartial();
          } else {
            get_ = value;
          }
          onChanged();
        } else {
          getBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearGet() {
        if (getBuilder_ == null) {
          get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
          onChanged();
        } else {
          getBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder getGetBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getGetFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
        if (getBuilder_ != null) {
          return getBuilder_.getMessageOrBuilder();
        } else {
          return get_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> 
          getGetFieldBuilder() {
        if (getBuilder_ == null) {
          getBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder>(
                  get_,
                  getParentForChildren(),
                  isClean());
          get_ = null;
        }
        return getBuilder_;
      }
      
      // optional bool closestRowBefore = 3;
      private boolean closestRowBefore_ ;
      public boolean hasClosestRowBefore() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public boolean getClosestRowBefore() {
        return closestRowBefore_;
      }
      public Builder setClosestRowBefore(boolean value) {
        bitField0_ |= 0x00000004;
        closestRowBefore_ = value;
        onChanged();
        return this;
      }
      public Builder clearClosestRowBefore() {
        bitField0_ = (bitField0_ & ~0x00000004);
        closestRowBefore_ = false;
        onChanged();
        return this;
      }
      
      // optional bool existenceOnly = 4;
      private boolean existenceOnly_ ;
      public boolean hasExistenceOnly() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public boolean getExistenceOnly() {
        return existenceOnly_;
      }
      public Builder setExistenceOnly(boolean value) {
        bitField0_ |= 0x00000008;
        existenceOnly_ = value;
        onChanged();
        return this;
      }
      public Builder clearExistenceOnly() {
        bitField0_ = (bitField0_ & ~0x00000008);
        existenceOnly_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:GetRequest)
    }
    
    static {
      defaultInstance = new GetRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetRequest)
  }
  
  public interface GetResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .Result result = 1;
    boolean hasResult();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder();
    
    // optional bool exists = 2;
    boolean hasExists();
    boolean getExists();
  }
  public static final class GetResponse extends
      com.google.protobuf.GeneratedMessage
      implements GetResponseOrBuilder {
    // Use GetResponse.newBuilder() to construct.
    private GetResponse(Builder builder) {
      super(builder);
    }
    private GetResponse(boolean noInit) {}
    
    private static final GetResponse defaultInstance;
    public static GetResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public GetResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .Result result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result_;
    public boolean hasResult() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult() {
      return result_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
      return result_;
    }
    
    // optional bool exists = 2;
    public static final int EXISTS_FIELD_NUMBER = 2;
    private boolean exists_;
    public boolean hasExists() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public boolean getExists() {
      return exists_;
    }
    
    private void initFields() {
      result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      exists_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, result_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, exists_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, exists_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse) obj;
      
      boolean result = true;
      result = result && (hasResult() == other.hasResult());
      if (hasResult()) {
        result = result && getResult()
            .equals(other.getResult());
      }
      result = result && (hasExists() == other.hasExists());
      if (hasExists()) {
        result = result && (getExists()
            == other.getExists());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResult()) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResult().hashCode();
      }
      if (hasExists()) {
        hash = (37 * hash) + EXISTS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getExists());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
        } else {
          resultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        exists_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resultBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.exists_ = exists_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance()) return this;
        if (other.hasResult()) {
          mergeResult(other.getResult());
        }
        if (other.hasExists()) {
          setExists(other.getExists());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder();
              if (hasResult()) {
                subBuilder.mergeFrom(getResult());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setResult(subBuilder.buildPartial());
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              exists_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .Result result = 1;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;
      public boolean hasResult() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult() {
        if (resultBuilder_ == null) {
          return result_;
        } else {
          return resultBuilder_.getMessage();
        }
      }
      public Builder setResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          result_ = value;
          onChanged();
        } else {
          resultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setResult(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          result_ = builderForValue.build();
          onChanged();
        } else {
          resultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              result_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance()) {
            result_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder(result_).mergeFrom(value).buildPartial();
          } else {
            result_ = value;
          }
          onChanged();
        } else {
          resultBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder getResultBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResultFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilder();
        } else {
          return result_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  result_,
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }
      
      // optional bool exists = 2;
      private boolean exists_ ;
      public boolean hasExists() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public boolean getExists() {
        return exists_;
      }
      public Builder setExists(boolean value) {
        bitField0_ |= 0x00000002;
        exists_ = value;
        onChanged();
        return this;
      }
      public Builder clearExists() {
        bitField0_ = (bitField0_ & ~0x00000002);
        exists_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:GetResponse)
    }
    
    static {
      defaultInstance = new GetResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:GetResponse)
  }
  
  public interface ConditionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required bytes row = 1;
    boolean hasRow();
    com.google.protobuf.ByteString getRow();
    
    // required bytes family = 2;
    boolean hasFamily();
    com.google.protobuf.ByteString getFamily();
    
    // required bytes qualifier = 3;
    boolean hasQualifier();
    com.google.protobuf.ByteString getQualifier();
    
    // required .CompareType compareType = 4;
    boolean hasCompareType();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType getCompareType();
    
    // required .Comparator comparator = 5;
    boolean hasComparator();
    org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator getComparator();
    org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder();
  }
  public static final class Condition extends
      com.google.protobuf.GeneratedMessage
      implements ConditionOrBuilder {
    // Use Condition.newBuilder() to construct.
    private Condition(Builder builder) {
      super(builder);
    }
    private Condition(boolean noInit) {}
    
    private static final Condition defaultInstance;
    public static Condition getDefaultInstance() {
      return defaultInstance;
    }
    
    public Condition getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }
    
    // required bytes family = 2;
    public static final int FAMILY_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString family_;
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public com.google.protobuf.ByteString getFamily() {
      return family_;
    }
    
    // required bytes qualifier = 3;
    public static final int QUALIFIER_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString qualifier_;
    public boolean hasQualifier() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public com.google.protobuf.ByteString getQualifier() {
      return qualifier_;
    }
    
    // required .CompareType compareType = 4;
    public static final int COMPARETYPE_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType compareType_;
    public boolean hasCompareType() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType getCompareType() {
      return compareType_;
    }
    
    // required .Comparator comparator = 5;
    public static final int COMPARATOR_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator comparator_;
    public boolean hasComparator() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator getComparator() {
      return comparator_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
      return comparator_;
    }
    
    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      family_ = com.google.protobuf.ByteString.EMPTY;
      qualifier_ = com.google.protobuf.ByteString.EMPTY;
      compareType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.LESS;
      comparator_ = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasQualifier()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCompareType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasComparator()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getComparator().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, compareType_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, comparator_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, compareType_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, comparator_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition) obj;
      
      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasFamily() == other.hasFamily());
      if (hasFamily()) {
        result = result && getFamily()
            .equals(other.getFamily());
      }
      result = result && (hasQualifier() == other.hasQualifier());
      if (hasQualifier()) {
        result = result && getQualifier()
            .equals(other.getQualifier());
      }
      result = result && (hasCompareType() == other.hasCompareType());
      if (hasCompareType()) {
        result = result &&
            (getCompareType() == other.getCompareType());
      }
      result = result && (hasComparator() == other.hasComparator());
      if (hasComparator()) {
        result = result && getComparator()
            .equals(other.getComparator());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (hasQualifier()) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifier().hashCode();
      }
      if (hasCompareType()) {
        hash = (37 * hash) + COMPARETYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getCompareType());
      }
      if (hasComparator()) {
        hash = (37 * hash) + COMPARATOR_FIELD_NUMBER;
        hash = (53 * hash) + getComparator().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getComparatorFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        qualifier_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        compareType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.LESS;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (comparatorBuilder_ == null) {
          comparator_ = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance();
        } else {
          comparatorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.family_ = family_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.qualifier_ = qualifier_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.compareType_ = compareType_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (comparatorBuilder_ == null) {
          result.comparator_ = comparator_;
        } else {
          result.comparator_ = comparatorBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (other.hasQualifier()) {
          setQualifier(other.getQualifier());
        }
        if (other.hasCompareType()) {
          setCompareType(other.getCompareType());
        }
        if (other.hasComparator()) {
          mergeComparator(other.getComparator());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        if (!hasFamily()) {
          
          return false;
        }
        if (!hasQualifier()) {
          
          return false;
        }
        if (!hasCompareType()) {
          
          return false;
        }
        if (!hasComparator()) {
          
          return false;
        }
        if (!getComparator().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              family_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              qualifier_ = input.readBytes();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType value = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                compareType_ = value;
              }
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.newBuilder();
              if (hasComparator()) {
                subBuilder.mergeFrom(getComparator());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setComparator(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }
      
      // required bytes family = 2;
      private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      public Builder setFamily(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        family_ = value;
        onChanged();
        return this;
      }
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000002);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }
      
      // required bytes qualifier = 3;
      private com.google.protobuf.ByteString qualifier_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasQualifier() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public com.google.protobuf.ByteString getQualifier() {
        return qualifier_;
      }
      public Builder setQualifier(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        qualifier_ = value;
        onChanged();
        return this;
      }
      public Builder clearQualifier() {
        bitField0_ = (bitField0_ & ~0x00000004);
        qualifier_ = getDefaultInstance().getQualifier();
        onChanged();
        return this;
      }
      
      // required .CompareType compareType = 4;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType compareType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.LESS;
      public boolean hasCompareType() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType getCompareType() {
        return compareType_;
      }
      public Builder setCompareType(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        compareType_ = value;
        onChanged();
        return this;
      }
      public Builder clearCompareType() {
        bitField0_ = (bitField0_ & ~0x00000008);
        compareType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.LESS;
        onChanged();
        return this;
      }
      
      // required .Comparator comparator = 5;
      private org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator comparator_ = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> comparatorBuilder_;
      public boolean hasComparator() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator getComparator() {
        if (comparatorBuilder_ == null) {
          return comparator_;
        } else {
          return comparatorBuilder_.getMessage();
        }
      }
      public Builder setComparator(org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          comparator_ = value;
          onChanged();
        } else {
          comparatorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder setComparator(
          org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder builderForValue) {
        if (comparatorBuilder_ == null) {
          comparator_ = builderForValue.build();
          onChanged();
        } else {
          comparatorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder mergeComparator(org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              comparator_ != org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance()) {
            comparator_ =
              org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.newBuilder(comparator_).mergeFrom(value).buildPartial();
          } else {
            comparator_ = value;
          }
          onChanged();
        } else {
          comparatorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder clearComparator() {
        if (comparatorBuilder_ == null) {
          comparator_ = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance();
          onChanged();
        } else {
          comparatorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder getComparatorBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getComparatorFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
        if (comparatorBuilder_ != null) {
          return comparatorBuilder_.getMessageOrBuilder();
        } else {
          return comparator_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> 
          getComparatorFieldBuilder() {
        if (comparatorBuilder_ == null) {
          comparatorBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder>(
                  comparator_,
                  getParentForChildren(),
                  isClean());
          comparator_ = null;
        }
        return comparatorBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:Condition)
    }
    
    static {
      defaultInstance = new Condition(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:Condition)
  }
  
  public interface MutateOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required bytes row = 1;
    boolean hasRow();
    com.google.protobuf.ByteString getRow();
    
    // required .Mutate.MutateType mutateType = 2;
    boolean hasMutateType();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType getMutateType();
    
    // repeated .Mutate.ColumnValue columnValue = 3;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue> 
        getColumnValueList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue getColumnValue(int index);
    int getColumnValueCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder> 
        getColumnValueOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder getColumnValueOrBuilder(
        int index);
    
    // repeated .NameBytesPair attribute = 4;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    int getAttributeCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);
    
    // optional uint64 timestamp = 5;
    boolean hasTimestamp();
    long getTimestamp();
    
    // optional uint64 lockId = 6;
    boolean hasLockId();
    long getLockId();
    
    // optional bool writeToWAL = 7 [default = true];
    boolean hasWriteToWAL();
    boolean getWriteToWAL();
    
    // optional .TimeRange timeRange = 10;
    boolean hasTimeRange();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();
  }
  public static final class Mutate extends
      com.google.protobuf.GeneratedMessage
      implements MutateOrBuilder {
    // Use Mutate.newBuilder() to construct.
    private Mutate(Builder builder) {
      super(builder);
    }
    private Mutate(boolean noInit) {}
    
    private static final Mutate defaultInstance;
    public static Mutate getDefaultInstance() {
      return defaultInstance;
    }
    
    public Mutate getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_fieldAccessorTable;
    }
    
    public enum MutateType
        implements com.google.protobuf.ProtocolMessageEnum {
      APPEND(0, 0),
      INCREMENT(1, 1),
      PUT(2, 2),
      DELETE(3, 3),
      ;
      
      public static final int APPEND_VALUE = 0;
      public static final int INCREMENT_VALUE = 1;
      public static final int PUT_VALUE = 2;
      public static final int DELETE_VALUE = 3;
      
      
      public final int getNumber() { return value; }
      
      public static MutateType valueOf(int value) {
        switch (value) {
          case 0: return APPEND;
          case 1: return INCREMENT;
          case 2: return PUT;
          case 3: return DELETE;
          default: return null;
        }
      }
      
      public static com.google.protobuf.Internal.EnumLiteMap<MutateType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<MutateType>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<MutateType>() {
              public MutateType findValueByNumber(int number) {
                return MutateType.valueOf(number);
              }
            };
      
      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDescriptor().getEnumTypes().get(0);
      }
      
      private static final MutateType[] VALUES = {
        APPEND, INCREMENT, PUT, DELETE, 
      };
      
      public static MutateType valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }
      
      private final int index;
      private final int value;
      
      private MutateType(int index, int value) {
        this.index = index;
        this.value = value;
      }
      
      // @@protoc_insertion_point(enum_scope:Mutate.MutateType)
    }
    
    public enum DeleteType
        implements com.google.protobuf.ProtocolMessageEnum {
      DELETE_ONE_VERSION(0, 0),
      DELETE_MULTIPLE_VERSIONS(1, 1),
      DELETE_FAMILY(2, 2),
      ;
      
      public static final int DELETE_ONE_VERSION_VALUE = 0;
      public static final int DELETE_MULTIPLE_VERSIONS_VALUE = 1;
      public static final int DELETE_FAMILY_VALUE = 2;
      
      
      public final int getNumber() { return value; }
      
      public static DeleteType valueOf(int value) {
        switch (value) {
          case 0: return DELETE_ONE_VERSION;
          case 1: return DELETE_MULTIPLE_VERSIONS;
          case 2: return DELETE_FAMILY;
          default: return null;
        }
      }
      
      public static com.google.protobuf.Internal.EnumLiteMap<DeleteType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<DeleteType>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<DeleteType>() {
              public DeleteType findValueByNumber(int number) {
                return DeleteType.valueOf(number);
              }
            };
      
      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDescriptor().getEnumTypes().get(1);
      }
      
      private static final DeleteType[] VALUES = {
        DELETE_ONE_VERSION, DELETE_MULTIPLE_VERSIONS, DELETE_FAMILY, 
      };
      
      public static DeleteType valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }
      
      private final int index;
      private final int value;
      
      private DeleteType(int index, int value) {
        this.index = index;
        this.value = value;
      }
      
      // @@protoc_insertion_point(enum_scope:Mutate.DeleteType)
    }
    
    public interface ColumnValueOrBuilder
        extends com.google.protobuf.MessageOrBuilder {
      
      // required bytes family = 1;
      boolean hasFamily();
      com.google.protobuf.ByteString getFamily();
      
      // repeated .Mutate.ColumnValue.QualifierValue qualifierValue = 2;
      java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue> 
          getQualifierValueList();
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue getQualifierValue(int index);
      int getQualifierValueCount();
      java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder> 
          getQualifierValueOrBuilderList();
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
          int index);
    }
    public static final class ColumnValue extends
        com.google.protobuf.GeneratedMessage
        implements ColumnValueOrBuilder {
      // Use ColumnValue.newBuilder() to construct.
      private ColumnValue(Builder builder) {
        super(builder);
      }
      private ColumnValue(boolean noInit) {}
      
      private static final ColumnValue defaultInstance;
      public static ColumnValue getDefaultInstance() {
        return defaultInstance;
      }
      
      public ColumnValue getDefaultInstanceForType() {
        return defaultInstance;
      }
      
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_ColumnValue_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_ColumnValue_fieldAccessorTable;
      }
      
      public interface QualifierValueOrBuilder
          extends com.google.protobuf.MessageOrBuilder {
        
        // optional bytes qualifier = 1;
        boolean hasQualifier();
        com.google.protobuf.ByteString getQualifier();
        
        // optional bytes value = 2;
        boolean hasValue();
        com.google.protobuf.ByteString getValue();
        
        // optional uint64 timestamp = 3;
        boolean hasTimestamp();
        long getTimestamp();
        
        // optional .Mutate.DeleteType deleteType = 4;
        boolean hasDeleteType();
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType getDeleteType();
      }
      public static final class QualifierValue extends
          com.google.protobuf.GeneratedMessage
          implements QualifierValueOrBuilder {
        // Use QualifierValue.newBuilder() to construct.
        private QualifierValue(Builder builder) {
          super(builder);
        }
        private QualifierValue(boolean noInit) {}
        
        private static final QualifierValue defaultInstance;
        public static QualifierValue getDefaultInstance() {
          return defaultInstance;
        }
        
        public QualifierValue getDefaultInstanceForType() {
          return defaultInstance;
        }
        
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_ColumnValue_QualifierValue_descriptor;
        }
        
        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_ColumnValue_QualifierValue_fieldAccessorTable;
        }
        
        private int bitField0_;
        // optional bytes qualifier = 1;
        public static final int QUALIFIER_FIELD_NUMBER = 1;
        private com.google.protobuf.ByteString qualifier_;
        public boolean hasQualifier() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        public com.google.protobuf.ByteString getQualifier() {
          return qualifier_;
        }
        
        // optional bytes value = 2;
        public static final int VALUE_FIELD_NUMBER = 2;
        private com.google.protobuf.ByteString value_;
        public boolean hasValue() {
          return ((bitField0_ & 0x00000002) == 0x00000002);
        }
        public com.google.protobuf.ByteString getValue() {
          return value_;
        }
        
        // optional uint64 timestamp = 3;
        public static final int TIMESTAMP_FIELD_NUMBER = 3;
        private long timestamp_;
        public boolean hasTimestamp() {
          return ((bitField0_ & 0x00000004) == 0x00000004);
        }
        public long getTimestamp() {
          return timestamp_;
        }
        
        // optional .Mutate.DeleteType deleteType = 4;
        public static final int DELETETYPE_FIELD_NUMBER = 4;
        private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType deleteType_;
        public boolean hasDeleteType() {
          return ((bitField0_ & 0x00000008) == 0x00000008);
        }
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType getDeleteType() {
          return deleteType_;
        }
        
        private void initFields() {
          qualifier_ = com.google.protobuf.ByteString.EMPTY;
          value_ = com.google.protobuf.ByteString.EMPTY;
          timestamp_ = 0L;
          deleteType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType.DELETE_ONE_VERSION;
        }
        private byte memoizedIsInitialized = -1;
        public final boolean isInitialized() {
          byte isInitialized = memoizedIsInitialized;
          if (isInitialized != -1) return isInitialized == 1;
          
          memoizedIsInitialized = 1;
          return true;
        }
        
        public void writeTo(com.google.protobuf.CodedOutputStream output)
                            throws java.io.IOException {
          getSerializedSize();
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            output.writeBytes(1, qualifier_);
          }
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            output.writeBytes(2, value_);
          }
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            output.writeUInt64(3, timestamp_);
          }
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            output.writeEnum(4, deleteType_.getNumber());
          }
          getUnknownFields().writeTo(output);
        }
        
        private int memoizedSerializedSize = -1;
        public int getSerializedSize() {
          int size = memoizedSerializedSize;
          if (size != -1) return size;
        
          size = 0;
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            size += com.google.protobuf.CodedOutputStream
              .computeBytesSize(1, qualifier_);
          }
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            size += com.google.protobuf.CodedOutputStream
              .computeBytesSize(2, value_);
          }
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            size += com.google.protobuf.CodedOutputStream
              .computeUInt64Size(3, timestamp_);
          }
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            size += com.google.protobuf.CodedOutputStream
              .computeEnumSize(4, deleteType_.getNumber());
          }
          size += getUnknownFields().getSerializedSize();
          memoizedSerializedSize = size;
          return size;
        }
        
        private static final long serialVersionUID = 0L;
        @java.lang.Override
        protected java.lang.Object writeReplace()
            throws java.io.ObjectStreamException {
          return super.writeReplace();
        }
        
        @java.lang.Override
        public boolean equals(final java.lang.Object obj) {
          if (obj == this) {
           return true;
          }
          if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue)) {
            return super.equals(obj);
          }
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue) obj;
          
          boolean result = true;
          result = result && (hasQualifier() == other.hasQualifier());
          if (hasQualifier()) {
            result = result && getQualifier()
                .equals(other.getQualifier());
          }
          result = result && (hasValue() == other.hasValue());
          if (hasValue()) {
            result = result && getValue()
                .equals(other.getValue());
          }
          result = result && (hasTimestamp() == other.hasTimestamp());
          if (hasTimestamp()) {
            result = result && (getTimestamp()
                == other.getTimestamp());
          }
          result = result && (hasDeleteType() == other.hasDeleteType());
          if (hasDeleteType()) {
            result = result &&
                (getDeleteType() == other.getDeleteType());
          }
          result = result &&
              getUnknownFields().equals(other.getUnknownFields());
          return result;
        }
        
        @java.lang.Override
        public int hashCode() {
          int hash = 41;
          hash = (19 * hash) + getDescriptorForType().hashCode();
          if (hasQualifier()) {
            hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
            hash = (53 * hash) + getQualifier().hashCode();
          }
          if (hasValue()) {
            hash = (37 * hash) + VALUE_FIELD_NUMBER;
            hash = (53 * hash) + getValue().hashCode();
          }
          if (hasTimestamp()) {
            hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
            hash = (53 * hash) + hashLong(getTimestamp());
          }
          if (hasDeleteType()) {
            hash = (37 * hash) + DELETETYPE_FIELD_NUMBER;
            hash = (53 * hash) + hashEnum(getDeleteType());
          }
          hash = (29 * hash) + getUnknownFields().hashCode();
          return hash;
        }
        
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseFrom(
            com.google.protobuf.ByteString data)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return newBuilder().mergeFrom(data).buildParsed();
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseFrom(
            com.google.protobuf.ByteString data,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return newBuilder().mergeFrom(data, extensionRegistry)
                   .buildParsed();
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseFrom(byte[] data)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return newBuilder().mergeFrom(data).buildParsed();
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseFrom(
            byte[] data,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return newBuilder().mergeFrom(data, extensionRegistry)
                   .buildParsed();
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseFrom(java.io.InputStream input)
            throws java.io.IOException {
          return newBuilder().mergeFrom(input).buildParsed();
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseFrom(
            java.io.InputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return newBuilder().mergeFrom(input, extensionRegistry)
                   .buildParsed();
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseDelimitedFrom(java.io.InputStream input)
            throws java.io.IOException {
          Builder builder = newBuilder();
          if (builder.mergeDelimitedFrom(input)) {
            return builder.buildParsed();
          } else {
            return null;
          }
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseDelimitedFrom(
            java.io.InputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          Builder builder = newBuilder();
          if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
            return builder.buildParsed();
          } else {
            return null;
          }
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseFrom(
            com.google.protobuf.CodedInputStream input)
            throws java.io.IOException {
          return newBuilder().mergeFrom(input).buildParsed();
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue parseFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return newBuilder().mergeFrom(input, extensionRegistry)
                   .buildParsed();
        }
        
        public static Builder newBuilder() { return Builder.create(); }
        public Builder newBuilderForType() { return newBuilder(); }
        public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue prototype) {
          return newBuilder().mergeFrom(prototype);
        }
        public Builder toBuilder() { return newBuilder(this); }
        
        @java.lang.Override
        protected Builder newBuilderForType(
            com.google.protobuf.GeneratedMessage.BuilderParent parent) {
          Builder builder = new Builder(parent);
          return builder;
        }
        public static final class Builder extends
            com.google.protobuf.GeneratedMessage.Builder<Builder>
           implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder {
          public static final com.google.protobuf.Descriptors.Descriptor
              getDescriptor() {
            return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_ColumnValue_QualifierValue_descriptor;
          }
          
          protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
              internalGetFieldAccessorTable() {
            return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_ColumnValue_QualifierValue_fieldAccessorTable;
          }
          
          // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.newBuilder()
          private Builder() {
            maybeForceBuilderInitialization();
          }
          
          private Builder(BuilderParent parent) {
            super(parent);
            maybeForceBuilderInitialization();
          }
          private void maybeForceBuilderInitialization() {
            if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
            }
          }
          private static Builder create() {
            return new Builder();
          }
          
          public Builder clear() {
            super.clear();
            qualifier_ = com.google.protobuf.ByteString.EMPTY;
            bitField0_ = (bitField0_ & ~0x00000001);
            value_ = com.google.protobuf.ByteString.EMPTY;
            bitField0_ = (bitField0_ & ~0x00000002);
            timestamp_ = 0L;
            bitField0_ = (bitField0_ & ~0x00000004);
            deleteType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType.DELETE_ONE_VERSION;
            bitField0_ = (bitField0_ & ~0x00000008);
            return this;
          }
          
          public Builder clone() {
            return create().mergeFrom(buildPartial());
          }
          
          public com.google.protobuf.Descriptors.Descriptor
              getDescriptorForType() {
            return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.getDescriptor();
          }
          
          public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue getDefaultInstanceForType() {
            return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.getDefaultInstance();
          }
          
          public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue build() {
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue result = buildPartial();
            if (!result.isInitialized()) {
              throw newUninitializedMessageException(result);
            }
            return result;
          }
          
          private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue buildParsed()
              throws com.google.protobuf.InvalidProtocolBufferException {
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue result = buildPartial();
            if (!result.isInitialized()) {
              throw newUninitializedMessageException(
                result).asInvalidProtocolBufferException();
            }
            return result;
          }
          
          public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue buildPartial() {
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue(this);
            int from_bitField0_ = bitField0_;
            int to_bitField0_ = 0;
            if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
              to_bitField0_ |= 0x00000001;
            }
            result.qualifier_ = qualifier_;
            if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
              to_bitField0_ |= 0x00000002;
            }
            result.value_ = value_;
            if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
              to_bitField0_ |= 0x00000004;
            }
            result.timestamp_ = timestamp_;
            if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
              to_bitField0_ |= 0x00000008;
            }
            result.deleteType_ = deleteType_;
            result.bitField0_ = to_bitField0_;
            onBuilt();
            return result;
          }
          
          public Builder mergeFrom(com.google.protobuf.Message other) {
            if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue) {
              return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue)other);
            } else {
              super.mergeFrom(other);
              return this;
            }
          }
          
          public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue other) {
            if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.getDefaultInstance()) return this;
            if (other.hasQualifier()) {
              setQualifier(other.getQualifier());
            }
            if (other.hasValue()) {
              setValue(other.getValue());
            }
            if (other.hasTimestamp()) {
              setTimestamp(other.getTimestamp());
            }
            if (other.hasDeleteType()) {
              setDeleteType(other.getDeleteType());
            }
            this.mergeUnknownFields(other.getUnknownFields());
            return this;
          }
          
          public final boolean isInitialized() {
            return true;
          }
          
          public Builder mergeFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
            com.google.protobuf.UnknownFieldSet.Builder unknownFields =
              com.google.protobuf.UnknownFieldSet.newBuilder(
                this.getUnknownFields());
            while (true) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  this.setUnknownFields(unknownFields.build());
                  onChanged();
                  return this;
                default: {
                  if (!parseUnknownField(input, unknownFields,
                                         extensionRegistry, tag)) {
                    this.setUnknownFields(unknownFields.build());
                    onChanged();
                    return this;
                  }
                  break;
                }
                case 10: {
                  bitField0_ |= 0x00000001;
                  qualifier_ = input.readBytes();
                  break;
                }
                case 18: {
                  bitField0_ |= 0x00000002;
                  value_ = input.readBytes();
                  break;
                }
                case 24: {
                  bitField0_ |= 0x00000004;
                  timestamp_ = input.readUInt64();
                  break;
                }
                case 32: {
                  int rawValue = input.readEnum();
                  org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType value = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType.valueOf(rawValue);
                  if (value == null) {
                    unknownFields.mergeVarintField(4, rawValue);
                  } else {
                    bitField0_ |= 0x00000008;
                    deleteType_ = value;
                  }
                  break;
                }
              }
            }
          }
          
          private int bitField0_;
          
          // optional bytes qualifier = 1;
          private com.google.protobuf.ByteString qualifier_ = com.google.protobuf.ByteString.EMPTY;
          public boolean hasQualifier() {
            return ((bitField0_ & 0x00000001) == 0x00000001);
          }
          public com.google.protobuf.ByteString getQualifier() {
            return qualifier_;
          }
          public Builder setQualifier(com.google.protobuf.ByteString value) {
            if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
            qualifier_ = value;
            onChanged();
            return this;
          }
          public Builder clearQualifier() {
            bitField0_ = (bitField0_ & ~0x00000001);
            qualifier_ = getDefaultInstance().getQualifier();
            onChanged();
            return this;
          }
          
          // optional bytes value = 2;
          private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
          public boolean hasValue() {
            return ((bitField0_ & 0x00000002) == 0x00000002);
          }
          public com.google.protobuf.ByteString getValue() {
            return value_;
          }
          public Builder setValue(com.google.protobuf.ByteString value) {
            if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
            value_ = value;
            onChanged();
            return this;
          }
          public Builder clearValue() {
            bitField0_ = (bitField0_ & ~0x00000002);
            value_ = getDefaultInstance().getValue();
            onChanged();
            return this;
          }
          
          // optional uint64 timestamp = 3;
          private long timestamp_ ;
          public boolean hasTimestamp() {
            return ((bitField0_ & 0x00000004) == 0x00000004);
          }
          public long getTimestamp() {
            return timestamp_;
          }
          public Builder setTimestamp(long value) {
            bitField0_ |= 0x00000004;
            timestamp_ = value;
            onChanged();
            return this;
          }
          public Builder clearTimestamp() {
            bitField0_ = (bitField0_ & ~0x00000004);
            timestamp_ = 0L;
            onChanged();
            return this;
          }
          
          // optional .Mutate.DeleteType deleteType = 4;
          private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType deleteType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType.DELETE_ONE_VERSION;
          public boolean hasDeleteType() {
            return ((bitField0_ & 0x00000008) == 0x00000008);
          }
          public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType getDeleteType() {
            return deleteType_;
          }
          public Builder setDeleteType(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType value) {
            if (value == null) {
              throw new NullPointerException();
            }
            bitField0_ |= 0x00000008;
            deleteType_ = value;
            onChanged();
            return this;
          }
          public Builder clearDeleteType() {
            bitField0_ = (bitField0_ & ~0x00000008);
            deleteType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.DeleteType.DELETE_ONE_VERSION;
            onChanged();
            return this;
          }
          
          // @@protoc_insertion_point(builder_scope:Mutate.ColumnValue.QualifierValue)
        }
        
        static {
          defaultInstance = new QualifierValue(true);
          defaultInstance.initFields();
        }
        
        // @@protoc_insertion_point(class_scope:Mutate.ColumnValue.QualifierValue)
      }
      
      private int bitField0_;
      // required bytes family = 1;
      public static final int FAMILY_FIELD_NUMBER = 1;
      private com.google.protobuf.ByteString family_;
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      
      // repeated .Mutate.ColumnValue.QualifierValue qualifierValue = 2;
      public static final int QUALIFIERVALUE_FIELD_NUMBER = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue> qualifierValue_;
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue> getQualifierValueList() {
        return qualifierValue_;
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder> 
          getQualifierValueOrBuilderList() {
        return qualifierValue_;
      }
      public int getQualifierValueCount() {
        return qualifierValue_.size();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue getQualifierValue(int index) {
        return qualifierValue_.get(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
          int index) {
        return qualifierValue_.get(index);
      }
      
      private void initFields() {
        family_ = com.google.protobuf.ByteString.EMPTY;
        qualifierValue_ = java.util.Collections.emptyList();
      }
      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized != -1) return isInitialized == 1;
        
        if (!hasFamily()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }
      
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          output.writeBytes(1, family_);
        }
        for (int i = 0; i < qualifierValue_.size(); i++) {
          output.writeMessage(2, qualifierValue_.get(i));
        }
        getUnknownFields().writeTo(output);
      }
      
      private int memoizedSerializedSize = -1;
      public int getSerializedSize() {
        int size = memoizedSerializedSize;
        if (size != -1) return size;
      
        size = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, family_);
        }
        for (int i = 0; i < qualifierValue_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, qualifierValue_.get(i));
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSerializedSize = size;
        return size;
      }
      
      private static final long serialVersionUID = 0L;
      @java.lang.Override
      protected java.lang.Object writeReplace()
          throws java.io.ObjectStreamException {
        return super.writeReplace();
      }
      
      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue) obj;
        
        boolean result = true;
        result = result && (hasFamily() == other.hasFamily());
        if (hasFamily()) {
          result = result && getFamily()
              .equals(other.getFamily());
        }
        result = result && getQualifierValueList()
            .equals(other.getQualifierValueList());
        result = result &&
            getUnknownFields().equals(other.getUnknownFields());
        return result;
      }
      
      @java.lang.Override
      public int hashCode() {
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        if (hasFamily()) {
          hash = (37 * hash) + FAMILY_FIELD_NUMBER;
          hash = (53 * hash) + getFamily().hashCode();
        }
        if (getQualifierValueCount() > 0) {
          hash = (37 * hash) + QUALIFIERVALUE_FIELD_NUMBER;
          hash = (53 * hash) + getQualifierValueList().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        return hash;
      }
      
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data).buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data).buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input).buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        Builder builder = newBuilder();
        if (builder.mergeDelimitedFrom(input)) {
          return builder.buildParsed();
        } else {
          return null;
        }
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        Builder builder = newBuilder();
        if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
          return builder.buildParsed();
        } else {
          return null;
        }
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input).buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input, extensionRegistry)
                 .buildParsed();
      }
      
      public static Builder newBuilder() { return Builder.create(); }
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue prototype) {
        return newBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() { return newBuilder(this); }
      
      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      public static final class Builder extends
          com.google.protobuf.GeneratedMessage.Builder<Builder>
         implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_ColumnValue_descriptor;
        }
        
        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_ColumnValue_fieldAccessorTable;
        }
        
        // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }
        
        private Builder(BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
            getQualifierValueFieldBuilder();
          }
        }
        private static Builder create() {
          return new Builder();
        }
        
        public Builder clear() {
          super.clear();
          family_ = com.google.protobuf.ByteString.EMPTY;
          bitField0_ = (bitField0_ & ~0x00000001);
          if (qualifierValueBuilder_ == null) {
            qualifierValue_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            qualifierValueBuilder_.clear();
          }
          return this;
        }
        
        public Builder clone() {
          return create().mergeFrom(buildPartial());
        }
        
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.getDescriptor();
        }
        
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.getDefaultInstance();
        }
        
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue build() {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }
        
        private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue buildParsed()
            throws com.google.protobuf.InvalidProtocolBufferException {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(
              result).asInvalidProtocolBufferException();
          }
          return result;
        }
        
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue buildPartial() {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
            to_bitField0_ |= 0x00000001;
          }
          result.family_ = family_;
          if (qualifierValueBuilder_ == null) {
            if (((bitField0_ & 0x00000002) == 0x00000002)) {
              qualifierValue_ = java.util.Collections.unmodifiableList(qualifierValue_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.qualifierValue_ = qualifierValue_;
          } else {
            result.qualifierValue_ = qualifierValueBuilder_.build();
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }
        
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue) {
            return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }
        
        public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue other) {
          if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.getDefaultInstance()) return this;
          if (other.hasFamily()) {
            setFamily(other.getFamily());
          }
          if (qualifierValueBuilder_ == null) {
            if (!other.qualifierValue_.isEmpty()) {
              if (qualifierValue_.isEmpty()) {
                qualifierValue_ = other.qualifierValue_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensureQualifierValueIsMutable();
                qualifierValue_.addAll(other.qualifierValue_);
              }
              onChanged();
            }
          } else {
            if (!other.qualifierValue_.isEmpty()) {
              if (qualifierValueBuilder_.isEmpty()) {
                qualifierValueBuilder_.dispose();
                qualifierValueBuilder_ = null;
                qualifierValue_ = other.qualifierValue_;
                bitField0_ = (bitField0_ & ~0x00000002);
                qualifierValueBuilder_ = 
                  com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                     getQualifierValueFieldBuilder() : null;
              } else {
                qualifierValueBuilder_.addAllMessages(other.qualifierValue_);
              }
            }
          }
          this.mergeUnknownFields(other.getUnknownFields());
          return this;
        }
        
        public final boolean isInitialized() {
          if (!hasFamily()) {
            
            return false;
          }
          return true;
        }
        
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder(
              this.getUnknownFields());
          while (true) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              default: {
                if (!parseUnknownField(input, unknownFields,
                                       extensionRegistry, tag)) {
                  this.setUnknownFields(unknownFields.build());
                  onChanged();
                  return this;
                }
                break;
              }
              case 10: {
                bitField0_ |= 0x00000001;
                family_ = input.readBytes();
                break;
              }
              case 18: {
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.newBuilder();
                input.readMessage(subBuilder, extensionRegistry);
                addQualifierValue(subBuilder.buildPartial());
                break;
              }
            }
          }
        }
        
        private int bitField0_;
        
        // required bytes family = 1;
        private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
        public boolean hasFamily() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        public com.google.protobuf.ByteString getFamily() {
          return family_;
        }
        public Builder setFamily(com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          family_ = value;
          onChanged();
          return this;
        }
        public Builder clearFamily() {
          bitField0_ = (bitField0_ & ~0x00000001);
          family_ = getDefaultInstance().getFamily();
          onChanged();
          return this;
        }
        
        // repeated .Mutate.ColumnValue.QualifierValue qualifierValue = 2;
        private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue> qualifierValue_ =
          java.util.Collections.emptyList();
        private void ensureQualifierValueIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            qualifierValue_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue>(qualifierValue_);
            bitField0_ |= 0x00000002;
           }
        }
        
        private com.google.protobuf.RepeatedFieldBuilder<
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder> qualifierValueBuilder_;
        
        public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue> getQualifierValueList() {
          if (qualifierValueBuilder_ == null) {
            return java.util.Collections.unmodifiableList(qualifierValue_);
          } else {
            return qualifierValueBuilder_.getMessageList();
          }
        }
        public int getQualifierValueCount() {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.size();
          } else {
            return qualifierValueBuilder_.getCount();
          }
        }
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue getQualifierValue(int index) {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.get(index);
          } else {
            return qualifierValueBuilder_.getMessage(index);
          }
        }
        public Builder setQualifierValue(
            int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.set(index, value);
            onChanged();
          } else {
            qualifierValueBuilder_.setMessage(index, value);
          }
          return this;
        }
        public Builder setQualifierValue(
            int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.set(index, builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        public Builder addQualifierValue(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.add(value);
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(value);
          }
          return this;
        }
        public Builder addQualifierValue(
            int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.add(index, value);
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(index, value);
          }
          return this;
        }
        public Builder addQualifierValue(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.add(builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        public Builder addQualifierValue(
            int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.add(index, builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        public Builder addAllQualifierValue(
            java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue> values) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            super.addAll(values, qualifierValue_);
            onChanged();
          } else {
            qualifierValueBuilder_.addAllMessages(values);
          }
          return this;
        }
        public Builder clearQualifierValue() {
          if (qualifierValueBuilder_ == null) {
            qualifierValue_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            qualifierValueBuilder_.clear();
          }
          return this;
        }
        public Builder removeQualifierValue(int index) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.remove(index);
            onChanged();
          } else {
            qualifierValueBuilder_.remove(index);
          }
          return this;
        }
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder getQualifierValueBuilder(
            int index) {
          return getQualifierValueFieldBuilder().getBuilder(index);
        }
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
            int index) {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.get(index);  } else {
            return qualifierValueBuilder_.getMessageOrBuilder(index);
          }
        }
        public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder> 
             getQualifierValueOrBuilderList() {
          if (qualifierValueBuilder_ != null) {
            return qualifierValueBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(qualifierValue_);
          }
        }
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder addQualifierValueBuilder() {
          return getQualifierValueFieldBuilder().addBuilder(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.getDefaultInstance());
        }
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder addQualifierValueBuilder(
            int index) {
          return getQualifierValueFieldBuilder().addBuilder(
              index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.getDefaultInstance());
        }
        public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder> 
             getQualifierValueBuilderList() {
          return getQualifierValueFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilder<
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder> 
            getQualifierValueFieldBuilder() {
          if (qualifierValueBuilder_ == null) {
            qualifierValueBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValueOrBuilder>(
                    qualifierValue_,
                    ((bitField0_ & 0x00000002) == 0x00000002),
                    getParentForChildren(),
                    isClean());
            qualifierValue_ = null;
          }
          return qualifierValueBuilder_;
        }
        
        // @@protoc_insertion_point(builder_scope:Mutate.ColumnValue)
      }
      
      static {
        defaultInstance = new ColumnValue(true);
        defaultInstance.initFields();
      }
      
      // @@protoc_insertion_point(class_scope:Mutate.ColumnValue)
    }
    
    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }
    
    // required .Mutate.MutateType mutateType = 2;
    public static final int MUTATETYPE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType mutateType_;
    public boolean hasMutateType() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType getMutateType() {
      return mutateType_;
    }
    
    // repeated .Mutate.ColumnValue columnValue = 3;
    public static final int COLUMNVALUE_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue> columnValue_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue> getColumnValueList() {
      return columnValue_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder> 
        getColumnValueOrBuilderList() {
      return columnValue_;
    }
    public int getColumnValueCount() {
      return columnValue_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue getColumnValue(int index) {
      return columnValue_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder getColumnValueOrBuilder(
        int index) {
      return columnValue_.get(index);
    }
    
    // repeated .NameBytesPair attribute = 4;
    public static final int ATTRIBUTE_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    public int getAttributeCount() {
      return attribute_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }
    
    // optional uint64 timestamp = 5;
    public static final int TIMESTAMP_FIELD_NUMBER = 5;
    private long timestamp_;
    public boolean hasTimestamp() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public long getTimestamp() {
      return timestamp_;
    }
    
    // optional uint64 lockId = 6;
    public static final int LOCKID_FIELD_NUMBER = 6;
    private long lockId_;
    public boolean hasLockId() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public long getLockId() {
      return lockId_;
    }
    
    // optional bool writeToWAL = 7 [default = true];
    public static final int WRITETOWAL_FIELD_NUMBER = 7;
    private boolean writeToWAL_;
    public boolean hasWriteToWAL() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public boolean getWriteToWAL() {
      return writeToWAL_;
    }
    
    // optional .TimeRange timeRange = 10;
    public static final int TIMERANGE_FIELD_NUMBER = 10;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_;
    }
    
    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      mutateType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType.APPEND;
      columnValue_ = java.util.Collections.emptyList();
      attribute_ = java.util.Collections.emptyList();
      timestamp_ = 0L;
      lockId_ = 0L;
      writeToWAL_ = true;
      timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMutateType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getColumnValueCount(); i++) {
        if (!getColumnValue(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, mutateType_.getNumber());
      }
      for (int i = 0; i < columnValue_.size(); i++) {
        output.writeMessage(3, columnValue_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(4, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(5, timestamp_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt64(6, lockId_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(7, writeToWAL_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeMessage(10, timeRange_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, mutateType_.getNumber());
      }
      for (int i = 0; i < columnValue_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, columnValue_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(5, timestamp_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(6, lockId_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, writeToWAL_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(10, timeRange_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate) obj;
      
      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasMutateType() == other.hasMutateType());
      if (hasMutateType()) {
        result = result &&
            (getMutateType() == other.getMutateType());
      }
      result = result && getColumnValueList()
          .equals(other.getColumnValueList());
      result = result && getAttributeList()
          .equals(other.getAttributeList());
      result = result && (hasTimestamp() == other.hasTimestamp());
      if (hasTimestamp()) {
        result = result && (getTimestamp()
            == other.getTimestamp());
      }
      result = result && (hasLockId() == other.hasLockId());
      if (hasLockId()) {
        result = result && (getLockId()
            == other.getLockId());
      }
      result = result && (hasWriteToWAL() == other.hasWriteToWAL());
      if (hasWriteToWAL()) {
        result = result && (getWriteToWAL()
            == other.getWriteToWAL());
      }
      result = result && (hasTimeRange() == other.hasTimeRange());
      if (hasTimeRange()) {
        result = result && getTimeRange()
            .equals(other.getTimeRange());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasMutateType()) {
        hash = (37 * hash) + MUTATETYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getMutateType());
      }
      if (getColumnValueCount() > 0) {
        hash = (37 * hash) + COLUMNVALUE_FIELD_NUMBER;
        hash = (53 * hash) + getColumnValueList().hashCode();
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasTimestamp()) {
        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTimestamp());
      }
      if (hasLockId()) {
        hash = (37 * hash) + LOCKID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getLockId());
      }
      if (hasWriteToWAL()) {
        hash = (37 * hash) + WRITETOWAL_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getWriteToWAL());
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIMERANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Mutate_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getColumnValueFieldBuilder();
          getAttributeFieldBuilder();
          getTimeRangeFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        mutateType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType.APPEND;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (columnValueBuilder_ == null) {
          columnValue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          columnValueBuilder_.clear();
        }
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          attributeBuilder_.clear();
        }
        timestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        lockId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        writeToWAL_ = true;
        bitField0_ = (bitField0_ & ~0x00000040);
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.mutateType_ = mutateType_;
        if (columnValueBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            columnValue_ = java.util.Collections.unmodifiableList(columnValue_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.columnValue_ = columnValue_;
        } else {
          result.columnValue_ = columnValueBuilder_.build();
        }
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        result.timestamp_ = timestamp_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000008;
        }
        result.lockId_ = lockId_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        result.writeToWAL_ = writeToWAL_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        if (timeRangeBuilder_ == null) {
          result.timeRange_ = timeRange_;
        } else {
          result.timeRange_ = timeRangeBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasMutateType()) {
          setMutateType(other.getMutateType());
        }
        if (columnValueBuilder_ == null) {
          if (!other.columnValue_.isEmpty()) {
            if (columnValue_.isEmpty()) {
              columnValue_ = other.columnValue_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureColumnValueIsMutable();
              columnValue_.addAll(other.columnValue_);
            }
            onChanged();
          }
        } else {
          if (!other.columnValue_.isEmpty()) {
            if (columnValueBuilder_.isEmpty()) {
              columnValueBuilder_.dispose();
              columnValueBuilder_ = null;
              columnValue_ = other.columnValue_;
              bitField0_ = (bitField0_ & ~0x00000004);
              columnValueBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getColumnValueFieldBuilder() : null;
            } else {
              columnValueBuilder_.addAllMessages(other.columnValue_);
            }
          }
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000008);
              attributeBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasTimestamp()) {
          setTimestamp(other.getTimestamp());
        }
        if (other.hasLockId()) {
          setLockId(other.getLockId());
        }
        if (other.hasWriteToWAL()) {
          setWriteToWAL(other.getWriteToWAL());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        if (!hasMutateType()) {
          
          return false;
        }
        for (int i = 0; i < getColumnValueCount(); i++) {
          if (!getColumnValue(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType value = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                mutateType_ = value;
              }
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addColumnValue(subBuilder.buildPartial());
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addAttribute(subBuilder.buildPartial());
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              timestamp_ = input.readUInt64();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              lockId_ = input.readUInt64();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              writeToWAL_ = input.readBool();
              break;
            }
            case 82: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder();
              if (hasTimeRange()) {
                subBuilder.mergeFrom(getTimeRange());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setTimeRange(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }
      
      // required .Mutate.MutateType mutateType = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType mutateType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType.APPEND;
      public boolean hasMutateType() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType getMutateType() {
        return mutateType_;
      }
      public Builder setMutateType(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        mutateType_ = value;
        onChanged();
        return this;
      }
      public Builder clearMutateType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        mutateType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.MutateType.APPEND;
        onChanged();
        return this;
      }
      
      // repeated .Mutate.ColumnValue columnValue = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue> columnValue_ =
        java.util.Collections.emptyList();
      private void ensureColumnValueIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          columnValue_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue>(columnValue_);
          bitField0_ |= 0x00000004;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder> columnValueBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue> getColumnValueList() {
        if (columnValueBuilder_ == null) {
          return java.util.Collections.unmodifiableList(columnValue_);
        } else {
          return columnValueBuilder_.getMessageList();
        }
      }
      public int getColumnValueCount() {
        if (columnValueBuilder_ == null) {
          return columnValue_.size();
        } else {
          return columnValueBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue getColumnValue(int index) {
        if (columnValueBuilder_ == null) {
          return columnValue_.get(index);
        } else {
          return columnValueBuilder_.getMessage(index);
        }
      }
      public Builder setColumnValue(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.set(index, value);
          onChanged();
        } else {
          columnValueBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setColumnValue(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addColumnValue(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.add(value);
          onChanged();
        } else {
          columnValueBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addColumnValue(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.add(index, value);
          onChanged();
        } else {
          columnValueBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addColumnValue(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.add(builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addColumnValue(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllColumnValue(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue> values) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          super.addAll(values, columnValue_);
          onChanged();
        } else {
          columnValueBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearColumnValue() {
        if (columnValueBuilder_ == null) {
          columnValue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          columnValueBuilder_.clear();
        }
        return this;
      }
      public Builder removeColumnValue(int index) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.remove(index);
          onChanged();
        } else {
          columnValueBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder getColumnValueBuilder(
          int index) {
        return getColumnValueFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder getColumnValueOrBuilder(
          int index) {
        if (columnValueBuilder_ == null) {
          return columnValue_.get(index);  } else {
          return columnValueBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder> 
           getColumnValueOrBuilderList() {
        if (columnValueBuilder_ != null) {
          return columnValueBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(columnValue_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder addColumnValueBuilder() {
        return getColumnValueFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder addColumnValueBuilder(
          int index) {
        return getColumnValueFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder> 
           getColumnValueBuilderList() {
        return getColumnValueFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder> 
          getColumnValueFieldBuilder() {
        if (columnValueBuilder_ == null) {
          columnValueBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValueOrBuilder>(
                  columnValue_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          columnValue_ = null;
        }
        return columnValueBuilder_;
      }
      
      // repeated .NameBytesPair attribute = 4;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000008;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAttribute(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addAttribute(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          super.addAll(values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }
      
      // optional uint64 timestamp = 5;
      private long timestamp_ ;
      public boolean hasTimestamp() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public long getTimestamp() {
        return timestamp_;
      }
      public Builder setTimestamp(long value) {
        bitField0_ |= 0x00000010;
        timestamp_ = value;
        onChanged();
        return this;
      }
      public Builder clearTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000010);
        timestamp_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint64 lockId = 6;
      private long lockId_ ;
      public boolean hasLockId() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      public long getLockId() {
        return lockId_;
      }
      public Builder setLockId(long value) {
        bitField0_ |= 0x00000020;
        lockId_ = value;
        onChanged();
        return this;
      }
      public Builder clearLockId() {
        bitField0_ = (bitField0_ & ~0x00000020);
        lockId_ = 0L;
        onChanged();
        return this;
      }
      
      // optional bool writeToWAL = 7 [default = true];
      private boolean writeToWAL_ = true;
      public boolean hasWriteToWAL() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      public boolean getWriteToWAL() {
        return writeToWAL_;
      }
      public Builder setWriteToWAL(boolean value) {
        bitField0_ |= 0x00000040;
        writeToWAL_ = value;
        onChanged();
        return this;
      }
      public Builder clearWriteToWAL() {
        bitField0_ = (bitField0_ & ~0x00000040);
        writeToWAL_ = true;
        onChanged();
        return this;
      }
      
      // optional .TimeRange timeRange = 10;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      public Builder setTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      public Builder setTimeRange(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      public Builder mergeTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000080) == 0x00000080) &&
              timeRange_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            timeRange_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder(timeRange_).mergeFrom(value).buildPartial();
          } else {
            timeRange_ = value;
          }
          onChanged();
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000080;
        return this;
      }
      public Builder clearTimeRange() {
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
          onChanged();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000080;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  timeRange_,
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:Mutate)
    }
    
    static {
      defaultInstance = new Mutate(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:Mutate)
  }
  
  public interface MutateRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // required .Mutate mutate = 2;
    boolean hasMutate();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate getMutate();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder getMutateOrBuilder();
    
    // optional .Condition condition = 3;
    boolean hasCondition();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition getCondition();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder();
  }
  public static final class MutateRequest extends
      com.google.protobuf.GeneratedMessage
      implements MutateRequestOrBuilder {
    // Use MutateRequest.newBuilder() to construct.
    private MutateRequest(Builder builder) {
      super(builder);
    }
    private MutateRequest(boolean noInit) {}
    
    private static final MutateRequest defaultInstance;
    public static MutateRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public MutateRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // required .Mutate mutate = 2;
    public static final int MUTATE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate mutate_;
    public boolean hasMutate() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate getMutate() {
      return mutate_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder getMutateOrBuilder() {
      return mutate_;
    }
    
    // optional .Condition condition = 3;
    public static final int CONDITION_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition condition_;
    public boolean hasCondition() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition getCondition() {
      return condition_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
      return condition_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      mutate_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
      condition_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMutate()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getMutate().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasCondition()) {
        if (!getCondition().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, mutate_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, condition_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, mutate_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, condition_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasMutate() == other.hasMutate());
      if (hasMutate()) {
        result = result && getMutate()
            .equals(other.getMutate());
      }
      result = result && (hasCondition() == other.hasCondition());
      if (hasCondition()) {
        result = result && getCondition()
            .equals(other.getCondition());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasMutate()) {
        hash = (37 * hash) + MUTATE_FIELD_NUMBER;
        hash = (53 * hash) + getMutate().hashCode();
      }
      if (hasCondition()) {
        hash = (37 * hash) + CONDITION_FIELD_NUMBER;
        hash = (53 * hash) + getCondition().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getMutateFieldBuilder();
          getConditionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (mutateBuilder_ == null) {
          mutate_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
        } else {
          mutateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (conditionBuilder_ == null) {
          condition_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
        } else {
          conditionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (mutateBuilder_ == null) {
          result.mutate_ = mutate_;
        } else {
          result.mutate_ = mutateBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (conditionBuilder_ == null) {
          result.condition_ = condition_;
        } else {
          result.condition_ = conditionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasMutate()) {
          mergeMutate(other.getMutate());
        }
        if (other.hasCondition()) {
          mergeCondition(other.getCondition());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasMutate()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getMutate().isInitialized()) {
          
          return false;
        }
        if (hasCondition()) {
          if (!getCondition().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.newBuilder();
              if (hasMutate()) {
                subBuilder.mergeFrom(getMutate());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setMutate(subBuilder.buildPartial());
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.newBuilder();
              if (hasCondition()) {
                subBuilder.mergeFrom(getCondition());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setCondition(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // required .Mutate mutate = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate mutate_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder> mutateBuilder_;
      public boolean hasMutate() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate getMutate() {
        if (mutateBuilder_ == null) {
          return mutate_;
        } else {
          return mutateBuilder_.getMessage();
        }
      }
      public Builder setMutate(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate value) {
        if (mutateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mutate_ = value;
          onChanged();
        } else {
          mutateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setMutate(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder builderForValue) {
        if (mutateBuilder_ == null) {
          mutate_ = builderForValue.build();
          onChanged();
        } else {
          mutateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeMutate(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate value) {
        if (mutateBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              mutate_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance()) {
            mutate_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.newBuilder(mutate_).mergeFrom(value).buildPartial();
          } else {
            mutate_ = value;
          }
          onChanged();
        } else {
          mutateBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearMutate() {
        if (mutateBuilder_ == null) {
          mutate_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
          onChanged();
        } else {
          mutateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder getMutateBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMutateFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder getMutateOrBuilder() {
        if (mutateBuilder_ != null) {
          return mutateBuilder_.getMessageOrBuilder();
        } else {
          return mutate_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder> 
          getMutateFieldBuilder() {
        if (mutateBuilder_ == null) {
          mutateBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder>(
                  mutate_,
                  getParentForChildren(),
                  isClean());
          mutate_ = null;
        }
        return mutateBuilder_;
      }
      
      // optional .Condition condition = 3;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition condition_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder> conditionBuilder_;
      public boolean hasCondition() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition getCondition() {
        if (conditionBuilder_ == null) {
          return condition_;
        } else {
          return conditionBuilder_.getMessage();
        }
      }
      public Builder setCondition(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          condition_ = value;
          onChanged();
        } else {
          conditionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder setCondition(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder builderForValue) {
        if (conditionBuilder_ == null) {
          condition_ = builderForValue.build();
          onChanged();
        } else {
          conditionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder mergeCondition(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              condition_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance()) {
            condition_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.newBuilder(condition_).mergeFrom(value).buildPartial();
          } else {
            condition_ = value;
          }
          onChanged();
        } else {
          conditionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder clearCondition() {
        if (conditionBuilder_ == null) {
          condition_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
          onChanged();
        } else {
          conditionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder getConditionBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getConditionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
        if (conditionBuilder_ != null) {
          return conditionBuilder_.getMessageOrBuilder();
        } else {
          return condition_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder> 
          getConditionFieldBuilder() {
        if (conditionBuilder_ == null) {
          conditionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder>(
                  condition_,
                  getParentForChildren(),
                  isClean());
          condition_ = null;
        }
        return conditionBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:MutateRequest)
    }
    
    static {
      defaultInstance = new MutateRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:MutateRequest)
  }
  
  public interface MutateResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .Result result = 1;
    boolean hasResult();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder();
    
    // optional bool processed = 2;
    boolean hasProcessed();
    boolean getProcessed();
  }
  public static final class MutateResponse extends
      com.google.protobuf.GeneratedMessage
      implements MutateResponseOrBuilder {
    // Use MutateResponse.newBuilder() to construct.
    private MutateResponse(Builder builder) {
      super(builder);
    }
    private MutateResponse(boolean noInit) {}
    
    private static final MutateResponse defaultInstance;
    public static MutateResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public MutateResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .Result result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result_;
    public boolean hasResult() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult() {
      return result_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
      return result_;
    }
    
    // optional bool processed = 2;
    public static final int PROCESSED_FIELD_NUMBER = 2;
    private boolean processed_;
    public boolean hasProcessed() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public boolean getProcessed() {
      return processed_;
    }
    
    private void initFields() {
      result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      processed_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, result_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, processed_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, processed_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse) obj;
      
      boolean result = true;
      result = result && (hasResult() == other.hasResult());
      if (hasResult()) {
        result = result && getResult()
            .equals(other.getResult());
      }
      result = result && (hasProcessed() == other.hasProcessed());
      if (hasProcessed()) {
        result = result && (getProcessed()
            == other.getProcessed());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResult()) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResult().hashCode();
      }
      if (hasProcessed()) {
        hash = (37 * hash) + PROCESSED_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getProcessed());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
        } else {
          resultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        processed_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resultBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.processed_ = processed_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance()) return this;
        if (other.hasResult()) {
          mergeResult(other.getResult());
        }
        if (other.hasProcessed()) {
          setProcessed(other.getProcessed());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder();
              if (hasResult()) {
                subBuilder.mergeFrom(getResult());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setResult(subBuilder.buildPartial());
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              processed_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .Result result = 1;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;
      public boolean hasResult() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult() {
        if (resultBuilder_ == null) {
          return result_;
        } else {
          return resultBuilder_.getMessage();
        }
      }
      public Builder setResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          result_ = value;
          onChanged();
        } else {
          resultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setResult(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          result_ = builderForValue.build();
          onChanged();
        } else {
          resultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              result_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance()) {
            result_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder(result_).mergeFrom(value).buildPartial();
          } else {
            result_ = value;
          }
          onChanged();
        } else {
          resultBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder getResultBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResultFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilder();
        } else {
          return result_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  result_,
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }
      
      // optional bool processed = 2;
      private boolean processed_ ;
      public boolean hasProcessed() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public boolean getProcessed() {
        return processed_;
      }
      public Builder setProcessed(boolean value) {
        bitField0_ |= 0x00000002;
        processed_ = value;
        onChanged();
        return this;
      }
      public Builder clearProcessed() {
        bitField0_ = (bitField0_ & ~0x00000002);
        processed_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:MutateResponse)
    }
    
    static {
      defaultInstance = new MutateResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:MutateResponse)
  }
  
  public interface ScanOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .Column column = 1;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> 
        getColumnList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index);
    int getColumnCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index);
    
    // repeated .NameBytesPair attribute = 2;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    int getAttributeCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);
    
    // optional bytes startRow = 3;
    boolean hasStartRow();
    com.google.protobuf.ByteString getStartRow();
    
    // optional bytes stopRow = 4;
    boolean hasStopRow();
    com.google.protobuf.ByteString getStopRow();
    
    // optional .Filter filter = 5;
    boolean hasFilter();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter getFilter();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder getFilterOrBuilder();
    
    // optional .TimeRange timeRange = 6;
    boolean hasTimeRange();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();
    
    // optional uint32 maxVersions = 7 [default = 1];
    boolean hasMaxVersions();
    int getMaxVersions();
    
    // optional bool cacheBlocks = 8 [default = true];
    boolean hasCacheBlocks();
    boolean getCacheBlocks();
    
    // optional uint32 batchSize = 9;
    boolean hasBatchSize();
    int getBatchSize();
    
    // optional uint64 maxResultSize = 10;
    boolean hasMaxResultSize();
    long getMaxResultSize();
    
    // optional uint32 storeLimit = 11;
    boolean hasStoreLimit();
    int getStoreLimit();
    
    // optional uint32 storeOffset = 12;
    boolean hasStoreOffset();
    int getStoreOffset();
  }
  public static final class Scan extends
      com.google.protobuf.GeneratedMessage
      implements ScanOrBuilder {
    // Use Scan.newBuilder() to construct.
    private Scan(Builder builder) {
      super(builder);
    }
    private Scan(boolean noInit) {}
    
    private static final Scan defaultInstance;
    public static Scan getDefaultInstance() {
      return defaultInstance;
    }
    
    public Scan getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_fieldAccessorTable;
    }
    
    private int bitField0_;
    // repeated .Column column = 1;
    public static final int COLUMN_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> column_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> getColumnList() {
      return column_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList() {
      return column_;
    }
    public int getColumnCount() {
      return column_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index) {
      return column_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index) {
      return column_.get(index);
    }
    
    // repeated .NameBytesPair attribute = 2;
    public static final int ATTRIBUTE_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    public int getAttributeCount() {
      return attribute_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }
    
    // optional bytes startRow = 3;
    public static final int STARTROW_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString startRow_;
    public boolean hasStartRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public com.google.protobuf.ByteString getStartRow() {
      return startRow_;
    }
    
    // optional bytes stopRow = 4;
    public static final int STOPROW_FIELD_NUMBER = 4;
    private com.google.protobuf.ByteString stopRow_;
    public boolean hasStopRow() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public com.google.protobuf.ByteString getStopRow() {
      return stopRow_;
    }
    
    // optional .Filter filter = 5;
    public static final int FILTER_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter filter_;
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter getFilter() {
      return filter_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_;
    }
    
    // optional .TimeRange timeRange = 6;
    public static final int TIMERANGE_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_;
    }
    
    // optional uint32 maxVersions = 7 [default = 1];
    public static final int MAXVERSIONS_FIELD_NUMBER = 7;
    private int maxVersions_;
    public boolean hasMaxVersions() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public int getMaxVersions() {
      return maxVersions_;
    }
    
    // optional bool cacheBlocks = 8 [default = true];
    public static final int CACHEBLOCKS_FIELD_NUMBER = 8;
    private boolean cacheBlocks_;
    public boolean hasCacheBlocks() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    public boolean getCacheBlocks() {
      return cacheBlocks_;
    }
    
    // optional uint32 batchSize = 9;
    public static final int BATCHSIZE_FIELD_NUMBER = 9;
    private int batchSize_;
    public boolean hasBatchSize() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    public int getBatchSize() {
      return batchSize_;
    }
    
    // optional uint64 maxResultSize = 10;
    public static final int MAXRESULTSIZE_FIELD_NUMBER = 10;
    private long maxResultSize_;
    public boolean hasMaxResultSize() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    public long getMaxResultSize() {
      return maxResultSize_;
    }
    
    // optional uint32 storeLimit = 11;
    public static final int STORELIMIT_FIELD_NUMBER = 11;
    private int storeLimit_;
    public boolean hasStoreLimit() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    public int getStoreLimit() {
      return storeLimit_;
    }
    
    // optional uint32 storeOffset = 12;
    public static final int STOREOFFSET_FIELD_NUMBER = 12;
    private int storeOffset_;
    public boolean hasStoreOffset() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    public int getStoreOffset() {
      return storeOffset_;
    }
    
    private void initFields() {
      column_ = java.util.Collections.emptyList();
      attribute_ = java.util.Collections.emptyList();
      startRow_ = com.google.protobuf.ByteString.EMPTY;
      stopRow_ = com.google.protobuf.ByteString.EMPTY;
      filter_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
      timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      maxVersions_ = 1;
      cacheBlocks_ = true;
      batchSize_ = 0;
      maxResultSize_ = 0L;
      storeLimit_ = 0;
      storeOffset_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      for (int i = 0; i < getColumnCount(); i++) {
        if (!getColumn(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasFilter()) {
        if (!getFilter().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < column_.size(); i++) {
        output.writeMessage(1, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(2, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(3, startRow_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(4, stopRow_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(5, filter_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(6, timeRange_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeUInt32(7, maxVersions_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBool(8, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeUInt32(9, batchSize_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeUInt64(10, maxResultSize_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeUInt32(11, storeLimit_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeUInt32(12, storeOffset_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < column_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, startRow_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, stopRow_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, filter_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, timeRange_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(7, maxVersions_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(9, batchSize_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(10, maxResultSize_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(11, storeLimit_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(12, storeOffset_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan) obj;
      
      boolean result = true;
      result = result && getColumnList()
          .equals(other.getColumnList());
      result = result && getAttributeList()
          .equals(other.getAttributeList());
      result = result && (hasStartRow() == other.hasStartRow());
      if (hasStartRow()) {
        result = result && getStartRow()
            .equals(other.getStartRow());
      }
      result = result && (hasStopRow() == other.hasStopRow());
      if (hasStopRow()) {
        result = result && getStopRow()
            .equals(other.getStopRow());
      }
      result = result && (hasFilter() == other.hasFilter());
      if (hasFilter()) {
        result = result && getFilter()
            .equals(other.getFilter());
      }
      result = result && (hasTimeRange() == other.hasTimeRange());
      if (hasTimeRange()) {
        result = result && getTimeRange()
            .equals(other.getTimeRange());
      }
      result = result && (hasMaxVersions() == other.hasMaxVersions());
      if (hasMaxVersions()) {
        result = result && (getMaxVersions()
            == other.getMaxVersions());
      }
      result = result && (hasCacheBlocks() == other.hasCacheBlocks());
      if (hasCacheBlocks()) {
        result = result && (getCacheBlocks()
            == other.getCacheBlocks());
      }
      result = result && (hasBatchSize() == other.hasBatchSize());
      if (hasBatchSize()) {
        result = result && (getBatchSize()
            == other.getBatchSize());
      }
      result = result && (hasMaxResultSize() == other.hasMaxResultSize());
      if (hasMaxResultSize()) {
        result = result && (getMaxResultSize()
            == other.getMaxResultSize());
      }
      result = result && (hasStoreLimit() == other.hasStoreLimit());
      if (hasStoreLimit()) {
        result = result && (getStoreLimit()
            == other.getStoreLimit());
      }
      result = result && (hasStoreOffset() == other.hasStoreOffset());
      if (hasStoreOffset()) {
        result = result && (getStoreOffset()
            == other.getStoreOffset());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getColumnCount() > 0) {
        hash = (37 * hash) + COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + getColumnList().hashCode();
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasStartRow()) {
        hash = (37 * hash) + STARTROW_FIELD_NUMBER;
        hash = (53 * hash) + getStartRow().hashCode();
      }
      if (hasStopRow()) {
        hash = (37 * hash) + STOPROW_FIELD_NUMBER;
        hash = (53 * hash) + getStopRow().hashCode();
      }
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIMERANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasMaxVersions()) {
        hash = (37 * hash) + MAXVERSIONS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxVersions();
      }
      if (hasCacheBlocks()) {
        hash = (37 * hash) + CACHEBLOCKS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCacheBlocks());
      }
      if (hasBatchSize()) {
        hash = (37 * hash) + BATCHSIZE_FIELD_NUMBER;
        hash = (53 * hash) + getBatchSize();
      }
      if (hasMaxResultSize()) {
        hash = (37 * hash) + MAXRESULTSIZE_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getMaxResultSize());
      }
      if (hasStoreLimit()) {
        hash = (37 * hash) + STORELIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getStoreLimit();
      }
      if (hasStoreOffset()) {
        hash = (37 * hash) + STOREOFFSET_FIELD_NUMBER;
        hash = (53 * hash) + getStoreOffset();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getColumnFieldBuilder();
          getAttributeFieldBuilder();
          getFilterFieldBuilder();
          getTimeRangeFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          columnBuilder_.clear();
        }
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          attributeBuilder_.clear();
        }
        startRow_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        stopRow_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (filterBuilder_ == null) {
          filter_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
        } else {
          filterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        maxVersions_ = 1;
        bitField0_ = (bitField0_ & ~0x00000040);
        cacheBlocks_ = true;
        bitField0_ = (bitField0_ & ~0x00000080);
        batchSize_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        maxResultSize_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000200);
        storeLimit_ = 0;
        bitField0_ = (bitField0_ & ~0x00000400);
        storeOffset_ = 0;
        bitField0_ = (bitField0_ & ~0x00000800);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (columnBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            column_ = java.util.Collections.unmodifiableList(column_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.column_ = column_;
        } else {
          result.column_ = columnBuilder_.build();
        }
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000001;
        }
        result.startRow_ = startRow_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000002;
        }
        result.stopRow_ = stopRow_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        if (filterBuilder_ == null) {
          result.filter_ = filter_;
        } else {
          result.filter_ = filterBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000008;
        }
        if (timeRangeBuilder_ == null) {
          result.timeRange_ = timeRange_;
        } else {
          result.timeRange_ = timeRangeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        result.maxVersions_ = maxVersions_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        result.cacheBlocks_ = cacheBlocks_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000040;
        }
        result.batchSize_ = batchSize_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000080;
        }
        result.maxResultSize_ = maxResultSize_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000100;
        }
        result.storeLimit_ = storeLimit_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000200;
        }
        result.storeOffset_ = storeOffset_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance()) return this;
        if (columnBuilder_ == null) {
          if (!other.column_.isEmpty()) {
            if (column_.isEmpty()) {
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureColumnIsMutable();
              column_.addAll(other.column_);
            }
            onChanged();
          }
        } else {
          if (!other.column_.isEmpty()) {
            if (columnBuilder_.isEmpty()) {
              columnBuilder_.dispose();
              columnBuilder_ = null;
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000001);
              columnBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getColumnFieldBuilder() : null;
            } else {
              columnBuilder_.addAllMessages(other.column_);
            }
          }
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000002);
              attributeBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasStartRow()) {
          setStartRow(other.getStartRow());
        }
        if (other.hasStopRow()) {
          setStopRow(other.getStopRow());
        }
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasMaxVersions()) {
          setMaxVersions(other.getMaxVersions());
        }
        if (other.hasCacheBlocks()) {
          setCacheBlocks(other.getCacheBlocks());
        }
        if (other.hasBatchSize()) {
          setBatchSize(other.getBatchSize());
        }
        if (other.hasMaxResultSize()) {
          setMaxResultSize(other.getMaxResultSize());
        }
        if (other.hasStoreLimit()) {
          setStoreLimit(other.getStoreLimit());
        }
        if (other.hasStoreOffset()) {
          setStoreOffset(other.getStoreOffset());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        for (int i = 0; i < getColumnCount(); i++) {
          if (!getColumn(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            
            return false;
          }
        }
        if (hasFilter()) {
          if (!getFilter().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addColumn(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addAttribute(subBuilder.buildPartial());
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              startRow_ = input.readBytes();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              stopRow_ = input.readBytes();
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.newBuilder();
              if (hasFilter()) {
                subBuilder.mergeFrom(getFilter());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setFilter(subBuilder.buildPartial());
              break;
            }
            case 50: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder();
              if (hasTimeRange()) {
                subBuilder.mergeFrom(getTimeRange());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setTimeRange(subBuilder.buildPartial());
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              maxVersions_ = input.readUInt32();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              cacheBlocks_ = input.readBool();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              batchSize_ = input.readUInt32();
              break;
            }
            case 80: {
              bitField0_ |= 0x00000200;
              maxResultSize_ = input.readUInt64();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              storeLimit_ = input.readUInt32();
              break;
            }
            case 96: {
              bitField0_ |= 0x00000800;
              storeOffset_ = input.readUInt32();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .Column column = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> column_ =
        java.util.Collections.emptyList();
      private void ensureColumnIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          column_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column>(column_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> columnBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> getColumnList() {
        if (columnBuilder_ == null) {
          return java.util.Collections.unmodifiableList(column_);
        } else {
          return columnBuilder_.getMessageList();
        }
      }
      public int getColumnCount() {
        if (columnBuilder_ == null) {
          return column_.size();
        } else {
          return columnBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);
        } else {
          return columnBuilder_.getMessage(index);
        }
      }
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.set(index, value);
          onChanged();
        } else {
          columnBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addColumn(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(value);
          onChanged();
        } else {
          columnBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(index, value);
          onChanged();
        } else {
          columnBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addColumn(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllColumn(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> values) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          super.addAll(values, column_);
          onChanged();
        } else {
          columnBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearColumn() {
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          columnBuilder_.clear();
        }
        return this;
      }
      public Builder removeColumn(int index) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.remove(index);
          onChanged();
        } else {
          columnBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder getColumnBuilder(
          int index) {
        return getColumnFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
          int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);  } else {
          return columnBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
           getColumnOrBuilderList() {
        if (columnBuilder_ != null) {
          return columnBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(column_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder() {
        return getColumnFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder(
          int index) {
        return getColumnFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder> 
           getColumnBuilderList() {
        return getColumnFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
          getColumnFieldBuilder() {
        if (columnBuilder_ == null) {
          columnBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder>(
                  column_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          column_ = null;
        }
        return columnBuilder_;
      }
      
      // repeated .NameBytesPair attribute = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000002;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAttribute(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addAttribute(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          super.addAll(values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }
      
      // optional bytes startRow = 3;
      private com.google.protobuf.ByteString startRow_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasStartRow() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public com.google.protobuf.ByteString getStartRow() {
        return startRow_;
      }
      public Builder setStartRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        startRow_ = value;
        onChanged();
        return this;
      }
      public Builder clearStartRow() {
        bitField0_ = (bitField0_ & ~0x00000004);
        startRow_ = getDefaultInstance().getStartRow();
        onChanged();
        return this;
      }
      
      // optional bytes stopRow = 4;
      private com.google.protobuf.ByteString stopRow_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasStopRow() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public com.google.protobuf.ByteString getStopRow() {
        return stopRow_;
      }
      public Builder setStopRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        stopRow_ = value;
        onChanged();
        return this;
      }
      public Builder clearStopRow() {
        bitField0_ = (bitField0_ & ~0x00000008);
        stopRow_ = getDefaultInstance().getStopRow();
        onChanged();
        return this;
      }
      
      // optional .Filter filter = 5;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter filter_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder> filterBuilder_;
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      public Builder setFilter(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
          onChanged();
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder setFilter(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
          onChanged();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder mergeFilter(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              filter_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance()) {
            filter_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.newBuilder(filter_).mergeFrom(value).buildPartial();
          } else {
            filter_ = value;
          }
          onChanged();
        } else {
          filterBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      public Builder clearFilter() {
        if (filterBuilder_ == null) {
          filter_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.getDefaultInstance();
          onChanged();
        } else {
          filterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.FilterOrBuilder>(
                  filter_,
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }
      
      // optional .TimeRange timeRange = 6;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      public Builder setTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      public Builder setTimeRange(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      public Builder mergeTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              timeRange_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            timeRange_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder(timeRange_).mergeFrom(value).buildPartial();
          } else {
            timeRange_ = value;
          }
          onChanged();
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      public Builder clearTimeRange() {
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
          onChanged();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  timeRange_,
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }
      
      // optional uint32 maxVersions = 7 [default = 1];
      private int maxVersions_ = 1;
      public boolean hasMaxVersions() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      public int getMaxVersions() {
        return maxVersions_;
      }
      public Builder setMaxVersions(int value) {
        bitField0_ |= 0x00000040;
        maxVersions_ = value;
        onChanged();
        return this;
      }
      public Builder clearMaxVersions() {
        bitField0_ = (bitField0_ & ~0x00000040);
        maxVersions_ = 1;
        onChanged();
        return this;
      }
      
      // optional bool cacheBlocks = 8 [default = true];
      private boolean cacheBlocks_ = true;
      public boolean hasCacheBlocks() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      public boolean getCacheBlocks() {
        return cacheBlocks_;
      }
      public Builder setCacheBlocks(boolean value) {
        bitField0_ |= 0x00000080;
        cacheBlocks_ = value;
        onChanged();
        return this;
      }
      public Builder clearCacheBlocks() {
        bitField0_ = (bitField0_ & ~0x00000080);
        cacheBlocks_ = true;
        onChanged();
        return this;
      }
      
      // optional uint32 batchSize = 9;
      private int batchSize_ ;
      public boolean hasBatchSize() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      public int getBatchSize() {
        return batchSize_;
      }
      public Builder setBatchSize(int value) {
        bitField0_ |= 0x00000100;
        batchSize_ = value;
        onChanged();
        return this;
      }
      public Builder clearBatchSize() {
        bitField0_ = (bitField0_ & ~0x00000100);
        batchSize_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint64 maxResultSize = 10;
      private long maxResultSize_ ;
      public boolean hasMaxResultSize() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      public long getMaxResultSize() {
        return maxResultSize_;
      }
      public Builder setMaxResultSize(long value) {
        bitField0_ |= 0x00000200;
        maxResultSize_ = value;
        onChanged();
        return this;
      }
      public Builder clearMaxResultSize() {
        bitField0_ = (bitField0_ & ~0x00000200);
        maxResultSize_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint32 storeLimit = 11;
      private int storeLimit_ ;
      public boolean hasStoreLimit() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      public int getStoreLimit() {
        return storeLimit_;
      }
      public Builder setStoreLimit(int value) {
        bitField0_ |= 0x00000400;
        storeLimit_ = value;
        onChanged();
        return this;
      }
      public Builder clearStoreLimit() {
        bitField0_ = (bitField0_ & ~0x00000400);
        storeLimit_ = 0;
        onChanged();
        return this;
      }
      
      // optional uint32 storeOffset = 12;
      private int storeOffset_ ;
      public boolean hasStoreOffset() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      public int getStoreOffset() {
        return storeOffset_;
      }
      public Builder setStoreOffset(int value) {
        bitField0_ |= 0x00000800;
        storeOffset_ = value;
        onChanged();
        return this;
      }
      public Builder clearStoreOffset() {
        bitField0_ = (bitField0_ & ~0x00000800);
        storeOffset_ = 0;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:Scan)
    }
    
    static {
      defaultInstance = new Scan(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:Scan)
  }
  
  public interface ScanRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // optional .Scan scan = 2;
    boolean hasScan();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan getScan();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder();
    
    // optional uint64 scannerId = 3;
    boolean hasScannerId();
    long getScannerId();
    
    // optional uint32 numberOfRows = 4;
    boolean hasNumberOfRows();
    int getNumberOfRows();
    
    // optional bool closeScanner = 5;
    boolean hasCloseScanner();
    boolean getCloseScanner();
  }
  public static final class ScanRequest extends
      com.google.protobuf.GeneratedMessage
      implements ScanRequestOrBuilder {
    // Use ScanRequest.newBuilder() to construct.
    private ScanRequest(Builder builder) {
      super(builder);
    }
    private ScanRequest(boolean noInit) {}
    
    private static final ScanRequest defaultInstance;
    public static ScanRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public ScanRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // optional .Scan scan = 2;
    public static final int SCAN_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan scan_;
    public boolean hasScan() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan getScan() {
      return scan_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder() {
      return scan_;
    }
    
    // optional uint64 scannerId = 3;
    public static final int SCANNERID_FIELD_NUMBER = 3;
    private long scannerId_;
    public boolean hasScannerId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public long getScannerId() {
      return scannerId_;
    }
    
    // optional uint32 numberOfRows = 4;
    public static final int NUMBEROFROWS_FIELD_NUMBER = 4;
    private int numberOfRows_;
    public boolean hasNumberOfRows() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public int getNumberOfRows() {
      return numberOfRows_;
    }
    
    // optional bool closeScanner = 5;
    public static final int CLOSESCANNER_FIELD_NUMBER = 5;
    private boolean closeScanner_;
    public boolean hasCloseScanner() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    public boolean getCloseScanner() {
      return closeScanner_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      scan_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
      scannerId_ = 0L;
      numberOfRows_ = 0;
      closeScanner_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (hasRegion()) {
        if (!getRegion().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasScan()) {
        if (!getScan().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, scan_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(3, scannerId_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(4, numberOfRows_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(5, closeScanner_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, scan_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, scannerId_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, numberOfRows_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, closeScanner_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasScan() == other.hasScan());
      if (hasScan()) {
        result = result && getScan()
            .equals(other.getScan());
      }
      result = result && (hasScannerId() == other.hasScannerId());
      if (hasScannerId()) {
        result = result && (getScannerId()
            == other.getScannerId());
      }
      result = result && (hasNumberOfRows() == other.hasNumberOfRows());
      if (hasNumberOfRows()) {
        result = result && (getNumberOfRows()
            == other.getNumberOfRows());
      }
      result = result && (hasCloseScanner() == other.hasCloseScanner());
      if (hasCloseScanner()) {
        result = result && (getCloseScanner()
            == other.getCloseScanner());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasScan()) {
        hash = (37 * hash) + SCAN_FIELD_NUMBER;
        hash = (53 * hash) + getScan().hashCode();
      }
      if (hasScannerId()) {
        hash = (37 * hash) + SCANNERID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getScannerId());
      }
      if (hasNumberOfRows()) {
        hash = (37 * hash) + NUMBEROFROWS_FIELD_NUMBER;
        hash = (53 * hash) + getNumberOfRows();
      }
      if (hasCloseScanner()) {
        hash = (37 * hash) + CLOSESCANNER_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCloseScanner());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getScanFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (scanBuilder_ == null) {
          scan_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
        } else {
          scanBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        scannerId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        numberOfRows_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        closeScanner_ = false;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (scanBuilder_ == null) {
          result.scan_ = scan_;
        } else {
          result.scan_ = scanBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.scannerId_ = scannerId_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.numberOfRows_ = numberOfRows_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.closeScanner_ = closeScanner_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasScan()) {
          mergeScan(other.getScan());
        }
        if (other.hasScannerId()) {
          setScannerId(other.getScannerId());
        }
        if (other.hasNumberOfRows()) {
          setNumberOfRows(other.getNumberOfRows());
        }
        if (other.hasCloseScanner()) {
          setCloseScanner(other.getCloseScanner());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (hasRegion()) {
          if (!getRegion().isInitialized()) {
            
            return false;
          }
        }
        if (hasScan()) {
          if (!getScan().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.newBuilder();
              if (hasScan()) {
                subBuilder.mergeFrom(getScan());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setScan(subBuilder.buildPartial());
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              scannerId_ = input.readUInt64();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              numberOfRows_ = input.readUInt32();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              closeScanner_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // optional .Scan scan = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan scan_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder> scanBuilder_;
      public boolean hasScan() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan getScan() {
        if (scanBuilder_ == null) {
          return scan_;
        } else {
          return scanBuilder_.getMessage();
        }
      }
      public Builder setScan(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan value) {
        if (scanBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          scan_ = value;
          onChanged();
        } else {
          scanBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setScan(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder builderForValue) {
        if (scanBuilder_ == null) {
          scan_ = builderForValue.build();
          onChanged();
        } else {
          scanBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeScan(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan value) {
        if (scanBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              scan_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance()) {
            scan_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.newBuilder(scan_).mergeFrom(value).buildPartial();
          } else {
            scan_ = value;
          }
          onChanged();
        } else {
          scanBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearScan() {
        if (scanBuilder_ == null) {
          scan_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
          onChanged();
        } else {
          scanBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder getScanBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getScanFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder() {
        if (scanBuilder_ != null) {
          return scanBuilder_.getMessageOrBuilder();
        } else {
          return scan_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder> 
          getScanFieldBuilder() {
        if (scanBuilder_ == null) {
          scanBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder>(
                  scan_,
                  getParentForChildren(),
                  isClean());
          scan_ = null;
        }
        return scanBuilder_;
      }
      
      // optional uint64 scannerId = 3;
      private long scannerId_ ;
      public boolean hasScannerId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public long getScannerId() {
        return scannerId_;
      }
      public Builder setScannerId(long value) {
        bitField0_ |= 0x00000004;
        scannerId_ = value;
        onChanged();
        return this;
      }
      public Builder clearScannerId() {
        bitField0_ = (bitField0_ & ~0x00000004);
        scannerId_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint32 numberOfRows = 4;
      private int numberOfRows_ ;
      public boolean hasNumberOfRows() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public int getNumberOfRows() {
        return numberOfRows_;
      }
      public Builder setNumberOfRows(int value) {
        bitField0_ |= 0x00000008;
        numberOfRows_ = value;
        onChanged();
        return this;
      }
      public Builder clearNumberOfRows() {
        bitField0_ = (bitField0_ & ~0x00000008);
        numberOfRows_ = 0;
        onChanged();
        return this;
      }
      
      // optional bool closeScanner = 5;
      private boolean closeScanner_ ;
      public boolean hasCloseScanner() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      public boolean getCloseScanner() {
        return closeScanner_;
      }
      public Builder setCloseScanner(boolean value) {
        bitField0_ |= 0x00000010;
        closeScanner_ = value;
        onChanged();
        return this;
      }
      public Builder clearCloseScanner() {
        bitField0_ = (bitField0_ & ~0x00000010);
        closeScanner_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:ScanRequest)
    }
    
    static {
      defaultInstance = new ScanRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:ScanRequest)
  }
  
  public interface ScanResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .Result result = 1;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> 
        getResultList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult(int index);
    int getResultCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
        getResultOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder(
        int index);
    
    // optional uint64 scannerId = 2;
    boolean hasScannerId();
    long getScannerId();
    
    // optional bool moreResults = 3;
    boolean hasMoreResults();
    boolean getMoreResults();
    
    // optional uint32 ttl = 4;
    boolean hasTtl();
    int getTtl();
  }
  public static final class ScanResponse extends
      com.google.protobuf.GeneratedMessage
      implements ScanResponseOrBuilder {
    // Use ScanResponse.newBuilder() to construct.
    private ScanResponse(Builder builder) {
      super(builder);
    }
    private ScanResponse(boolean noInit) {}
    
    private static final ScanResponse defaultInstance;
    public static ScanResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public ScanResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_fieldAccessorTable;
    }
    
    private int bitField0_;
    // repeated .Result result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> result_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> getResultList() {
      return result_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
        getResultOrBuilderList() {
      return result_;
    }
    public int getResultCount() {
      return result_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult(int index) {
      return result_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder(
        int index) {
      return result_.get(index);
    }
    
    // optional uint64 scannerId = 2;
    public static final int SCANNERID_FIELD_NUMBER = 2;
    private long scannerId_;
    public boolean hasScannerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public long getScannerId() {
      return scannerId_;
    }
    
    // optional bool moreResults = 3;
    public static final int MORERESULTS_FIELD_NUMBER = 3;
    private boolean moreResults_;
    public boolean hasMoreResults() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public boolean getMoreResults() {
      return moreResults_;
    }
    
    // optional uint32 ttl = 4;
    public static final int TTL_FIELD_NUMBER = 4;
    private int ttl_;
    public boolean hasTtl() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public int getTtl() {
      return ttl_;
    }
    
    private void initFields() {
      result_ = java.util.Collections.emptyList();
      scannerId_ = 0L;
      moreResults_ = false;
      ttl_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < result_.size(); i++) {
        output.writeMessage(1, result_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(2, scannerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(3, moreResults_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt32(4, ttl_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < result_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, scannerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, moreResults_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, ttl_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse) obj;
      
      boolean result = true;
      result = result && getResultList()
          .equals(other.getResultList());
      result = result && (hasScannerId() == other.hasScannerId());
      if (hasScannerId()) {
        result = result && (getScannerId()
            == other.getScannerId());
      }
      result = result && (hasMoreResults() == other.hasMoreResults());
      if (hasMoreResults()) {
        result = result && (getMoreResults()
            == other.getMoreResults());
      }
      result = result && (hasTtl() == other.hasTtl());
      if (hasTtl()) {
        result = result && (getTtl()
            == other.getTtl());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResultCount() > 0) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResultList().hashCode();
      }
      if (hasScannerId()) {
        hash = (37 * hash) + SCANNERID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getScannerId());
      }
      if (hasMoreResults()) {
        hash = (37 * hash) + MORERESULTS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getMoreResults());
      }
      if (hasTtl()) {
        hash = (37 * hash) + TTL_FIELD_NUMBER;
        hash = (53 * hash) + getTtl();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resultBuilder_.clear();
        }
        scannerId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        moreResults_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        ttl_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            result_ = java.util.Collections.unmodifiableList(result_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.scannerId_ = scannerId_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.moreResults_ = moreResults_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        result.ttl_ = ttl_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance()) return this;
        if (resultBuilder_ == null) {
          if (!other.result_.isEmpty()) {
            if (result_.isEmpty()) {
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultIsMutable();
              result_.addAll(other.result_);
            }
            onChanged();
          }
        } else {
          if (!other.result_.isEmpty()) {
            if (resultBuilder_.isEmpty()) {
              resultBuilder_.dispose();
              resultBuilder_ = null;
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getResultFieldBuilder() : null;
            } else {
              resultBuilder_.addAllMessages(other.result_);
            }
          }
        }
        if (other.hasScannerId()) {
          setScannerId(other.getScannerId());
        }
        if (other.hasMoreResults()) {
          setMoreResults(other.getMoreResults());
        }
        if (other.hasTtl()) {
          setTtl(other.getTtl());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addResult(subBuilder.buildPartial());
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              scannerId_ = input.readUInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              moreResults_ = input.readBool();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              ttl_ = input.readUInt32();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .Result result = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> result_ =
        java.util.Collections.emptyList();
      private void ensureResultIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          result_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result>(result_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> getResultList() {
        if (resultBuilder_ == null) {
          return java.util.Collections.unmodifiableList(result_);
        } else {
          return resultBuilder_.getMessageList();
        }
      }
      public int getResultCount() {
        if (resultBuilder_ == null) {
          return result_.size();
        } else {
          return resultBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult(int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);
        } else {
          return resultBuilder_.getMessage(index);
        }
      }
      public Builder setResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.set(index, value);
          onChanged();
        } else {
          resultBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(value);
          onChanged();
        } else {
          resultBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(index, value);
          onChanged();
        } else {
          resultBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addResult(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllResult(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> values) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          super.addAll(values, result_);
          onChanged();
        } else {
          resultBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        return this;
      }
      public Builder removeResult(int index) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.remove(index);
          onChanged();
        } else {
          resultBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder getResultBuilder(
          int index) {
        return getResultFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder(
          int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);  } else {
          return resultBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
           getResultOrBuilderList() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(result_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder addResultBuilder() {
        return getResultFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder addResultBuilder(
          int index) {
        return getResultFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder> 
           getResultBuilderList() {
        return getResultFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  result_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }
      
      // optional uint64 scannerId = 2;
      private long scannerId_ ;
      public boolean hasScannerId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public long getScannerId() {
        return scannerId_;
      }
      public Builder setScannerId(long value) {
        bitField0_ |= 0x00000002;
        scannerId_ = value;
        onChanged();
        return this;
      }
      public Builder clearScannerId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        scannerId_ = 0L;
        onChanged();
        return this;
      }
      
      // optional bool moreResults = 3;
      private boolean moreResults_ ;
      public boolean hasMoreResults() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public boolean getMoreResults() {
        return moreResults_;
      }
      public Builder setMoreResults(boolean value) {
        bitField0_ |= 0x00000004;
        moreResults_ = value;
        onChanged();
        return this;
      }
      public Builder clearMoreResults() {
        bitField0_ = (bitField0_ & ~0x00000004);
        moreResults_ = false;
        onChanged();
        return this;
      }
      
      // optional uint32 ttl = 4;
      private int ttl_ ;
      public boolean hasTtl() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public int getTtl() {
        return ttl_;
      }
      public Builder setTtl(int value) {
        bitField0_ |= 0x00000008;
        ttl_ = value;
        onChanged();
        return this;
      }
      public Builder clearTtl() {
        bitField0_ = (bitField0_ & ~0x00000008);
        ttl_ = 0;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:ScanResponse)
    }
    
    static {
      defaultInstance = new ScanResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:ScanResponse)
  }
  
  public interface LockRowRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // repeated bytes row = 2;
    java.util.List<com.google.protobuf.ByteString> getRowList();
    int getRowCount();
    com.google.protobuf.ByteString getRow(int index);
  }
  public static final class LockRowRequest extends
      com.google.protobuf.GeneratedMessage
      implements LockRowRequestOrBuilder {
    // Use LockRowRequest.newBuilder() to construct.
    private LockRowRequest(Builder builder) {
      super(builder);
    }
    private LockRowRequest(boolean noInit) {}
    
    private static final LockRowRequest defaultInstance;
    public static LockRowRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public LockRowRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_LockRowRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_LockRowRequest_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // repeated bytes row = 2;
    public static final int ROW_FIELD_NUMBER = 2;
    private java.util.List<com.google.protobuf.ByteString> row_;
    public java.util.List<com.google.protobuf.ByteString>
        getRowList() {
      return row_;
    }
    public int getRowCount() {
      return row_.size();
    }
    public com.google.protobuf.ByteString getRow(int index) {
      return row_.get(index);
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      row_ = java.util.Collections.emptyList();;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      for (int i = 0; i < row_.size(); i++) {
        output.writeBytes(2, row_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < row_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(row_.get(i));
        }
        size += dataSize;
        size += 1 * getRowList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && getRowList()
          .equals(other.getRowList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (getRowCount() > 0) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRowList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_LockRowRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_LockRowRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          row_ = java.util.Collections.unmodifiableList(row_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.row_ = row_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (!other.row_.isEmpty()) {
          if (row_.isEmpty()) {
            row_ = other.row_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureRowIsMutable();
            row_.addAll(other.row_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              ensureRowIsMutable();
              row_.add(input.readBytes());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // repeated bytes row = 2;
      private java.util.List<com.google.protobuf.ByteString> row_ = java.util.Collections.emptyList();;
      private void ensureRowIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          row_ = new java.util.ArrayList<com.google.protobuf.ByteString>(row_);
          bitField0_ |= 0x00000002;
         }
      }
      public java.util.List<com.google.protobuf.ByteString>
          getRowList() {
        return java.util.Collections.unmodifiableList(row_);
      }
      public int getRowCount() {
        return row_.size();
      }
      public com.google.protobuf.ByteString getRow(int index) {
        return row_.get(index);
      }
      public Builder setRow(
          int index, com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureRowIsMutable();
        row_.set(index, value);
        onChanged();
        return this;
      }
      public Builder addRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureRowIsMutable();
        row_.add(value);
        onChanged();
        return this;
      }
      public Builder addAllRow(
          java.lang.Iterable<? extends com.google.protobuf.ByteString> values) {
        ensureRowIsMutable();
        super.addAll(values, row_);
        onChanged();
        return this;
      }
      public Builder clearRow() {
        row_ = java.util.Collections.emptyList();;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:LockRowRequest)
    }
    
    static {
      defaultInstance = new LockRowRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:LockRowRequest)
  }
  
  public interface LockRowResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required uint64 lockId = 1;
    boolean hasLockId();
    long getLockId();
    
    // optional uint32 ttl = 2;
    boolean hasTtl();
    int getTtl();
  }
  public static final class LockRowResponse extends
      com.google.protobuf.GeneratedMessage
      implements LockRowResponseOrBuilder {
    // Use LockRowResponse.newBuilder() to construct.
    private LockRowResponse(Builder builder) {
      super(builder);
    }
    private LockRowResponse(boolean noInit) {}
    
    private static final LockRowResponse defaultInstance;
    public static LockRowResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public LockRowResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_LockRowResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_LockRowResponse_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required uint64 lockId = 1;
    public static final int LOCKID_FIELD_NUMBER = 1;
    private long lockId_;
    public boolean hasLockId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public long getLockId() {
      return lockId_;
    }
    
    // optional uint32 ttl = 2;
    public static final int TTL_FIELD_NUMBER = 2;
    private int ttl_;
    public boolean hasTtl() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public int getTtl() {
      return ttl_;
    }
    
    private void initFields() {
      lockId_ = 0L;
      ttl_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasLockId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(1, lockId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt32(2, ttl_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, lockId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, ttl_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse) obj;
      
      boolean result = true;
      result = result && (hasLockId() == other.hasLockId());
      if (hasLockId()) {
        result = result && (getLockId()
            == other.getLockId());
      }
      result = result && (hasTtl() == other.hasTtl());
      if (hasTtl()) {
        result = result && (getTtl()
            == other.getTtl());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasLockId()) {
        hash = (37 * hash) + LOCKID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getLockId());
      }
      if (hasTtl()) {
        hash = (37 * hash) + TTL_FIELD_NUMBER;
        hash = (53 * hash) + getTtl();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_LockRowResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_LockRowResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        lockId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        ttl_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.lockId_ = lockId_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.ttl_ = ttl_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.getDefaultInstance()) return this;
        if (other.hasLockId()) {
          setLockId(other.getLockId());
        }
        if (other.hasTtl()) {
          setTtl(other.getTtl());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasLockId()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              lockId_ = input.readUInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              ttl_ = input.readUInt32();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required uint64 lockId = 1;
      private long lockId_ ;
      public boolean hasLockId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public long getLockId() {
        return lockId_;
      }
      public Builder setLockId(long value) {
        bitField0_ |= 0x00000001;
        lockId_ = value;
        onChanged();
        return this;
      }
      public Builder clearLockId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        lockId_ = 0L;
        onChanged();
        return this;
      }
      
      // optional uint32 ttl = 2;
      private int ttl_ ;
      public boolean hasTtl() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public int getTtl() {
        return ttl_;
      }
      public Builder setTtl(int value) {
        bitField0_ |= 0x00000002;
        ttl_ = value;
        onChanged();
        return this;
      }
      public Builder clearTtl() {
        bitField0_ = (bitField0_ & ~0x00000002);
        ttl_ = 0;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:LockRowResponse)
    }
    
    static {
      defaultInstance = new LockRowResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:LockRowResponse)
  }
  
  public interface UnlockRowRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // required uint64 lockId = 2;
    boolean hasLockId();
    long getLockId();
  }
  public static final class UnlockRowRequest extends
      com.google.protobuf.GeneratedMessage
      implements UnlockRowRequestOrBuilder {
    // Use UnlockRowRequest.newBuilder() to construct.
    private UnlockRowRequest(Builder builder) {
      super(builder);
    }
    private UnlockRowRequest(boolean noInit) {}
    
    private static final UnlockRowRequest defaultInstance;
    public static UnlockRowRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public UnlockRowRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_UnlockRowRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_UnlockRowRequest_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // required uint64 lockId = 2;
    public static final int LOCKID_FIELD_NUMBER = 2;
    private long lockId_;
    public boolean hasLockId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public long getLockId() {
      return lockId_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      lockId_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasLockId()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeUInt64(2, lockId_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, lockId_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasLockId() == other.hasLockId());
      if (hasLockId()) {
        result = result && (getLockId()
            == other.getLockId());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasLockId()) {
        hash = (37 * hash) + LOCKID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getLockId());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_UnlockRowRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_UnlockRowRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        lockId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.lockId_ = lockId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasLockId()) {
          setLockId(other.getLockId());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasLockId()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              lockId_ = input.readUInt64();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // required uint64 lockId = 2;
      private long lockId_ ;
      public boolean hasLockId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public long getLockId() {
        return lockId_;
      }
      public Builder setLockId(long value) {
        bitField0_ |= 0x00000002;
        lockId_ = value;
        onChanged();
        return this;
      }
      public Builder clearLockId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        lockId_ = 0L;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:UnlockRowRequest)
    }
    
    static {
      defaultInstance = new UnlockRowRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:UnlockRowRequest)
  }
  
  public interface UnlockRowResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
  }
  public static final class UnlockRowResponse extends
      com.google.protobuf.GeneratedMessage
      implements UnlockRowResponseOrBuilder {
    // Use UnlockRowResponse.newBuilder() to construct.
    private UnlockRowResponse(Builder builder) {
      super(builder);
    }
    private UnlockRowResponse(boolean noInit) {}
    
    private static final UnlockRowResponse defaultInstance;
    public static UnlockRowResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public UnlockRowResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_UnlockRowResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_UnlockRowResponse_fieldAccessorTable;
    }
    
    private void initFields() {
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse) obj;
      
      boolean result = true;
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_UnlockRowResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_UnlockRowResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse(this);
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.getDefaultInstance()) return this;
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
          }
        }
      }
      
      
      // @@protoc_insertion_point(builder_scope:UnlockRowResponse)
    }
    
    static {
      defaultInstance = new UnlockRowResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:UnlockRowResponse)
  }
  
  public interface BulkLoadHFileRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // repeated .BulkLoadHFileRequest.FamilyPath familyPath = 2;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> 
        getFamilyPathList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index);
    int getFamilyPathCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
        getFamilyPathOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
        int index);
    
    // optional bool assignSeqNum = 3;
    boolean hasAssignSeqNum();
    boolean getAssignSeqNum();
  }
  public static final class BulkLoadHFileRequest extends
      com.google.protobuf.GeneratedMessage
      implements BulkLoadHFileRequestOrBuilder {
    // Use BulkLoadHFileRequest.newBuilder() to construct.
    private BulkLoadHFileRequest(Builder builder) {
      super(builder);
    }
    private BulkLoadHFileRequest(boolean noInit) {}
    
    private static final BulkLoadHFileRequest defaultInstance;
    public static BulkLoadHFileRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public BulkLoadHFileRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_fieldAccessorTable;
    }
    
    public interface FamilyPathOrBuilder
        extends com.google.protobuf.MessageOrBuilder {
      
      // required bytes family = 1;
      boolean hasFamily();
      com.google.protobuf.ByteString getFamily();
      
      // required string path = 2;
      boolean hasPath();
      String getPath();
    }
    public static final class FamilyPath extends
        com.google.protobuf.GeneratedMessage
        implements FamilyPathOrBuilder {
      // Use FamilyPath.newBuilder() to construct.
      private FamilyPath(Builder builder) {
        super(builder);
      }
      private FamilyPath(boolean noInit) {}
      
      private static final FamilyPath defaultInstance;
      public static FamilyPath getDefaultInstance() {
        return defaultInstance;
      }
      
      public FamilyPath getDefaultInstanceForType() {
        return defaultInstance;
      }
      
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable;
      }
      
      private int bitField0_;
      // required bytes family = 1;
      public static final int FAMILY_FIELD_NUMBER = 1;
      private com.google.protobuf.ByteString family_;
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      
      // required string path = 2;
      public static final int PATH_FIELD_NUMBER = 2;
      private java.lang.Object path_;
      public boolean hasPath() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public String getPath() {
        java.lang.Object ref = path_;
        if (ref instanceof String) {
          return (String) ref;
        } else {
          com.google.protobuf.ByteString bs = 
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          if (com.google.protobuf.Internal.isValidUtf8(bs)) {
            path_ = s;
          }
          return s;
        }
      }
      private com.google.protobuf.ByteString getPathBytes() {
        java.lang.Object ref = path_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8((String) ref);
          path_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      
      private void initFields() {
        family_ = com.google.protobuf.ByteString.EMPTY;
        path_ = "";
      }
      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized != -1) return isInitialized == 1;
        
        if (!hasFamily()) {
          memoizedIsInitialized = 0;
          return false;
        }
        if (!hasPath()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }
      
      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          output.writeBytes(1, family_);
        }
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          output.writeBytes(2, getPathBytes());
        }
        getUnknownFields().writeTo(output);
      }
      
      private int memoizedSerializedSize = -1;
      public int getSerializedSize() {
        int size = memoizedSerializedSize;
        if (size != -1) return size;
      
        size = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, family_);
        }
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(2, getPathBytes());
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSerializedSize = size;
        return size;
      }
      
      private static final long serialVersionUID = 0L;
      @java.lang.Override
      protected java.lang.Object writeReplace()
          throws java.io.ObjectStreamException {
        return super.writeReplace();
      }
      
      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath) obj;
        
        boolean result = true;
        result = result && (hasFamily() == other.hasFamily());
        if (hasFamily()) {
          result = result && getFamily()
              .equals(other.getFamily());
        }
        result = result && (hasPath() == other.hasPath());
        if (hasPath()) {
          result = result && getPath()
              .equals(other.getPath());
        }
        result = result &&
            getUnknownFields().equals(other.getUnknownFields());
        return result;
      }
      
      @java.lang.Override
      public int hashCode() {
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        if (hasFamily()) {
          hash = (37 * hash) + FAMILY_FIELD_NUMBER;
          hash = (53 * hash) + getFamily().hashCode();
        }
        if (hasPath()) {
          hash = (37 * hash) + PATH_FIELD_NUMBER;
          hash = (53 * hash) + getPath().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        return hash;
      }
      
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data).buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data).buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return newBuilder().mergeFrom(data, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input).buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input, extensionRegistry)
                 .buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        Builder builder = newBuilder();
        if (builder.mergeDelimitedFrom(input)) {
          return builder.buildParsed();
        } else {
          return null;
        }
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        Builder builder = newBuilder();
        if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
          return builder.buildParsed();
        } else {
          return null;
        }
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input).buildParsed();
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return newBuilder().mergeFrom(input, extensionRegistry)
                 .buildParsed();
      }
      
      public static Builder newBuilder() { return Builder.create(); }
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath prototype) {
        return newBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() { return newBuilder(this); }
      
      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      public static final class Builder extends
          com.google.protobuf.GeneratedMessage.Builder<Builder>
         implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_descriptor;
        }
        
        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable;
        }
        
        // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }
        
        private Builder(BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          }
        }
        private static Builder create() {
          return new Builder();
        }
        
        public Builder clear() {
          super.clear();
          family_ = com.google.protobuf.ByteString.EMPTY;
          bitField0_ = (bitField0_ & ~0x00000001);
          path_ = "";
          bitField0_ = (bitField0_ & ~0x00000002);
          return this;
        }
        
        public Builder clone() {
          return create().mergeFrom(buildPartial());
        }
        
        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDescriptor();
        }
        
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance();
        }
        
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath build() {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }
        
        private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath buildParsed()
            throws com.google.protobuf.InvalidProtocolBufferException {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(
              result).asInvalidProtocolBufferException();
          }
          return result;
        }
        
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath buildPartial() {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
            to_bitField0_ |= 0x00000001;
          }
          result.family_ = family_;
          if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
            to_bitField0_ |= 0x00000002;
          }
          result.path_ = path_;
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }
        
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath) {
            return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }
        
        public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath other) {
          if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance()) return this;
          if (other.hasFamily()) {
            setFamily(other.getFamily());
          }
          if (other.hasPath()) {
            setPath(other.getPath());
          }
          this.mergeUnknownFields(other.getUnknownFields());
          return this;
        }
        
        public final boolean isInitialized() {
          if (!hasFamily()) {
            
            return false;
          }
          if (!hasPath()) {
            
            return false;
          }
          return true;
        }
        
        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder(
              this.getUnknownFields());
          while (true) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              default: {
                if (!parseUnknownField(input, unknownFields,
                                       extensionRegistry, tag)) {
                  this.setUnknownFields(unknownFields.build());
                  onChanged();
                  return this;
                }
                break;
              }
              case 10: {
                bitField0_ |= 0x00000001;
                family_ = input.readBytes();
                break;
              }
              case 18: {
                bitField0_ |= 0x00000002;
                path_ = input.readBytes();
                break;
              }
            }
          }
        }
        
        private int bitField0_;
        
        // required bytes family = 1;
        private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
        public boolean hasFamily() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        public com.google.protobuf.ByteString getFamily() {
          return family_;
        }
        public Builder setFamily(com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          family_ = value;
          onChanged();
          return this;
        }
        public Builder clearFamily() {
          bitField0_ = (bitField0_ & ~0x00000001);
          family_ = getDefaultInstance().getFamily();
          onChanged();
          return this;
        }
        
        // required string path = 2;
        private java.lang.Object path_ = "";
        public boolean hasPath() {
          return ((bitField0_ & 0x00000002) == 0x00000002);
        }
        public String getPath() {
          java.lang.Object ref = path_;
          if (!(ref instanceof String)) {
            String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
            path_ = s;
            return s;
          } else {
            return (String) ref;
          }
        }
        public Builder setPath(String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
          path_ = value;
          onChanged();
          return this;
        }
        public Builder clearPath() {
          bitField0_ = (bitField0_ & ~0x00000002);
          path_ = getDefaultInstance().getPath();
          onChanged();
          return this;
        }
        void setPath(com.google.protobuf.ByteString value) {
          bitField0_ |= 0x00000002;
          path_ = value;
          onChanged();
        }
        
        // @@protoc_insertion_point(builder_scope:BulkLoadHFileRequest.FamilyPath)
      }
      
      static {
        defaultInstance = new FamilyPath(true);
        defaultInstance.initFields();
      }
      
      // @@protoc_insertion_point(class_scope:BulkLoadHFileRequest.FamilyPath)
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // repeated .BulkLoadHFileRequest.FamilyPath familyPath = 2;
    public static final int FAMILYPATH_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> familyPath_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> getFamilyPathList() {
      return familyPath_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
        getFamilyPathOrBuilderList() {
      return familyPath_;
    }
    public int getFamilyPathCount() {
      return familyPath_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index) {
      return familyPath_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
        int index) {
      return familyPath_.get(index);
    }
    
    // optional bool assignSeqNum = 3;
    public static final int ASSIGNSEQNUM_FIELD_NUMBER = 3;
    private boolean assignSeqNum_;
    public boolean hasAssignSeqNum() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public boolean getAssignSeqNum() {
      return assignSeqNum_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      familyPath_ = java.util.Collections.emptyList();
      assignSeqNum_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getFamilyPathCount(); i++) {
        if (!getFamilyPath(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      for (int i = 0; i < familyPath_.size(); i++) {
        output.writeMessage(2, familyPath_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(3, assignSeqNum_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      for (int i = 0; i < familyPath_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, familyPath_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, assignSeqNum_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && getFamilyPathList()
          .equals(other.getFamilyPathList());
      result = result && (hasAssignSeqNum() == other.hasAssignSeqNum());
      if (hasAssignSeqNum()) {
        result = result && (getAssignSeqNum()
            == other.getAssignSeqNum());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (getFamilyPathCount() > 0) {
        hash = (37 * hash) + FAMILYPATH_FIELD_NUMBER;
        hash = (53 * hash) + getFamilyPathList().hashCode();
      }
      if (hasAssignSeqNum()) {
        hash = (37 * hash) + ASSIGNSEQNUM_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getAssignSeqNum());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getFamilyPathFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (familyPathBuilder_ == null) {
          familyPath_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          familyPathBuilder_.clear();
        }
        assignSeqNum_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (familyPathBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            familyPath_ = java.util.Collections.unmodifiableList(familyPath_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.familyPath_ = familyPath_;
        } else {
          result.familyPath_ = familyPathBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.assignSeqNum_ = assignSeqNum_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (familyPathBuilder_ == null) {
          if (!other.familyPath_.isEmpty()) {
            if (familyPath_.isEmpty()) {
              familyPath_ = other.familyPath_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureFamilyPathIsMutable();
              familyPath_.addAll(other.familyPath_);
            }
            onChanged();
          }
        } else {
          if (!other.familyPath_.isEmpty()) {
            if (familyPathBuilder_.isEmpty()) {
              familyPathBuilder_.dispose();
              familyPathBuilder_ = null;
              familyPath_ = other.familyPath_;
              bitField0_ = (bitField0_ & ~0x00000002);
              familyPathBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getFamilyPathFieldBuilder() : null;
            } else {
              familyPathBuilder_.addAllMessages(other.familyPath_);
            }
          }
        }
        if (other.hasAssignSeqNum()) {
          setAssignSeqNum(other.getAssignSeqNum());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        for (int i = 0; i < getFamilyPathCount(); i++) {
          if (!getFamilyPath(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addFamilyPath(subBuilder.buildPartial());
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              assignSeqNum_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // repeated .BulkLoadHFileRequest.FamilyPath familyPath = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> familyPath_ =
        java.util.Collections.emptyList();
      private void ensureFamilyPathIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          familyPath_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath>(familyPath_);
          bitField0_ |= 0x00000002;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> familyPathBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> getFamilyPathList() {
        if (familyPathBuilder_ == null) {
          return java.util.Collections.unmodifiableList(familyPath_);
        } else {
          return familyPathBuilder_.getMessageList();
        }
      }
      public int getFamilyPathCount() {
        if (familyPathBuilder_ == null) {
          return familyPath_.size();
        } else {
          return familyPathBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index) {
        if (familyPathBuilder_ == null) {
          return familyPath_.get(index);
        } else {
          return familyPathBuilder_.getMessage(index);
        }
      }
      public Builder setFamilyPath(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.set(index, value);
          onChanged();
        } else {
          familyPathBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setFamilyPath(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.set(index, builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addFamilyPath(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.add(value);
          onChanged();
        } else {
          familyPathBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addFamilyPath(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.add(index, value);
          onChanged();
        } else {
          familyPathBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addFamilyPath(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.add(builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addFamilyPath(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.add(index, builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllFamilyPath(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> values) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          super.addAll(values, familyPath_);
          onChanged();
        } else {
          familyPathBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearFamilyPath() {
        if (familyPathBuilder_ == null) {
          familyPath_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          familyPathBuilder_.clear();
        }
        return this;
      }
      public Builder removeFamilyPath(int index) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.remove(index);
          onChanged();
        } else {
          familyPathBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder getFamilyPathBuilder(
          int index) {
        return getFamilyPathFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
          int index) {
        if (familyPathBuilder_ == null) {
          return familyPath_.get(index);  } else {
          return familyPathBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
           getFamilyPathOrBuilderList() {
        if (familyPathBuilder_ != null) {
          return familyPathBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(familyPath_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder addFamilyPathBuilder() {
        return getFamilyPathFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder addFamilyPathBuilder(
          int index) {
        return getFamilyPathFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder> 
           getFamilyPathBuilderList() {
        return getFamilyPathFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
          getFamilyPathFieldBuilder() {
        if (familyPathBuilder_ == null) {
          familyPathBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder>(
                  familyPath_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          familyPath_ = null;
        }
        return familyPathBuilder_;
      }
      
      // optional bool assignSeqNum = 3;
      private boolean assignSeqNum_ ;
      public boolean hasAssignSeqNum() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public boolean getAssignSeqNum() {
        return assignSeqNum_;
      }
      public Builder setAssignSeqNum(boolean value) {
        bitField0_ |= 0x00000004;
        assignSeqNum_ = value;
        onChanged();
        return this;
      }
      public Builder clearAssignSeqNum() {
        bitField0_ = (bitField0_ & ~0x00000004);
        assignSeqNum_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:BulkLoadHFileRequest)
    }
    
    static {
      defaultInstance = new BulkLoadHFileRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:BulkLoadHFileRequest)
  }
  
  public interface BulkLoadHFileResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required bool loaded = 1;
    boolean hasLoaded();
    boolean getLoaded();
  }
  public static final class BulkLoadHFileResponse extends
      com.google.protobuf.GeneratedMessage
      implements BulkLoadHFileResponseOrBuilder {
    // Use BulkLoadHFileResponse.newBuilder() to construct.
    private BulkLoadHFileResponse(Builder builder) {
      super(builder);
    }
    private BulkLoadHFileResponse(boolean noInit) {}
    
    private static final BulkLoadHFileResponse defaultInstance;
    public static BulkLoadHFileResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public BulkLoadHFileResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required bool loaded = 1;
    public static final int LOADED_FIELD_NUMBER = 1;
    private boolean loaded_;
    public boolean hasLoaded() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public boolean getLoaded() {
      return loaded_;
    }
    
    private void initFields() {
      loaded_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasLoaded()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, loaded_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, loaded_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse) obj;
      
      boolean result = true;
      result = result && (hasLoaded() == other.hasLoaded());
      if (hasLoaded()) {
        result = result && (getLoaded()
            == other.getLoaded());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasLoaded()) {
        hash = (37 * hash) + LOADED_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getLoaded());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        loaded_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.loaded_ = loaded_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance()) return this;
        if (other.hasLoaded()) {
          setLoaded(other.getLoaded());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasLoaded()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              loaded_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required bool loaded = 1;
      private boolean loaded_ ;
      public boolean hasLoaded() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public boolean getLoaded() {
        return loaded_;
      }
      public Builder setLoaded(boolean value) {
        bitField0_ |= 0x00000001;
        loaded_ = value;
        onChanged();
        return this;
      }
      public Builder clearLoaded() {
        bitField0_ = (bitField0_ & ~0x00000001);
        loaded_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:BulkLoadHFileResponse)
    }
    
    static {
      defaultInstance = new BulkLoadHFileResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:BulkLoadHFileResponse)
  }
  
  public interface ExecOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required bytes row = 1;
    boolean hasRow();
    com.google.protobuf.ByteString getRow();
    
    // required string protocolName = 2;
    boolean hasProtocolName();
    String getProtocolName();
    
    // required string methodName = 3;
    boolean hasMethodName();
    String getMethodName();
    
    // repeated .NameStringPair property = 4;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> 
        getPropertyList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getProperty(int index);
    int getPropertyCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
        getPropertyOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getPropertyOrBuilder(
        int index);
    
    // repeated .NameBytesPair parameter = 5;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> 
        getParameterList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getParameter(int index);
    int getParameterCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getParameterOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getParameterOrBuilder(
        int index);
  }
  public static final class Exec extends
      com.google.protobuf.GeneratedMessage
      implements ExecOrBuilder {
    // Use Exec.newBuilder() to construct.
    private Exec(Builder builder) {
      super(builder);
    }
    private Exec(boolean noInit) {}
    
    private static final Exec defaultInstance;
    public static Exec getDefaultInstance() {
      return defaultInstance;
    }
    
    public Exec getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Exec_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Exec_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }
    
    // required string protocolName = 2;
    public static final int PROTOCOLNAME_FIELD_NUMBER = 2;
    private java.lang.Object protocolName_;
    public boolean hasProtocolName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public String getProtocolName() {
      java.lang.Object ref = protocolName_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          protocolName_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getProtocolNameBytes() {
      java.lang.Object ref = protocolName_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        protocolName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // required string methodName = 3;
    public static final int METHODNAME_FIELD_NUMBER = 3;
    private java.lang.Object methodName_;
    public boolean hasMethodName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public String getMethodName() {
      java.lang.Object ref = methodName_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          methodName_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getMethodNameBytes() {
      java.lang.Object ref = methodName_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        methodName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // repeated .NameStringPair property = 4;
    public static final int PROPERTY_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> property_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> getPropertyList() {
      return property_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
        getPropertyOrBuilderList() {
      return property_;
    }
    public int getPropertyCount() {
      return property_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getProperty(int index) {
      return property_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getPropertyOrBuilder(
        int index) {
      return property_.get(index);
    }
    
    // repeated .NameBytesPair parameter = 5;
    public static final int PARAMETER_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> parameter_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getParameterList() {
      return parameter_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getParameterOrBuilderList() {
      return parameter_;
    }
    public int getParameterCount() {
      return parameter_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getParameter(int index) {
      return parameter_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getParameterOrBuilder(
        int index) {
      return parameter_.get(index);
    }
    
    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      protocolName_ = "";
      methodName_ = "";
      property_ = java.util.Collections.emptyList();
      parameter_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasProtocolName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMethodName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getPropertyCount(); i++) {
        if (!getProperty(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getParameterCount(); i++) {
        if (!getParameter(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getProtocolNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getMethodNameBytes());
      }
      for (int i = 0; i < property_.size(); i++) {
        output.writeMessage(4, property_.get(i));
      }
      for (int i = 0; i < parameter_.size(); i++) {
        output.writeMessage(5, parameter_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getProtocolNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getMethodNameBytes());
      }
      for (int i = 0; i < property_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, property_.get(i));
      }
      for (int i = 0; i < parameter_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, parameter_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec) obj;
      
      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasProtocolName() == other.hasProtocolName());
      if (hasProtocolName()) {
        result = result && getProtocolName()
            .equals(other.getProtocolName());
      }
      result = result && (hasMethodName() == other.hasMethodName());
      if (hasMethodName()) {
        result = result && getMethodName()
            .equals(other.getMethodName());
      }
      result = result && getPropertyList()
          .equals(other.getPropertyList());
      result = result && getParameterList()
          .equals(other.getParameterList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasProtocolName()) {
        hash = (37 * hash) + PROTOCOLNAME_FIELD_NUMBER;
        hash = (53 * hash) + getProtocolName().hashCode();
      }
      if (hasMethodName()) {
        hash = (37 * hash) + METHODNAME_FIELD_NUMBER;
        hash = (53 * hash) + getMethodName().hashCode();
      }
      if (getPropertyCount() > 0) {
        hash = (37 * hash) + PROPERTY_FIELD_NUMBER;
        hash = (53 * hash) + getPropertyList().hashCode();
      }
      if (getParameterCount() > 0) {
        hash = (37 * hash) + PARAMETER_FIELD_NUMBER;
        hash = (53 * hash) + getParameterList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Exec_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Exec_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getPropertyFieldBuilder();
          getParameterFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        protocolName_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        methodName_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (propertyBuilder_ == null) {
          property_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          propertyBuilder_.clear();
        }
        if (parameterBuilder_ == null) {
          parameter_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          parameterBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.protocolName_ = protocolName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.methodName_ = methodName_;
        if (propertyBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            property_ = java.util.Collections.unmodifiableList(property_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.property_ = property_;
        } else {
          result.property_ = propertyBuilder_.build();
        }
        if (parameterBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            parameter_ = java.util.Collections.unmodifiableList(parameter_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.parameter_ = parameter_;
        } else {
          result.parameter_ = parameterBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasProtocolName()) {
          setProtocolName(other.getProtocolName());
        }
        if (other.hasMethodName()) {
          setMethodName(other.getMethodName());
        }
        if (propertyBuilder_ == null) {
          if (!other.property_.isEmpty()) {
            if (property_.isEmpty()) {
              property_ = other.property_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensurePropertyIsMutable();
              property_.addAll(other.property_);
            }
            onChanged();
          }
        } else {
          if (!other.property_.isEmpty()) {
            if (propertyBuilder_.isEmpty()) {
              propertyBuilder_.dispose();
              propertyBuilder_ = null;
              property_ = other.property_;
              bitField0_ = (bitField0_ & ~0x00000008);
              propertyBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getPropertyFieldBuilder() : null;
            } else {
              propertyBuilder_.addAllMessages(other.property_);
            }
          }
        }
        if (parameterBuilder_ == null) {
          if (!other.parameter_.isEmpty()) {
            if (parameter_.isEmpty()) {
              parameter_ = other.parameter_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureParameterIsMutable();
              parameter_.addAll(other.parameter_);
            }
            onChanged();
          }
        } else {
          if (!other.parameter_.isEmpty()) {
            if (parameterBuilder_.isEmpty()) {
              parameterBuilder_.dispose();
              parameterBuilder_ = null;
              parameter_ = other.parameter_;
              bitField0_ = (bitField0_ & ~0x00000010);
              parameterBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getParameterFieldBuilder() : null;
            } else {
              parameterBuilder_.addAllMessages(other.parameter_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        if (!hasProtocolName()) {
          
          return false;
        }
        if (!hasMethodName()) {
          
          return false;
        }
        for (int i = 0; i < getPropertyCount(); i++) {
          if (!getProperty(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getParameterCount(); i++) {
          if (!getParameter(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              protocolName_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              methodName_ = input.readBytes();
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addProperty(subBuilder.buildPartial());
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addParameter(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }
      
      // required string protocolName = 2;
      private java.lang.Object protocolName_ = "";
      public boolean hasProtocolName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public String getProtocolName() {
        java.lang.Object ref = protocolName_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          protocolName_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setProtocolName(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        protocolName_ = value;
        onChanged();
        return this;
      }
      public Builder clearProtocolName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        protocolName_ = getDefaultInstance().getProtocolName();
        onChanged();
        return this;
      }
      void setProtocolName(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000002;
        protocolName_ = value;
        onChanged();
      }
      
      // required string methodName = 3;
      private java.lang.Object methodName_ = "";
      public boolean hasMethodName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public String getMethodName() {
        java.lang.Object ref = methodName_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          methodName_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setMethodName(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        methodName_ = value;
        onChanged();
        return this;
      }
      public Builder clearMethodName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        methodName_ = getDefaultInstance().getMethodName();
        onChanged();
        return this;
      }
      void setMethodName(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000004;
        methodName_ = value;
        onChanged();
      }
      
      // repeated .NameStringPair property = 4;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> property_ =
        java.util.Collections.emptyList();
      private void ensurePropertyIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          property_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair>(property_);
          bitField0_ |= 0x00000008;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> propertyBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> getPropertyList() {
        if (propertyBuilder_ == null) {
          return java.util.Collections.unmodifiableList(property_);
        } else {
          return propertyBuilder_.getMessageList();
        }
      }
      public int getPropertyCount() {
        if (propertyBuilder_ == null) {
          return property_.size();
        } else {
          return propertyBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair getProperty(int index) {
        if (propertyBuilder_ == null) {
          return property_.get(index);
        } else {
          return propertyBuilder_.getMessage(index);
        }
      }
      public Builder setProperty(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (propertyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePropertyIsMutable();
          property_.set(index, value);
          onChanged();
        } else {
          propertyBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setProperty(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (propertyBuilder_ == null) {
          ensurePropertyIsMutable();
          property_.set(index, builderForValue.build());
          onChanged();
        } else {
          propertyBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addProperty(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (propertyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePropertyIsMutable();
          property_.add(value);
          onChanged();
        } else {
          propertyBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addProperty(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair value) {
        if (propertyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensurePropertyIsMutable();
          property_.add(index, value);
          onChanged();
        } else {
          propertyBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addProperty(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (propertyBuilder_ == null) {
          ensurePropertyIsMutable();
          property_.add(builderForValue.build());
          onChanged();
        } else {
          propertyBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addProperty(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder builderForValue) {
        if (propertyBuilder_ == null) {
          ensurePropertyIsMutable();
          property_.add(index, builderForValue.build());
          onChanged();
        } else {
          propertyBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllProperty(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair> values) {
        if (propertyBuilder_ == null) {
          ensurePropertyIsMutable();
          super.addAll(values, property_);
          onChanged();
        } else {
          propertyBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearProperty() {
        if (propertyBuilder_ == null) {
          property_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          propertyBuilder_.clear();
        }
        return this;
      }
      public Builder removeProperty(int index) {
        if (propertyBuilder_ == null) {
          ensurePropertyIsMutable();
          property_.remove(index);
          onChanged();
        } else {
          propertyBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder getPropertyBuilder(
          int index) {
        return getPropertyFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder getPropertyOrBuilder(
          int index) {
        if (propertyBuilder_ == null) {
          return property_.get(index);  } else {
          return propertyBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
           getPropertyOrBuilderList() {
        if (propertyBuilder_ != null) {
          return propertyBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(property_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder addPropertyBuilder() {
        return getPropertyFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder addPropertyBuilder(
          int index) {
        return getPropertyFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder> 
           getPropertyBuilderList() {
        return getPropertyFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder> 
          getPropertyFieldBuilder() {
        if (propertyBuilder_ == null) {
          propertyBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameStringPairOrBuilder>(
                  property_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          property_ = null;
        }
        return propertyBuilder_;
      }
      
      // repeated .NameBytesPair parameter = 5;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> parameter_ =
        java.util.Collections.emptyList();
      private void ensureParameterIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          parameter_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>(parameter_);
          bitField0_ |= 0x00000010;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> parameterBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getParameterList() {
        if (parameterBuilder_ == null) {
          return java.util.Collections.unmodifiableList(parameter_);
        } else {
          return parameterBuilder_.getMessageList();
        }
      }
      public int getParameterCount() {
        if (parameterBuilder_ == null) {
          return parameter_.size();
        } else {
          return parameterBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getParameter(int index) {
        if (parameterBuilder_ == null) {
          return parameter_.get(index);
        } else {
          return parameterBuilder_.getMessage(index);
        }
      }
      public Builder setParameter(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (parameterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParameterIsMutable();
          parameter_.set(index, value);
          onChanged();
        } else {
          parameterBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setParameter(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (parameterBuilder_ == null) {
          ensureParameterIsMutable();
          parameter_.set(index, builderForValue.build());
          onChanged();
        } else {
          parameterBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addParameter(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (parameterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParameterIsMutable();
          parameter_.add(value);
          onChanged();
        } else {
          parameterBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addParameter(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (parameterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureParameterIsMutable();
          parameter_.add(index, value);
          onChanged();
        } else {
          parameterBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addParameter(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (parameterBuilder_ == null) {
          ensureParameterIsMutable();
          parameter_.add(builderForValue.build());
          onChanged();
        } else {
          parameterBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addParameter(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (parameterBuilder_ == null) {
          ensureParameterIsMutable();
          parameter_.add(index, builderForValue.build());
          onChanged();
        } else {
          parameterBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllParameter(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (parameterBuilder_ == null) {
          ensureParameterIsMutable();
          super.addAll(values, parameter_);
          onChanged();
        } else {
          parameterBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearParameter() {
        if (parameterBuilder_ == null) {
          parameter_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          parameterBuilder_.clear();
        }
        return this;
      }
      public Builder removeParameter(int index) {
        if (parameterBuilder_ == null) {
          ensureParameterIsMutable();
          parameter_.remove(index);
          onChanged();
        } else {
          parameterBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getParameterBuilder(
          int index) {
        return getParameterFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getParameterOrBuilder(
          int index) {
        if (parameterBuilder_ == null) {
          return parameter_.get(index);  } else {
          return parameterBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getParameterOrBuilderList() {
        if (parameterBuilder_ != null) {
          return parameterBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(parameter_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addParameterBuilder() {
        return getParameterFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addParameterBuilder(
          int index) {
        return getParameterFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getParameterBuilderList() {
        return getParameterFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getParameterFieldBuilder() {
        if (parameterBuilder_ == null) {
          parameterBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  parameter_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          parameter_ = null;
        }
        return parameterBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:Exec)
    }
    
    static {
      defaultInstance = new Exec(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:Exec)
  }
  
  public interface ExecCoprocessorRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // required .Exec call = 2;
    boolean hasCall();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec getCall();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder getCallOrBuilder();
  }
  public static final class ExecCoprocessorRequest extends
      com.google.protobuf.GeneratedMessage
      implements ExecCoprocessorRequestOrBuilder {
    // Use ExecCoprocessorRequest.newBuilder() to construct.
    private ExecCoprocessorRequest(Builder builder) {
      super(builder);
    }
    private ExecCoprocessorRequest(boolean noInit) {}
    
    private static final ExecCoprocessorRequest defaultInstance;
    public static ExecCoprocessorRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public ExecCoprocessorRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ExecCoprocessorRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ExecCoprocessorRequest_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // required .Exec call = 2;
    public static final int CALL_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec call_;
    public boolean hasCall() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec getCall() {
      return call_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder getCallOrBuilder() {
      return call_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCall()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCall().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, call_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, call_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasCall() == other.hasCall());
      if (hasCall()) {
        result = result && getCall()
            .equals(other.getCall());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasCall()) {
        hash = (37 * hash) + CALL_FIELD_NUMBER;
        hash = (53 * hash) + getCall().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ExecCoprocessorRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ExecCoprocessorRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getCallFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (callBuilder_ == null) {
          call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
        } else {
          callBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (callBuilder_ == null) {
          result.call_ = call_;
        } else {
          result.call_ = callBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasCall()) {
          mergeCall(other.getCall());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasCall()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getCall().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.newBuilder();
              if (hasCall()) {
                subBuilder.mergeFrom(getCall());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setCall(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // required .Exec call = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder> callBuilder_;
      public boolean hasCall() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec getCall() {
        if (callBuilder_ == null) {
          return call_;
        } else {
          return callBuilder_.getMessage();
        }
      }
      public Builder setCall(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec value) {
        if (callBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          call_ = value;
          onChanged();
        } else {
          callBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setCall(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder builderForValue) {
        if (callBuilder_ == null) {
          call_ = builderForValue.build();
          onChanged();
        } else {
          callBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeCall(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec value) {
        if (callBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              call_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance()) {
            call_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.newBuilder(call_).mergeFrom(value).buildPartial();
          } else {
            call_ = value;
          }
          onChanged();
        } else {
          callBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearCall() {
        if (callBuilder_ == null) {
          call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
          onChanged();
        } else {
          callBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder getCallBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCallFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder getCallOrBuilder() {
        if (callBuilder_ != null) {
          return callBuilder_.getMessageOrBuilder();
        } else {
          return call_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder> 
          getCallFieldBuilder() {
        if (callBuilder_ == null) {
          callBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder>(
                  call_,
                  getParentForChildren(),
                  isClean());
          call_ = null;
        }
        return callBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:ExecCoprocessorRequest)
    }
    
    static {
      defaultInstance = new ExecCoprocessorRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:ExecCoprocessorRequest)
  }
  
  public interface ExecCoprocessorResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .NameBytesPair value = 1;
    boolean hasValue();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder();
  }
  public static final class ExecCoprocessorResponse extends
      com.google.protobuf.GeneratedMessage
      implements ExecCoprocessorResponseOrBuilder {
    // Use ExecCoprocessorResponse.newBuilder() to construct.
    private ExecCoprocessorResponse(Builder builder) {
      super(builder);
    }
    private ExecCoprocessorResponse(boolean noInit) {}
    
    private static final ExecCoprocessorResponse defaultInstance;
    public static ExecCoprocessorResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public ExecCoprocessorResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ExecCoprocessorResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ExecCoprocessorResponse_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .NameBytesPair value = 1;
    public static final int VALUE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value_;
    public boolean hasValue() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
      return value_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
      return value_;
    }
    
    private void initFields() {
      value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getValue().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, value_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse) obj;
      
      boolean result = true;
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ExecCoprocessorResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ExecCoprocessorResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getValueFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.getDefaultInstance()) return this;
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasValue()) {
          
          return false;
        }
        if (!getValue().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder();
              if (hasValue()) {
                subBuilder.mergeFrom(getValue());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setValue(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .NameBytesPair value = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> valueBuilder_;
      public boolean hasValue() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
        if (valueBuilder_ == null) {
          return value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      public Builder setValue(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setValue(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeValue(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              value_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getValueBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  value_,
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:ExecCoprocessorResponse)
    }
    
    static {
      defaultInstance = new ExecCoprocessorResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:ExecCoprocessorResponse)
  }
  
  public interface CoprocessorServiceCallOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required bytes row = 1;
    boolean hasRow();
    com.google.protobuf.ByteString getRow();
    
    // required string serviceName = 2;
    boolean hasServiceName();
    String getServiceName();
    
    // required string methodName = 3;
    boolean hasMethodName();
    String getMethodName();
    
    // required bytes request = 4;
    boolean hasRequest();
    com.google.protobuf.ByteString getRequest();
  }
  public static final class CoprocessorServiceCall extends
      com.google.protobuf.GeneratedMessage
      implements CoprocessorServiceCallOrBuilder {
    // Use CoprocessorServiceCall.newBuilder() to construct.
    private CoprocessorServiceCall(Builder builder) {
      super(builder);
    }
    private CoprocessorServiceCall(boolean noInit) {}
    
    private static final CoprocessorServiceCall defaultInstance;
    public static CoprocessorServiceCall getDefaultInstance() {
      return defaultInstance;
    }
    
    public CoprocessorServiceCall getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }
    
    // required string serviceName = 2;
    public static final int SERVICENAME_FIELD_NUMBER = 2;
    private java.lang.Object serviceName_;
    public boolean hasServiceName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public String getServiceName() {
      java.lang.Object ref = serviceName_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          serviceName_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getServiceNameBytes() {
      java.lang.Object ref = serviceName_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        serviceName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // required string methodName = 3;
    public static final int METHODNAME_FIELD_NUMBER = 3;
    private java.lang.Object methodName_;
    public boolean hasMethodName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public String getMethodName() {
      java.lang.Object ref = methodName_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        if (com.google.protobuf.Internal.isValidUtf8(bs)) {
          methodName_ = s;
        }
        return s;
      }
    }
    private com.google.protobuf.ByteString getMethodNameBytes() {
      java.lang.Object ref = methodName_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8((String) ref);
        methodName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    
    // required bytes request = 4;
    public static final int REQUEST_FIELD_NUMBER = 4;
    private com.google.protobuf.ByteString request_;
    public boolean hasRequest() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    public com.google.protobuf.ByteString getRequest() {
      return request_;
    }
    
    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      serviceName_ = "";
      methodName_ = "";
      request_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasServiceName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMethodName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRequest()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getServiceNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getMethodNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, request_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getServiceNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getMethodNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, request_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall) obj;
      
      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasServiceName() == other.hasServiceName());
      if (hasServiceName()) {
        result = result && getServiceName()
            .equals(other.getServiceName());
      }
      result = result && (hasMethodName() == other.hasMethodName());
      if (hasMethodName()) {
        result = result && getMethodName()
            .equals(other.getMethodName());
      }
      result = result && (hasRequest() == other.hasRequest());
      if (hasRequest()) {
        result = result && getRequest()
            .equals(other.getRequest());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasServiceName()) {
        hash = (37 * hash) + SERVICENAME_FIELD_NUMBER;
        hash = (53 * hash) + getServiceName().hashCode();
      }
      if (hasMethodName()) {
        hash = (37 * hash) + METHODNAME_FIELD_NUMBER;
        hash = (53 * hash) + getMethodName().hashCode();
      }
      if (hasRequest()) {
        hash = (37 * hash) + REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getRequest().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        serviceName_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        methodName_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        request_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.serviceName_ = serviceName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.methodName_ = methodName_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.request_ = request_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasServiceName()) {
          setServiceName(other.getServiceName());
        }
        if (other.hasMethodName()) {
          setMethodName(other.getMethodName());
        }
        if (other.hasRequest()) {
          setRequest(other.getRequest());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        if (!hasServiceName()) {
          
          return false;
        }
        if (!hasMethodName()) {
          
          return false;
        }
        if (!hasRequest()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              serviceName_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              methodName_ = input.readBytes();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              request_ = input.readBytes();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }
      
      // required string serviceName = 2;
      private java.lang.Object serviceName_ = "";
      public boolean hasServiceName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public String getServiceName() {
        java.lang.Object ref = serviceName_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          serviceName_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setServiceName(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        serviceName_ = value;
        onChanged();
        return this;
      }
      public Builder clearServiceName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        serviceName_ = getDefaultInstance().getServiceName();
        onChanged();
        return this;
      }
      void setServiceName(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000002;
        serviceName_ = value;
        onChanged();
      }
      
      // required string methodName = 3;
      private java.lang.Object methodName_ = "";
      public boolean hasMethodName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public String getMethodName() {
        java.lang.Object ref = methodName_;
        if (!(ref instanceof String)) {
          String s = ((com.google.protobuf.ByteString) ref).toStringUtf8();
          methodName_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      public Builder setMethodName(String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        methodName_ = value;
        onChanged();
        return this;
      }
      public Builder clearMethodName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        methodName_ = getDefaultInstance().getMethodName();
        onChanged();
        return this;
      }
      void setMethodName(com.google.protobuf.ByteString value) {
        bitField0_ |= 0x00000004;
        methodName_ = value;
        onChanged();
      }
      
      // required bytes request = 4;
      private com.google.protobuf.ByteString request_ = com.google.protobuf.ByteString.EMPTY;
      public boolean hasRequest() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      public com.google.protobuf.ByteString getRequest() {
        return request_;
      }
      public Builder setRequest(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        request_ = value;
        onChanged();
        return this;
      }
      public Builder clearRequest() {
        bitField0_ = (bitField0_ & ~0x00000008);
        request_ = getDefaultInstance().getRequest();
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:CoprocessorServiceCall)
    }
    
    static {
      defaultInstance = new CoprocessorServiceCall(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:CoprocessorServiceCall)
  }
  
  public interface CoprocessorServiceRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // required .CoprocessorServiceCall call = 2;
    boolean hasCall();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder();
  }
  public static final class CoprocessorServiceRequest extends
      com.google.protobuf.GeneratedMessage
      implements CoprocessorServiceRequestOrBuilder {
    // Use CoprocessorServiceRequest.newBuilder() to construct.
    private CoprocessorServiceRequest(Builder builder) {
      super(builder);
    }
    private CoprocessorServiceRequest(boolean noInit) {}
    
    private static final CoprocessorServiceRequest defaultInstance;
    public static CoprocessorServiceRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public CoprocessorServiceRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // required .CoprocessorServiceCall call = 2;
    public static final int CALL_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall call_;
    public boolean hasCall() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall() {
      return call_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder() {
      return call_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCall()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCall().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, call_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, call_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasCall() == other.hasCall());
      if (hasCall()) {
        result = result && getCall()
            .equals(other.getCall());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasCall()) {
        hash = (37 * hash) + CALL_FIELD_NUMBER;
        hash = (53 * hash) + getCall().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getCallFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (callBuilder_ == null) {
          call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
        } else {
          callBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (callBuilder_ == null) {
          result.call_ = call_;
        } else {
          result.call_ = callBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasCall()) {
          mergeCall(other.getCall());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasCall()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getCall().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.newBuilder();
              if (hasCall()) {
                subBuilder.mergeFrom(getCall());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setCall(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // required .CoprocessorServiceCall call = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder> callBuilder_;
      public boolean hasCall() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall() {
        if (callBuilder_ == null) {
          return call_;
        } else {
          return callBuilder_.getMessage();
        }
      }
      public Builder setCall(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall value) {
        if (callBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          call_ = value;
          onChanged();
        } else {
          callBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setCall(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder builderForValue) {
        if (callBuilder_ == null) {
          call_ = builderForValue.build();
          onChanged();
        } else {
          callBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeCall(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall value) {
        if (callBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              call_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance()) {
            call_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.newBuilder(call_).mergeFrom(value).buildPartial();
          } else {
            call_ = value;
          }
          onChanged();
        } else {
          callBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearCall() {
        if (callBuilder_ == null) {
          call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
          onChanged();
        } else {
          callBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder getCallBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCallFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder() {
        if (callBuilder_ != null) {
          return callBuilder_.getMessageOrBuilder();
        } else {
          return call_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder> 
          getCallFieldBuilder() {
        if (callBuilder_ == null) {
          callBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder>(
                  call_,
                  getParentForChildren(),
                  isClean());
          call_ = null;
        }
        return callBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:CoprocessorServiceRequest)
    }
    
    static {
      defaultInstance = new CoprocessorServiceRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:CoprocessorServiceRequest)
  }
  
  public interface CoprocessorServiceResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // required .NameBytesPair value = 2;
    boolean hasValue();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder();
  }
  public static final class CoprocessorServiceResponse extends
      com.google.protobuf.GeneratedMessage
      implements CoprocessorServiceResponseOrBuilder {
    // Use CoprocessorServiceResponse.newBuilder() to construct.
    private CoprocessorServiceResponse(Builder builder) {
      super(builder);
    }
    private CoprocessorServiceResponse(boolean noInit) {}
    
    private static final CoprocessorServiceResponse defaultInstance;
    public static CoprocessorServiceResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public CoprocessorServiceResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // required .NameBytesPair value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value_;
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
      return value_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
      return value_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getValue().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, value_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getValueFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasValue()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getValue().isInitialized()) {
          
          return false;
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder();
              if (hasValue()) {
                subBuilder.mergeFrom(getValue());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setValue(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // required .NameBytesPair value = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> valueBuilder_;
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
        if (valueBuilder_ == null) {
          return value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      public Builder setValue(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setValue(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeValue(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              value_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getValueBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  value_,
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:CoprocessorServiceResponse)
    }
    
    static {
      defaultInstance = new CoprocessorServiceResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:CoprocessorServiceResponse)
  }
  
  public interface MultiActionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .Mutate mutate = 1;
    boolean hasMutate();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate getMutate();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder getMutateOrBuilder();
    
    // optional .Get get = 2;
    boolean hasGet();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder();
    
    // optional .Exec exec = 3;
    boolean hasExec();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec getExec();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder getExecOrBuilder();
  }
  public static final class MultiAction extends
      com.google.protobuf.GeneratedMessage
      implements MultiActionOrBuilder {
    // Use MultiAction.newBuilder() to construct.
    private MultiAction(Builder builder) {
      super(builder);
    }
    private MultiAction(boolean noInit) {}
    
    private static final MultiAction defaultInstance;
    public static MultiAction getDefaultInstance() {
      return defaultInstance;
    }
    
    public MultiAction getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .Mutate mutate = 1;
    public static final int MUTATE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate mutate_;
    public boolean hasMutate() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate getMutate() {
      return mutate_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder getMutateOrBuilder() {
      return mutate_;
    }
    
    // optional .Get get = 2;
    public static final int GET_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get get_;
    public boolean hasGet() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet() {
      return get_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
      return get_;
    }
    
    // optional .Exec exec = 3;
    public static final int EXEC_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec exec_;
    public boolean hasExec() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec getExec() {
      return exec_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder getExecOrBuilder() {
      return exec_;
    }
    
    private void initFields() {
      mutate_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
      get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      exec_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (hasMutate()) {
        if (!getMutate().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasGet()) {
        if (!getGet().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasExec()) {
        if (!getExec().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, mutate_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, get_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, exec_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, mutate_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, get_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, exec_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction) obj;
      
      boolean result = true;
      result = result && (hasMutate() == other.hasMutate());
      if (hasMutate()) {
        result = result && getMutate()
            .equals(other.getMutate());
      }
      result = result && (hasGet() == other.hasGet());
      if (hasGet()) {
        result = result && getGet()
            .equals(other.getGet());
      }
      result = result && (hasExec() == other.hasExec());
      if (hasExec()) {
        result = result && getExec()
            .equals(other.getExec());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMutate()) {
        hash = (37 * hash) + MUTATE_FIELD_NUMBER;
        hash = (53 * hash) + getMutate().hashCode();
      }
      if (hasGet()) {
        hash = (37 * hash) + GET_FIELD_NUMBER;
        hash = (53 * hash) + getGet().hashCode();
      }
      if (hasExec()) {
        hash = (37 * hash) + EXEC_FIELD_NUMBER;
        hash = (53 * hash) + getExec().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getMutateFieldBuilder();
          getGetFieldBuilder();
          getExecFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (mutateBuilder_ == null) {
          mutate_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
        } else {
          mutateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (getBuilder_ == null) {
          get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
        } else {
          getBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (execBuilder_ == null) {
          exec_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
        } else {
          execBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (mutateBuilder_ == null) {
          result.mutate_ = mutate_;
        } else {
          result.mutate_ = mutateBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (getBuilder_ == null) {
          result.get_ = get_;
        } else {
          result.get_ = getBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (execBuilder_ == null) {
          result.exec_ = exec_;
        } else {
          result.exec_ = execBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDefaultInstance()) return this;
        if (other.hasMutate()) {
          mergeMutate(other.getMutate());
        }
        if (other.hasGet()) {
          mergeGet(other.getGet());
        }
        if (other.hasExec()) {
          mergeExec(other.getExec());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (hasMutate()) {
          if (!getMutate().isInitialized()) {
            
            return false;
          }
        }
        if (hasGet()) {
          if (!getGet().isInitialized()) {
            
            return false;
          }
        }
        if (hasExec()) {
          if (!getExec().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.newBuilder();
              if (hasMutate()) {
                subBuilder.mergeFrom(getMutate());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setMutate(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.newBuilder();
              if (hasGet()) {
                subBuilder.mergeFrom(getGet());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setGet(subBuilder.buildPartial());
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.newBuilder();
              if (hasExec()) {
                subBuilder.mergeFrom(getExec());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setExec(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .Mutate mutate = 1;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate mutate_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder> mutateBuilder_;
      public boolean hasMutate() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate getMutate() {
        if (mutateBuilder_ == null) {
          return mutate_;
        } else {
          return mutateBuilder_.getMessage();
        }
      }
      public Builder setMutate(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate value) {
        if (mutateBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mutate_ = value;
          onChanged();
        } else {
          mutateBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setMutate(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder builderForValue) {
        if (mutateBuilder_ == null) {
          mutate_ = builderForValue.build();
          onChanged();
        } else {
          mutateBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeMutate(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate value) {
        if (mutateBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              mutate_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance()) {
            mutate_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.newBuilder(mutate_).mergeFrom(value).buildPartial();
          } else {
            mutate_ = value;
          }
          onChanged();
        } else {
          mutateBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearMutate() {
        if (mutateBuilder_ == null) {
          mutate_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.getDefaultInstance();
          onChanged();
        } else {
          mutateBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder getMutateBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getMutateFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder getMutateOrBuilder() {
        if (mutateBuilder_ != null) {
          return mutateBuilder_.getMessageOrBuilder();
        } else {
          return mutate_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder> 
          getMutateFieldBuilder() {
        if (mutateBuilder_ == null) {
          mutateBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateOrBuilder>(
                  mutate_,
                  getParentForChildren(),
                  isClean());
          mutate_ = null;
        }
        return mutateBuilder_;
      }
      
      // optional .Get get = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> getBuilder_;
      public boolean hasGet() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet() {
        if (getBuilder_ == null) {
          return get_;
        } else {
          return getBuilder_.getMessage();
        }
      }
      public Builder setGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          get_ = value;
          onChanged();
        } else {
          getBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setGet(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          get_ = builderForValue.build();
          onChanged();
        } else {
          getBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              get_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance()) {
            get_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.newBuilder(get_).mergeFrom(value).buildPartial();
          } else {
            get_ = value;
          }
          onChanged();
        } else {
          getBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearGet() {
        if (getBuilder_ == null) {
          get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
          onChanged();
        } else {
          getBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder getGetBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getGetFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
        if (getBuilder_ != null) {
          return getBuilder_.getMessageOrBuilder();
        } else {
          return get_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> 
          getGetFieldBuilder() {
        if (getBuilder_ == null) {
          getBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder>(
                  get_,
                  getParentForChildren(),
                  isClean());
          get_ = null;
        }
        return getBuilder_;
      }
      
      // optional .Exec exec = 3;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec exec_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder> execBuilder_;
      public boolean hasExec() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec getExec() {
        if (execBuilder_ == null) {
          return exec_;
        } else {
          return execBuilder_.getMessage();
        }
      }
      public Builder setExec(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec value) {
        if (execBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exec_ = value;
          onChanged();
        } else {
          execBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder setExec(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder builderForValue) {
        if (execBuilder_ == null) {
          exec_ = builderForValue.build();
          onChanged();
        } else {
          execBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder mergeExec(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec value) {
        if (execBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              exec_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance()) {
            exec_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.newBuilder(exec_).mergeFrom(value).buildPartial();
          } else {
            exec_ = value;
          }
          onChanged();
        } else {
          execBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      public Builder clearExec() {
        if (execBuilder_ == null) {
          exec_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.getDefaultInstance();
          onChanged();
        } else {
          execBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder getExecBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getExecFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder getExecOrBuilder() {
        if (execBuilder_ != null) {
          return execBuilder_.getMessageOrBuilder();
        } else {
          return exec_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder> 
          getExecFieldBuilder() {
        if (execBuilder_ == null) {
          execBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecOrBuilder>(
                  exec_,
                  getParentForChildren(),
                  isClean());
          exec_ = null;
        }
        return execBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:MultiAction)
    }
    
    static {
      defaultInstance = new MultiAction(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:MultiAction)
  }
  
  public interface ActionResultOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // optional .NameBytesPair value = 1;
    boolean hasValue();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder();
    
    // optional .NameBytesPair exception = 2;
    boolean hasException();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getException();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder();
  }
  public static final class ActionResult extends
      com.google.protobuf.GeneratedMessage
      implements ActionResultOrBuilder {
    // Use ActionResult.newBuilder() to construct.
    private ActionResult(Builder builder) {
      super(builder);
    }
    private ActionResult(boolean noInit) {}
    
    private static final ActionResult defaultInstance;
    public static ActionResult getDefaultInstance() {
      return defaultInstance;
    }
    
    public ActionResult getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_fieldAccessorTable;
    }
    
    private int bitField0_;
    // optional .NameBytesPair value = 1;
    public static final int VALUE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value_;
    public boolean hasValue() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
      return value_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
      return value_;
    }
    
    // optional .NameBytesPair exception = 2;
    public static final int EXCEPTION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair exception_;
    public boolean hasException() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getException() {
      return exception_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder() {
      return exception_;
    }
    
    private void initFields() {
      value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
      exception_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (hasValue()) {
        if (!getValue().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasException()) {
        if (!getException().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, value_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, exception_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, value_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, exception_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult) obj;
      
      boolean result = true;
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result && (hasException() == other.hasException());
      if (hasException()) {
        result = result && getException()
            .equals(other.getException());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      if (hasException()) {
        hash = (37 * hash) + EXCEPTION_FIELD_NUMBER;
        hash = (53 * hash) + getException().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getValueFieldBuilder();
          getExceptionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (exceptionBuilder_ == null) {
          exception_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
        } else {
          exceptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (exceptionBuilder_ == null) {
          result.exception_ = exception_;
        } else {
          result.exception_ = exceptionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDefaultInstance()) return this;
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        if (other.hasException()) {
          mergeException(other.getException());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (hasValue()) {
          if (!getValue().isInitialized()) {
            
            return false;
          }
        }
        if (hasException()) {
          if (!getException().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder();
              if (hasValue()) {
                subBuilder.mergeFrom(getValue());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setValue(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder();
              if (hasException()) {
                subBuilder.mergeFrom(getException());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setException(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // optional .NameBytesPair value = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> valueBuilder_;
      public boolean hasValue() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
        if (valueBuilder_ == null) {
          return value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      public Builder setValue(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setValue(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeValue(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              value_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getValueBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  value_,
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }
      
      // optional .NameBytesPair exception = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair exception_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> exceptionBuilder_;
      public boolean hasException() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getException() {
        if (exceptionBuilder_ == null) {
          return exception_;
        } else {
          return exceptionBuilder_.getMessage();
        }
      }
      public Builder setException(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (exceptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exception_ = value;
          onChanged();
        } else {
          exceptionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder setException(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (exceptionBuilder_ == null) {
          exception_ = builderForValue.build();
          onChanged();
        } else {
          exceptionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder mergeException(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (exceptionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              exception_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            exception_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder(exception_).mergeFrom(value).buildPartial();
          } else {
            exception_ = value;
          }
          onChanged();
        } else {
          exceptionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      public Builder clearException() {
        if (exceptionBuilder_ == null) {
          exception_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
          onChanged();
        } else {
          exceptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getExceptionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getExceptionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder() {
        if (exceptionBuilder_ != null) {
          return exceptionBuilder_.getMessageOrBuilder();
        } else {
          return exception_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getExceptionFieldBuilder() {
        if (exceptionBuilder_ == null) {
          exceptionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  exception_,
                  getParentForChildren(),
                  isClean());
          exception_ = null;
        }
        return exceptionBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:ActionResult)
    }
    
    static {
      defaultInstance = new ActionResult(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:ActionResult)
  }
  
  public interface MultiRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // required .RegionSpecifier region = 1;
    boolean hasRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();
    
    // repeated .MultiAction action = 2;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> 
        getActionList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction getAction(int index);
    int getActionCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> 
        getActionOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder getActionOrBuilder(
        int index);
    
    // optional bool atomic = 3;
    boolean hasAtomic();
    boolean getAtomic();
  }
  public static final class MultiRequest extends
      com.google.protobuf.GeneratedMessage
      implements MultiRequestOrBuilder {
    // Use MultiRequest.newBuilder() to construct.
    private MultiRequest(Builder builder) {
      super(builder);
    }
    private MultiRequest(boolean noInit) {}
    
    private static final MultiRequest defaultInstance;
    public static MultiRequest getDefaultInstance() {
      return defaultInstance;
    }
    
    public MultiRequest getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_fieldAccessorTable;
    }
    
    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }
    
    // repeated .MultiAction action = 2;
    public static final int ACTION_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> action_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> getActionList() {
      return action_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> 
        getActionOrBuilderList() {
      return action_;
    }
    public int getActionCount() {
      return action_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction getAction(int index) {
      return action_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder getActionOrBuilder(
        int index) {
      return action_.get(index);
    }
    
    // optional bool atomic = 3;
    public static final int ATOMIC_FIELD_NUMBER = 3;
    private boolean atomic_;
    public boolean hasAtomic() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    public boolean getAtomic() {
      return atomic_;
    }
    
    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      action_ = java.util.Collections.emptyList();
      atomic_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getActionCount(); i++) {
        if (!getAction(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      for (int i = 0; i < action_.size(); i++) {
        output.writeMessage(2, action_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(3, atomic_);
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      for (int i = 0; i < action_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, action_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, atomic_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest) obj;
      
      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && getActionList()
          .equals(other.getActionList());
      result = result && (hasAtomic() == other.hasAtomic());
      if (hasAtomic()) {
        result = result && (getAtomic()
            == other.getAtomic());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (getActionCount() > 0) {
        hash = (37 * hash) + ACTION_FIELD_NUMBER;
        hash = (53 * hash) + getActionList().hashCode();
      }
      if (hasAtomic()) {
        hash = (37 * hash) + ATOMIC_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getAtomic());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getActionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (actionBuilder_ == null) {
          action_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          actionBuilder_.clear();
        }
        atomic_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (actionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            action_ = java.util.Collections.unmodifiableList(action_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.action_ = action_;
        } else {
          result.action_ = actionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.atomic_ = atomic_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (actionBuilder_ == null) {
          if (!other.action_.isEmpty()) {
            if (action_.isEmpty()) {
              action_ = other.action_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureActionIsMutable();
              action_.addAll(other.action_);
            }
            onChanged();
          }
        } else {
          if (!other.action_.isEmpty()) {
            if (actionBuilder_.isEmpty()) {
              actionBuilder_.dispose();
              actionBuilder_ = null;
              action_ = other.action_;
              bitField0_ = (bitField0_ & ~0x00000002);
              actionBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getActionFieldBuilder() : null;
            } else {
              actionBuilder_.addAllMessages(other.action_);
            }
          }
        }
        if (other.hasAtomic()) {
          setAtomic(other.getAtomic());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        for (int i = 0; i < getActionCount(); i++) {
          if (!getAction(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder();
              if (hasRegion()) {
                subBuilder.mergeFrom(getRegion());
              }
              input.readMessage(subBuilder, extensionRegistry);
              setRegion(subBuilder.buildPartial());
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addAction(subBuilder.buildPartial());
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              atomic_ = input.readBool();
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }
      
      // repeated .MultiAction action = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> action_ =
        java.util.Collections.emptyList();
      private void ensureActionIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction>(action_);
          bitField0_ |= 0x00000002;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> actionBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> getActionList() {
        if (actionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(action_);
        } else {
          return actionBuilder_.getMessageList();
        }
      }
      public int getActionCount() {
        if (actionBuilder_ == null) {
          return action_.size();
        } else {
          return actionBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction getAction(int index) {
        if (actionBuilder_ == null) {
          return action_.get(index);
        } else {
          return actionBuilder_.getMessage(index);
        }
      }
      public Builder setAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.set(index, value);
          onChanged();
        } else {
          actionBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.set(index, builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAction(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.add(value);
          onChanged();
        } else {
          actionBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.add(index, value);
          onChanged();
        } else {
          actionBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addAction(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.add(builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.add(index, builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllAction(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> values) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          super.addAll(values, action_);
          onChanged();
        } else {
          actionBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearAction() {
        if (actionBuilder_ == null) {
          action_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          actionBuilder_.clear();
        }
        return this;
      }
      public Builder removeAction(int index) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.remove(index);
          onChanged();
        } else {
          actionBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder getActionBuilder(
          int index) {
        return getActionFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder getActionOrBuilder(
          int index) {
        if (actionBuilder_ == null) {
          return action_.get(index);  } else {
          return actionBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> 
           getActionOrBuilderList() {
        if (actionBuilder_ != null) {
          return actionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(action_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder addActionBuilder() {
        return getActionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder addActionBuilder(
          int index) {
        return getActionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder> 
           getActionBuilderList() {
        return getActionFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> 
          getActionFieldBuilder() {
        if (actionBuilder_ == null) {
          actionBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder>(
                  action_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          action_ = null;
        }
        return actionBuilder_;
      }
      
      // optional bool atomic = 3;
      private boolean atomic_ ;
      public boolean hasAtomic() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      public boolean getAtomic() {
        return atomic_;
      }
      public Builder setAtomic(boolean value) {
        bitField0_ |= 0x00000004;
        atomic_ = value;
        onChanged();
        return this;
      }
      public Builder clearAtomic() {
        bitField0_ = (bitField0_ & ~0x00000004);
        atomic_ = false;
        onChanged();
        return this;
      }
      
      // @@protoc_insertion_point(builder_scope:MultiRequest)
    }
    
    static {
      defaultInstance = new MultiRequest(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:MultiRequest)
  }
  
  public interface MultiResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {
    
    // repeated .ActionResult result = 1;
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> 
        getResultList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult getResult(int index);
    int getResultCount();
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> 
        getResultOrBuilderList();
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder getResultOrBuilder(
        int index);
  }
  public static final class MultiResponse extends
      com.google.protobuf.GeneratedMessage
      implements MultiResponseOrBuilder {
    // Use MultiResponse.newBuilder() to construct.
    private MultiResponse(Builder builder) {
      super(builder);
    }
    private MultiResponse(boolean noInit) {}
    
    private static final MultiResponse defaultInstance;
    public static MultiResponse getDefaultInstance() {
      return defaultInstance;
    }
    
    public MultiResponse getDefaultInstanceForType() {
      return defaultInstance;
    }
    
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_descriptor;
    }
    
    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_fieldAccessorTable;
    }
    
    // repeated .ActionResult result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> result_;
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> getResultList() {
      return result_;
    }
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> 
        getResultOrBuilderList() {
      return result_;
    }
    public int getResultCount() {
      return result_.size();
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult getResult(int index) {
      return result_.get(index);
    }
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder getResultOrBuilder(
        int index) {
      return result_.get(index);
    }
    
    private void initFields() {
      result_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;
      
      for (int i = 0; i < getResultCount(); i++) {
        if (!getResult(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }
    
    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < result_.size(); i++) {
        output.writeMessage(1, result_.get(i));
      }
      getUnknownFields().writeTo(output);
    }
    
    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;
    
      size = 0;
      for (int i = 0; i < result_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }
    
    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }
    
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse) obj;
      
      boolean result = true;
      result = result && getResultList()
          .equals(other.getResultList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }
    
    @java.lang.Override
    public int hashCode() {
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResultCount() > 0) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResultList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      return hash;
    }
    
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return newBuilder().mergeFrom(data, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      Builder builder = newBuilder();
      if (builder.mergeDelimitedFrom(input, extensionRegistry)) {
        return builder.buildParsed();
      } else {
        return null;
      }
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input).buildParsed();
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return newBuilder().mergeFrom(input, extensionRegistry)
               .buildParsed();
    }
    
    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }
    
    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_descriptor;
      }
      
      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_fieldAccessorTable;
      }
      
      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }
      
      private Builder(BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }
      
      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resultBuilder_.clear();
        }
        return this;
      }
      
      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }
      
      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDescriptor();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }
      
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse buildParsed()
          throws com.google.protobuf.InvalidProtocolBufferException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(
            result).asInvalidProtocolBufferException();
        }
        return result;
      }
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse(this);
        int from_bitField0_ = bitField0_;
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            result_ = java.util.Collections.unmodifiableList(result_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        onBuilt();
        return result;
      }
      
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }
      
      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance()) return this;
        if (resultBuilder_ == null) {
          if (!other.result_.isEmpty()) {
            if (result_.isEmpty()) {
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultIsMutable();
              result_.addAll(other.result_);
            }
            onChanged();
          }
        } else {
          if (!other.result_.isEmpty()) {
            if (resultBuilder_.isEmpty()) {
              resultBuilder_.dispose();
              resultBuilder_ = null;
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getResultFieldBuilder() : null;
            } else {
              resultBuilder_.addAllMessages(other.result_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }
      
      public final boolean isInitialized() {
        for (int i = 0; i < getResultCount(); i++) {
          if (!getResult(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }
      
      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder(
            this.getUnknownFields());
        while (true) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              this.setUnknownFields(unknownFields.build());
              onChanged();
              return this;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                this.setUnknownFields(unknownFields.build());
                onChanged();
                return this;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder subBuilder = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.newBuilder();
              input.readMessage(subBuilder, extensionRegistry);
              addResult(subBuilder.buildPartial());
              break;
            }
          }
        }
      }
      
      private int bitField0_;
      
      // repeated .ActionResult result = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> result_ =
        java.util.Collections.emptyList();
      private void ensureResultIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          result_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult>(result_);
          bitField0_ |= 0x00000001;
         }
      }
      
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> resultBuilder_;
      
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> getResultList() {
        if (resultBuilder_ == null) {
          return java.util.Collections.unmodifiableList(result_);
        } else {
          return resultBuilder_.getMessageList();
        }
      }
      public int getResultCount() {
        if (resultBuilder_ == null) {
          return result_.size();
        } else {
          return resultBuilder_.getCount();
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult getResult(int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);
        } else {
          return resultBuilder_.getMessage(index);
        }
      }
      public Builder setResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.set(index, value);
          onChanged();
        } else {
          resultBuilder_.setMessage(index, value);
        }
        return this;
      }
      public Builder setResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(value);
          onChanged();
        } else {
          resultBuilder_.addMessage(value);
        }
        return this;
      }
      public Builder addResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(index, value);
          onChanged();
        } else {
          resultBuilder_.addMessage(index, value);
        }
        return this;
      }
      public Builder addResult(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      public Builder addResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      public Builder addAllResult(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> values) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          super.addAll(values, result_);
          onChanged();
        } else {
          resultBuilder_.addAllMessages(values);
        }
        return this;
      }
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        return this;
      }
      public Builder removeResult(int index) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.remove(index);
          onChanged();
        } else {
          resultBuilder_.remove(index);
        }
        return this;
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder getResultBuilder(
          int index) {
        return getResultFieldBuilder().getBuilder(index);
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder getResultOrBuilder(
          int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);  } else {
          return resultBuilder_.getMessageOrBuilder(index);
        }
      }
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> 
           getResultOrBuilderList() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(result_);
        }
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder addResultBuilder() {
        return getResultFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDefaultInstance());
      }
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder addResultBuilder(
          int index) {
        return getResultFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDefaultInstance());
      }
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder> 
           getResultBuilderList() {
        return getResultFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder>(
                  result_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }
      
      // @@protoc_insertion_point(builder_scope:MultiResponse)
    }
    
    static {
      defaultInstance = new MultiResponse(true);
      defaultInstance.initFields();
    }
    
    // @@protoc_insertion_point(class_scope:MultiResponse)
  }
  
  public static abstract class ClientService
      implements com.google.protobuf.Service {
    protected ClientService() {}
    
    public interface Interface {
      public abstract void get(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse> done);
      
      public abstract void mutate(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse> done);
      
      public abstract void scan(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse> done);
      
      public abstract void lockRow(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse> done);
      
      public abstract void unlockRow(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse> done);
      
      public abstract void bulkLoadHFile(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done);
      
      public abstract void execCoprocessor(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse> done);
      
      public abstract void execService(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done);
      
      public abstract void multi(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse> done);
      
    }
    
    public static com.google.protobuf.Service newReflectiveService(
        final Interface impl) {
      return new ClientService() {
        @java.lang.Override
        public  void get(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse> done) {
          impl.get(controller, request, done);
        }
        
        @java.lang.Override
        public  void mutate(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse> done) {
          impl.mutate(controller, request, done);
        }
        
        @java.lang.Override
        public  void scan(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse> done) {
          impl.scan(controller, request, done);
        }
        
        @java.lang.Override
        public  void lockRow(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse> done) {
          impl.lockRow(controller, request, done);
        }
        
        @java.lang.Override
        public  void unlockRow(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse> done) {
          impl.unlockRow(controller, request, done);
        }
        
        @java.lang.Override
        public  void bulkLoadHFile(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done) {
          impl.bulkLoadHFile(controller, request, done);
        }
        
        @java.lang.Override
        public  void execCoprocessor(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse> done) {
          impl.execCoprocessor(controller, request, done);
        }
        
        @java.lang.Override
        public  void execService(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done) {
          impl.execService(controller, request, done);
        }
        
        @java.lang.Override
        public  void multi(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse> done) {
          impl.multi(controller, request, done);
        }
        
      };
    }
    
    public static com.google.protobuf.BlockingService
        newReflectiveBlockingService(final BlockingInterface impl) {
      return new com.google.protobuf.BlockingService() {
        public final com.google.protobuf.Descriptors.ServiceDescriptor
            getDescriptorForType() {
          return getDescriptor();
        }
        
        public final com.google.protobuf.Message callBlockingMethod(
            com.google.protobuf.Descriptors.MethodDescriptor method,
            com.google.protobuf.RpcController controller,
            com.google.protobuf.Message request)
            throws com.google.protobuf.ServiceException {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.callBlockingMethod() given method descriptor for " +
              "wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return impl.get(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest)request);
            case 1:
              return impl.mutate(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest)request);
            case 2:
              return impl.scan(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest)request);
            case 3:
              return impl.lockRow(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest)request);
            case 4:
              return impl.unlockRow(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest)request);
            case 5:
              return impl.bulkLoadHFile(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest)request);
            case 6:
              return impl.execCoprocessor(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest)request);
            case 7:
              return impl.execService(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest)request);
            case 8:
              return impl.multi(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest)request);
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }
        
        public final com.google.protobuf.Message
            getRequestPrototype(
            com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getRequestPrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest.getDefaultInstance();
            case 5:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
            case 6:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest.getDefaultInstance();
            case 7:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
            case 8:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }
        
        public final com.google.protobuf.Message
            getResponsePrototype(
            com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getResponsePrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.getDefaultInstance();
            case 5:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
            case 6:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.getDefaultInstance();
            case 7:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
            case 8:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }
        
      };
    }
    
    public abstract void get(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse> done);
    
    public abstract void mutate(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse> done);
    
    public abstract void scan(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse> done);
    
    public abstract void lockRow(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse> done);
    
    public abstract void unlockRow(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse> done);
    
    public abstract void bulkLoadHFile(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done);
    
    public abstract void execCoprocessor(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse> done);
    
    public abstract void execService(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done);
    
    public abstract void multi(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse> done);
    
    public static final
        com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.getDescriptor().getServices().get(0);
    }
    public final com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    
    public final void callMethod(
        com.google.protobuf.Descriptors.MethodDescriptor method,
        com.google.protobuf.RpcController controller,
        com.google.protobuf.Message request,
        com.google.protobuf.RpcCallback<
          com.google.protobuf.Message> done) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.callMethod() given method descriptor for wrong " +
          "service type.");
      }
      switch(method.getIndex()) {
        case 0:
          this.get(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse>specializeCallback(
              done));
          return;
        case 1:
          this.mutate(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse>specializeCallback(
              done));
          return;
        case 2:
          this.scan(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse>specializeCallback(
              done));
          return;
        case 3:
          this.lockRow(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse>specializeCallback(
              done));
          return;
        case 4:
          this.unlockRow(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse>specializeCallback(
              done));
          return;
        case 5:
          this.bulkLoadHFile(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse>specializeCallback(
              done));
          return;
        case 6:
          this.execCoprocessor(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse>specializeCallback(
              done));
          return;
        case 7:
          this.execService(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse>specializeCallback(
              done));
          return;
        case 8:
          this.multi(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse>specializeCallback(
              done));
          return;
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }
    
    public final com.google.protobuf.Message
        getRequestPrototype(
        com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getRequestPrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest.getDefaultInstance();
        case 5:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
        case 6:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest.getDefaultInstance();
        case 7:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
        case 8:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }
    
    public final com.google.protobuf.Message
        getResponsePrototype(
        com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getResponsePrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.getDefaultInstance();
        case 5:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
        case 6:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.getDefaultInstance();
        case 7:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
        case 8:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }
    
    public static Stub newStub(
        com.google.protobuf.RpcChannel channel) {
      return new Stub(channel);
    }
    
    public static final class Stub extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ClientService implements Interface {
      private Stub(com.google.protobuf.RpcChannel channel) {
        this.channel = channel;
      }
      
      private final com.google.protobuf.RpcChannel channel;
      
      public com.google.protobuf.RpcChannel getChannel() {
        return channel;
      }
      
      public  void get(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance()));
      }
      
      public  void mutate(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance()));
      }
      
      public  void scan(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance()));
      }
      
      public  void lockRow(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.getDefaultInstance()));
      }
      
      public  void unlockRow(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.getDefaultInstance()));
      }
      
      public  void bulkLoadHFile(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance()));
      }
      
      public  void execCoprocessor(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.getDefaultInstance()));
      }
      
      public  void execService(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(7),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance()));
      }
      
      public  void multi(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(8),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance()));
      }
    }
    
    public static BlockingInterface newBlockingStub(
        com.google.protobuf.BlockingRpcChannel channel) {
      return new BlockingStub(channel);
    }
    
    public interface BlockingInterface {
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse get(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse mutate(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse scan(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse lockRow(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse unlockRow(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse bulkLoadHFile(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse execCoprocessor(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse execService(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request)
          throws com.google.protobuf.ServiceException;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse multi(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request)
          throws com.google.protobuf.ServiceException;
    }
    
    private static final class BlockingStub implements BlockingInterface {
      private BlockingStub(com.google.protobuf.BlockingRpcChannel channel) {
        this.channel = channel;
      }
      
      private final com.google.protobuf.BlockingRpcChannel channel;
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse get(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse mutate(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse scan(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse lockRow(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse unlockRow(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse bulkLoadHFile(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse execCoprocessor(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse execService(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(7),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance());
      }
      
      
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse multi(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(8),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance());
      }
      
    }
  }
  
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Column_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Column_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Get_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Get_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Result_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Result_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Condition_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Condition_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Mutate_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Mutate_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Mutate_ColumnValue_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Mutate_ColumnValue_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Mutate_ColumnValue_QualifierValue_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Mutate_ColumnValue_QualifierValue_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MutateRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MutateRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MutateResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MutateResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Scan_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Scan_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ScanRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ScanRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ScanResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ScanResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_LockRowRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_LockRowRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_LockRowResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_LockRowResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_UnlockRowRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_UnlockRowRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_UnlockRowResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_UnlockRowResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_BulkLoadHFileRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_BulkLoadHFileRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_BulkLoadHFileRequest_FamilyPath_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_BulkLoadHFileResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_BulkLoadHFileResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Exec_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Exec_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ExecCoprocessorRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ExecCoprocessorRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ExecCoprocessorResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ExecCoprocessorResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_CoprocessorServiceCall_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_CoprocessorServiceCall_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_CoprocessorServiceRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_CoprocessorServiceRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_CoprocessorServiceResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_CoprocessorServiceResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MultiAction_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MultiAction_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ActionResult_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ActionResult_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MultiRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MultiRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MultiResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MultiResponse_fieldAccessorTable;
  
  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\014Client.proto\032\013hbase.proto\032\020Comparator." +
      "proto\"+\n\006Column\022\016\n\006family\030\001 \002(\014\022\021\n\tquali" +
      "fier\030\002 \003(\014\"\362\001\n\003Get\022\013\n\003row\030\001 \002(\014\022\027\n\006colum" +
      "n\030\002 \003(\0132\007.Column\022!\n\tattribute\030\003 \003(\0132\016.Na" +
      "meBytesPair\022\016\n\006lockId\030\004 \001(\004\022\027\n\006filter\030\005 " +
      "\001(\0132\007.Filter\022\035\n\ttimeRange\030\006 \001(\0132\n.TimeRa" +
      "nge\022\026\n\013maxVersions\030\007 \001(\r:\0011\022\031\n\013cacheBloc" +
      "ks\030\010 \001(\010:\004true\022\022\n\nstoreLimit\030\t \001(\r\022\023\n\013st" +
      "oreOffset\030\n \001(\r\"\037\n\006Result\022\025\n\rkeyValueByt" +
      "es\030\001 \003(\014\"r\n\nGetRequest\022 \n\006region\030\001 \002(\0132\020",
      ".RegionSpecifier\022\021\n\003get\030\002 \002(\0132\004.Get\022\030\n\020c" +
      "losestRowBefore\030\003 \001(\010\022\025\n\rexistenceOnly\030\004" +
      " \001(\010\"6\n\013GetResponse\022\027\n\006result\030\001 \001(\0132\007.Re" +
      "sult\022\016\n\006exists\030\002 \001(\010\"\177\n\tCondition\022\013\n\003row" +
      "\030\001 \002(\014\022\016\n\006family\030\002 \002(\014\022\021\n\tqualifier\030\003 \002(" +
      "\014\022!\n\013compareType\030\004 \002(\0162\014.CompareType\022\037\n\n" +
      "comparator\030\005 \002(\0132\013.Comparator\"\306\004\n\006Mutate" +
      "\022\013\n\003row\030\001 \002(\014\022&\n\nmutateType\030\002 \002(\0162\022.Muta" +
      "te.MutateType\022(\n\013columnValue\030\003 \003(\0132\023.Mut" +
      "ate.ColumnValue\022!\n\tattribute\030\004 \003(\0132\016.Nam",
      "eBytesPair\022\021\n\ttimestamp\030\005 \001(\004\022\016\n\006lockId\030" +
      "\006 \001(\004\022\030\n\nwriteToWAL\030\007 \001(\010:\004true\022\035\n\ttimeR" +
      "ange\030\n \001(\0132\n.TimeRange\032\310\001\n\013ColumnValue\022\016" +
      "\n\006family\030\001 \002(\014\022:\n\016qualifierValue\030\002 \003(\0132\"" +
      ".Mutate.ColumnValue.QualifierValue\032m\n\016Qu" +
      "alifierValue\022\021\n\tqualifier\030\001 \001(\014\022\r\n\005value" +
      "\030\002 \001(\014\022\021\n\ttimestamp\030\003 \001(\004\022&\n\ndeleteType\030" +
      "\004 \001(\0162\022.Mutate.DeleteType\"<\n\nMutateType\022" +
      "\n\n\006APPEND\020\000\022\r\n\tINCREMENT\020\001\022\007\n\003PUT\020\002\022\n\n\006D" +
      "ELETE\020\003\"U\n\nDeleteType\022\026\n\022DELETE_ONE_VERS",
      "ION\020\000\022\034\n\030DELETE_MULTIPLE_VERSIONS\020\001\022\021\n\rD" +
      "ELETE_FAMILY\020\002\"i\n\rMutateRequest\022 \n\006regio" +
      "n\030\001 \002(\0132\020.RegionSpecifier\022\027\n\006mutate\030\002 \002(" +
      "\0132\007.Mutate\022\035\n\tcondition\030\003 \001(\0132\n.Conditio" +
      "n\"<\n\016MutateResponse\022\027\n\006result\030\001 \001(\0132\007.Re" +
      "sult\022\021\n\tprocessed\030\002 \001(\010\"\243\002\n\004Scan\022\027\n\006colu" +
      "mn\030\001 \003(\0132\007.Column\022!\n\tattribute\030\002 \003(\0132\016.N" +
      "ameBytesPair\022\020\n\010startRow\030\003 \001(\014\022\017\n\007stopRo" +
      "w\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007.Filter\022\035\n\ttime" +
      "Range\030\006 \001(\0132\n.TimeRange\022\026\n\013maxVersions\030\007",
      " \001(\r:\0011\022\031\n\013cacheBlocks\030\010 \001(\010:\004true\022\021\n\tba" +
      "tchSize\030\t \001(\r\022\025\n\rmaxResultSize\030\n \001(\004\022\022\n\n" +
      "storeLimit\030\013 \001(\r\022\023\n\013storeOffset\030\014 \001(\r\"\203\001" +
      "\n\013ScanRequest\022 \n\006region\030\001 \001(\0132\020.RegionSp" +
      "ecifier\022\023\n\004scan\030\002 \001(\0132\005.Scan\022\021\n\tscannerI" +
      "d\030\003 \001(\004\022\024\n\014numberOfRows\030\004 \001(\r\022\024\n\014closeSc" +
      "anner\030\005 \001(\010\"\\\n\014ScanResponse\022\027\n\006result\030\001 " +
      "\003(\0132\007.Result\022\021\n\tscannerId\030\002 \001(\004\022\023\n\013moreR" +
      "esults\030\003 \001(\010\022\013\n\003ttl\030\004 \001(\r\"?\n\016LockRowRequ" +
      "est\022 \n\006region\030\001 \002(\0132\020.RegionSpecifier\022\013\n",
      "\003row\030\002 \003(\014\".\n\017LockRowResponse\022\016\n\006lockId\030" +
      "\001 \002(\004\022\013\n\003ttl\030\002 \001(\r\"D\n\020UnlockRowRequest\022 " +
      "\n\006region\030\001 \002(\0132\020.RegionSpecifier\022\016\n\006lock" +
      "Id\030\002 \002(\004\"\023\n\021UnlockRowResponse\"\260\001\n\024BulkLo" +
      "adHFileRequest\022 \n\006region\030\001 \002(\0132\020.RegionS" +
      "pecifier\0224\n\nfamilyPath\030\002 \003(\0132 .BulkLoadH" +
      "FileRequest.FamilyPath\022\024\n\014assignSeqNum\030\003" +
      " \001(\010\032*\n\nFamilyPath\022\016\n\006family\030\001 \002(\014\022\014\n\004pa" +
      "th\030\002 \002(\t\"\'\n\025BulkLoadHFileResponse\022\016\n\006loa" +
      "ded\030\001 \002(\010\"\203\001\n\004Exec\022\013\n\003row\030\001 \002(\014\022\024\n\014proto",
      "colName\030\002 \002(\t\022\022\n\nmethodName\030\003 \002(\t\022!\n\010pro" +
      "perty\030\004 \003(\0132\017.NameStringPair\022!\n\tparamete" +
      "r\030\005 \003(\0132\016.NameBytesPair\"O\n\026ExecCoprocess" +
      "orRequest\022 \n\006region\030\001 \002(\0132\020.RegionSpecif" +
      "ier\022\023\n\004call\030\002 \002(\0132\005.Exec\"8\n\027ExecCoproces" +
      "sorResponse\022\035\n\005value\030\001 \002(\0132\016.NameBytesPa" +
      "ir\"_\n\026CoprocessorServiceCall\022\013\n\003row\030\001 \002(" +
      "\014\022\023\n\013serviceName\030\002 \002(\t\022\022\n\nmethodName\030\003 \002" +
      "(\t\022\017\n\007request\030\004 \002(\014\"d\n\031CoprocessorServic" +
      "eRequest\022 \n\006region\030\001 \002(\0132\020.RegionSpecifi",
      "er\022%\n\004call\030\002 \002(\0132\027.CoprocessorServiceCal" +
      "l\"]\n\032CoprocessorServiceResponse\022 \n\006regio" +
      "n\030\001 \002(\0132\020.RegionSpecifier\022\035\n\005value\030\002 \002(\013" +
      "2\016.NameBytesPair\"N\n\013MultiAction\022\027\n\006mutat" +
      "e\030\001 \001(\0132\007.Mutate\022\021\n\003get\030\002 \001(\0132\004.Get\022\023\n\004e" +
      "xec\030\003 \001(\0132\005.Exec\"P\n\014ActionResult\022\035\n\005valu" +
      "e\030\001 \001(\0132\016.NameBytesPair\022!\n\texception\030\002 \001" +
      "(\0132\016.NameBytesPair\"^\n\014MultiRequest\022 \n\006re" +
      "gion\030\001 \002(\0132\020.RegionSpecifier\022\034\n\006action\030\002" +
      " \003(\0132\014.MultiAction\022\016\n\006atomic\030\003 \001(\010\".\n\rMu",
      "ltiResponse\022\035\n\006result\030\001 \003(\0132\r.ActionResu" +
      "lt2\331\003\n\rClientService\022 \n\003get\022\013.GetRequest" +
      "\032\014.GetResponse\022)\n\006mutate\022\016.MutateRequest" +
      "\032\017.MutateResponse\022#\n\004scan\022\014.ScanRequest\032" +
      "\r.ScanResponse\022,\n\007lockRow\022\017.LockRowReque" +
      "st\032\020.LockRowResponse\0222\n\tunlockRow\022\021.Unlo" +
      "ckRowRequest\032\022.UnlockRowResponse\022>\n\rbulk" +
      "LoadHFile\022\025.BulkLoadHFileRequest\032\026.BulkL" +
      "oadHFileResponse\022D\n\017execCoprocessor\022\027.Ex" +
      "ecCoprocessorRequest\032\030.ExecCoprocessorRe",
      "sponse\022F\n\013execService\022\032.CoprocessorServi" +
      "ceRequest\032\033.CoprocessorServiceResponse\022&" +
      "\n\005multi\022\r.MultiRequest\032\016.MultiResponseBB" +
      "\n*org.apache.hadoop.hbase.protobuf.gener" +
      "atedB\014ClientProtosH\001\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_Column_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_Column_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Column_descriptor,
              new java.lang.String[] { "Family", "Qualifier", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder.class);
          internal_static_Get_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_Get_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Get_descriptor,
              new java.lang.String[] { "Row", "Column", "Attribute", "LockId", "Filter", "TimeRange", "MaxVersions", "CacheBlocks", "StoreLimit", "StoreOffset", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder.class);
          internal_static_Result_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_Result_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Result_descriptor,
              new java.lang.String[] { "KeyValueBytes", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder.class);
          internal_static_GetRequest_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_GetRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetRequest_descriptor,
              new java.lang.String[] { "Region", "Get", "ClosestRowBefore", "ExistenceOnly", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.Builder.class);
          internal_static_GetResponse_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_GetResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetResponse_descriptor,
              new java.lang.String[] { "Result", "Exists", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.Builder.class);
          internal_static_Condition_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_Condition_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Condition_descriptor,
              new java.lang.String[] { "Row", "Family", "Qualifier", "CompareType", "Comparator", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder.class);
          internal_static_Mutate_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_Mutate_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Mutate_descriptor,
              new java.lang.String[] { "Row", "MutateType", "ColumnValue", "Attribute", "Timestamp", "LockId", "WriteToWAL", "TimeRange", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.Builder.class);
          internal_static_Mutate_ColumnValue_descriptor =
            internal_static_Mutate_descriptor.getNestedTypes().get(0);
          internal_static_Mutate_ColumnValue_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Mutate_ColumnValue_descriptor,
              new java.lang.String[] { "Family", "QualifierValue", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.Builder.class);
          internal_static_Mutate_ColumnValue_QualifierValue_descriptor =
            internal_static_Mutate_ColumnValue_descriptor.getNestedTypes().get(0);
          internal_static_Mutate_ColumnValue_QualifierValue_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Mutate_ColumnValue_QualifierValue_descriptor,
              new java.lang.String[] { "Qualifier", "Value", "Timestamp", "DeleteType", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Mutate.ColumnValue.QualifierValue.Builder.class);
          internal_static_MutateRequest_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_MutateRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MutateRequest_descriptor,
              new java.lang.String[] { "Region", "Mutate", "Condition", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.Builder.class);
          internal_static_MutateResponse_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_MutateResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MutateResponse_descriptor,
              new java.lang.String[] { "Result", "Processed", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.Builder.class);
          internal_static_Scan_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_Scan_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Scan_descriptor,
              new java.lang.String[] { "Column", "Attribute", "StartRow", "StopRow", "Filter", "TimeRange", "MaxVersions", "CacheBlocks", "BatchSize", "MaxResultSize", "StoreLimit", "StoreOffset", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder.class);
          internal_static_ScanRequest_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_ScanRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ScanRequest_descriptor,
              new java.lang.String[] { "Region", "Scan", "ScannerId", "NumberOfRows", "CloseScanner", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.Builder.class);
          internal_static_ScanResponse_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_ScanResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ScanResponse_descriptor,
              new java.lang.String[] { "Result", "ScannerId", "MoreResults", "Ttl", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.Builder.class);
          internal_static_LockRowRequest_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_LockRowRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_LockRowRequest_descriptor,
              new java.lang.String[] { "Region", "Row", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowRequest.Builder.class);
          internal_static_LockRowResponse_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_LockRowResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_LockRowResponse_descriptor,
              new java.lang.String[] { "LockId", "Ttl", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.LockRowResponse.Builder.class);
          internal_static_UnlockRowRequest_descriptor =
            getDescriptor().getMessageTypes().get(14);
          internal_static_UnlockRowRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_UnlockRowRequest_descriptor,
              new java.lang.String[] { "Region", "LockId", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowRequest.Builder.class);
          internal_static_UnlockRowResponse_descriptor =
            getDescriptor().getMessageTypes().get(15);
          internal_static_UnlockRowResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_UnlockRowResponse_descriptor,
              new java.lang.String[] { },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.UnlockRowResponse.Builder.class);
          internal_static_BulkLoadHFileRequest_descriptor =
            getDescriptor().getMessageTypes().get(16);
          internal_static_BulkLoadHFileRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_BulkLoadHFileRequest_descriptor,
              new java.lang.String[] { "Region", "FamilyPath", "AssignSeqNum", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.Builder.class);
          internal_static_BulkLoadHFileRequest_FamilyPath_descriptor =
            internal_static_BulkLoadHFileRequest_descriptor.getNestedTypes().get(0);
          internal_static_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_BulkLoadHFileRequest_FamilyPath_descriptor,
              new java.lang.String[] { "Family", "Path", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder.class);
          internal_static_BulkLoadHFileResponse_descriptor =
            getDescriptor().getMessageTypes().get(17);
          internal_static_BulkLoadHFileResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_BulkLoadHFileResponse_descriptor,
              new java.lang.String[] { "Loaded", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.Builder.class);
          internal_static_Exec_descriptor =
            getDescriptor().getMessageTypes().get(18);
          internal_static_Exec_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Exec_descriptor,
              new java.lang.String[] { "Row", "ProtocolName", "MethodName", "Property", "Parameter", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Exec.Builder.class);
          internal_static_ExecCoprocessorRequest_descriptor =
            getDescriptor().getMessageTypes().get(19);
          internal_static_ExecCoprocessorRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ExecCoprocessorRequest_descriptor,
              new java.lang.String[] { "Region", "Call", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorRequest.Builder.class);
          internal_static_ExecCoprocessorResponse_descriptor =
            getDescriptor().getMessageTypes().get(20);
          internal_static_ExecCoprocessorResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ExecCoprocessorResponse_descriptor,
              new java.lang.String[] { "Value", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ExecCoprocessorResponse.Builder.class);
          internal_static_CoprocessorServiceCall_descriptor =
            getDescriptor().getMessageTypes().get(21);
          internal_static_CoprocessorServiceCall_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_CoprocessorServiceCall_descriptor,
              new java.lang.String[] { "Row", "ServiceName", "MethodName", "Request", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder.class);
          internal_static_CoprocessorServiceRequest_descriptor =
            getDescriptor().getMessageTypes().get(22);
          internal_static_CoprocessorServiceRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_CoprocessorServiceRequest_descriptor,
              new java.lang.String[] { "Region", "Call", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.Builder.class);
          internal_static_CoprocessorServiceResponse_descriptor =
            getDescriptor().getMessageTypes().get(23);
          internal_static_CoprocessorServiceResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_CoprocessorServiceResponse_descriptor,
              new java.lang.String[] { "Region", "Value", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.Builder.class);
          internal_static_MultiAction_descriptor =
            getDescriptor().getMessageTypes().get(24);
          internal_static_MultiAction_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MultiAction_descriptor,
              new java.lang.String[] { "Mutate", "Get", "Exec", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder.class);
          internal_static_ActionResult_descriptor =
            getDescriptor().getMessageTypes().get(25);
          internal_static_ActionResult_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ActionResult_descriptor,
              new java.lang.String[] { "Value", "Exception", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder.class);
          internal_static_MultiRequest_descriptor =
            getDescriptor().getMessageTypes().get(26);
          internal_static_MultiRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MultiRequest_descriptor,
              new java.lang.String[] { "Region", "Action", "Atomic", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.Builder.class);
          internal_static_MultiResponse_descriptor =
            getDescriptor().getMessageTypes().get(27);
          internal_static_MultiResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MultiResponse_descriptor,
              new java.lang.String[] { "Result", },
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.class,
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.Builder.class);
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.getDescriptor(),
        }, assigner);
  }
  
  // @@protoc_insertion_point(outer_class_scope)
}

// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: Client.proto

package org.apache.hadoop.hbase.protobuf.generated;

public final class ClientProtos {
  private ClientProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
  }
  public interface ColumnOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes family = 1;
    /**
     * <code>required bytes family = 1;</code>
     */
    boolean hasFamily();
    /**
     * <code>required bytes family = 1;</code>
     */
    com.google.protobuf.ByteString getFamily();

    // repeated bytes qualifier = 2;
    /**
     * <code>repeated bytes qualifier = 2;</code>
     */
    java.util.List<com.google.protobuf.ByteString> getQualifierList();
    /**
     * <code>repeated bytes qualifier = 2;</code>
     */
    int getQualifierCount();
    /**
     * <code>repeated bytes qualifier = 2;</code>
     */
    com.google.protobuf.ByteString getQualifier(int index);
  }
  /**
   * Protobuf type {@code Column}
   *
   * <pre>
   **
   * Container for a list of column qualifier names of a family.
   * </pre>
   */
  public static final class Column extends
      com.google.protobuf.GeneratedMessage
      implements ColumnOrBuilder {
    // Use Column.newBuilder() to construct.
    private Column(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Column(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Column defaultInstance;
    public static Column getDefaultInstance() {
      return defaultInstance;
    }

    public Column getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Column(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              family_ = input.readBytes();
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                qualifier_ = new java.util.ArrayList<com.google.protobuf.ByteString>();
                mutable_bitField0_ |= 0x00000002;
              }
              qualifier_.add(input.readBytes());
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          qualifier_ = java.util.Collections.unmodifiableList(qualifier_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder.class);
    }

    public static com.google.protobuf.Parser<Column> PARSER =
        new com.google.protobuf.AbstractParser<Column>() {
      public Column parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Column(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Column> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes family = 1;
    public static final int FAMILY_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString family_;
    /**
     * <code>required bytes family = 1;</code>
     */
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes family = 1;</code>
     */
    public com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    // repeated bytes qualifier = 2;
    public static final int QUALIFIER_FIELD_NUMBER = 2;
    private java.util.List<com.google.protobuf.ByteString> qualifier_;
    /**
     * <code>repeated bytes qualifier = 2;</code>
     */
    public java.util.List<com.google.protobuf.ByteString>
        getQualifierList() {
      return qualifier_;
    }
    /**
     * <code>repeated bytes qualifier = 2;</code>
     */
    public int getQualifierCount() {
      return qualifier_.size();
    }
    /**
     * <code>repeated bytes qualifier = 2;</code>
     */
    public com.google.protobuf.ByteString getQualifier(int index) {
      return qualifier_.get(index);
    }

    private void initFields() {
      family_ = com.google.protobuf.ByteString.EMPTY;
      qualifier_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, family_);
      }
      for (int i = 0; i < qualifier_.size(); i++) {
        output.writeBytes(2, qualifier_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, family_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < qualifier_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeBytesSizeNoTag(qualifier_.get(i));
        }
        size += dataSize;
        size += 1 * getQualifierList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column) obj;

      boolean result = true;
      result = result && (hasFamily() == other.hasFamily());
      if (hasFamily()) {
        result = result && getFamily()
            .equals(other.getFamily());
      }
      result = result && getQualifierList()
          .equals(other.getQualifierList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (getQualifierCount() > 0) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifierList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code Column}
     *
     * <pre>
     **
     * Container for a list of column qualifier names of a family.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        family_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        qualifier_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Column_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.family_ = family_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          qualifier_ = java.util.Collections.unmodifiableList(qualifier_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.qualifier_ = qualifier_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance()) return this;
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (!other.qualifier_.isEmpty()) {
          if (qualifier_.isEmpty()) {
            qualifier_ = other.qualifier_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureQualifierIsMutable();
            qualifier_.addAll(other.qualifier_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasFamily()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes family = 1;
      private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 1;</code>
       */
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes family = 1;</code>
       */
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>required bytes family = 1;</code>
       */
      public Builder setFamily(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        family_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family = 1;</code>
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      // repeated bytes qualifier = 2;
      private java.util.List<com.google.protobuf.ByteString> qualifier_ = java.util.Collections.emptyList();
      private void ensureQualifierIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          qualifier_ = new java.util.ArrayList<com.google.protobuf.ByteString>(qualifier_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       */
      public java.util.List<com.google.protobuf.ByteString>
          getQualifierList() {
        return java.util.Collections.unmodifiableList(qualifier_);
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       */
      public int getQualifierCount() {
        return qualifier_.size();
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       */
      public com.google.protobuf.ByteString getQualifier(int index) {
        return qualifier_.get(index);
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       */
      public Builder setQualifier(
          int index, com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureQualifierIsMutable();
        qualifier_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       */
      public Builder addQualifier(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureQualifierIsMutable();
        qualifier_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       */
      public Builder addAllQualifier(
          java.lang.Iterable<? extends com.google.protobuf.ByteString> values) {
        ensureQualifierIsMutable();
        super.addAll(values, qualifier_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated bytes qualifier = 2;</code>
       */
      public Builder clearQualifier() {
        qualifier_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:Column)
    }

    static {
      defaultInstance = new Column(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:Column)
  }

  public interface GetOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes row = 1;
    /**
     * <code>required bytes row = 1;</code>
     */
    boolean hasRow();
    /**
     * <code>required bytes row = 1;</code>
     */
    com.google.protobuf.ByteString getRow();

    // repeated .Column column = 2;
    /**
     * <code>repeated .Column column = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> 
        getColumnList();
    /**
     * <code>repeated .Column column = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index);
    /**
     * <code>repeated .Column column = 2;</code>
     */
    int getColumnCount();
    /**
     * <code>repeated .Column column = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList();
    /**
     * <code>repeated .Column column = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index);

    // repeated .NameBytesPair attribute = 3;
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    int getAttributeCount();
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);

    // optional .Filter filter = 4;
    /**
     * <code>optional .Filter filter = 4;</code>
     */
    boolean hasFilter();
    /**
     * <code>optional .Filter filter = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter getFilter();
    /**
     * <code>optional .Filter filter = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder();

    // optional .TimeRange time_range = 5;
    /**
     * <code>optional .TimeRange time_range = 5;</code>
     */
    boolean hasTimeRange();
    /**
     * <code>optional .TimeRange time_range = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    /**
     * <code>optional .TimeRange time_range = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();

    // optional uint32 max_versions = 6 [default = 1];
    /**
     * <code>optional uint32 max_versions = 6 [default = 1];</code>
     */
    boolean hasMaxVersions();
    /**
     * <code>optional uint32 max_versions = 6 [default = 1];</code>
     */
    int getMaxVersions();

    // optional bool cache_blocks = 7 [default = true];
    /**
     * <code>optional bool cache_blocks = 7 [default = true];</code>
     */
    boolean hasCacheBlocks();
    /**
     * <code>optional bool cache_blocks = 7 [default = true];</code>
     */
    boolean getCacheBlocks();

    // optional uint32 store_limit = 8;
    /**
     * <code>optional uint32 store_limit = 8;</code>
     */
    boolean hasStoreLimit();
    /**
     * <code>optional uint32 store_limit = 8;</code>
     */
    int getStoreLimit();

    // optional uint32 store_offset = 9;
    /**
     * <code>optional uint32 store_offset = 9;</code>
     */
    boolean hasStoreOffset();
    /**
     * <code>optional uint32 store_offset = 9;</code>
     */
    int getStoreOffset();
  }
  /**
   * Protobuf type {@code Get}
   *
   * <pre>
   **
   * The protocol buffer version of Get
   * </pre>
   */
  public static final class Get extends
      com.google.protobuf.GeneratedMessage
      implements GetOrBuilder {
    // Use Get.newBuilder() to construct.
    private Get(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Get(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Get defaultInstance;
    public static Get getDefaultInstance() {
      return defaultInstance;
    }

    public Get getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Get(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                column_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column>();
                mutable_bitField0_ |= 0x00000002;
              }
              column_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.PARSER, extensionRegistry));
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>();
                mutable_bitField0_ |= 0x00000004;
              }
              attribute_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = filter_.toBuilder();
              }
              filter_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(filter_);
                filter_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = timeRange_.toBuilder();
              }
              timeRange_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(timeRange_);
                timeRange_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000008;
              maxVersions_ = input.readUInt32();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000010;
              cacheBlocks_ = input.readBool();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000020;
              storeLimit_ = input.readUInt32();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000040;
              storeOffset_ = input.readUInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          column_ = java.util.Collections.unmodifiableList(column_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          attribute_ = java.util.Collections.unmodifiableList(attribute_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder.class);
    }

    public static com.google.protobuf.Parser<Get> PARSER =
        new com.google.protobuf.AbstractParser<Get>() {
      public Get parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Get(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Get> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    /**
     * <code>required bytes row = 1;</code>
     */
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes row = 1;</code>
     */
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }

    // repeated .Column column = 2;
    public static final int COLUMN_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> column_;
    /**
     * <code>repeated .Column column = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> getColumnList() {
      return column_;
    }
    /**
     * <code>repeated .Column column = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList() {
      return column_;
    }
    /**
     * <code>repeated .Column column = 2;</code>
     */
    public int getColumnCount() {
      return column_.size();
    }
    /**
     * <code>repeated .Column column = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index) {
      return column_.get(index);
    }
    /**
     * <code>repeated .Column column = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index) {
      return column_.get(index);
    }

    // repeated .NameBytesPair attribute = 3;
    public static final int ATTRIBUTE_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    public int getAttributeCount() {
      return attribute_.size();
    }
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    /**
     * <code>repeated .NameBytesPair attribute = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }

    // optional .Filter filter = 4;
    public static final int FILTER_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter filter_;
    /**
     * <code>optional .Filter filter = 4;</code>
     */
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .Filter filter = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter getFilter() {
      return filter_;
    }
    /**
     * <code>optional .Filter filter = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_;
    }

    // optional .TimeRange time_range = 5;
    public static final int TIME_RANGE_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    /**
     * <code>optional .TimeRange time_range = 5;</code>
     */
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .TimeRange time_range = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_;
    }
    /**
     * <code>optional .TimeRange time_range = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_;
    }

    // optional uint32 max_versions = 6 [default = 1];
    public static final int MAX_VERSIONS_FIELD_NUMBER = 6;
    private int maxVersions_;
    /**
     * <code>optional uint32 max_versions = 6 [default = 1];</code>
     */
    public boolean hasMaxVersions() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional uint32 max_versions = 6 [default = 1];</code>
     */
    public int getMaxVersions() {
      return maxVersions_;
    }

    // optional bool cache_blocks = 7 [default = true];
    public static final int CACHE_BLOCKS_FIELD_NUMBER = 7;
    private boolean cacheBlocks_;
    /**
     * <code>optional bool cache_blocks = 7 [default = true];</code>
     */
    public boolean hasCacheBlocks() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool cache_blocks = 7 [default = true];</code>
     */
    public boolean getCacheBlocks() {
      return cacheBlocks_;
    }

    // optional uint32 store_limit = 8;
    public static final int STORE_LIMIT_FIELD_NUMBER = 8;
    private int storeLimit_;
    /**
     * <code>optional uint32 store_limit = 8;</code>
     */
    public boolean hasStoreLimit() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional uint32 store_limit = 8;</code>
     */
    public int getStoreLimit() {
      return storeLimit_;
    }

    // optional uint32 store_offset = 9;
    public static final int STORE_OFFSET_FIELD_NUMBER = 9;
    private int storeOffset_;
    /**
     * <code>optional uint32 store_offset = 9;</code>
     */
    public boolean hasStoreOffset() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional uint32 store_offset = 9;</code>
     */
    public int getStoreOffset() {
      return storeOffset_;
    }

    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      column_ = java.util.Collections.emptyList();
      attribute_ = java.util.Collections.emptyList();
      filter_ = org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
      timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      maxVersions_ = 1;
      cacheBlocks_ = true;
      storeLimit_ = 0;
      storeOffset_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getColumnCount(); i++) {
        if (!getColumn(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasFilter()) {
        if (!getFilter().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      for (int i = 0; i < column_.size(); i++) {
        output.writeMessage(2, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(3, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(4, filter_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(5, timeRange_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(6, maxVersions_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(7, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeUInt32(8, storeLimit_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeUInt32(9, storeOffset_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      for (int i = 0; i < column_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, filter_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, timeRange_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(6, maxVersions_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(8, storeLimit_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(9, storeOffset_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get) obj;

      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && getColumnList()
          .equals(other.getColumnList());
      result = result && getAttributeList()
          .equals(other.getAttributeList());
      result = result && (hasFilter() == other.hasFilter());
      if (hasFilter()) {
        result = result && getFilter()
            .equals(other.getFilter());
      }
      result = result && (hasTimeRange() == other.hasTimeRange());
      if (hasTimeRange()) {
        result = result && getTimeRange()
            .equals(other.getTimeRange());
      }
      result = result && (hasMaxVersions() == other.hasMaxVersions());
      if (hasMaxVersions()) {
        result = result && (getMaxVersions()
            == other.getMaxVersions());
      }
      result = result && (hasCacheBlocks() == other.hasCacheBlocks());
      if (hasCacheBlocks()) {
        result = result && (getCacheBlocks()
            == other.getCacheBlocks());
      }
      result = result && (hasStoreLimit() == other.hasStoreLimit());
      if (hasStoreLimit()) {
        result = result && (getStoreLimit()
            == other.getStoreLimit());
      }
      result = result && (hasStoreOffset() == other.hasStoreOffset());
      if (hasStoreOffset()) {
        result = result && (getStoreOffset()
            == other.getStoreOffset());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (getColumnCount() > 0) {
        hash = (37 * hash) + COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + getColumnList().hashCode();
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasMaxVersions()) {
        hash = (37 * hash) + MAX_VERSIONS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxVersions();
      }
      if (hasCacheBlocks()) {
        hash = (37 * hash) + CACHE_BLOCKS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCacheBlocks());
      }
      if (hasStoreLimit()) {
        hash = (37 * hash) + STORE_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getStoreLimit();
      }
      if (hasStoreOffset()) {
        hash = (37 * hash) + STORE_OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + getStoreOffset();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code Get}
     *
     * <pre>
     **
     * The protocol buffer version of Get
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getColumnFieldBuilder();
          getAttributeFieldBuilder();
          getFilterFieldBuilder();
          getTimeRangeFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          columnBuilder_.clear();
        }
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          attributeBuilder_.clear();
        }
        if (filterBuilder_ == null) {
          filter_ = org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
        } else {
          filterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        maxVersions_ = 1;
        bitField0_ = (bitField0_ & ~0x00000020);
        cacheBlocks_ = true;
        bitField0_ = (bitField0_ & ~0x00000040);
        storeLimit_ = 0;
        bitField0_ = (bitField0_ & ~0x00000080);
        storeOffset_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Get_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (columnBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            column_ = java.util.Collections.unmodifiableList(column_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.column_ = column_;
        } else {
          result.column_ = columnBuilder_.build();
        }
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000002;
        }
        if (filterBuilder_ == null) {
          result.filter_ = filter_;
        } else {
          result.filter_ = filterBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        if (timeRangeBuilder_ == null) {
          result.timeRange_ = timeRange_;
        } else {
          result.timeRange_ = timeRangeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000008;
        }
        result.maxVersions_ = maxVersions_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        result.cacheBlocks_ = cacheBlocks_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        result.storeLimit_ = storeLimit_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000040;
        }
        result.storeOffset_ = storeOffset_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (columnBuilder_ == null) {
          if (!other.column_.isEmpty()) {
            if (column_.isEmpty()) {
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureColumnIsMutable();
              column_.addAll(other.column_);
            }
            onChanged();
          }
        } else {
          if (!other.column_.isEmpty()) {
            if (columnBuilder_.isEmpty()) {
              columnBuilder_.dispose();
              columnBuilder_ = null;
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000002);
              columnBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getColumnFieldBuilder() : null;
            } else {
              columnBuilder_.addAllMessages(other.column_);
            }
          }
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000004);
              attributeBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasMaxVersions()) {
          setMaxVersions(other.getMaxVersions());
        }
        if (other.hasCacheBlocks()) {
          setCacheBlocks(other.getCacheBlocks());
        }
        if (other.hasStoreLimit()) {
          setStoreLimit(other.getStoreLimit());
        }
        if (other.hasStoreOffset()) {
          setStoreOffset(other.getStoreOffset());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        for (int i = 0; i < getColumnCount(); i++) {
          if (!getColumn(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            
            return false;
          }
        }
        if (hasFilter()) {
          if (!getFilter().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes row = 1;</code>
       */
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      // repeated .Column column = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> column_ =
        java.util.Collections.emptyList();
      private void ensureColumnIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          column_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column>(column_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> columnBuilder_;

      /**
       * <code>repeated .Column column = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> getColumnList() {
        if (columnBuilder_ == null) {
          return java.util.Collections.unmodifiableList(column_);
        } else {
          return columnBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public int getColumnCount() {
        if (columnBuilder_ == null) {
          return column_.size();
        } else {
          return columnBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);
        } else {
          return columnBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.set(index, value);
          onChanged();
        } else {
          columnBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder addColumn(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(value);
          onChanged();
        } else {
          columnBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(index, value);
          onChanged();
        } else {
          columnBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder addColumn(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder addAllColumn(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> values) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          super.addAll(values, column_);
          onChanged();
        } else {
          columnBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder clearColumn() {
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          columnBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public Builder removeColumn(int index) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.remove(index);
          onChanged();
        } else {
          columnBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder getColumnBuilder(
          int index) {
        return getColumnFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
          int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);  } else {
          return columnBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
           getColumnOrBuilderList() {
        if (columnBuilder_ != null) {
          return columnBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(column_);
        }
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder() {
        return getColumnFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder(
          int index) {
        return getColumnFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      /**
       * <code>repeated .Column column = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder> 
           getColumnBuilderList() {
        return getColumnFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
          getColumnFieldBuilder() {
        if (columnBuilder_ == null) {
          columnBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder>(
                  column_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          column_ = null;
        }
        return columnBuilder_;
      }

      // repeated .NameBytesPair attribute = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;

      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder addAttribute(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder addAttribute(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          super.addAll(values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameBytesPair attribute = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }

      // optional .Filter filter = 4;
      private org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter filter_ = org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder> filterBuilder_;
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      public Builder setFilter(org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
          onChanged();
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      public Builder setFilter(
          org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
          onChanged();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      public Builder mergeFilter(org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              filter_ != org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) {
            filter_ =
              org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.newBuilder(filter_).mergeFrom(value).buildPartial();
          } else {
            filter_ = value;
          }
          onChanged();
        } else {
          filterBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      public Builder clearFilter() {
        if (filterBuilder_ == null) {
          filter_ = org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
          onChanged();
        } else {
          filterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_;
        }
      }
      /**
       * <code>optional .Filter filter = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  filter_,
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }

      // optional .TimeRange time_range = 5;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      public Builder setTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      public Builder setTimeRange(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      public Builder mergeTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              timeRange_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            timeRange_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder(timeRange_).mergeFrom(value).buildPartial();
          } else {
            timeRange_ = value;
          }
          onChanged();
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      public Builder clearTimeRange() {
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
          onChanged();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_;
        }
      }
      /**
       * <code>optional .TimeRange time_range = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  timeRange_,
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }

      // optional uint32 max_versions = 6 [default = 1];
      private int maxVersions_ = 1;
      /**
       * <code>optional uint32 max_versions = 6 [default = 1];</code>
       */
      public boolean hasMaxVersions() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional uint32 max_versions = 6 [default = 1];</code>
       */
      public int getMaxVersions() {
        return maxVersions_;
      }
      /**
       * <code>optional uint32 max_versions = 6 [default = 1];</code>
       */
      public Builder setMaxVersions(int value) {
        bitField0_ |= 0x00000020;
        maxVersions_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 max_versions = 6 [default = 1];</code>
       */
      public Builder clearMaxVersions() {
        bitField0_ = (bitField0_ & ~0x00000020);
        maxVersions_ = 1;
        onChanged();
        return this;
      }

      // optional bool cache_blocks = 7 [default = true];
      private boolean cacheBlocks_ = true;
      /**
       * <code>optional bool cache_blocks = 7 [default = true];</code>
       */
      public boolean hasCacheBlocks() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional bool cache_blocks = 7 [default = true];</code>
       */
      public boolean getCacheBlocks() {
        return cacheBlocks_;
      }
      /**
       * <code>optional bool cache_blocks = 7 [default = true];</code>
       */
      public Builder setCacheBlocks(boolean value) {
        bitField0_ |= 0x00000040;
        cacheBlocks_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool cache_blocks = 7 [default = true];</code>
       */
      public Builder clearCacheBlocks() {
        bitField0_ = (bitField0_ & ~0x00000040);
        cacheBlocks_ = true;
        onChanged();
        return this;
      }

      // optional uint32 store_limit = 8;
      private int storeLimit_ ;
      /**
       * <code>optional uint32 store_limit = 8;</code>
       */
      public boolean hasStoreLimit() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional uint32 store_limit = 8;</code>
       */
      public int getStoreLimit() {
        return storeLimit_;
      }
      /**
       * <code>optional uint32 store_limit = 8;</code>
       */
      public Builder setStoreLimit(int value) {
        bitField0_ |= 0x00000080;
        storeLimit_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 store_limit = 8;</code>
       */
      public Builder clearStoreLimit() {
        bitField0_ = (bitField0_ & ~0x00000080);
        storeLimit_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 store_offset = 9;
      private int storeOffset_ ;
      /**
       * <code>optional uint32 store_offset = 9;</code>
       */
      public boolean hasStoreOffset() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional uint32 store_offset = 9;</code>
       */
      public int getStoreOffset() {
        return storeOffset_;
      }
      /**
       * <code>optional uint32 store_offset = 9;</code>
       */
      public Builder setStoreOffset(int value) {
        bitField0_ |= 0x00000100;
        storeOffset_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 store_offset = 9;</code>
       */
      public Builder clearStoreOffset() {
        bitField0_ = (bitField0_ & ~0x00000100);
        storeOffset_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:Get)
    }

    static {
      defaultInstance = new Get(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:Get)
  }

  public interface ResultOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .Cell cell = 1;
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell> 
        getCellList();
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell getCell(int index);
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    int getCellCount();
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder> 
        getCellOrBuilderList();
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder getCellOrBuilder(
        int index);

    // optional int32 associated_cell_count = 2;
    /**
     * <code>optional int32 associated_cell_count = 2;</code>
     *
     * <pre>
     * The below count is set when the associated cells are
     * not part of this protobuf message; they are passed alongside
     * and then this Message is just a placeholder with metadata.
     * The count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     */
    boolean hasAssociatedCellCount();
    /**
     * <code>optional int32 associated_cell_count = 2;</code>
     *
     * <pre>
     * The below count is set when the associated cells are
     * not part of this protobuf message; they are passed alongside
     * and then this Message is just a placeholder with metadata.
     * The count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     */
    int getAssociatedCellCount();
  }
  /**
   * Protobuf type {@code Result}
   */
  public static final class Result extends
      com.google.protobuf.GeneratedMessage
      implements ResultOrBuilder {
    // Use Result.newBuilder() to construct.
    private Result(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Result(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Result defaultInstance;
    public static Result getDefaultInstance() {
      return defaultInstance;
    }

    public Result getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Result(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                cell_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell>();
                mutable_bitField0_ |= 0x00000001;
              }
              cell_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.PARSER, extensionRegistry));
              break;
            }
            case 16: {
              bitField0_ |= 0x00000001;
              associatedCellCount_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          cell_ = java.util.Collections.unmodifiableList(cell_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder.class);
    }

    public static com.google.protobuf.Parser<Result> PARSER =
        new com.google.protobuf.AbstractParser<Result>() {
      public Result parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Result(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Result> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // repeated .Cell cell = 1;
    public static final int CELL_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell> cell_;
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell> getCellList() {
      return cell_;
    }
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder> 
        getCellOrBuilderList() {
      return cell_;
    }
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    public int getCellCount() {
      return cell_.size();
    }
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell getCell(int index) {
      return cell_.get(index);
    }
    /**
     * <code>repeated .Cell cell = 1;</code>
     *
     * <pre>
     * Result includes the Cells or else it just has a count of Cells
     * that are carried otherwise.
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder getCellOrBuilder(
        int index) {
      return cell_.get(index);
    }

    // optional int32 associated_cell_count = 2;
    public static final int ASSOCIATED_CELL_COUNT_FIELD_NUMBER = 2;
    private int associatedCellCount_;
    /**
     * <code>optional int32 associated_cell_count = 2;</code>
     *
     * <pre>
     * The below count is set when the associated cells are
     * not part of this protobuf message; they are passed alongside
     * and then this Message is just a placeholder with metadata.
     * The count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     */
    public boolean hasAssociatedCellCount() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 associated_cell_count = 2;</code>
     *
     * <pre>
     * The below count is set when the associated cells are
     * not part of this protobuf message; they are passed alongside
     * and then this Message is just a placeholder with metadata.
     * The count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     */
    public int getAssociatedCellCount() {
      return associatedCellCount_;
    }

    private void initFields() {
      cell_ = java.util.Collections.emptyList();
      associatedCellCount_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < cell_.size(); i++) {
        output.writeMessage(1, cell_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(2, associatedCellCount_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < cell_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, cell_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, associatedCellCount_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result) obj;

      boolean result = true;
      result = result && getCellList()
          .equals(other.getCellList());
      result = result && (hasAssociatedCellCount() == other.hasAssociatedCellCount());
      if (hasAssociatedCellCount()) {
        result = result && (getAssociatedCellCount()
            == other.getAssociatedCellCount());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getCellCount() > 0) {
        hash = (37 * hash) + CELL_FIELD_NUMBER;
        hash = (53 * hash) + getCellList().hashCode();
      }
      if (hasAssociatedCellCount()) {
        hash = (37 * hash) + ASSOCIATED_CELL_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getAssociatedCellCount();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code Result}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getCellFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (cellBuilder_ == null) {
          cell_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          cellBuilder_.clear();
        }
        associatedCellCount_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Result_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (cellBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            cell_ = java.util.Collections.unmodifiableList(cell_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.cell_ = cell_;
        } else {
          result.cell_ = cellBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.associatedCellCount_ = associatedCellCount_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance()) return this;
        if (cellBuilder_ == null) {
          if (!other.cell_.isEmpty()) {
            if (cell_.isEmpty()) {
              cell_ = other.cell_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureCellIsMutable();
              cell_.addAll(other.cell_);
            }
            onChanged();
          }
        } else {
          if (!other.cell_.isEmpty()) {
            if (cellBuilder_.isEmpty()) {
              cellBuilder_.dispose();
              cellBuilder_ = null;
              cell_ = other.cell_;
              bitField0_ = (bitField0_ & ~0x00000001);
              cellBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getCellFieldBuilder() : null;
            } else {
              cellBuilder_.addAllMessages(other.cell_);
            }
          }
        }
        if (other.hasAssociatedCellCount()) {
          setAssociatedCellCount(other.getAssociatedCellCount());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .Cell cell = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell> cell_ =
        java.util.Collections.emptyList();
      private void ensureCellIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          cell_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell>(cell_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell, org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder, org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder> cellBuilder_;

      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell> getCellList() {
        if (cellBuilder_ == null) {
          return java.util.Collections.unmodifiableList(cell_);
        } else {
          return cellBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public int getCellCount() {
        if (cellBuilder_ == null) {
          return cell_.size();
        } else {
          return cellBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell getCell(int index) {
        if (cellBuilder_ == null) {
          return cell_.get(index);
        } else {
          return cellBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder setCell(
          int index, org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell value) {
        if (cellBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCellIsMutable();
          cell_.set(index, value);
          onChanged();
        } else {
          cellBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder setCell(
          int index, org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder builderForValue) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          cell_.set(index, builderForValue.build());
          onChanged();
        } else {
          cellBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder addCell(org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell value) {
        if (cellBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCellIsMutable();
          cell_.add(value);
          onChanged();
        } else {
          cellBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder addCell(
          int index, org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell value) {
        if (cellBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureCellIsMutable();
          cell_.add(index, value);
          onChanged();
        } else {
          cellBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder addCell(
          org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder builderForValue) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          cell_.add(builderForValue.build());
          onChanged();
        } else {
          cellBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder addCell(
          int index, org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder builderForValue) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          cell_.add(index, builderForValue.build());
          onChanged();
        } else {
          cellBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder addAllCell(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell> values) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          super.addAll(values, cell_);
          onChanged();
        } else {
          cellBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder clearCell() {
        if (cellBuilder_ == null) {
          cell_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          cellBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public Builder removeCell(int index) {
        if (cellBuilder_ == null) {
          ensureCellIsMutable();
          cell_.remove(index);
          onChanged();
        } else {
          cellBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder getCellBuilder(
          int index) {
        return getCellFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder getCellOrBuilder(
          int index) {
        if (cellBuilder_ == null) {
          return cell_.get(index);  } else {
          return cellBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder> 
           getCellOrBuilderList() {
        if (cellBuilder_ != null) {
          return cellBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(cell_);
        }
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder addCellBuilder() {
        return getCellFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.getDefaultInstance());
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder addCellBuilder(
          int index) {
        return getCellFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.getDefaultInstance());
      }
      /**
       * <code>repeated .Cell cell = 1;</code>
       *
       * <pre>
       * Result includes the Cells or else it just has a count of Cells
       * that are carried otherwise.
       * </pre>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder> 
           getCellBuilderList() {
        return getCellFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell, org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder, org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder> 
          getCellFieldBuilder() {
        if (cellBuilder_ == null) {
          cellBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell, org.apache.hadoop.hbase.protobuf.generated.CellProtos.Cell.Builder, org.apache.hadoop.hbase.protobuf.generated.CellProtos.CellOrBuilder>(
                  cell_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          cell_ = null;
        }
        return cellBuilder_;
      }

      // optional int32 associated_cell_count = 2;
      private int associatedCellCount_ ;
      /**
       * <code>optional int32 associated_cell_count = 2;</code>
       *
       * <pre>
       * The below count is set when the associated cells are
       * not part of this protobuf message; they are passed alongside
       * and then this Message is just a placeholder with metadata.
       * The count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       */
      public boolean hasAssociatedCellCount() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 associated_cell_count = 2;</code>
       *
       * <pre>
       * The below count is set when the associated cells are
       * not part of this protobuf message; they are passed alongside
       * and then this Message is just a placeholder with metadata.
       * The count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       */
      public int getAssociatedCellCount() {
        return associatedCellCount_;
      }
      /**
       * <code>optional int32 associated_cell_count = 2;</code>
       *
       * <pre>
       * The below count is set when the associated cells are
       * not part of this protobuf message; they are passed alongside
       * and then this Message is just a placeholder with metadata.
       * The count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       */
      public Builder setAssociatedCellCount(int value) {
        bitField0_ |= 0x00000002;
        associatedCellCount_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 associated_cell_count = 2;</code>
       *
       * <pre>
       * The below count is set when the associated cells are
       * not part of this protobuf message; they are passed alongside
       * and then this Message is just a placeholder with metadata.
       * The count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       */
      public Builder clearAssociatedCellCount() {
        bitField0_ = (bitField0_ & ~0x00000002);
        associatedCellCount_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:Result)
    }

    static {
      defaultInstance = new Result(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:Result)
  }

  public interface GetRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier region = 1;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    // required .Get get = 2;
    /**
     * <code>required .Get get = 2;</code>
     */
    boolean hasGet();
    /**
     * <code>required .Get get = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet();
    /**
     * <code>required .Get get = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder();

    // optional bool closest_row_before = 3;
    /**
     * <code>optional bool closest_row_before = 3;</code>
     *
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before.
     * </pre>
     */
    boolean hasClosestRowBefore();
    /**
     * <code>optional bool closest_row_before = 3;</code>
     *
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before.
     * </pre>
     */
    boolean getClosestRowBefore();

    // optional bool existence_only = 4;
    /**
     * <code>optional bool existence_only = 4;</code>
     *
     * <pre>
     * The result isn't asked for, just check for
     * the existence. If closest_row_before specified,
     * this will be ignored
     * </pre>
     */
    boolean hasExistenceOnly();
    /**
     * <code>optional bool existence_only = 4;</code>
     *
     * <pre>
     * The result isn't asked for, just check for
     * the existence. If closest_row_before specified,
     * this will be ignored
     * </pre>
     */
    boolean getExistenceOnly();
  }
  /**
   * Protobuf type {@code GetRequest}
   *
   * <pre>
   **
   * The get request. Perform a single Get operation.
   * Unless existence_only is specified, return all the requested data
   * for the row that matches exactly, or the one that immediately
   * precedes it if closest_row_before is specified.
   *
   * If existence_only is set, only the existence will be returned.
   * </pre>
   */
  public static final class GetRequest extends
      com.google.protobuf.GeneratedMessage
      implements GetRequestOrBuilder {
    // Use GetRequest.newBuilder() to construct.
    private GetRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GetRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GetRequest defaultInstance;
    public static GetRequest getDefaultInstance() {
      return defaultInstance;
    }

    public GetRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GetRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = get_.toBuilder();
              }
              get_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(get_);
                get_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              closestRowBefore_ = input.readBool();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              existenceOnly_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<GetRequest> PARSER =
        new com.google.protobuf.AbstractParser<GetRequest>() {
      public GetRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GetRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GetRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }

    // required .Get get = 2;
    public static final int GET_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get get_;
    /**
     * <code>required .Get get = 2;</code>
     */
    public boolean hasGet() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .Get get = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet() {
      return get_;
    }
    /**
     * <code>required .Get get = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
      return get_;
    }

    // optional bool closest_row_before = 3;
    public static final int CLOSEST_ROW_BEFORE_FIELD_NUMBER = 3;
    private boolean closestRowBefore_;
    /**
     * <code>optional bool closest_row_before = 3;</code>
     *
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before.
     * </pre>
     */
    public boolean hasClosestRowBefore() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool closest_row_before = 3;</code>
     *
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before.
     * </pre>
     */
    public boolean getClosestRowBefore() {
      return closestRowBefore_;
    }

    // optional bool existence_only = 4;
    public static final int EXISTENCE_ONLY_FIELD_NUMBER = 4;
    private boolean existenceOnly_;
    /**
     * <code>optional bool existence_only = 4;</code>
     *
     * <pre>
     * The result isn't asked for, just check for
     * the existence. If closest_row_before specified,
     * this will be ignored
     * </pre>
     */
    public boolean hasExistenceOnly() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional bool existence_only = 4;</code>
     *
     * <pre>
     * The result isn't asked for, just check for
     * the existence. If closest_row_before specified,
     * this will be ignored
     * </pre>
     */
    public boolean getExistenceOnly() {
      return existenceOnly_;
    }

    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      closestRowBefore_ = false;
      existenceOnly_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasGet()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getGet().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, get_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(3, closestRowBefore_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBool(4, existenceOnly_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, get_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, closestRowBefore_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, existenceOnly_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasGet() == other.hasGet());
      if (hasGet()) {
        result = result && getGet()
            .equals(other.getGet());
      }
      result = result && (hasClosestRowBefore() == other.hasClosestRowBefore());
      if (hasClosestRowBefore()) {
        result = result && (getClosestRowBefore()
            == other.getClosestRowBefore());
      }
      result = result && (hasExistenceOnly() == other.hasExistenceOnly());
      if (hasExistenceOnly()) {
        result = result && (getExistenceOnly()
            == other.getExistenceOnly());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasGet()) {
        hash = (37 * hash) + GET_FIELD_NUMBER;
        hash = (53 * hash) + getGet().hashCode();
      }
      if (hasClosestRowBefore()) {
        hash = (37 * hash) + CLOSEST_ROW_BEFORE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getClosestRowBefore());
      }
      if (hasExistenceOnly()) {
        hash = (37 * hash) + EXISTENCE_ONLY_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getExistenceOnly());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code GetRequest}
     *
     * <pre>
     **
     * The get request. Perform a single Get operation.
     * Unless existence_only is specified, return all the requested data
     * for the row that matches exactly, or the one that immediately
     * precedes it if closest_row_before is specified.
     *
     * If existence_only is set, only the existence will be returned.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getGetFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (getBuilder_ == null) {
          get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
        } else {
          getBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        closestRowBefore_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        existenceOnly_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (getBuilder_ == null) {
          result.get_ = get_;
        } else {
          result.get_ = getBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.closestRowBefore_ = closestRowBefore_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.existenceOnly_ = existenceOnly_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasGet()) {
          mergeGet(other.getGet());
        }
        if (other.hasClosestRowBefore()) {
          setClosestRowBefore(other.getClosestRowBefore());
        }
        if (other.hasExistenceOnly()) {
          setExistenceOnly(other.getExistenceOnly());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasGet()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getGet().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      // required .Get get = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> getBuilder_;
      /**
       * <code>required .Get get = 2;</code>
       */
      public boolean hasGet() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet() {
        if (getBuilder_ == null) {
          return get_;
        } else {
          return getBuilder_.getMessage();
        }
      }
      /**
       * <code>required .Get get = 2;</code>
       */
      public Builder setGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          get_ = value;
          onChanged();
        } else {
          getBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .Get get = 2;</code>
       */
      public Builder setGet(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          get_ = builderForValue.build();
          onChanged();
        } else {
          getBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .Get get = 2;</code>
       */
      public Builder mergeGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              get_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance()) {
            get_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.newBuilder(get_).mergeFrom(value).buildPartial();
          } else {
            get_ = value;
          }
          onChanged();
        } else {
          getBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .Get get = 2;</code>
       */
      public Builder clearGet() {
        if (getBuilder_ == null) {
          get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
          onChanged();
        } else {
          getBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder getGetBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getGetFieldBuilder().getBuilder();
      }
      /**
       * <code>required .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
        if (getBuilder_ != null) {
          return getBuilder_.getMessageOrBuilder();
        } else {
          return get_;
        }
      }
      /**
       * <code>required .Get get = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> 
          getGetFieldBuilder() {
        if (getBuilder_ == null) {
          getBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder>(
                  get_,
                  getParentForChildren(),
                  isClean());
          get_ = null;
        }
        return getBuilder_;
      }

      // optional bool closest_row_before = 3;
      private boolean closestRowBefore_ ;
      /**
       * <code>optional bool closest_row_before = 3;</code>
       *
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before.
       * </pre>
       */
      public boolean hasClosestRowBefore() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bool closest_row_before = 3;</code>
       *
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before.
       * </pre>
       */
      public boolean getClosestRowBefore() {
        return closestRowBefore_;
      }
      /**
       * <code>optional bool closest_row_before = 3;</code>
       *
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before.
       * </pre>
       */
      public Builder setClosestRowBefore(boolean value) {
        bitField0_ |= 0x00000004;
        closestRowBefore_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool closest_row_before = 3;</code>
       *
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before.
       * </pre>
       */
      public Builder clearClosestRowBefore() {
        bitField0_ = (bitField0_ & ~0x00000004);
        closestRowBefore_ = false;
        onChanged();
        return this;
      }

      // optional bool existence_only = 4;
      private boolean existenceOnly_ ;
      /**
       * <code>optional bool existence_only = 4;</code>
       *
       * <pre>
       * The result isn't asked for, just check for
       * the existence. If closest_row_before specified,
       * this will be ignored
       * </pre>
       */
      public boolean hasExistenceOnly() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional bool existence_only = 4;</code>
       *
       * <pre>
       * The result isn't asked for, just check for
       * the existence. If closest_row_before specified,
       * this will be ignored
       * </pre>
       */
      public boolean getExistenceOnly() {
        return existenceOnly_;
      }
      /**
       * <code>optional bool existence_only = 4;</code>
       *
       * <pre>
       * The result isn't asked for, just check for
       * the existence. If closest_row_before specified,
       * this will be ignored
       * </pre>
       */
      public Builder setExistenceOnly(boolean value) {
        bitField0_ |= 0x00000008;
        existenceOnly_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool existence_only = 4;</code>
       *
       * <pre>
       * The result isn't asked for, just check for
       * the existence. If closest_row_before specified,
       * this will be ignored
       * </pre>
       */
      public Builder clearExistenceOnly() {
        bitField0_ = (bitField0_ & ~0x00000008);
        existenceOnly_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:GetRequest)
    }

    static {
      defaultInstance = new GetRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:GetRequest)
  }

  public interface MultiGetRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier region = 1;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    // repeated .Get get = 2;
    /**
     * <code>repeated .Get get = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get> 
        getGetList();
    /**
     * <code>repeated .Get get = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet(int index);
    /**
     * <code>repeated .Get get = 2;</code>
     */
    int getGetCount();
    /**
     * <code>repeated .Get get = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> 
        getGetOrBuilderList();
    /**
     * <code>repeated .Get get = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder(
        int index);

    // optional bool closest_row_before = 3;
    /**
     * <code>optional bool closest_row_before = 3;</code>
     *
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before.
     * </pre>
     */
    boolean hasClosestRowBefore();
    /**
     * <code>optional bool closest_row_before = 3;</code>
     *
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before.
     * </pre>
     */
    boolean getClosestRowBefore();

    // optional bool existence_only = 4;
    /**
     * <code>optional bool existence_only = 4;</code>
     *
     * <pre>
     * The result isn't asked for, just check for
     * the existence. If closest_row_before specified,
     * this will be ignored
     * </pre>
     */
    boolean hasExistenceOnly();
    /**
     * <code>optional bool existence_only = 4;</code>
     *
     * <pre>
     * The result isn't asked for, just check for
     * the existence. If closest_row_before specified,
     * this will be ignored
     * </pre>
     */
    boolean getExistenceOnly();
  }
  /**
   * Protobuf type {@code MultiGetRequest}
   */
  public static final class MultiGetRequest extends
      com.google.protobuf.GeneratedMessage
      implements MultiGetRequestOrBuilder {
    // Use MultiGetRequest.newBuilder() to construct.
    private MultiGetRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MultiGetRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MultiGetRequest defaultInstance;
    public static MultiGetRequest getDefaultInstance() {
      return defaultInstance;
    }

    public MultiGetRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MultiGetRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                get_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get>();
                mutable_bitField0_ |= 0x00000002;
              }
              get_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.PARSER, extensionRegistry));
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              closestRowBefore_ = input.readBool();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000004;
              existenceOnly_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          get_ = java.util.Collections.unmodifiableList(get_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<MultiGetRequest> PARSER =
        new com.google.protobuf.AbstractParser<MultiGetRequest>() {
      public MultiGetRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MultiGetRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MultiGetRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }

    // repeated .Get get = 2;
    public static final int GET_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get> get_;
    /**
     * <code>repeated .Get get = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get> getGetList() {
      return get_;
    }
    /**
     * <code>repeated .Get get = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> 
        getGetOrBuilderList() {
      return get_;
    }
    /**
     * <code>repeated .Get get = 2;</code>
     */
    public int getGetCount() {
      return get_.size();
    }
    /**
     * <code>repeated .Get get = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet(int index) {
      return get_.get(index);
    }
    /**
     * <code>repeated .Get get = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder(
        int index) {
      return get_.get(index);
    }

    // optional bool closest_row_before = 3;
    public static final int CLOSEST_ROW_BEFORE_FIELD_NUMBER = 3;
    private boolean closestRowBefore_;
    /**
     * <code>optional bool closest_row_before = 3;</code>
     *
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before.
     * </pre>
     */
    public boolean hasClosestRowBefore() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool closest_row_before = 3;</code>
     *
     * <pre>
     * If the row to get doesn't exist, return the
     * closest row before.
     * </pre>
     */
    public boolean getClosestRowBefore() {
      return closestRowBefore_;
    }

    // optional bool existence_only = 4;
    public static final int EXISTENCE_ONLY_FIELD_NUMBER = 4;
    private boolean existenceOnly_;
    /**
     * <code>optional bool existence_only = 4;</code>
     *
     * <pre>
     * The result isn't asked for, just check for
     * the existence. If closest_row_before specified,
     * this will be ignored
     * </pre>
     */
    public boolean hasExistenceOnly() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional bool existence_only = 4;</code>
     *
     * <pre>
     * The result isn't asked for, just check for
     * the existence. If closest_row_before specified,
     * this will be ignored
     * </pre>
     */
    public boolean getExistenceOnly() {
      return existenceOnly_;
    }

    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      get_ = java.util.Collections.emptyList();
      closestRowBefore_ = false;
      existenceOnly_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getGetCount(); i++) {
        if (!getGet(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      for (int i = 0; i < get_.size(); i++) {
        output.writeMessage(2, get_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(3, closestRowBefore_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBool(4, existenceOnly_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      for (int i = 0; i < get_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, get_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, closestRowBefore_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(4, existenceOnly_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && getGetList()
          .equals(other.getGetList());
      result = result && (hasClosestRowBefore() == other.hasClosestRowBefore());
      if (hasClosestRowBefore()) {
        result = result && (getClosestRowBefore()
            == other.getClosestRowBefore());
      }
      result = result && (hasExistenceOnly() == other.hasExistenceOnly());
      if (hasExistenceOnly()) {
        result = result && (getExistenceOnly()
            == other.getExistenceOnly());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (getGetCount() > 0) {
        hash = (37 * hash) + GET_FIELD_NUMBER;
        hash = (53 * hash) + getGetList().hashCode();
      }
      if (hasClosestRowBefore()) {
        hash = (37 * hash) + CLOSEST_ROW_BEFORE_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getClosestRowBefore());
      }
      if (hasExistenceOnly()) {
        hash = (37 * hash) + EXISTENCE_ONLY_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getExistenceOnly());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MultiGetRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getGetFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (getBuilder_ == null) {
          get_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          getBuilder_.clear();
        }
        closestRowBefore_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        existenceOnly_ = false;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (getBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            get_ = java.util.Collections.unmodifiableList(get_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.get_ = get_;
        } else {
          result.get_ = getBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.closestRowBefore_ = closestRowBefore_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        result.existenceOnly_ = existenceOnly_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (getBuilder_ == null) {
          if (!other.get_.isEmpty()) {
            if (get_.isEmpty()) {
              get_ = other.get_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureGetIsMutable();
              get_.addAll(other.get_);
            }
            onChanged();
          }
        } else {
          if (!other.get_.isEmpty()) {
            if (getBuilder_.isEmpty()) {
              getBuilder_.dispose();
              getBuilder_ = null;
              get_ = other.get_;
              bitField0_ = (bitField0_ & ~0x00000002);
              getBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getGetFieldBuilder() : null;
            } else {
              getBuilder_.addAllMessages(other.get_);
            }
          }
        }
        if (other.hasClosestRowBefore()) {
          setClosestRowBefore(other.getClosestRowBefore());
        }
        if (other.hasExistenceOnly()) {
          setExistenceOnly(other.getExistenceOnly());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        for (int i = 0; i < getGetCount(); i++) {
          if (!getGet(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      // repeated .Get get = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get> get_ =
        java.util.Collections.emptyList();
      private void ensureGetIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          get_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get>(get_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> getBuilder_;

      /**
       * <code>repeated .Get get = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get> getGetList() {
        if (getBuilder_ == null) {
          return java.util.Collections.unmodifiableList(get_);
        } else {
          return getBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public int getGetCount() {
        if (getBuilder_ == null) {
          return get_.size();
        } else {
          return getBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet(int index) {
        if (getBuilder_ == null) {
          return get_.get(index);
        } else {
          return getBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder setGet(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureGetIsMutable();
          get_.set(index, value);
          onChanged();
        } else {
          getBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder setGet(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          ensureGetIsMutable();
          get_.set(index, builderForValue.build());
          onChanged();
        } else {
          getBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder addGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureGetIsMutable();
          get_.add(value);
          onChanged();
        } else {
          getBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder addGet(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureGetIsMutable();
          get_.add(index, value);
          onChanged();
        } else {
          getBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder addGet(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          ensureGetIsMutable();
          get_.add(builderForValue.build());
          onChanged();
        } else {
          getBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder addGet(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          ensureGetIsMutable();
          get_.add(index, builderForValue.build());
          onChanged();
        } else {
          getBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder addAllGet(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get> values) {
        if (getBuilder_ == null) {
          ensureGetIsMutable();
          super.addAll(values, get_);
          onChanged();
        } else {
          getBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder clearGet() {
        if (getBuilder_ == null) {
          get_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          getBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public Builder removeGet(int index) {
        if (getBuilder_ == null) {
          ensureGetIsMutable();
          get_.remove(index);
          onChanged();
        } else {
          getBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder getGetBuilder(
          int index) {
        return getGetFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder(
          int index) {
        if (getBuilder_ == null) {
          return get_.get(index);  } else {
          return getBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> 
           getGetOrBuilderList() {
        if (getBuilder_ != null) {
          return getBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(get_);
        }
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder addGetBuilder() {
        return getGetFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance());
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder addGetBuilder(
          int index) {
        return getGetFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance());
      }
      /**
       * <code>repeated .Get get = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder> 
           getGetBuilderList() {
        return getGetFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> 
          getGetFieldBuilder() {
        if (getBuilder_ == null) {
          getBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder>(
                  get_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          get_ = null;
        }
        return getBuilder_;
      }

      // optional bool closest_row_before = 3;
      private boolean closestRowBefore_ ;
      /**
       * <code>optional bool closest_row_before = 3;</code>
       *
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before.
       * </pre>
       */
      public boolean hasClosestRowBefore() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bool closest_row_before = 3;</code>
       *
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before.
       * </pre>
       */
      public boolean getClosestRowBefore() {
        return closestRowBefore_;
      }
      /**
       * <code>optional bool closest_row_before = 3;</code>
       *
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before.
       * </pre>
       */
      public Builder setClosestRowBefore(boolean value) {
        bitField0_ |= 0x00000004;
        closestRowBefore_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool closest_row_before = 3;</code>
       *
       * <pre>
       * If the row to get doesn't exist, return the
       * closest row before.
       * </pre>
       */
      public Builder clearClosestRowBefore() {
        bitField0_ = (bitField0_ & ~0x00000004);
        closestRowBefore_ = false;
        onChanged();
        return this;
      }

      // optional bool existence_only = 4;
      private boolean existenceOnly_ ;
      /**
       * <code>optional bool existence_only = 4;</code>
       *
       * <pre>
       * The result isn't asked for, just check for
       * the existence. If closest_row_before specified,
       * this will be ignored
       * </pre>
       */
      public boolean hasExistenceOnly() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional bool existence_only = 4;</code>
       *
       * <pre>
       * The result isn't asked for, just check for
       * the existence. If closest_row_before specified,
       * this will be ignored
       * </pre>
       */
      public boolean getExistenceOnly() {
        return existenceOnly_;
      }
      /**
       * <code>optional bool existence_only = 4;</code>
       *
       * <pre>
       * The result isn't asked for, just check for
       * the existence. If closest_row_before specified,
       * this will be ignored
       * </pre>
       */
      public Builder setExistenceOnly(boolean value) {
        bitField0_ |= 0x00000008;
        existenceOnly_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool existence_only = 4;</code>
       *
       * <pre>
       * The result isn't asked for, just check for
       * the existence. If closest_row_before specified,
       * this will be ignored
       * </pre>
       */
      public Builder clearExistenceOnly() {
        bitField0_ = (bitField0_ & ~0x00000008);
        existenceOnly_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:MultiGetRequest)
    }

    static {
      defaultInstance = new MultiGetRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MultiGetRequest)
  }

  public interface GetResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .Result result = 1;
    /**
     * <code>optional .Result result = 1;</code>
     */
    boolean hasResult();
    /**
     * <code>optional .Result result = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult();
    /**
     * <code>optional .Result result = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder();

    // optional bool exists = 2;
    /**
     * <code>optional bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    boolean hasExists();
    /**
     * <code>optional bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    boolean getExists();
  }
  /**
   * Protobuf type {@code GetResponse}
   */
  public static final class GetResponse extends
      com.google.protobuf.GeneratedMessage
      implements GetResponseOrBuilder {
    // Use GetResponse.newBuilder() to construct.
    private GetResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private GetResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final GetResponse defaultInstance;
    public static GetResponse getDefaultInstance() {
      return defaultInstance;
    }

    public GetResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private GetResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = result_.toBuilder();
              }
              result_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(result_);
                result_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              exists_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<GetResponse> PARSER =
        new com.google.protobuf.AbstractParser<GetResponse>() {
      public GetResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new GetResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<GetResponse> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .Result result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result_;
    /**
     * <code>optional .Result result = 1;</code>
     */
    public boolean hasResult() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .Result result = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult() {
      return result_;
    }
    /**
     * <code>optional .Result result = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
      return result_;
    }

    // optional bool exists = 2;
    public static final int EXISTS_FIELD_NUMBER = 2;
    private boolean exists_;
    /**
     * <code>optional bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    public boolean hasExists() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    public boolean getExists() {
      return exists_;
    }

    private void initFields() {
      result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      exists_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, result_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, exists_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, exists_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse) obj;

      boolean result = true;
      result = result && (hasResult() == other.hasResult());
      if (hasResult()) {
        result = result && getResult()
            .equals(other.getResult());
      }
      result = result && (hasExists() == other.hasExists());
      if (hasExists()) {
        result = result && (getExists()
            == other.getExists());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResult()) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResult().hashCode();
      }
      if (hasExists()) {
        hash = (37 * hash) + EXISTS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getExists());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code GetResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
        } else {
          resultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        exists_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_GetResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resultBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.exists_ = exists_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance()) return this;
        if (other.hasResult()) {
          mergeResult(other.getResult());
        }
        if (other.hasExists()) {
          setExists(other.getExists());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .Result result = 1;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;
      /**
       * <code>optional .Result result = 1;</code>
       */
      public boolean hasResult() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult() {
        if (resultBuilder_ == null) {
          return result_;
        } else {
          return resultBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public Builder setResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          result_ = value;
          onChanged();
        } else {
          resultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public Builder setResult(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          result_ = builderForValue.build();
          onChanged();
        } else {
          resultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public Builder mergeResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              result_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance()) {
            result_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder(result_).mergeFrom(value).buildPartial();
          } else {
            result_ = value;
          }
          onChanged();
        } else {
          resultBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder getResultBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResultFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilder();
        } else {
          return result_;
        }
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  result_,
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }

      // optional bool exists = 2;
      private boolean exists_ ;
      /**
       * <code>optional bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public boolean hasExists() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public boolean getExists() {
        return exists_;
      }
      /**
       * <code>optional bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public Builder setExists(boolean value) {
        bitField0_ |= 0x00000002;
        exists_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public Builder clearExists() {
        bitField0_ = (bitField0_ & ~0x00000002);
        exists_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:GetResponse)
    }

    static {
      defaultInstance = new GetResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:GetResponse)
  }

  public interface MultiGetResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .Result result = 1;
    /**
     * <code>repeated .Result result = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> 
        getResultList();
    /**
     * <code>repeated .Result result = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult(int index);
    /**
     * <code>repeated .Result result = 1;</code>
     */
    int getResultCount();
    /**
     * <code>repeated .Result result = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
        getResultOrBuilderList();
    /**
     * <code>repeated .Result result = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder(
        int index);

    // repeated bool exists = 2;
    /**
     * <code>repeated bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    java.util.List<java.lang.Boolean> getExistsList();
    /**
     * <code>repeated bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    int getExistsCount();
    /**
     * <code>repeated bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    boolean getExists(int index);
  }
  /**
   * Protobuf type {@code MultiGetResponse}
   */
  public static final class MultiGetResponse extends
      com.google.protobuf.GeneratedMessage
      implements MultiGetResponseOrBuilder {
    // Use MultiGetResponse.newBuilder() to construct.
    private MultiGetResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MultiGetResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MultiGetResponse defaultInstance;
    public static MultiGetResponse getDefaultInstance() {
      return defaultInstance;
    }

    public MultiGetResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MultiGetResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                result_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result>();
                mutable_bitField0_ |= 0x00000001;
              }
              result_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.PARSER, extensionRegistry));
              break;
            }
            case 16: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                exists_ = new java.util.ArrayList<java.lang.Boolean>();
                mutable_bitField0_ |= 0x00000002;
              }
              exists_.add(input.readBool());
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002) && input.getBytesUntilLimit() > 0) {
                exists_ = new java.util.ArrayList<java.lang.Boolean>();
                mutable_bitField0_ |= 0x00000002;
              }
              while (input.getBytesUntilLimit() > 0) {
                exists_.add(input.readBool());
              }
              input.popLimit(limit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          result_ = java.util.Collections.unmodifiableList(result_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          exists_ = java.util.Collections.unmodifiableList(exists_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<MultiGetResponse> PARSER =
        new com.google.protobuf.AbstractParser<MultiGetResponse>() {
      public MultiGetResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MultiGetResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MultiGetResponse> getParserForType() {
      return PARSER;
    }

    // repeated .Result result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> result_;
    /**
     * <code>repeated .Result result = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> getResultList() {
      return result_;
    }
    /**
     * <code>repeated .Result result = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
        getResultOrBuilderList() {
      return result_;
    }
    /**
     * <code>repeated .Result result = 1;</code>
     */
    public int getResultCount() {
      return result_.size();
    }
    /**
     * <code>repeated .Result result = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult(int index) {
      return result_.get(index);
    }
    /**
     * <code>repeated .Result result = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder(
        int index) {
      return result_.get(index);
    }

    // repeated bool exists = 2;
    public static final int EXISTS_FIELD_NUMBER = 2;
    private java.util.List<java.lang.Boolean> exists_;
    /**
     * <code>repeated bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    public java.util.List<java.lang.Boolean>
        getExistsList() {
      return exists_;
    }
    /**
     * <code>repeated bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    public int getExistsCount() {
      return exists_.size();
    }
    /**
     * <code>repeated bool exists = 2;</code>
     *
     * <pre>
     * used for Get to check existence only
     * </pre>
     */
    public boolean getExists(int index) {
      return exists_.get(index);
    }

    private void initFields() {
      result_ = java.util.Collections.emptyList();
      exists_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < result_.size(); i++) {
        output.writeMessage(1, result_.get(i));
      }
      for (int i = 0; i < exists_.size(); i++) {
        output.writeBool(2, exists_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < result_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_.get(i));
      }
      {
        int dataSize = 0;
        dataSize = 1 * getExistsList().size();
        size += dataSize;
        size += 1 * getExistsList().size();
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse) obj;

      boolean result = true;
      result = result && getResultList()
          .equals(other.getResultList());
      result = result && getExistsList()
          .equals(other.getExistsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResultCount() > 0) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResultList().hashCode();
      }
      if (getExistsCount() > 0) {
        hash = (37 * hash) + EXISTS_FIELD_NUMBER;
        hash = (53 * hash) + getExistsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MultiGetResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resultBuilder_.clear();
        }
        exists_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiGetResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse(this);
        int from_bitField0_ = bitField0_;
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            result_ = java.util.Collections.unmodifiableList(result_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          exists_ = java.util.Collections.unmodifiableList(exists_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.exists_ = exists_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.getDefaultInstance()) return this;
        if (resultBuilder_ == null) {
          if (!other.result_.isEmpty()) {
            if (result_.isEmpty()) {
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultIsMutable();
              result_.addAll(other.result_);
            }
            onChanged();
          }
        } else {
          if (!other.result_.isEmpty()) {
            if (resultBuilder_.isEmpty()) {
              resultBuilder_.dispose();
              resultBuilder_ = null;
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getResultFieldBuilder() : null;
            } else {
              resultBuilder_.addAllMessages(other.result_);
            }
          }
        }
        if (!other.exists_.isEmpty()) {
          if (exists_.isEmpty()) {
            exists_ = other.exists_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureExistsIsMutable();
            exists_.addAll(other.exists_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .Result result = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> result_ =
        java.util.Collections.emptyList();
      private void ensureResultIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          result_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result>(result_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;

      /**
       * <code>repeated .Result result = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> getResultList() {
        if (resultBuilder_ == null) {
          return java.util.Collections.unmodifiableList(result_);
        } else {
          return resultBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public int getResultCount() {
        if (resultBuilder_ == null) {
          return result_.size();
        } else {
          return resultBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult(int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);
        } else {
          return resultBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder setResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.set(index, value);
          onChanged();
        } else {
          resultBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder setResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder addResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(value);
          onChanged();
        } else {
          resultBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder addResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(index, value);
          onChanged();
        } else {
          resultBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder addResult(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder addResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder addAllResult(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> values) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          super.addAll(values, result_);
          onChanged();
        } else {
          resultBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public Builder removeResult(int index) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.remove(index);
          onChanged();
        } else {
          resultBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder getResultBuilder(
          int index) {
        return getResultFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder(
          int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);  } else {
          return resultBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
           getResultOrBuilderList() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(result_);
        }
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder addResultBuilder() {
        return getResultFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance());
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder addResultBuilder(
          int index) {
        return getResultFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance());
      }
      /**
       * <code>repeated .Result result = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder> 
           getResultBuilderList() {
        return getResultFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  result_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }

      // repeated bool exists = 2;
      private java.util.List<java.lang.Boolean> exists_ = java.util.Collections.emptyList();
      private void ensureExistsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          exists_ = new java.util.ArrayList<java.lang.Boolean>(exists_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public java.util.List<java.lang.Boolean>
          getExistsList() {
        return java.util.Collections.unmodifiableList(exists_);
      }
      /**
       * <code>repeated bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public int getExistsCount() {
        return exists_.size();
      }
      /**
       * <code>repeated bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public boolean getExists(int index) {
        return exists_.get(index);
      }
      /**
       * <code>repeated bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public Builder setExists(
          int index, boolean value) {
        ensureExistsIsMutable();
        exists_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public Builder addExists(boolean value) {
        ensureExistsIsMutable();
        exists_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public Builder addAllExists(
          java.lang.Iterable<? extends java.lang.Boolean> values) {
        ensureExistsIsMutable();
        super.addAll(values, exists_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated bool exists = 2;</code>
       *
       * <pre>
       * used for Get to check existence only
       * </pre>
       */
      public Builder clearExists() {
        exists_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:MultiGetResponse)
    }

    static {
      defaultInstance = new MultiGetResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MultiGetResponse)
  }

  public interface ConditionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes row = 1;
    /**
     * <code>required bytes row = 1;</code>
     */
    boolean hasRow();
    /**
     * <code>required bytes row = 1;</code>
     */
    com.google.protobuf.ByteString getRow();

    // required bytes family = 2;
    /**
     * <code>required bytes family = 2;</code>
     */
    boolean hasFamily();
    /**
     * <code>required bytes family = 2;</code>
     */
    com.google.protobuf.ByteString getFamily();

    // required bytes qualifier = 3;
    /**
     * <code>required bytes qualifier = 3;</code>
     */
    boolean hasQualifier();
    /**
     * <code>required bytes qualifier = 3;</code>
     */
    com.google.protobuf.ByteString getQualifier();

    // required .CompareType compare_type = 4;
    /**
     * <code>required .CompareType compare_type = 4;</code>
     */
    boolean hasCompareType();
    /**
     * <code>required .CompareType compare_type = 4;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType getCompareType();

    // required .Comparator comparator = 5;
    /**
     * <code>required .Comparator comparator = 5;</code>
     */
    boolean hasComparator();
    /**
     * <code>required .Comparator comparator = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator getComparator();
    /**
     * <code>required .Comparator comparator = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder();
  }
  /**
   * Protobuf type {@code Condition}
   *
   * <pre>
   **
   * Condition to check if the value of a given cell (row,
   * family, qualifier) matches a value via a given comparator.
   *
   * Condition is used in check and mutate operations.
   * </pre>
   */
  public static final class Condition extends
      com.google.protobuf.GeneratedMessage
      implements ConditionOrBuilder {
    // Use Condition.newBuilder() to construct.
    private Condition(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Condition(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Condition defaultInstance;
    public static Condition getDefaultInstance() {
      return defaultInstance;
    }

    public Condition getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Condition(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              family_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              qualifier_ = input.readBytes();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType value = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                compareType_ = value;
              }
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = comparator_.toBuilder();
              }
              comparator_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(comparator_);
                comparator_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder.class);
    }

    public static com.google.protobuf.Parser<Condition> PARSER =
        new com.google.protobuf.AbstractParser<Condition>() {
      public Condition parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Condition(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Condition> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    /**
     * <code>required bytes row = 1;</code>
     */
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes row = 1;</code>
     */
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }

    // required bytes family = 2;
    public static final int FAMILY_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString family_;
    /**
     * <code>required bytes family = 2;</code>
     */
    public boolean hasFamily() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required bytes family = 2;</code>
     */
    public com.google.protobuf.ByteString getFamily() {
      return family_;
    }

    // required bytes qualifier = 3;
    public static final int QUALIFIER_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString qualifier_;
    /**
     * <code>required bytes qualifier = 3;</code>
     */
    public boolean hasQualifier() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required bytes qualifier = 3;</code>
     */
    public com.google.protobuf.ByteString getQualifier() {
      return qualifier_;
    }

    // required .CompareType compare_type = 4;
    public static final int COMPARE_TYPE_FIELD_NUMBER = 4;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType compareType_;
    /**
     * <code>required .CompareType compare_type = 4;</code>
     */
    public boolean hasCompareType() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>required .CompareType compare_type = 4;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType getCompareType() {
      return compareType_;
    }

    // required .Comparator comparator = 5;
    public static final int COMPARATOR_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator comparator_;
    /**
     * <code>required .Comparator comparator = 5;</code>
     */
    public boolean hasComparator() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>required .Comparator comparator = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator getComparator() {
      return comparator_;
    }
    /**
     * <code>required .Comparator comparator = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
      return comparator_;
    }

    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      family_ = com.google.protobuf.ByteString.EMPTY;
      qualifier_ = com.google.protobuf.ByteString.EMPTY;
      compareType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.LESS;
      comparator_ = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasFamily()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasQualifier()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCompareType()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasComparator()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getComparator().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, compareType_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, comparator_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, family_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, qualifier_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, compareType_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, comparator_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition) obj;

      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasFamily() == other.hasFamily());
      if (hasFamily()) {
        result = result && getFamily()
            .equals(other.getFamily());
      }
      result = result && (hasQualifier() == other.hasQualifier());
      if (hasQualifier()) {
        result = result && getQualifier()
            .equals(other.getQualifier());
      }
      result = result && (hasCompareType() == other.hasCompareType());
      if (hasCompareType()) {
        result = result &&
            (getCompareType() == other.getCompareType());
      }
      result = result && (hasComparator() == other.hasComparator());
      if (hasComparator()) {
        result = result && getComparator()
            .equals(other.getComparator());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasFamily()) {
        hash = (37 * hash) + FAMILY_FIELD_NUMBER;
        hash = (53 * hash) + getFamily().hashCode();
      }
      if (hasQualifier()) {
        hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
        hash = (53 * hash) + getQualifier().hashCode();
      }
      if (hasCompareType()) {
        hash = (37 * hash) + COMPARE_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getCompareType());
      }
      if (hasComparator()) {
        hash = (37 * hash) + COMPARATOR_FIELD_NUMBER;
        hash = (53 * hash) + getComparator().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code Condition}
     *
     * <pre>
     **
     * Condition to check if the value of a given cell (row,
     * family, qualifier) matches a value via a given comparator.
     *
     * Condition is used in check and mutate operations.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getComparatorFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        family_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        qualifier_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        compareType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.LESS;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (comparatorBuilder_ == null) {
          comparator_ = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance();
        } else {
          comparatorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Condition_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.family_ = family_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.qualifier_ = qualifier_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.compareType_ = compareType_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (comparatorBuilder_ == null) {
          result.comparator_ = comparator_;
        } else {
          result.comparator_ = comparatorBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasFamily()) {
          setFamily(other.getFamily());
        }
        if (other.hasQualifier()) {
          setQualifier(other.getQualifier());
        }
        if (other.hasCompareType()) {
          setCompareType(other.getCompareType());
        }
        if (other.hasComparator()) {
          mergeComparator(other.getComparator());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        if (!hasFamily()) {
          
          return false;
        }
        if (!hasQualifier()) {
          
          return false;
        }
        if (!hasCompareType()) {
          
          return false;
        }
        if (!hasComparator()) {
          
          return false;
        }
        if (!getComparator().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes row = 1;</code>
       */
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      // required bytes family = 2;
      private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes family = 2;</code>
       */
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required bytes family = 2;</code>
       */
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }
      /**
       * <code>required bytes family = 2;</code>
       */
      public Builder setFamily(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        family_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes family = 2;</code>
       */
      public Builder clearFamily() {
        bitField0_ = (bitField0_ & ~0x00000002);
        family_ = getDefaultInstance().getFamily();
        onChanged();
        return this;
      }

      // required bytes qualifier = 3;
      private com.google.protobuf.ByteString qualifier_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes qualifier = 3;</code>
       */
      public boolean hasQualifier() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required bytes qualifier = 3;</code>
       */
      public com.google.protobuf.ByteString getQualifier() {
        return qualifier_;
      }
      /**
       * <code>required bytes qualifier = 3;</code>
       */
      public Builder setQualifier(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        qualifier_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes qualifier = 3;</code>
       */
      public Builder clearQualifier() {
        bitField0_ = (bitField0_ & ~0x00000004);
        qualifier_ = getDefaultInstance().getQualifier();
        onChanged();
        return this;
      }

      // required .CompareType compare_type = 4;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType compareType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.LESS;
      /**
       * <code>required .CompareType compare_type = 4;</code>
       */
      public boolean hasCompareType() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>required .CompareType compare_type = 4;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType getCompareType() {
        return compareType_;
      }
      /**
       * <code>required .CompareType compare_type = 4;</code>
       */
      public Builder setCompareType(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        compareType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required .CompareType compare_type = 4;</code>
       */
      public Builder clearCompareType() {
        bitField0_ = (bitField0_ & ~0x00000008);
        compareType_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.CompareType.LESS;
        onChanged();
        return this;
      }

      // required .Comparator comparator = 5;
      private org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator comparator_ = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> comparatorBuilder_;
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      public boolean hasComparator() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator getComparator() {
        if (comparatorBuilder_ == null) {
          return comparator_;
        } else {
          return comparatorBuilder_.getMessage();
        }
      }
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      public Builder setComparator(org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          comparator_ = value;
          onChanged();
        } else {
          comparatorBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      public Builder setComparator(
          org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder builderForValue) {
        if (comparatorBuilder_ == null) {
          comparator_ = builderForValue.build();
          onChanged();
        } else {
          comparatorBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      public Builder mergeComparator(org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator value) {
        if (comparatorBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              comparator_ != org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance()) {
            comparator_ =
              org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.newBuilder(comparator_).mergeFrom(value).buildPartial();
          } else {
            comparator_ = value;
          }
          onChanged();
        } else {
          comparatorBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      public Builder clearComparator() {
        if (comparatorBuilder_ == null) {
          comparator_ = org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.getDefaultInstance();
          onChanged();
        } else {
          comparatorBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder getComparatorBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getComparatorFieldBuilder().getBuilder();
      }
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder getComparatorOrBuilder() {
        if (comparatorBuilder_ != null) {
          return comparatorBuilder_.getMessageOrBuilder();
        } else {
          return comparator_;
        }
      }
      /**
       * <code>required .Comparator comparator = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder> 
          getComparatorFieldBuilder() {
        if (comparatorBuilder_ == null) {
          comparatorBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.Comparator.Builder, org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.ComparatorOrBuilder>(
                  comparator_,
                  getParentForChildren(),
                  isClean());
          comparator_ = null;
        }
        return comparatorBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:Condition)
    }

    static {
      defaultInstance = new Condition(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:Condition)
  }

  public interface MutationProtoOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional bytes row = 1;
    /**
     * <code>optional bytes row = 1;</code>
     */
    boolean hasRow();
    /**
     * <code>optional bytes row = 1;</code>
     */
    com.google.protobuf.ByteString getRow();

    // optional .MutationProto.MutationType mutate_type = 2;
    /**
     * <code>optional .MutationProto.MutationType mutate_type = 2;</code>
     */
    boolean hasMutateType();
    /**
     * <code>optional .MutationProto.MutationType mutate_type = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType getMutateType();

    // repeated .MutationProto.ColumnValue column_value = 3;
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue> 
        getColumnValueList();
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue getColumnValue(int index);
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    int getColumnValueCount();
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> 
        getColumnValueOrBuilderList();
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder getColumnValueOrBuilder(
        int index);

    // optional uint64 timestamp = 4;
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    boolean hasTimestamp();
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    long getTimestamp();

    // repeated .NameBytesPair attribute = 5;
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    int getAttributeCount();
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);

    // optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];
    /**
     * <code>optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
     */
    boolean hasDurability();
    /**
     * <code>optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability getDurability();

    // optional .TimeRange time_range = 7;
    /**
     * <code>optional .TimeRange time_range = 7;</code>
     *
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     */
    boolean hasTimeRange();
    /**
     * <code>optional .TimeRange time_range = 7;</code>
     *
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    /**
     * <code>optional .TimeRange time_range = 7;</code>
     *
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();

    // optional int32 associated_cell_count = 8;
    /**
     * <code>optional int32 associated_cell_count = 8;</code>
     *
     * <pre>
     * The below count is set when the associated cells are NOT
     * part of this protobuf message; they are passed alongside
     * and then this Message is a placeholder with metadata.  The
     * count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     */
    boolean hasAssociatedCellCount();
    /**
     * <code>optional int32 associated_cell_count = 8;</code>
     *
     * <pre>
     * The below count is set when the associated cells are NOT
     * part of this protobuf message; they are passed alongside
     * and then this Message is a placeholder with metadata.  The
     * count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     */
    int getAssociatedCellCount();
  }
  /**
   * Protobuf type {@code MutationProto}
   *
   * <pre>
   **
   * A specific mutation inside a mutate request.
   * It can be an append, increment, put or delete based
   * on the mutation type.  It can be fully filled in or
   * only metadata present because data is being carried
   * elsewhere outside of pb.
   * </pre>
   */
  public static final class MutationProto extends
      com.google.protobuf.GeneratedMessage
      implements MutationProtoOrBuilder {
    // Use MutationProto.newBuilder() to construct.
    private MutationProto(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MutationProto(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MutationProto defaultInstance;
    public static MutationProto getDefaultInstance() {
      return defaultInstance;
    }

    public MutationProto getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MutationProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType value = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                mutateType_ = value;
              }
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                columnValue_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue>();
                mutable_bitField0_ |= 0x00000004;
              }
              columnValue_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.PARSER, extensionRegistry));
              break;
            }
            case 32: {
              bitField0_ |= 0x00000004;
              timestamp_ = input.readUInt64();
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>();
                mutable_bitField0_ |= 0x00000010;
              }
              attribute_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.PARSER, extensionRegistry));
              break;
            }
            case 48: {
              int rawValue = input.readEnum();
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability value = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(6, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                durability_ = value;
              }
              break;
            }
            case 58: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = timeRange_.toBuilder();
              }
              timeRange_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(timeRange_);
                timeRange_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 64: {
              bitField0_ |= 0x00000020;
              associatedCellCount_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          columnValue_ = java.util.Collections.unmodifiableList(columnValue_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          attribute_ = java.util.Collections.unmodifiableList(attribute_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder.class);
    }

    public static com.google.protobuf.Parser<MutationProto> PARSER =
        new com.google.protobuf.AbstractParser<MutationProto>() {
      public MutationProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MutationProto(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MutationProto> getParserForType() {
      return PARSER;
    }

    /**
     * Protobuf enum {@code MutationProto.Durability}
     */
    public enum Durability
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>USE_DEFAULT = 0;</code>
       */
      USE_DEFAULT(0, 0),
      /**
       * <code>SKIP_WAL = 1;</code>
       */
      SKIP_WAL(1, 1),
      /**
       * <code>ASYNC_WAL = 2;</code>
       */
      ASYNC_WAL(2, 2),
      /**
       * <code>SYNC_WAL = 3;</code>
       */
      SYNC_WAL(3, 3),
      /**
       * <code>FSYNC_WAL = 4;</code>
       */
      FSYNC_WAL(4, 4),
      ;

      /**
       * <code>USE_DEFAULT = 0;</code>
       */
      public static final int USE_DEFAULT_VALUE = 0;
      /**
       * <code>SKIP_WAL = 1;</code>
       */
      public static final int SKIP_WAL_VALUE = 1;
      /**
       * <code>ASYNC_WAL = 2;</code>
       */
      public static final int ASYNC_WAL_VALUE = 2;
      /**
       * <code>SYNC_WAL = 3;</code>
       */
      public static final int SYNC_WAL_VALUE = 3;
      /**
       * <code>FSYNC_WAL = 4;</code>
       */
      public static final int FSYNC_WAL_VALUE = 4;


      public final int getNumber() { return value; }

      public static Durability valueOf(int value) {
        switch (value) {
          case 0: return USE_DEFAULT;
          case 1: return SKIP_WAL;
          case 2: return ASYNC_WAL;
          case 3: return SYNC_WAL;
          case 4: return FSYNC_WAL;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Durability>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<Durability>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Durability>() {
              public Durability findValueByNumber(int number) {
                return Durability.valueOf(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDescriptor().getEnumTypes().get(0);
      }

      private static final Durability[] VALUES = values();

      public static Durability valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int index;
      private final int value;

      private Durability(int index, int value) {
        this.index = index;
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:MutationProto.Durability)
    }

    /**
     * Protobuf enum {@code MutationProto.MutationType}
     */
    public enum MutationType
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>APPEND = 0;</code>
       */
      APPEND(0, 0),
      /**
       * <code>INCREMENT = 1;</code>
       */
      INCREMENT(1, 1),
      /**
       * <code>PUT = 2;</code>
       */
      PUT(2, 2),
      /**
       * <code>DELETE = 3;</code>
       */
      DELETE(3, 3),
      ;

      /**
       * <code>APPEND = 0;</code>
       */
      public static final int APPEND_VALUE = 0;
      /**
       * <code>INCREMENT = 1;</code>
       */
      public static final int INCREMENT_VALUE = 1;
      /**
       * <code>PUT = 2;</code>
       */
      public static final int PUT_VALUE = 2;
      /**
       * <code>DELETE = 3;</code>
       */
      public static final int DELETE_VALUE = 3;


      public final int getNumber() { return value; }

      public static MutationType valueOf(int value) {
        switch (value) {
          case 0: return APPEND;
          case 1: return INCREMENT;
          case 2: return PUT;
          case 3: return DELETE;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<MutationType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<MutationType>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<MutationType>() {
              public MutationType findValueByNumber(int number) {
                return MutationType.valueOf(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDescriptor().getEnumTypes().get(1);
      }

      private static final MutationType[] VALUES = values();

      public static MutationType valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int index;
      private final int value;

      private MutationType(int index, int value) {
        this.index = index;
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:MutationProto.MutationType)
    }

    /**
     * Protobuf enum {@code MutationProto.DeleteType}
     */
    public enum DeleteType
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <code>DELETE_ONE_VERSION = 0;</code>
       */
      DELETE_ONE_VERSION(0, 0),
      /**
       * <code>DELETE_MULTIPLE_VERSIONS = 1;</code>
       */
      DELETE_MULTIPLE_VERSIONS(1, 1),
      /**
       * <code>DELETE_FAMILY = 2;</code>
       */
      DELETE_FAMILY(2, 2),
      /**
       * <code>DELETE_FAMILY_VERSION = 3;</code>
       */
      DELETE_FAMILY_VERSION(3, 3),
      ;

      /**
       * <code>DELETE_ONE_VERSION = 0;</code>
       */
      public static final int DELETE_ONE_VERSION_VALUE = 0;
      /**
       * <code>DELETE_MULTIPLE_VERSIONS = 1;</code>
       */
      public static final int DELETE_MULTIPLE_VERSIONS_VALUE = 1;
      /**
       * <code>DELETE_FAMILY = 2;</code>
       */
      public static final int DELETE_FAMILY_VALUE = 2;
      /**
       * <code>DELETE_FAMILY_VERSION = 3;</code>
       */
      public static final int DELETE_FAMILY_VERSION_VALUE = 3;


      public final int getNumber() { return value; }

      public static DeleteType valueOf(int value) {
        switch (value) {
          case 0: return DELETE_ONE_VERSION;
          case 1: return DELETE_MULTIPLE_VERSIONS;
          case 2: return DELETE_FAMILY;
          case 3: return DELETE_FAMILY_VERSION;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<DeleteType>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static com.google.protobuf.Internal.EnumLiteMap<DeleteType>
          internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<DeleteType>() {
              public DeleteType findValueByNumber(int number) {
                return DeleteType.valueOf(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(index);
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDescriptor().getEnumTypes().get(2);
      }

      private static final DeleteType[] VALUES = values();

      public static DeleteType valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new java.lang.IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        return VALUES[desc.getIndex()];
      }

      private final int index;
      private final int value;

      private DeleteType(int index, int value) {
        this.index = index;
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:MutationProto.DeleteType)
    }

    public interface ColumnValueOrBuilder
        extends com.google.protobuf.MessageOrBuilder {

      // required bytes family = 1;
      /**
       * <code>required bytes family = 1;</code>
       */
      boolean hasFamily();
      /**
       * <code>required bytes family = 1;</code>
       */
      com.google.protobuf.ByteString getFamily();

      // repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> 
          getQualifierValueList();
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getQualifierValue(int index);
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      int getQualifierValueCount();
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> 
          getQualifierValueOrBuilderList();
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
          int index);
    }
    /**
     * Protobuf type {@code MutationProto.ColumnValue}
     */
    public static final class ColumnValue extends
        com.google.protobuf.GeneratedMessage
        implements ColumnValueOrBuilder {
      // Use ColumnValue.newBuilder() to construct.
      private ColumnValue(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
        super(builder);
        this.unknownFields = builder.getUnknownFields();
      }
      private ColumnValue(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

      private static final ColumnValue defaultInstance;
      public static ColumnValue getDefaultInstance() {
        return defaultInstance;
      }

      public ColumnValue getDefaultInstanceForType() {
        return defaultInstance;
      }

      private final com.google.protobuf.UnknownFieldSet unknownFields;
      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
          getUnknownFields() {
        return this.unknownFields;
      }
      private ColumnValue(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        initFields();
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!parseUnknownField(input, unknownFields,
                                       extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                bitField0_ |= 0x00000001;
                family_ = input.readBytes();
                break;
              }
              case 18: {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  qualifierValue_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue>();
                  mutable_bitField0_ |= 0x00000002;
                }
                qualifierValue_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.PARSER, extensionRegistry));
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e.getMessage()).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
            qualifierValue_ = java.util.Collections.unmodifiableList(qualifierValue_);
          }
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder.class);
      }

      public static com.google.protobuf.Parser<ColumnValue> PARSER =
          new com.google.protobuf.AbstractParser<ColumnValue>() {
        public ColumnValue parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new ColumnValue(input, extensionRegistry);
        }
      };

      @java.lang.Override
      public com.google.protobuf.Parser<ColumnValue> getParserForType() {
        return PARSER;
      }

      public interface QualifierValueOrBuilder
          extends com.google.protobuf.MessageOrBuilder {

        // optional bytes qualifier = 1;
        /**
         * <code>optional bytes qualifier = 1;</code>
         */
        boolean hasQualifier();
        /**
         * <code>optional bytes qualifier = 1;</code>
         */
        com.google.protobuf.ByteString getQualifier();

        // optional bytes value = 2;
        /**
         * <code>optional bytes value = 2;</code>
         */
        boolean hasValue();
        /**
         * <code>optional bytes value = 2;</code>
         */
        com.google.protobuf.ByteString getValue();

        // optional uint64 timestamp = 3;
        /**
         * <code>optional uint64 timestamp = 3;</code>
         */
        boolean hasTimestamp();
        /**
         * <code>optional uint64 timestamp = 3;</code>
         */
        long getTimestamp();

        // optional .MutationProto.DeleteType delete_type = 4;
        /**
         * <code>optional .MutationProto.DeleteType delete_type = 4;</code>
         */
        boolean hasDeleteType();
        /**
         * <code>optional .MutationProto.DeleteType delete_type = 4;</code>
         */
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType getDeleteType();
      }
      /**
       * Protobuf type {@code MutationProto.ColumnValue.QualifierValue}
       */
      public static final class QualifierValue extends
          com.google.protobuf.GeneratedMessage
          implements QualifierValueOrBuilder {
        // Use QualifierValue.newBuilder() to construct.
        private QualifierValue(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
          super(builder);
          this.unknownFields = builder.getUnknownFields();
        }
        private QualifierValue(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

        private static final QualifierValue defaultInstance;
        public static QualifierValue getDefaultInstance() {
          return defaultInstance;
        }

        public QualifierValue getDefaultInstanceForType() {
          return defaultInstance;
        }

        private final com.google.protobuf.UnknownFieldSet unknownFields;
        @java.lang.Override
        public final com.google.protobuf.UnknownFieldSet
            getUnknownFields() {
          return this.unknownFields;
        }
        private QualifierValue(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          initFields();
          int mutable_bitField0_ = 0;
          com.google.protobuf.UnknownFieldSet.Builder unknownFields =
              com.google.protobuf.UnknownFieldSet.newBuilder();
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                default: {
                  if (!parseUnknownField(input, unknownFields,
                                         extensionRegistry, tag)) {
                    done = true;
                  }
                  break;
                }
                case 10: {
                  bitField0_ |= 0x00000001;
                  qualifier_ = input.readBytes();
                  break;
                }
                case 18: {
                  bitField0_ |= 0x00000002;
                  value_ = input.readBytes();
                  break;
                }
                case 24: {
                  bitField0_ |= 0x00000004;
                  timestamp_ = input.readUInt64();
                  break;
                }
                case 32: {
                  int rawValue = input.readEnum();
                  org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType value = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType.valueOf(rawValue);
                  if (value == null) {
                    unknownFields.mergeVarintField(4, rawValue);
                  } else {
                    bitField0_ |= 0x00000008;
                    deleteType_ = value;
                  }
                  break;
                }
              }
            }
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(this);
          } catch (java.io.IOException e) {
            throw new com.google.protobuf.InvalidProtocolBufferException(
                e.getMessage()).setUnfinishedMessage(this);
          } finally {
            this.unknownFields = unknownFields.build();
            makeExtensionsImmutable();
          }
        }
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_QualifierValue_descriptor;
        }

        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_QualifierValue_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder.class);
        }

        public static com.google.protobuf.Parser<QualifierValue> PARSER =
            new com.google.protobuf.AbstractParser<QualifierValue>() {
          public QualifierValue parsePartialFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
            return new QualifierValue(input, extensionRegistry);
          }
        };

        @java.lang.Override
        public com.google.protobuf.Parser<QualifierValue> getParserForType() {
          return PARSER;
        }

        private int bitField0_;
        // optional bytes qualifier = 1;
        public static final int QUALIFIER_FIELD_NUMBER = 1;
        private com.google.protobuf.ByteString qualifier_;
        /**
         * <code>optional bytes qualifier = 1;</code>
         */
        public boolean hasQualifier() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        /**
         * <code>optional bytes qualifier = 1;</code>
         */
        public com.google.protobuf.ByteString getQualifier() {
          return qualifier_;
        }

        // optional bytes value = 2;
        public static final int VALUE_FIELD_NUMBER = 2;
        private com.google.protobuf.ByteString value_;
        /**
         * <code>optional bytes value = 2;</code>
         */
        public boolean hasValue() {
          return ((bitField0_ & 0x00000002) == 0x00000002);
        }
        /**
         * <code>optional bytes value = 2;</code>
         */
        public com.google.protobuf.ByteString getValue() {
          return value_;
        }

        // optional uint64 timestamp = 3;
        public static final int TIMESTAMP_FIELD_NUMBER = 3;
        private long timestamp_;
        /**
         * <code>optional uint64 timestamp = 3;</code>
         */
        public boolean hasTimestamp() {
          return ((bitField0_ & 0x00000004) == 0x00000004);
        }
        /**
         * <code>optional uint64 timestamp = 3;</code>
         */
        public long getTimestamp() {
          return timestamp_;
        }

        // optional .MutationProto.DeleteType delete_type = 4;
        public static final int DELETE_TYPE_FIELD_NUMBER = 4;
        private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType deleteType_;
        /**
         * <code>optional .MutationProto.DeleteType delete_type = 4;</code>
         */
        public boolean hasDeleteType() {
          return ((bitField0_ & 0x00000008) == 0x00000008);
        }
        /**
         * <code>optional .MutationProto.DeleteType delete_type = 4;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType getDeleteType() {
          return deleteType_;
        }

        private void initFields() {
          qualifier_ = com.google.protobuf.ByteString.EMPTY;
          value_ = com.google.protobuf.ByteString.EMPTY;
          timestamp_ = 0L;
          deleteType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType.DELETE_ONE_VERSION;
        }
        private byte memoizedIsInitialized = -1;
        public final boolean isInitialized() {
          byte isInitialized = memoizedIsInitialized;
          if (isInitialized != -1) return isInitialized == 1;

          memoizedIsInitialized = 1;
          return true;
        }

        public void writeTo(com.google.protobuf.CodedOutputStream output)
                            throws java.io.IOException {
          getSerializedSize();
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            output.writeBytes(1, qualifier_);
          }
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            output.writeBytes(2, value_);
          }
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            output.writeUInt64(3, timestamp_);
          }
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            output.writeEnum(4, deleteType_.getNumber());
          }
          getUnknownFields().writeTo(output);
        }

        private int memoizedSerializedSize = -1;
        public int getSerializedSize() {
          int size = memoizedSerializedSize;
          if (size != -1) return size;

          size = 0;
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            size += com.google.protobuf.CodedOutputStream
              .computeBytesSize(1, qualifier_);
          }
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            size += com.google.protobuf.CodedOutputStream
              .computeBytesSize(2, value_);
          }
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            size += com.google.protobuf.CodedOutputStream
              .computeUInt64Size(3, timestamp_);
          }
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            size += com.google.protobuf.CodedOutputStream
              .computeEnumSize(4, deleteType_.getNumber());
          }
          size += getUnknownFields().getSerializedSize();
          memoizedSerializedSize = size;
          return size;
        }

        private static final long serialVersionUID = 0L;
        @java.lang.Override
        protected java.lang.Object writeReplace()
            throws java.io.ObjectStreamException {
          return super.writeReplace();
        }

        @java.lang.Override
        public boolean equals(final java.lang.Object obj) {
          if (obj == this) {
           return true;
          }
          if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue)) {
            return super.equals(obj);
          }
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue) obj;

          boolean result = true;
          result = result && (hasQualifier() == other.hasQualifier());
          if (hasQualifier()) {
            result = result && getQualifier()
                .equals(other.getQualifier());
          }
          result = result && (hasValue() == other.hasValue());
          if (hasValue()) {
            result = result && getValue()
                .equals(other.getValue());
          }
          result = result && (hasTimestamp() == other.hasTimestamp());
          if (hasTimestamp()) {
            result = result && (getTimestamp()
                == other.getTimestamp());
          }
          result = result && (hasDeleteType() == other.hasDeleteType());
          if (hasDeleteType()) {
            result = result &&
                (getDeleteType() == other.getDeleteType());
          }
          result = result &&
              getUnknownFields().equals(other.getUnknownFields());
          return result;
        }

        private int memoizedHashCode = 0;
        @java.lang.Override
        public int hashCode() {
          if (memoizedHashCode != 0) {
            return memoizedHashCode;
          }
          int hash = 41;
          hash = (19 * hash) + getDescriptorForType().hashCode();
          if (hasQualifier()) {
            hash = (37 * hash) + QUALIFIER_FIELD_NUMBER;
            hash = (53 * hash) + getQualifier().hashCode();
          }
          if (hasValue()) {
            hash = (37 * hash) + VALUE_FIELD_NUMBER;
            hash = (53 * hash) + getValue().hashCode();
          }
          if (hasTimestamp()) {
            hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
            hash = (53 * hash) + hashLong(getTimestamp());
          }
          if (hasDeleteType()) {
            hash = (37 * hash) + DELETE_TYPE_FIELD_NUMBER;
            hash = (53 * hash) + hashEnum(getDeleteType());
          }
          hash = (29 * hash) + getUnknownFields().hashCode();
          memoizedHashCode = hash;
          return hash;
        }

        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            com.google.protobuf.ByteString data)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            com.google.protobuf.ByteString data,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(byte[] data)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            byte[] data,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(java.io.InputStream input)
            throws java.io.IOException {
          return PARSER.parseFrom(input);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            java.io.InputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return PARSER.parseFrom(input, extensionRegistry);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseDelimitedFrom(java.io.InputStream input)
            throws java.io.IOException {
          return PARSER.parseDelimitedFrom(input);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseDelimitedFrom(
            java.io.InputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return PARSER.parseDelimitedFrom(input, extensionRegistry);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            com.google.protobuf.CodedInputStream input)
            throws java.io.IOException {
          return PARSER.parseFrom(input);
        }
        public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parseFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return PARSER.parseFrom(input, extensionRegistry);
        }

        public static Builder newBuilder() { return Builder.create(); }
        public Builder newBuilderForType() { return newBuilder(); }
        public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue prototype) {
          return newBuilder().mergeFrom(prototype);
        }
        public Builder toBuilder() { return newBuilder(this); }

        @java.lang.Override
        protected Builder newBuilderForType(
            com.google.protobuf.GeneratedMessage.BuilderParent parent) {
          Builder builder = new Builder(parent);
          return builder;
        }
        /**
         * Protobuf type {@code MutationProto.ColumnValue.QualifierValue}
         */
        public static final class Builder extends
            com.google.protobuf.GeneratedMessage.Builder<Builder>
           implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder {
          public static final com.google.protobuf.Descriptors.Descriptor
              getDescriptor() {
            return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_QualifierValue_descriptor;
          }

          protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
              internalGetFieldAccessorTable() {
            return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_QualifierValue_fieldAccessorTable
                .ensureFieldAccessorsInitialized(
                    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder.class);
          }

          // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.newBuilder()
          private Builder() {
            maybeForceBuilderInitialization();
          }

          private Builder(
              com.google.protobuf.GeneratedMessage.BuilderParent parent) {
            super(parent);
            maybeForceBuilderInitialization();
          }
          private void maybeForceBuilderInitialization() {
            if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
            }
          }
          private static Builder create() {
            return new Builder();
          }

          public Builder clear() {
            super.clear();
            qualifier_ = com.google.protobuf.ByteString.EMPTY;
            bitField0_ = (bitField0_ & ~0x00000001);
            value_ = com.google.protobuf.ByteString.EMPTY;
            bitField0_ = (bitField0_ & ~0x00000002);
            timestamp_ = 0L;
            bitField0_ = (bitField0_ & ~0x00000004);
            deleteType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType.DELETE_ONE_VERSION;
            bitField0_ = (bitField0_ & ~0x00000008);
            return this;
          }

          public Builder clone() {
            return create().mergeFrom(buildPartial());
          }

          public com.google.protobuf.Descriptors.Descriptor
              getDescriptorForType() {
            return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_QualifierValue_descriptor;
          }

          public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getDefaultInstanceForType() {
            return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.getDefaultInstance();
          }

          public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue build() {
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue result = buildPartial();
            if (!result.isInitialized()) {
              throw newUninitializedMessageException(result);
            }
            return result;
          }

          public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue buildPartial() {
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue(this);
            int from_bitField0_ = bitField0_;
            int to_bitField0_ = 0;
            if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
              to_bitField0_ |= 0x00000001;
            }
            result.qualifier_ = qualifier_;
            if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
              to_bitField0_ |= 0x00000002;
            }
            result.value_ = value_;
            if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
              to_bitField0_ |= 0x00000004;
            }
            result.timestamp_ = timestamp_;
            if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
              to_bitField0_ |= 0x00000008;
            }
            result.deleteType_ = deleteType_;
            result.bitField0_ = to_bitField0_;
            onBuilt();
            return result;
          }

          public Builder mergeFrom(com.google.protobuf.Message other) {
            if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue) {
              return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue)other);
            } else {
              super.mergeFrom(other);
              return this;
            }
          }

          public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue other) {
            if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.getDefaultInstance()) return this;
            if (other.hasQualifier()) {
              setQualifier(other.getQualifier());
            }
            if (other.hasValue()) {
              setValue(other.getValue());
            }
            if (other.hasTimestamp()) {
              setTimestamp(other.getTimestamp());
            }
            if (other.hasDeleteType()) {
              setDeleteType(other.getDeleteType());
            }
            this.mergeUnknownFields(other.getUnknownFields());
            return this;
          }

          public final boolean isInitialized() {
            return true;
          }

          public Builder mergeFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue parsedMessage = null;
            try {
              parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
            } catch (com.google.protobuf.InvalidProtocolBufferException e) {
              parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue) e.getUnfinishedMessage();
              throw e;
            } finally {
              if (parsedMessage != null) {
                mergeFrom(parsedMessage);
              }
            }
            return this;
          }
          private int bitField0_;

          // optional bytes qualifier = 1;
          private com.google.protobuf.ByteString qualifier_ = com.google.protobuf.ByteString.EMPTY;
          /**
           * <code>optional bytes qualifier = 1;</code>
           */
          public boolean hasQualifier() {
            return ((bitField0_ & 0x00000001) == 0x00000001);
          }
          /**
           * <code>optional bytes qualifier = 1;</code>
           */
          public com.google.protobuf.ByteString getQualifier() {
            return qualifier_;
          }
          /**
           * <code>optional bytes qualifier = 1;</code>
           */
          public Builder setQualifier(com.google.protobuf.ByteString value) {
            if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
            qualifier_ = value;
            onChanged();
            return this;
          }
          /**
           * <code>optional bytes qualifier = 1;</code>
           */
          public Builder clearQualifier() {
            bitField0_ = (bitField0_ & ~0x00000001);
            qualifier_ = getDefaultInstance().getQualifier();
            onChanged();
            return this;
          }

          // optional bytes value = 2;
          private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
          /**
           * <code>optional bytes value = 2;</code>
           */
          public boolean hasValue() {
            return ((bitField0_ & 0x00000002) == 0x00000002);
          }
          /**
           * <code>optional bytes value = 2;</code>
           */
          public com.google.protobuf.ByteString getValue() {
            return value_;
          }
          /**
           * <code>optional bytes value = 2;</code>
           */
          public Builder setValue(com.google.protobuf.ByteString value) {
            if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
            value_ = value;
            onChanged();
            return this;
          }
          /**
           * <code>optional bytes value = 2;</code>
           */
          public Builder clearValue() {
            bitField0_ = (bitField0_ & ~0x00000002);
            value_ = getDefaultInstance().getValue();
            onChanged();
            return this;
          }

          // optional uint64 timestamp = 3;
          private long timestamp_ ;
          /**
           * <code>optional uint64 timestamp = 3;</code>
           */
          public boolean hasTimestamp() {
            return ((bitField0_ & 0x00000004) == 0x00000004);
          }
          /**
           * <code>optional uint64 timestamp = 3;</code>
           */
          public long getTimestamp() {
            return timestamp_;
          }
          /**
           * <code>optional uint64 timestamp = 3;</code>
           */
          public Builder setTimestamp(long value) {
            bitField0_ |= 0x00000004;
            timestamp_ = value;
            onChanged();
            return this;
          }
          /**
           * <code>optional uint64 timestamp = 3;</code>
           */
          public Builder clearTimestamp() {
            bitField0_ = (bitField0_ & ~0x00000004);
            timestamp_ = 0L;
            onChanged();
            return this;
          }

          // optional .MutationProto.DeleteType delete_type = 4;
          private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType deleteType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType.DELETE_ONE_VERSION;
          /**
           * <code>optional .MutationProto.DeleteType delete_type = 4;</code>
           */
          public boolean hasDeleteType() {
            return ((bitField0_ & 0x00000008) == 0x00000008);
          }
          /**
           * <code>optional .MutationProto.DeleteType delete_type = 4;</code>
           */
          public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType getDeleteType() {
            return deleteType_;
          }
          /**
           * <code>optional .MutationProto.DeleteType delete_type = 4;</code>
           */
          public Builder setDeleteType(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType value) {
            if (value == null) {
              throw new NullPointerException();
            }
            bitField0_ |= 0x00000008;
            deleteType_ = value;
            onChanged();
            return this;
          }
          /**
           * <code>optional .MutationProto.DeleteType delete_type = 4;</code>
           */
          public Builder clearDeleteType() {
            bitField0_ = (bitField0_ & ~0x00000008);
            deleteType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.DeleteType.DELETE_ONE_VERSION;
            onChanged();
            return this;
          }

          // @@protoc_insertion_point(builder_scope:MutationProto.ColumnValue.QualifierValue)
        }

        static {
          defaultInstance = new QualifierValue(true);
          defaultInstance.initFields();
        }

        // @@protoc_insertion_point(class_scope:MutationProto.ColumnValue.QualifierValue)
      }

      private int bitField0_;
      // required bytes family = 1;
      public static final int FAMILY_FIELD_NUMBER = 1;
      private com.google.protobuf.ByteString family_;
      /**
       * <code>required bytes family = 1;</code>
       */
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes family = 1;</code>
       */
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }

      // repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;
      public static final int QUALIFIER_VALUE_FIELD_NUMBER = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> qualifierValue_;
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> getQualifierValueList() {
        return qualifierValue_;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> 
          getQualifierValueOrBuilderList() {
        return qualifierValue_;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      public int getQualifierValueCount() {
        return qualifierValue_.size();
      }
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getQualifierValue(int index) {
        return qualifierValue_.get(index);
      }
      /**
       * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
          int index) {
        return qualifierValue_.get(index);
      }

      private void initFields() {
        family_ = com.google.protobuf.ByteString.EMPTY;
        qualifierValue_ = java.util.Collections.emptyList();
      }
      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized != -1) return isInitialized == 1;

        if (!hasFamily()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          output.writeBytes(1, family_);
        }
        for (int i = 0; i < qualifierValue_.size(); i++) {
          output.writeMessage(2, qualifierValue_.get(i));
        }
        getUnknownFields().writeTo(output);
      }

      private int memoizedSerializedSize = -1;
      public int getSerializedSize() {
        int size = memoizedSerializedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, family_);
        }
        for (int i = 0; i < qualifierValue_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, qualifierValue_.get(i));
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSerializedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @java.lang.Override
      protected java.lang.Object writeReplace()
          throws java.io.ObjectStreamException {
        return super.writeReplace();
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue) obj;

        boolean result = true;
        result = result && (hasFamily() == other.hasFamily());
        if (hasFamily()) {
          result = result && getFamily()
              .equals(other.getFamily());
        }
        result = result && getQualifierValueList()
            .equals(other.getQualifierValueList());
        result = result &&
            getUnknownFields().equals(other.getUnknownFields());
        return result;
      }

      private int memoizedHashCode = 0;
      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        if (hasFamily()) {
          hash = (37 * hash) + FAMILY_FIELD_NUMBER;
          hash = (53 * hash) + getFamily().hashCode();
        }
        if (getQualifierValueCount() > 0) {
          hash = (37 * hash) + QUALIFIER_VALUE_FIELD_NUMBER;
          hash = (53 * hash) + getQualifierValueList().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return PARSER.parseFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseFrom(input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return PARSER.parseDelimitedFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseDelimitedFrom(input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return PARSER.parseFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseFrom(input, extensionRegistry);
      }

      public static Builder newBuilder() { return Builder.create(); }
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue prototype) {
        return newBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() { return newBuilder(this); }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code MutationProto.ColumnValue}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessage.Builder<Builder>
         implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_descriptor;
        }

        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessage.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
            getQualifierValueFieldBuilder();
          }
        }
        private static Builder create() {
          return new Builder();
        }

        public Builder clear() {
          super.clear();
          family_ = com.google.protobuf.ByteString.EMPTY;
          bitField0_ = (bitField0_ & ~0x00000001);
          if (qualifierValueBuilder_ == null) {
            qualifierValue_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            qualifierValueBuilder_.clear();
          }
          return this;
        }

        public Builder clone() {
          return create().mergeFrom(buildPartial());
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_ColumnValue_descriptor;
        }

        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.getDefaultInstance();
        }

        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue build() {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue buildPartial() {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
            to_bitField0_ |= 0x00000001;
          }
          result.family_ = family_;
          if (qualifierValueBuilder_ == null) {
            if (((bitField0_ & 0x00000002) == 0x00000002)) {
              qualifierValue_ = java.util.Collections.unmodifiableList(qualifierValue_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.qualifierValue_ = qualifierValue_;
          } else {
            result.qualifierValue_ = qualifierValueBuilder_.build();
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue) {
            return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue other) {
          if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.getDefaultInstance()) return this;
          if (other.hasFamily()) {
            setFamily(other.getFamily());
          }
          if (qualifierValueBuilder_ == null) {
            if (!other.qualifierValue_.isEmpty()) {
              if (qualifierValue_.isEmpty()) {
                qualifierValue_ = other.qualifierValue_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensureQualifierValueIsMutable();
                qualifierValue_.addAll(other.qualifierValue_);
              }
              onChanged();
            }
          } else {
            if (!other.qualifierValue_.isEmpty()) {
              if (qualifierValueBuilder_.isEmpty()) {
                qualifierValueBuilder_.dispose();
                qualifierValueBuilder_ = null;
                qualifierValue_ = other.qualifierValue_;
                bitField0_ = (bitField0_ & ~0x00000002);
                qualifierValueBuilder_ = 
                  com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                     getQualifierValueFieldBuilder() : null;
              } else {
                qualifierValueBuilder_.addAllMessages(other.qualifierValue_);
              }
            }
          }
          this.mergeUnknownFields(other.getUnknownFields());
          return this;
        }

        public final boolean isInitialized() {
          if (!hasFamily()) {
            
            return false;
          }
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue) e.getUnfinishedMessage();
            throw e;
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        // required bytes family = 1;
        private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>required bytes family = 1;</code>
         */
        public boolean hasFamily() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        /**
         * <code>required bytes family = 1;</code>
         */
        public com.google.protobuf.ByteString getFamily() {
          return family_;
        }
        /**
         * <code>required bytes family = 1;</code>
         */
        public Builder setFamily(com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          family_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>required bytes family = 1;</code>
         */
        public Builder clearFamily() {
          bitField0_ = (bitField0_ & ~0x00000001);
          family_ = getDefaultInstance().getFamily();
          onChanged();
          return this;
        }

        // repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;
        private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> qualifierValue_ =
          java.util.Collections.emptyList();
        private void ensureQualifierValueIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            qualifierValue_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue>(qualifierValue_);
            bitField0_ |= 0x00000002;
           }
        }

        private com.google.protobuf.RepeatedFieldBuilder<
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> qualifierValueBuilder_;

        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> getQualifierValueList() {
          if (qualifierValueBuilder_ == null) {
            return java.util.Collections.unmodifiableList(qualifierValue_);
          } else {
            return qualifierValueBuilder_.getMessageList();
          }
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public int getQualifierValueCount() {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.size();
          } else {
            return qualifierValueBuilder_.getCount();
          }
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue getQualifierValue(int index) {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.get(index);
          } else {
            return qualifierValueBuilder_.getMessage(index);
          }
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder setQualifierValue(
            int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.set(index, value);
            onChanged();
          } else {
            qualifierValueBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder setQualifierValue(
            int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.set(index, builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addQualifierValue(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.add(value);
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addQualifierValue(
            int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue value) {
          if (qualifierValueBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureQualifierValueIsMutable();
            qualifierValue_.add(index, value);
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addQualifierValue(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.add(builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addQualifierValue(
            int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder builderForValue) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.add(index, builderForValue.build());
            onChanged();
          } else {
            qualifierValueBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder addAllQualifierValue(
            java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue> values) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            super.addAll(values, qualifierValue_);
            onChanged();
          } else {
            qualifierValueBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder clearQualifierValue() {
          if (qualifierValueBuilder_ == null) {
            qualifierValue_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            qualifierValueBuilder_.clear();
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public Builder removeQualifierValue(int index) {
          if (qualifierValueBuilder_ == null) {
            ensureQualifierValueIsMutable();
            qualifierValue_.remove(index);
            onChanged();
          } else {
            qualifierValueBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder getQualifierValueBuilder(
            int index) {
          return getQualifierValueFieldBuilder().getBuilder(index);
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder getQualifierValueOrBuilder(
            int index) {
          if (qualifierValueBuilder_ == null) {
            return qualifierValue_.get(index);  } else {
            return qualifierValueBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> 
             getQualifierValueOrBuilderList() {
          if (qualifierValueBuilder_ != null) {
            return qualifierValueBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(qualifierValue_);
          }
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder addQualifierValueBuilder() {
          return getQualifierValueFieldBuilder().addBuilder(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.getDefaultInstance());
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder addQualifierValueBuilder(
            int index) {
          return getQualifierValueFieldBuilder().addBuilder(
              index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.getDefaultInstance());
        }
        /**
         * <code>repeated .MutationProto.ColumnValue.QualifierValue qualifier_value = 2;</code>
         */
        public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder> 
             getQualifierValueBuilderList() {
          return getQualifierValueFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilder<
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder> 
            getQualifierValueFieldBuilder() {
          if (qualifierValueBuilder_ == null) {
            qualifierValueBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.QualifierValueOrBuilder>(
                    qualifierValue_,
                    ((bitField0_ & 0x00000002) == 0x00000002),
                    getParentForChildren(),
                    isClean());
            qualifierValue_ = null;
          }
          return qualifierValueBuilder_;
        }

        // @@protoc_insertion_point(builder_scope:MutationProto.ColumnValue)
      }

      static {
        defaultInstance = new ColumnValue(true);
        defaultInstance.initFields();
      }

      // @@protoc_insertion_point(class_scope:MutationProto.ColumnValue)
    }

    private int bitField0_;
    // optional bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    /**
     * <code>optional bytes row = 1;</code>
     */
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bytes row = 1;</code>
     */
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }

    // optional .MutationProto.MutationType mutate_type = 2;
    public static final int MUTATE_TYPE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType mutateType_;
    /**
     * <code>optional .MutationProto.MutationType mutate_type = 2;</code>
     */
    public boolean hasMutateType() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .MutationProto.MutationType mutate_type = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType getMutateType() {
      return mutateType_;
    }

    // repeated .MutationProto.ColumnValue column_value = 3;
    public static final int COLUMN_VALUE_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue> columnValue_;
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue> getColumnValueList() {
      return columnValue_;
    }
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> 
        getColumnValueOrBuilderList() {
      return columnValue_;
    }
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    public int getColumnValueCount() {
      return columnValue_.size();
    }
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue getColumnValue(int index) {
      return columnValue_.get(index);
    }
    /**
     * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder getColumnValueOrBuilder(
        int index) {
      return columnValue_.get(index);
    }

    // optional uint64 timestamp = 4;
    public static final int TIMESTAMP_FIELD_NUMBER = 4;
    private long timestamp_;
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    public boolean hasTimestamp() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional uint64 timestamp = 4;</code>
     */
    public long getTimestamp() {
      return timestamp_;
    }

    // repeated .NameBytesPair attribute = 5;
    public static final int ATTRIBUTE_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    public int getAttributeCount() {
      return attribute_.size();
    }
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    /**
     * <code>repeated .NameBytesPair attribute = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }

    // optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];
    public static final int DURABILITY_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability durability_;
    /**
     * <code>optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
     */
    public boolean hasDurability() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability getDurability() {
      return durability_;
    }

    // optional .TimeRange time_range = 7;
    public static final int TIME_RANGE_FIELD_NUMBER = 7;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    /**
     * <code>optional .TimeRange time_range = 7;</code>
     *
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     */
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .TimeRange time_range = 7;</code>
     *
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_;
    }
    /**
     * <code>optional .TimeRange time_range = 7;</code>
     *
     * <pre>
     * For some mutations, a result may be returned, in which case,
     * time range can be specified for potential performance gain
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_;
    }

    // optional int32 associated_cell_count = 8;
    public static final int ASSOCIATED_CELL_COUNT_FIELD_NUMBER = 8;
    private int associatedCellCount_;
    /**
     * <code>optional int32 associated_cell_count = 8;</code>
     *
     * <pre>
     * The below count is set when the associated cells are NOT
     * part of this protobuf message; they are passed alongside
     * and then this Message is a placeholder with metadata.  The
     * count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     */
    public boolean hasAssociatedCellCount() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 associated_cell_count = 8;</code>
     *
     * <pre>
     * The below count is set when the associated cells are NOT
     * part of this protobuf message; they are passed alongside
     * and then this Message is a placeholder with metadata.  The
     * count is needed to know how many to peel off the block of Cells as
     * ours.  NOTE: This is different from the pb managed cell_count of the
     * 'cell' field above which is non-null when the cells are pb'd.
     * </pre>
     */
    public int getAssociatedCellCount() {
      return associatedCellCount_;
    }

    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      mutateType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType.APPEND;
      columnValue_ = java.util.Collections.emptyList();
      timestamp_ = 0L;
      attribute_ = java.util.Collections.emptyList();
      durability_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability.USE_DEFAULT;
      timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      associatedCellCount_ = 0;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getColumnValueCount(); i++) {
        if (!getColumnValue(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, mutateType_.getNumber());
      }
      for (int i = 0; i < columnValue_.size(); i++) {
        output.writeMessage(3, columnValue_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(4, timestamp_);
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(5, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(6, durability_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(7, timeRange_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(8, associatedCellCount_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, mutateType_.getNumber());
      }
      for (int i = 0; i < columnValue_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, columnValue_.get(i));
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(4, timestamp_);
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(6, durability_.getNumber());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, timeRange_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(8, associatedCellCount_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto) obj;

      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasMutateType() == other.hasMutateType());
      if (hasMutateType()) {
        result = result &&
            (getMutateType() == other.getMutateType());
      }
      result = result && getColumnValueList()
          .equals(other.getColumnValueList());
      result = result && (hasTimestamp() == other.hasTimestamp());
      if (hasTimestamp()) {
        result = result && (getTimestamp()
            == other.getTimestamp());
      }
      result = result && getAttributeList()
          .equals(other.getAttributeList());
      result = result && (hasDurability() == other.hasDurability());
      if (hasDurability()) {
        result = result &&
            (getDurability() == other.getDurability());
      }
      result = result && (hasTimeRange() == other.hasTimeRange());
      if (hasTimeRange()) {
        result = result && getTimeRange()
            .equals(other.getTimeRange());
      }
      result = result && (hasAssociatedCellCount() == other.hasAssociatedCellCount());
      if (hasAssociatedCellCount()) {
        result = result && (getAssociatedCellCount()
            == other.getAssociatedCellCount());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasMutateType()) {
        hash = (37 * hash) + MUTATE_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getMutateType());
      }
      if (getColumnValueCount() > 0) {
        hash = (37 * hash) + COLUMN_VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getColumnValueList().hashCode();
      }
      if (hasTimestamp()) {
        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getTimestamp());
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasDurability()) {
        hash = (37 * hash) + DURABILITY_FIELD_NUMBER;
        hash = (53 * hash) + hashEnum(getDurability());
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasAssociatedCellCount()) {
        hash = (37 * hash) + ASSOCIATED_CELL_COUNT_FIELD_NUMBER;
        hash = (53 * hash) + getAssociatedCellCount();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MutationProto}
     *
     * <pre>
     **
     * A specific mutation inside a mutate request.
     * It can be an append, increment, put or delete based
     * on the mutation type.  It can be fully filled in or
     * only metadata present because data is being carried
     * elsewhere outside of pb.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getColumnValueFieldBuilder();
          getAttributeFieldBuilder();
          getTimeRangeFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        mutateType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType.APPEND;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (columnValueBuilder_ == null) {
          columnValue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          columnValueBuilder_.clear();
        }
        timestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          attributeBuilder_.clear();
        }
        durability_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability.USE_DEFAULT;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        associatedCellCount_ = 0;
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutationProto_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.mutateType_ = mutateType_;
        if (columnValueBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            columnValue_ = java.util.Collections.unmodifiableList(columnValue_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.columnValue_ = columnValue_;
        } else {
          result.columnValue_ = columnValueBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        result.timestamp_ = timestamp_;
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000008;
        }
        result.durability_ = durability_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        if (timeRangeBuilder_ == null) {
          result.timeRange_ = timeRange_;
        } else {
          result.timeRange_ = timeRangeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        result.associatedCellCount_ = associatedCellCount_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasMutateType()) {
          setMutateType(other.getMutateType());
        }
        if (columnValueBuilder_ == null) {
          if (!other.columnValue_.isEmpty()) {
            if (columnValue_.isEmpty()) {
              columnValue_ = other.columnValue_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureColumnValueIsMutable();
              columnValue_.addAll(other.columnValue_);
            }
            onChanged();
          }
        } else {
          if (!other.columnValue_.isEmpty()) {
            if (columnValueBuilder_.isEmpty()) {
              columnValueBuilder_.dispose();
              columnValueBuilder_ = null;
              columnValue_ = other.columnValue_;
              bitField0_ = (bitField0_ & ~0x00000004);
              columnValueBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getColumnValueFieldBuilder() : null;
            } else {
              columnValueBuilder_.addAllMessages(other.columnValue_);
            }
          }
        }
        if (other.hasTimestamp()) {
          setTimestamp(other.getTimestamp());
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000010);
              attributeBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasDurability()) {
          setDurability(other.getDurability());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasAssociatedCellCount()) {
          setAssociatedCellCount(other.getAssociatedCellCount());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getColumnValueCount(); i++) {
          if (!getColumnValue(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes row = 1;</code>
       */
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional bytes row = 1;</code>
       */
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>optional bytes row = 1;</code>
       */
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes row = 1;</code>
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      // optional .MutationProto.MutationType mutate_type = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType mutateType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType.APPEND;
      /**
       * <code>optional .MutationProto.MutationType mutate_type = 2;</code>
       */
      public boolean hasMutateType() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .MutationProto.MutationType mutate_type = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType getMutateType() {
        return mutateType_;
      }
      /**
       * <code>optional .MutationProto.MutationType mutate_type = 2;</code>
       */
      public Builder setMutateType(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        mutateType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .MutationProto.MutationType mutate_type = 2;</code>
       */
      public Builder clearMutateType() {
        bitField0_ = (bitField0_ & ~0x00000002);
        mutateType_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.MutationType.APPEND;
        onChanged();
        return this;
      }

      // repeated .MutationProto.ColumnValue column_value = 3;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue> columnValue_ =
        java.util.Collections.emptyList();
      private void ensureColumnValueIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          columnValue_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue>(columnValue_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> columnValueBuilder_;

      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue> getColumnValueList() {
        if (columnValueBuilder_ == null) {
          return java.util.Collections.unmodifiableList(columnValue_);
        } else {
          return columnValueBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public int getColumnValueCount() {
        if (columnValueBuilder_ == null) {
          return columnValue_.size();
        } else {
          return columnValueBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue getColumnValue(int index) {
        if (columnValueBuilder_ == null) {
          return columnValue_.get(index);
        } else {
          return columnValueBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder setColumnValue(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.set(index, value);
          onChanged();
        } else {
          columnValueBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder setColumnValue(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addColumnValue(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.add(value);
          onChanged();
        } else {
          columnValueBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addColumnValue(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue value) {
        if (columnValueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnValueIsMutable();
          columnValue_.add(index, value);
          onChanged();
        } else {
          columnValueBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addColumnValue(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.add(builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addColumnValue(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder builderForValue) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnValueBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder addAllColumnValue(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue> values) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          super.addAll(values, columnValue_);
          onChanged();
        } else {
          columnValueBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder clearColumnValue() {
        if (columnValueBuilder_ == null) {
          columnValue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          columnValueBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public Builder removeColumnValue(int index) {
        if (columnValueBuilder_ == null) {
          ensureColumnValueIsMutable();
          columnValue_.remove(index);
          onChanged();
        } else {
          columnValueBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder getColumnValueBuilder(
          int index) {
        return getColumnValueFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder getColumnValueOrBuilder(
          int index) {
        if (columnValueBuilder_ == null) {
          return columnValue_.get(index);  } else {
          return columnValueBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> 
           getColumnValueOrBuilderList() {
        if (columnValueBuilder_ != null) {
          return columnValueBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(columnValue_);
        }
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder addColumnValueBuilder() {
        return getColumnValueFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.getDefaultInstance());
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder addColumnValueBuilder(
          int index) {
        return getColumnValueFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.getDefaultInstance());
      }
      /**
       * <code>repeated .MutationProto.ColumnValue column_value = 3;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder> 
           getColumnValueBuilderList() {
        return getColumnValueFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder> 
          getColumnValueFieldBuilder() {
        if (columnValueBuilder_ == null) {
          columnValueBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValue.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.ColumnValueOrBuilder>(
                  columnValue_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          columnValue_ = null;
        }
        return columnValueBuilder_;
      }

      // optional uint64 timestamp = 4;
      private long timestamp_ ;
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public boolean hasTimestamp() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public long getTimestamp() {
        return timestamp_;
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public Builder setTimestamp(long value) {
        bitField0_ |= 0x00000008;
        timestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 timestamp = 4;</code>
       */
      public Builder clearTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000008);
        timestamp_ = 0L;
        onChanged();
        return this;
      }

      // repeated .NameBytesPair attribute = 5;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;

      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder addAttribute(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder addAttribute(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          super.addAll(values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameBytesPair attribute = 5;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }

      // optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability durability_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability.USE_DEFAULT;
      /**
       * <code>optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
       */
      public boolean hasDurability() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability getDurability() {
        return durability_;
      }
      /**
       * <code>optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
       */
      public Builder setDurability(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000020;
        durability_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional .MutationProto.Durability durability = 6 [default = USE_DEFAULT];</code>
       */
      public Builder clearDurability() {
        bitField0_ = (bitField0_ & ~0x00000020);
        durability_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Durability.USE_DEFAULT;
        onChanged();
        return this;
      }

      // optional .TimeRange time_range = 7;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      public Builder setTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      public Builder setTimeRange(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      public Builder mergeTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              timeRange_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            timeRange_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder(timeRange_).mergeFrom(value).buildPartial();
          } else {
            timeRange_ = value;
          }
          onChanged();
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      public Builder clearTimeRange() {
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
          onChanged();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_;
        }
      }
      /**
       * <code>optional .TimeRange time_range = 7;</code>
       *
       * <pre>
       * For some mutations, a result may be returned, in which case,
       * time range can be specified for potential performance gain
       * </pre>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  timeRange_,
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }

      // optional int32 associated_cell_count = 8;
      private int associatedCellCount_ ;
      /**
       * <code>optional int32 associated_cell_count = 8;</code>
       *
       * <pre>
       * The below count is set when the associated cells are NOT
       * part of this protobuf message; they are passed alongside
       * and then this Message is a placeholder with metadata.  The
       * count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       */
      public boolean hasAssociatedCellCount() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional int32 associated_cell_count = 8;</code>
       *
       * <pre>
       * The below count is set when the associated cells are NOT
       * part of this protobuf message; they are passed alongside
       * and then this Message is a placeholder with metadata.  The
       * count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       */
      public int getAssociatedCellCount() {
        return associatedCellCount_;
      }
      /**
       * <code>optional int32 associated_cell_count = 8;</code>
       *
       * <pre>
       * The below count is set when the associated cells are NOT
       * part of this protobuf message; they are passed alongside
       * and then this Message is a placeholder with metadata.  The
       * count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       */
      public Builder setAssociatedCellCount(int value) {
        bitField0_ |= 0x00000080;
        associatedCellCount_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 associated_cell_count = 8;</code>
       *
       * <pre>
       * The below count is set when the associated cells are NOT
       * part of this protobuf message; they are passed alongside
       * and then this Message is a placeholder with metadata.  The
       * count is needed to know how many to peel off the block of Cells as
       * ours.  NOTE: This is different from the pb managed cell_count of the
       * 'cell' field above which is non-null when the cells are pb'd.
       * </pre>
       */
      public Builder clearAssociatedCellCount() {
        bitField0_ = (bitField0_ & ~0x00000080);
        associatedCellCount_ = 0;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:MutationProto)
    }

    static {
      defaultInstance = new MutationProto(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MutationProto)
  }

  public interface MutateRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier region = 1;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    // required .MutationProto mutation = 2;
    /**
     * <code>required .MutationProto mutation = 2;</code>
     */
    boolean hasMutation();
    /**
     * <code>required .MutationProto mutation = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto getMutation();
    /**
     * <code>required .MutationProto mutation = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder();

    // optional .Condition condition = 3;
    /**
     * <code>optional .Condition condition = 3;</code>
     */
    boolean hasCondition();
    /**
     * <code>optional .Condition condition = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition getCondition();
    /**
     * <code>optional .Condition condition = 3;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder();
  }
  /**
   * Protobuf type {@code MutateRequest}
   *
   * <pre>
   **
   * The mutate request. Perform a single Mutate operation.
   *
   * Optionally, you can specify a condition. The mutate
   * will take place only if the condition is met.  Otherwise,
   * the mutate will be ignored.  In the response result,
   * parameter processed is used to indicate if the mutate
   * actually happened.
   * </pre>
   */
  public static final class MutateRequest extends
      com.google.protobuf.GeneratedMessage
      implements MutateRequestOrBuilder {
    // Use MutateRequest.newBuilder() to construct.
    private MutateRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MutateRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MutateRequest defaultInstance;
    public static MutateRequest getDefaultInstance() {
      return defaultInstance;
    }

    public MutateRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MutateRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = mutation_.toBuilder();
              }
              mutation_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(mutation_);
                mutation_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = condition_.toBuilder();
              }
              condition_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(condition_);
                condition_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<MutateRequest> PARSER =
        new com.google.protobuf.AbstractParser<MutateRequest>() {
      public MutateRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MutateRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MutateRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }

    // required .MutationProto mutation = 2;
    public static final int MUTATION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto mutation_;
    /**
     * <code>required .MutationProto mutation = 2;</code>
     */
    public boolean hasMutation() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .MutationProto mutation = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto getMutation() {
      return mutation_;
    }
    /**
     * <code>required .MutationProto mutation = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder() {
      return mutation_;
    }

    // optional .Condition condition = 3;
    public static final int CONDITION_FIELD_NUMBER = 3;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition condition_;
    /**
     * <code>optional .Condition condition = 3;</code>
     */
    public boolean hasCondition() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .Condition condition = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition getCondition() {
      return condition_;
    }
    /**
     * <code>optional .Condition condition = 3;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
      return condition_;
    }

    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      mutation_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
      condition_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMutation()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getMutation().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (hasCondition()) {
        if (!getCondition().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, mutation_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, condition_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, mutation_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, condition_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasMutation() == other.hasMutation());
      if (hasMutation()) {
        result = result && getMutation()
            .equals(other.getMutation());
      }
      result = result && (hasCondition() == other.hasCondition());
      if (hasCondition()) {
        result = result && getCondition()
            .equals(other.getCondition());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasMutation()) {
        hash = (37 * hash) + MUTATION_FIELD_NUMBER;
        hash = (53 * hash) + getMutation().hashCode();
      }
      if (hasCondition()) {
        hash = (37 * hash) + CONDITION_FIELD_NUMBER;
        hash = (53 * hash) + getCondition().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MutateRequest}
     *
     * <pre>
     **
     * The mutate request. Perform a single Mutate operation.
     *
     * Optionally, you can specify a condition. The mutate
     * will take place only if the condition is met.  Otherwise,
     * the mutate will be ignored.  In the response result,
     * parameter processed is used to indicate if the mutate
     * actually happened.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getMutationFieldBuilder();
          getConditionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (mutationBuilder_ == null) {
          mutation_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
        } else {
          mutationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (conditionBuilder_ == null) {
          condition_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
        } else {
          conditionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (mutationBuilder_ == null) {
          result.mutation_ = mutation_;
        } else {
          result.mutation_ = mutationBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (conditionBuilder_ == null) {
          result.condition_ = condition_;
        } else {
          result.condition_ = conditionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasMutation()) {
          mergeMutation(other.getMutation());
        }
        if (other.hasCondition()) {
          mergeCondition(other.getCondition());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasMutation()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getMutation().isInitialized()) {
          
          return false;
        }
        if (hasCondition()) {
          if (!getCondition().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      // required .MutationProto mutation = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto mutation_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder> mutationBuilder_;
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      public boolean hasMutation() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto getMutation() {
        if (mutationBuilder_ == null) {
          return mutation_;
        } else {
          return mutationBuilder_.getMessage();
        }
      }
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      public Builder setMutation(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto value) {
        if (mutationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mutation_ = value;
          onChanged();
        } else {
          mutationBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      public Builder setMutation(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder builderForValue) {
        if (mutationBuilder_ == null) {
          mutation_ = builderForValue.build();
          onChanged();
        } else {
          mutationBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      public Builder mergeMutation(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto value) {
        if (mutationBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              mutation_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance()) {
            mutation_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.newBuilder(mutation_).mergeFrom(value).buildPartial();
          } else {
            mutation_ = value;
          }
          onChanged();
        } else {
          mutationBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      public Builder clearMutation() {
        if (mutationBuilder_ == null) {
          mutation_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
          onChanged();
        } else {
          mutationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder getMutationBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getMutationFieldBuilder().getBuilder();
      }
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder() {
        if (mutationBuilder_ != null) {
          return mutationBuilder_.getMessageOrBuilder();
        } else {
          return mutation_;
        }
      }
      /**
       * <code>required .MutationProto mutation = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder> 
          getMutationFieldBuilder() {
        if (mutationBuilder_ == null) {
          mutationBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder>(
                  mutation_,
                  getParentForChildren(),
                  isClean());
          mutation_ = null;
        }
        return mutationBuilder_;
      }

      // optional .Condition condition = 3;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition condition_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder> conditionBuilder_;
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      public boolean hasCondition() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition getCondition() {
        if (conditionBuilder_ == null) {
          return condition_;
        } else {
          return conditionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      public Builder setCondition(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          condition_ = value;
          onChanged();
        } else {
          conditionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      public Builder setCondition(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder builderForValue) {
        if (conditionBuilder_ == null) {
          condition_ = builderForValue.build();
          onChanged();
        } else {
          conditionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      public Builder mergeCondition(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition value) {
        if (conditionBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              condition_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance()) {
            condition_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.newBuilder(condition_).mergeFrom(value).buildPartial();
          } else {
            condition_ = value;
          }
          onChanged();
        } else {
          conditionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      public Builder clearCondition() {
        if (conditionBuilder_ == null) {
          condition_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.getDefaultInstance();
          onChanged();
        } else {
          conditionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder getConditionBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getConditionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder getConditionOrBuilder() {
        if (conditionBuilder_ != null) {
          return conditionBuilder_.getMessageOrBuilder();
        } else {
          return condition_;
        }
      }
      /**
       * <code>optional .Condition condition = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder> 
          getConditionFieldBuilder() {
        if (conditionBuilder_ == null) {
          conditionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Condition.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ConditionOrBuilder>(
                  condition_,
                  getParentForChildren(),
                  isClean());
          condition_ = null;
        }
        return conditionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:MutateRequest)
    }

    static {
      defaultInstance = new MutateRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MutateRequest)
  }

  public interface MutateResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .Result result = 1;
    /**
     * <code>optional .Result result = 1;</code>
     */
    boolean hasResult();
    /**
     * <code>optional .Result result = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult();
    /**
     * <code>optional .Result result = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder();

    // optional bool processed = 2;
    /**
     * <code>optional bool processed = 2;</code>
     *
     * <pre>
     * used for mutate to indicate processed only
     * </pre>
     */
    boolean hasProcessed();
    /**
     * <code>optional bool processed = 2;</code>
     *
     * <pre>
     * used for mutate to indicate processed only
     * </pre>
     */
    boolean getProcessed();
  }
  /**
   * Protobuf type {@code MutateResponse}
   */
  public static final class MutateResponse extends
      com.google.protobuf.GeneratedMessage
      implements MutateResponseOrBuilder {
    // Use MutateResponse.newBuilder() to construct.
    private MutateResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MutateResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MutateResponse defaultInstance;
    public static MutateResponse getDefaultInstance() {
      return defaultInstance;
    }

    public MutateResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MutateResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = result_.toBuilder();
              }
              result_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(result_);
                result_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              processed_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<MutateResponse> PARSER =
        new com.google.protobuf.AbstractParser<MutateResponse>() {
      public MutateResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MutateResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MutateResponse> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .Result result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result_;
    /**
     * <code>optional .Result result = 1;</code>
     */
    public boolean hasResult() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .Result result = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult() {
      return result_;
    }
    /**
     * <code>optional .Result result = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
      return result_;
    }

    // optional bool processed = 2;
    public static final int PROCESSED_FIELD_NUMBER = 2;
    private boolean processed_;
    /**
     * <code>optional bool processed = 2;</code>
     *
     * <pre>
     * used for mutate to indicate processed only
     * </pre>
     */
    public boolean hasProcessed() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool processed = 2;</code>
     *
     * <pre>
     * used for mutate to indicate processed only
     * </pre>
     */
    public boolean getProcessed() {
      return processed_;
    }

    private void initFields() {
      result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      processed_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, result_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(2, processed_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, processed_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse) obj;

      boolean result = true;
      result = result && (hasResult() == other.hasResult());
      if (hasResult()) {
        result = result && getResult()
            .equals(other.getResult());
      }
      result = result && (hasProcessed() == other.hasProcessed());
      if (hasProcessed()) {
        result = result && (getProcessed()
            == other.getProcessed());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasResult()) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResult().hashCode();
      }
      if (hasProcessed()) {
        hash = (37 * hash) + PROCESSED_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getProcessed());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MutateResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
        } else {
          resultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        processed_ = false;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MutateResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resultBuilder_ == null) {
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.processed_ = processed_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance()) return this;
        if (other.hasResult()) {
          mergeResult(other.getResult());
        }
        if (other.hasProcessed()) {
          setProcessed(other.getProcessed());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .Result result = 1;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> resultBuilder_;
      /**
       * <code>optional .Result result = 1;</code>
       */
      public boolean hasResult() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResult() {
        if (resultBuilder_ == null) {
          return result_;
        } else {
          return resultBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public Builder setResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          result_ = value;
          onChanged();
        } else {
          resultBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public Builder setResult(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultBuilder_ == null) {
          result_ = builderForValue.build();
          onChanged();
        } else {
          resultBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public Builder mergeResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              result_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance()) {
            result_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder(result_).mergeFrom(value).buildPartial();
          } else {
            result_ = value;
          }
          onChanged();
        } else {
          resultBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder getResultBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResultFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultOrBuilder() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilder();
        } else {
          return result_;
        }
      }
      /**
       * <code>optional .Result result = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  result_,
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }

      // optional bool processed = 2;
      private boolean processed_ ;
      /**
       * <code>optional bool processed = 2;</code>
       *
       * <pre>
       * used for mutate to indicate processed only
       * </pre>
       */
      public boolean hasProcessed() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bool processed = 2;</code>
       *
       * <pre>
       * used for mutate to indicate processed only
       * </pre>
       */
      public boolean getProcessed() {
        return processed_;
      }
      /**
       * <code>optional bool processed = 2;</code>
       *
       * <pre>
       * used for mutate to indicate processed only
       * </pre>
       */
      public Builder setProcessed(boolean value) {
        bitField0_ |= 0x00000002;
        processed_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool processed = 2;</code>
       *
       * <pre>
       * used for mutate to indicate processed only
       * </pre>
       */
      public Builder clearProcessed() {
        bitField0_ = (bitField0_ & ~0x00000002);
        processed_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:MutateResponse)
    }

    static {
      defaultInstance = new MutateResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MutateResponse)
  }

  public interface ScanOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .Column column = 1;
    /**
     * <code>repeated .Column column = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> 
        getColumnList();
    /**
     * <code>repeated .Column column = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index);
    /**
     * <code>repeated .Column column = 1;</code>
     */
    int getColumnCount();
    /**
     * <code>repeated .Column column = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList();
    /**
     * <code>repeated .Column column = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index);

    // repeated .NameBytesPair attribute = 2;
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> 
        getAttributeList();
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index);
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    int getAttributeCount();
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList();
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index);

    // optional bytes start_row = 3;
    /**
     * <code>optional bytes start_row = 3;</code>
     */
    boolean hasStartRow();
    /**
     * <code>optional bytes start_row = 3;</code>
     */
    com.google.protobuf.ByteString getStartRow();

    // optional bytes stop_row = 4;
    /**
     * <code>optional bytes stop_row = 4;</code>
     */
    boolean hasStopRow();
    /**
     * <code>optional bytes stop_row = 4;</code>
     */
    com.google.protobuf.ByteString getStopRow();

    // optional .Filter filter = 5;
    /**
     * <code>optional .Filter filter = 5;</code>
     */
    boolean hasFilter();
    /**
     * <code>optional .Filter filter = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter getFilter();
    /**
     * <code>optional .Filter filter = 5;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder();

    // optional .TimeRange time_range = 6;
    /**
     * <code>optional .TimeRange time_range = 6;</code>
     */
    boolean hasTimeRange();
    /**
     * <code>optional .TimeRange time_range = 6;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange();
    /**
     * <code>optional .TimeRange time_range = 6;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder();

    // optional uint32 max_versions = 7 [default = 1];
    /**
     * <code>optional uint32 max_versions = 7 [default = 1];</code>
     */
    boolean hasMaxVersions();
    /**
     * <code>optional uint32 max_versions = 7 [default = 1];</code>
     */
    int getMaxVersions();

    // optional bool cache_blocks = 8 [default = true];
    /**
     * <code>optional bool cache_blocks = 8 [default = true];</code>
     */
    boolean hasCacheBlocks();
    /**
     * <code>optional bool cache_blocks = 8 [default = true];</code>
     */
    boolean getCacheBlocks();

    // optional uint32 batch_size = 9;
    /**
     * <code>optional uint32 batch_size = 9;</code>
     */
    boolean hasBatchSize();
    /**
     * <code>optional uint32 batch_size = 9;</code>
     */
    int getBatchSize();

    // optional uint64 max_result_size = 10;
    /**
     * <code>optional uint64 max_result_size = 10;</code>
     */
    boolean hasMaxResultSize();
    /**
     * <code>optional uint64 max_result_size = 10;</code>
     */
    long getMaxResultSize();

    // optional uint32 store_limit = 11;
    /**
     * <code>optional uint32 store_limit = 11;</code>
     */
    boolean hasStoreLimit();
    /**
     * <code>optional uint32 store_limit = 11;</code>
     */
    int getStoreLimit();

    // optional uint32 store_offset = 12;
    /**
     * <code>optional uint32 store_offset = 12;</code>
     */
    boolean hasStoreOffset();
    /**
     * <code>optional uint32 store_offset = 12;</code>
     */
    int getStoreOffset();

    // optional bool load_column_families_on_demand = 13;
    /**
     * <code>optional bool load_column_families_on_demand = 13;</code>
     *
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     */
    boolean hasLoadColumnFamiliesOnDemand();
    /**
     * <code>optional bool load_column_families_on_demand = 13;</code>
     *
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     */
    boolean getLoadColumnFamiliesOnDemand();
  }
  /**
   * Protobuf type {@code Scan}
   *
   * <pre>
   **
   * Instead of get from a table, you can scan it with optional filters.
   * You can specify the row key range, time range, the columns/families
   * to scan and so on.
   *
   * This scan is used the first time in a scan request. The response of
   * the initial scan will return a scanner id, which should be used to
   * fetch result batches later on before it is closed.
   * </pre>
   */
  public static final class Scan extends
      com.google.protobuf.GeneratedMessage
      implements ScanOrBuilder {
    // Use Scan.newBuilder() to construct.
    private Scan(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private Scan(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final Scan defaultInstance;
    public static Scan getDefaultInstance() {
      return defaultInstance;
    }

    public Scan getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private Scan(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                column_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column>();
                mutable_bitField0_ |= 0x00000001;
              }
              column_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>();
                mutable_bitField0_ |= 0x00000002;
              }
              attribute_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.PARSER, extensionRegistry));
              break;
            }
            case 26: {
              bitField0_ |= 0x00000001;
              startRow_ = input.readBytes();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000002;
              stopRow_ = input.readBytes();
              break;
            }
            case 42: {
              org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = filter_.toBuilder();
              }
              filter_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(filter_);
                filter_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 50: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = timeRange_.toBuilder();
              }
              timeRange_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(timeRange_);
                timeRange_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 56: {
              bitField0_ |= 0x00000010;
              maxVersions_ = input.readUInt32();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000020;
              cacheBlocks_ = input.readBool();
              break;
            }
            case 72: {
              bitField0_ |= 0x00000040;
              batchSize_ = input.readUInt32();
              break;
            }
            case 80: {
              bitField0_ |= 0x00000080;
              maxResultSize_ = input.readUInt64();
              break;
            }
            case 88: {
              bitField0_ |= 0x00000100;
              storeLimit_ = input.readUInt32();
              break;
            }
            case 96: {
              bitField0_ |= 0x00000200;
              storeOffset_ = input.readUInt32();
              break;
            }
            case 104: {
              bitField0_ |= 0x00000400;
              loadColumnFamiliesOnDemand_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          column_ = java.util.Collections.unmodifiableList(column_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          attribute_ = java.util.Collections.unmodifiableList(attribute_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder.class);
    }

    public static com.google.protobuf.Parser<Scan> PARSER =
        new com.google.protobuf.AbstractParser<Scan>() {
      public Scan parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new Scan(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<Scan> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // repeated .Column column = 1;
    public static final int COLUMN_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> column_;
    /**
     * <code>repeated .Column column = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> getColumnList() {
      return column_;
    }
    /**
     * <code>repeated .Column column = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
        getColumnOrBuilderList() {
      return column_;
    }
    /**
     * <code>repeated .Column column = 1;</code>
     */
    public int getColumnCount() {
      return column_.size();
    }
    /**
     * <code>repeated .Column column = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index) {
      return column_.get(index);
    }
    /**
     * <code>repeated .Column column = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
        int index) {
      return column_.get(index);
    }

    // repeated .NameBytesPair attribute = 2;
    public static final int ATTRIBUTE_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_;
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
      return attribute_;
    }
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
        getAttributeOrBuilderList() {
      return attribute_;
    }
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    public int getAttributeCount() {
      return attribute_.size();
    }
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
      return attribute_.get(index);
    }
    /**
     * <code>repeated .NameBytesPair attribute = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
        int index) {
      return attribute_.get(index);
    }

    // optional bytes start_row = 3;
    public static final int START_ROW_FIELD_NUMBER = 3;
    private com.google.protobuf.ByteString startRow_;
    /**
     * <code>optional bytes start_row = 3;</code>
     */
    public boolean hasStartRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bytes start_row = 3;</code>
     */
    public com.google.protobuf.ByteString getStartRow() {
      return startRow_;
    }

    // optional bytes stop_row = 4;
    public static final int STOP_ROW_FIELD_NUMBER = 4;
    private com.google.protobuf.ByteString stopRow_;
    /**
     * <code>optional bytes stop_row = 4;</code>
     */
    public boolean hasStopRow() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes stop_row = 4;</code>
     */
    public com.google.protobuf.ByteString getStopRow() {
      return stopRow_;
    }

    // optional .Filter filter = 5;
    public static final int FILTER_FIELD_NUMBER = 5;
    private org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter filter_;
    /**
     * <code>optional .Filter filter = 5;</code>
     */
    public boolean hasFilter() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .Filter filter = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter getFilter() {
      return filter_;
    }
    /**
     * <code>optional .Filter filter = 5;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
      return filter_;
    }

    // optional .TimeRange time_range = 6;
    public static final int TIME_RANGE_FIELD_NUMBER = 6;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_;
    /**
     * <code>optional .TimeRange time_range = 6;</code>
     */
    public boolean hasTimeRange() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .TimeRange time_range = 6;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
      return timeRange_;
    }
    /**
     * <code>optional .TimeRange time_range = 6;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
      return timeRange_;
    }

    // optional uint32 max_versions = 7 [default = 1];
    public static final int MAX_VERSIONS_FIELD_NUMBER = 7;
    private int maxVersions_;
    /**
     * <code>optional uint32 max_versions = 7 [default = 1];</code>
     */
    public boolean hasMaxVersions() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional uint32 max_versions = 7 [default = 1];</code>
     */
    public int getMaxVersions() {
      return maxVersions_;
    }

    // optional bool cache_blocks = 8 [default = true];
    public static final int CACHE_BLOCKS_FIELD_NUMBER = 8;
    private boolean cacheBlocks_;
    /**
     * <code>optional bool cache_blocks = 8 [default = true];</code>
     */
    public boolean hasCacheBlocks() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional bool cache_blocks = 8 [default = true];</code>
     */
    public boolean getCacheBlocks() {
      return cacheBlocks_;
    }

    // optional uint32 batch_size = 9;
    public static final int BATCH_SIZE_FIELD_NUMBER = 9;
    private int batchSize_;
    /**
     * <code>optional uint32 batch_size = 9;</code>
     */
    public boolean hasBatchSize() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional uint32 batch_size = 9;</code>
     */
    public int getBatchSize() {
      return batchSize_;
    }

    // optional uint64 max_result_size = 10;
    public static final int MAX_RESULT_SIZE_FIELD_NUMBER = 10;
    private long maxResultSize_;
    /**
     * <code>optional uint64 max_result_size = 10;</code>
     */
    public boolean hasMaxResultSize() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional uint64 max_result_size = 10;</code>
     */
    public long getMaxResultSize() {
      return maxResultSize_;
    }

    // optional uint32 store_limit = 11;
    public static final int STORE_LIMIT_FIELD_NUMBER = 11;
    private int storeLimit_;
    /**
     * <code>optional uint32 store_limit = 11;</code>
     */
    public boolean hasStoreLimit() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional uint32 store_limit = 11;</code>
     */
    public int getStoreLimit() {
      return storeLimit_;
    }

    // optional uint32 store_offset = 12;
    public static final int STORE_OFFSET_FIELD_NUMBER = 12;
    private int storeOffset_;
    /**
     * <code>optional uint32 store_offset = 12;</code>
     */
    public boolean hasStoreOffset() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional uint32 store_offset = 12;</code>
     */
    public int getStoreOffset() {
      return storeOffset_;
    }

    // optional bool load_column_families_on_demand = 13;
    public static final int LOAD_COLUMN_FAMILIES_ON_DEMAND_FIELD_NUMBER = 13;
    private boolean loadColumnFamiliesOnDemand_;
    /**
     * <code>optional bool load_column_families_on_demand = 13;</code>
     *
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     */
    public boolean hasLoadColumnFamiliesOnDemand() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional bool load_column_families_on_demand = 13;</code>
     *
     * <pre>
     * DO NOT add defaults to load_column_families_on_demand. 
     * </pre>
     */
    public boolean getLoadColumnFamiliesOnDemand() {
      return loadColumnFamiliesOnDemand_;
    }

    private void initFields() {
      column_ = java.util.Collections.emptyList();
      attribute_ = java.util.Collections.emptyList();
      startRow_ = com.google.protobuf.ByteString.EMPTY;
      stopRow_ = com.google.protobuf.ByteString.EMPTY;
      filter_ = org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
      timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      maxVersions_ = 1;
      cacheBlocks_ = true;
      batchSize_ = 0;
      maxResultSize_ = 0L;
      storeLimit_ = 0;
      storeOffset_ = 0;
      loadColumnFamiliesOnDemand_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getColumnCount(); i++) {
        if (!getColumn(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getAttributeCount(); i++) {
        if (!getAttribute(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasFilter()) {
        if (!getFilter().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < column_.size(); i++) {
        output.writeMessage(1, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        output.writeMessage(2, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(3, startRow_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(4, stopRow_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(5, filter_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(6, timeRange_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeUInt32(7, maxVersions_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBool(8, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeUInt32(9, batchSize_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeUInt64(10, maxResultSize_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeUInt32(11, storeLimit_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeUInt32(12, storeOffset_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeBool(13, loadColumnFamiliesOnDemand_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < column_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, column_.get(i));
      }
      for (int i = 0; i < attribute_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, attribute_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, startRow_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, stopRow_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, filter_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, timeRange_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(7, maxVersions_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, cacheBlocks_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(9, batchSize_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(10, maxResultSize_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(11, storeLimit_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(12, storeOffset_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(13, loadColumnFamiliesOnDemand_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan) obj;

      boolean result = true;
      result = result && getColumnList()
          .equals(other.getColumnList());
      result = result && getAttributeList()
          .equals(other.getAttributeList());
      result = result && (hasStartRow() == other.hasStartRow());
      if (hasStartRow()) {
        result = result && getStartRow()
            .equals(other.getStartRow());
      }
      result = result && (hasStopRow() == other.hasStopRow());
      if (hasStopRow()) {
        result = result && getStopRow()
            .equals(other.getStopRow());
      }
      result = result && (hasFilter() == other.hasFilter());
      if (hasFilter()) {
        result = result && getFilter()
            .equals(other.getFilter());
      }
      result = result && (hasTimeRange() == other.hasTimeRange());
      if (hasTimeRange()) {
        result = result && getTimeRange()
            .equals(other.getTimeRange());
      }
      result = result && (hasMaxVersions() == other.hasMaxVersions());
      if (hasMaxVersions()) {
        result = result && (getMaxVersions()
            == other.getMaxVersions());
      }
      result = result && (hasCacheBlocks() == other.hasCacheBlocks());
      if (hasCacheBlocks()) {
        result = result && (getCacheBlocks()
            == other.getCacheBlocks());
      }
      result = result && (hasBatchSize() == other.hasBatchSize());
      if (hasBatchSize()) {
        result = result && (getBatchSize()
            == other.getBatchSize());
      }
      result = result && (hasMaxResultSize() == other.hasMaxResultSize());
      if (hasMaxResultSize()) {
        result = result && (getMaxResultSize()
            == other.getMaxResultSize());
      }
      result = result && (hasStoreLimit() == other.hasStoreLimit());
      if (hasStoreLimit()) {
        result = result && (getStoreLimit()
            == other.getStoreLimit());
      }
      result = result && (hasStoreOffset() == other.hasStoreOffset());
      if (hasStoreOffset()) {
        result = result && (getStoreOffset()
            == other.getStoreOffset());
      }
      result = result && (hasLoadColumnFamiliesOnDemand() == other.hasLoadColumnFamiliesOnDemand());
      if (hasLoadColumnFamiliesOnDemand()) {
        result = result && (getLoadColumnFamiliesOnDemand()
            == other.getLoadColumnFamiliesOnDemand());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getColumnCount() > 0) {
        hash = (37 * hash) + COLUMN_FIELD_NUMBER;
        hash = (53 * hash) + getColumnList().hashCode();
      }
      if (getAttributeCount() > 0) {
        hash = (37 * hash) + ATTRIBUTE_FIELD_NUMBER;
        hash = (53 * hash) + getAttributeList().hashCode();
      }
      if (hasStartRow()) {
        hash = (37 * hash) + START_ROW_FIELD_NUMBER;
        hash = (53 * hash) + getStartRow().hashCode();
      }
      if (hasStopRow()) {
        hash = (37 * hash) + STOP_ROW_FIELD_NUMBER;
        hash = (53 * hash) + getStopRow().hashCode();
      }
      if (hasFilter()) {
        hash = (37 * hash) + FILTER_FIELD_NUMBER;
        hash = (53 * hash) + getFilter().hashCode();
      }
      if (hasTimeRange()) {
        hash = (37 * hash) + TIME_RANGE_FIELD_NUMBER;
        hash = (53 * hash) + getTimeRange().hashCode();
      }
      if (hasMaxVersions()) {
        hash = (37 * hash) + MAX_VERSIONS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxVersions();
      }
      if (hasCacheBlocks()) {
        hash = (37 * hash) + CACHE_BLOCKS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCacheBlocks());
      }
      if (hasBatchSize()) {
        hash = (37 * hash) + BATCH_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getBatchSize();
      }
      if (hasMaxResultSize()) {
        hash = (37 * hash) + MAX_RESULT_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getMaxResultSize());
      }
      if (hasStoreLimit()) {
        hash = (37 * hash) + STORE_LIMIT_FIELD_NUMBER;
        hash = (53 * hash) + getStoreLimit();
      }
      if (hasStoreOffset()) {
        hash = (37 * hash) + STORE_OFFSET_FIELD_NUMBER;
        hash = (53 * hash) + getStoreOffset();
      }
      if (hasLoadColumnFamiliesOnDemand()) {
        hash = (37 * hash) + LOAD_COLUMN_FAMILIES_ON_DEMAND_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getLoadColumnFamiliesOnDemand());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code Scan}
     *
     * <pre>
     **
     * Instead of get from a table, you can scan it with optional filters.
     * You can specify the row key range, time range, the columns/families
     * to scan and so on.
     *
     * This scan is used the first time in a scan request. The response of
     * the initial scan will return a scanner id, which should be used to
     * fetch result batches later on before it is closed.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getColumnFieldBuilder();
          getAttributeFieldBuilder();
          getFilterFieldBuilder();
          getTimeRangeFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          columnBuilder_.clear();
        }
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          attributeBuilder_.clear();
        }
        startRow_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000004);
        stopRow_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (filterBuilder_ == null) {
          filter_ = org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
        } else {
          filterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        maxVersions_ = 1;
        bitField0_ = (bitField0_ & ~0x00000040);
        cacheBlocks_ = true;
        bitField0_ = (bitField0_ & ~0x00000080);
        batchSize_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        maxResultSize_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000200);
        storeLimit_ = 0;
        bitField0_ = (bitField0_ & ~0x00000400);
        storeOffset_ = 0;
        bitField0_ = (bitField0_ & ~0x00000800);
        loadColumnFamiliesOnDemand_ = false;
        bitField0_ = (bitField0_ & ~0x00001000);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_Scan_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (columnBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            column_ = java.util.Collections.unmodifiableList(column_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.column_ = column_;
        } else {
          result.column_ = columnBuilder_.build();
        }
        if (attributeBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            attribute_ = java.util.Collections.unmodifiableList(attribute_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.attribute_ = attribute_;
        } else {
          result.attribute_ = attributeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000001;
        }
        result.startRow_ = startRow_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000002;
        }
        result.stopRow_ = stopRow_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000004;
        }
        if (filterBuilder_ == null) {
          result.filter_ = filter_;
        } else {
          result.filter_ = filterBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000008;
        }
        if (timeRangeBuilder_ == null) {
          result.timeRange_ = timeRange_;
        } else {
          result.timeRange_ = timeRangeBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000010;
        }
        result.maxVersions_ = maxVersions_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000020;
        }
        result.cacheBlocks_ = cacheBlocks_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000040;
        }
        result.batchSize_ = batchSize_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000080;
        }
        result.maxResultSize_ = maxResultSize_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000100;
        }
        result.storeLimit_ = storeLimit_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000200;
        }
        result.storeOffset_ = storeOffset_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00000400;
        }
        result.loadColumnFamiliesOnDemand_ = loadColumnFamiliesOnDemand_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance()) return this;
        if (columnBuilder_ == null) {
          if (!other.column_.isEmpty()) {
            if (column_.isEmpty()) {
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureColumnIsMutable();
              column_.addAll(other.column_);
            }
            onChanged();
          }
        } else {
          if (!other.column_.isEmpty()) {
            if (columnBuilder_.isEmpty()) {
              columnBuilder_.dispose();
              columnBuilder_ = null;
              column_ = other.column_;
              bitField0_ = (bitField0_ & ~0x00000001);
              columnBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getColumnFieldBuilder() : null;
            } else {
              columnBuilder_.addAllMessages(other.column_);
            }
          }
        }
        if (attributeBuilder_ == null) {
          if (!other.attribute_.isEmpty()) {
            if (attribute_.isEmpty()) {
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureAttributeIsMutable();
              attribute_.addAll(other.attribute_);
            }
            onChanged();
          }
        } else {
          if (!other.attribute_.isEmpty()) {
            if (attributeBuilder_.isEmpty()) {
              attributeBuilder_.dispose();
              attributeBuilder_ = null;
              attribute_ = other.attribute_;
              bitField0_ = (bitField0_ & ~0x00000002);
              attributeBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getAttributeFieldBuilder() : null;
            } else {
              attributeBuilder_.addAllMessages(other.attribute_);
            }
          }
        }
        if (other.hasStartRow()) {
          setStartRow(other.getStartRow());
        }
        if (other.hasStopRow()) {
          setStopRow(other.getStopRow());
        }
        if (other.hasFilter()) {
          mergeFilter(other.getFilter());
        }
        if (other.hasTimeRange()) {
          mergeTimeRange(other.getTimeRange());
        }
        if (other.hasMaxVersions()) {
          setMaxVersions(other.getMaxVersions());
        }
        if (other.hasCacheBlocks()) {
          setCacheBlocks(other.getCacheBlocks());
        }
        if (other.hasBatchSize()) {
          setBatchSize(other.getBatchSize());
        }
        if (other.hasMaxResultSize()) {
          setMaxResultSize(other.getMaxResultSize());
        }
        if (other.hasStoreLimit()) {
          setStoreLimit(other.getStoreLimit());
        }
        if (other.hasStoreOffset()) {
          setStoreOffset(other.getStoreOffset());
        }
        if (other.hasLoadColumnFamiliesOnDemand()) {
          setLoadColumnFamiliesOnDemand(other.getLoadColumnFamiliesOnDemand());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getColumnCount(); i++) {
          if (!getColumn(i).isInitialized()) {
            
            return false;
          }
        }
        for (int i = 0; i < getAttributeCount(); i++) {
          if (!getAttribute(i).isInitialized()) {
            
            return false;
          }
        }
        if (hasFilter()) {
          if (!getFilter().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .Column column = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> column_ =
        java.util.Collections.emptyList();
      private void ensureColumnIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          column_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column>(column_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> columnBuilder_;

      /**
       * <code>repeated .Column column = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> getColumnList() {
        if (columnBuilder_ == null) {
          return java.util.Collections.unmodifiableList(column_);
        } else {
          return columnBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public int getColumnCount() {
        if (columnBuilder_ == null) {
          return column_.size();
        } else {
          return columnBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column getColumn(int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);
        } else {
          return columnBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.set(index, value);
          onChanged();
        } else {
          columnBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder setColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.set(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder addColumn(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(value);
          onChanged();
        } else {
          columnBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column value) {
        if (columnBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureColumnIsMutable();
          column_.add(index, value);
          onChanged();
        } else {
          columnBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder addColumn(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder addColumn(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder builderForValue) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.add(index, builderForValue.build());
          onChanged();
        } else {
          columnBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder addAllColumn(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column> values) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          super.addAll(values, column_);
          onChanged();
        } else {
          columnBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder clearColumn() {
        if (columnBuilder_ == null) {
          column_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          columnBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public Builder removeColumn(int index) {
        if (columnBuilder_ == null) {
          ensureColumnIsMutable();
          column_.remove(index);
          onChanged();
        } else {
          columnBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder getColumnBuilder(
          int index) {
        return getColumnFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder getColumnOrBuilder(
          int index) {
        if (columnBuilder_ == null) {
          return column_.get(index);  } else {
          return columnBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
           getColumnOrBuilderList() {
        if (columnBuilder_ != null) {
          return columnBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(column_);
        }
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder() {
        return getColumnFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder addColumnBuilder(
          int index) {
        return getColumnFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.getDefaultInstance());
      }
      /**
       * <code>repeated .Column column = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder> 
           getColumnBuilderList() {
        return getColumnFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder> 
          getColumnFieldBuilder() {
        if (columnBuilder_ == null) {
          columnBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Column.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ColumnOrBuilder>(
                  column_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          column_ = null;
        }
        return columnBuilder_;
      }

      // repeated .NameBytesPair attribute = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> attribute_ =
        java.util.Collections.emptyList();
      private void ensureAttributeIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          attribute_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair>(attribute_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> attributeBuilder_;

      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> getAttributeList() {
        if (attributeBuilder_ == null) {
          return java.util.Collections.unmodifiableList(attribute_);
        } else {
          return attributeBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public int getAttributeCount() {
        if (attributeBuilder_ == null) {
          return attribute_.size();
        } else {
          return attributeBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getAttribute(int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);
        } else {
          return attributeBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.set(index, value);
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder setAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.set(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder addAttribute(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (attributeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAttributeIsMutable();
          attribute_.add(index, value);
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder addAttribute(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder addAttribute(
          int index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.add(index, builderForValue.build());
          onChanged();
        } else {
          attributeBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder addAllAttribute(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair> values) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          super.addAll(values, attribute_);
          onChanged();
        } else {
          attributeBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder clearAttribute() {
        if (attributeBuilder_ == null) {
          attribute_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          attributeBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public Builder removeAttribute(int index) {
        if (attributeBuilder_ == null) {
          ensureAttributeIsMutable();
          attribute_.remove(index);
          onChanged();
        } else {
          attributeBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getAttributeOrBuilder(
          int index) {
        if (attributeBuilder_ == null) {
          return attribute_.get(index);  } else {
          return attributeBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
           getAttributeOrBuilderList() {
        if (attributeBuilder_ != null) {
          return attributeBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(attribute_);
        }
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder() {
        return getAttributeFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder addAttributeBuilder(
          int index) {
        return getAttributeFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance());
      }
      /**
       * <code>repeated .NameBytesPair attribute = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder> 
           getAttributeBuilderList() {
        return getAttributeFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getAttributeFieldBuilder() {
        if (attributeBuilder_ == null) {
          attributeBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  attribute_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          attribute_ = null;
        }
        return attributeBuilder_;
      }

      // optional bytes start_row = 3;
      private com.google.protobuf.ByteString startRow_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes start_row = 3;</code>
       */
      public boolean hasStartRow() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bytes start_row = 3;</code>
       */
      public com.google.protobuf.ByteString getStartRow() {
        return startRow_;
      }
      /**
       * <code>optional bytes start_row = 3;</code>
       */
      public Builder setStartRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        startRow_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes start_row = 3;</code>
       */
      public Builder clearStartRow() {
        bitField0_ = (bitField0_ & ~0x00000004);
        startRow_ = getDefaultInstance().getStartRow();
        onChanged();
        return this;
      }

      // optional bytes stop_row = 4;
      private com.google.protobuf.ByteString stopRow_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes stop_row = 4;</code>
       */
      public boolean hasStopRow() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional bytes stop_row = 4;</code>
       */
      public com.google.protobuf.ByteString getStopRow() {
        return stopRow_;
      }
      /**
       * <code>optional bytes stop_row = 4;</code>
       */
      public Builder setStopRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        stopRow_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes stop_row = 4;</code>
       */
      public Builder clearStopRow() {
        bitField0_ = (bitField0_ & ~0x00000008);
        stopRow_ = getDefaultInstance().getStopRow();
        onChanged();
        return this;
      }

      // optional .Filter filter = 5;
      private org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter filter_ = org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder> filterBuilder_;
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      public boolean hasFilter() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter getFilter() {
        if (filterBuilder_ == null) {
          return filter_;
        } else {
          return filterBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      public Builder setFilter(org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          filter_ = value;
          onChanged();
        } else {
          filterBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      public Builder setFilter(
          org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder builderForValue) {
        if (filterBuilder_ == null) {
          filter_ = builderForValue.build();
          onChanged();
        } else {
          filterBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      public Builder mergeFilter(org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter value) {
        if (filterBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              filter_ != org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance()) {
            filter_ =
              org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.newBuilder(filter_).mergeFrom(value).buildPartial();
          } else {
            filter_ = value;
          }
          onChanged();
        } else {
          filterBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      public Builder clearFilter() {
        if (filterBuilder_ == null) {
          filter_ = org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.getDefaultInstance();
          onChanged();
        } else {
          filterBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder getFilterBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getFilterFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder getFilterOrBuilder() {
        if (filterBuilder_ != null) {
          return filterBuilder_.getMessageOrBuilder();
        } else {
          return filter_;
        }
      }
      /**
       * <code>optional .Filter filter = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder> 
          getFilterFieldBuilder() {
        if (filterBuilder_ == null) {
          filterBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.Filter.Builder, org.apache.hadoop.hbase.protobuf.generated.FilterProtos.FilterOrBuilder>(
                  filter_,
                  getParentForChildren(),
                  isClean());
          filter_ = null;
        }
        return filterBuilder_;
      }

      // optional .TimeRange time_range = 6;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> timeRangeBuilder_;
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      public boolean hasTimeRange() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange getTimeRange() {
        if (timeRangeBuilder_ == null) {
          return timeRange_;
        } else {
          return timeRangeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      public Builder setTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          timeRange_ = value;
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      public Builder setTimeRange(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder builderForValue) {
        if (timeRangeBuilder_ == null) {
          timeRange_ = builderForValue.build();
          onChanged();
        } else {
          timeRangeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      public Builder mergeTimeRange(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange value) {
        if (timeRangeBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              timeRange_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance()) {
            timeRange_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.newBuilder(timeRange_).mergeFrom(value).buildPartial();
          } else {
            timeRange_ = value;
          }
          onChanged();
        } else {
          timeRangeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      public Builder clearTimeRange() {
        if (timeRangeBuilder_ == null) {
          timeRange_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.getDefaultInstance();
          onChanged();
        } else {
          timeRangeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder getTimeRangeBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getTimeRangeFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder getTimeRangeOrBuilder() {
        if (timeRangeBuilder_ != null) {
          return timeRangeBuilder_.getMessageOrBuilder();
        } else {
          return timeRange_;
        }
      }
      /**
       * <code>optional .TimeRange time_range = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder> 
          getTimeRangeFieldBuilder() {
        if (timeRangeBuilder_ == null) {
          timeRangeBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRange.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.TimeRangeOrBuilder>(
                  timeRange_,
                  getParentForChildren(),
                  isClean());
          timeRange_ = null;
        }
        return timeRangeBuilder_;
      }

      // optional uint32 max_versions = 7 [default = 1];
      private int maxVersions_ = 1;
      /**
       * <code>optional uint32 max_versions = 7 [default = 1];</code>
       */
      public boolean hasMaxVersions() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional uint32 max_versions = 7 [default = 1];</code>
       */
      public int getMaxVersions() {
        return maxVersions_;
      }
      /**
       * <code>optional uint32 max_versions = 7 [default = 1];</code>
       */
      public Builder setMaxVersions(int value) {
        bitField0_ |= 0x00000040;
        maxVersions_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 max_versions = 7 [default = 1];</code>
       */
      public Builder clearMaxVersions() {
        bitField0_ = (bitField0_ & ~0x00000040);
        maxVersions_ = 1;
        onChanged();
        return this;
      }

      // optional bool cache_blocks = 8 [default = true];
      private boolean cacheBlocks_ = true;
      /**
       * <code>optional bool cache_blocks = 8 [default = true];</code>
       */
      public boolean hasCacheBlocks() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional bool cache_blocks = 8 [default = true];</code>
       */
      public boolean getCacheBlocks() {
        return cacheBlocks_;
      }
      /**
       * <code>optional bool cache_blocks = 8 [default = true];</code>
       */
      public Builder setCacheBlocks(boolean value) {
        bitField0_ |= 0x00000080;
        cacheBlocks_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool cache_blocks = 8 [default = true];</code>
       */
      public Builder clearCacheBlocks() {
        bitField0_ = (bitField0_ & ~0x00000080);
        cacheBlocks_ = true;
        onChanged();
        return this;
      }

      // optional uint32 batch_size = 9;
      private int batchSize_ ;
      /**
       * <code>optional uint32 batch_size = 9;</code>
       */
      public boolean hasBatchSize() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional uint32 batch_size = 9;</code>
       */
      public int getBatchSize() {
        return batchSize_;
      }
      /**
       * <code>optional uint32 batch_size = 9;</code>
       */
      public Builder setBatchSize(int value) {
        bitField0_ |= 0x00000100;
        batchSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 batch_size = 9;</code>
       */
      public Builder clearBatchSize() {
        bitField0_ = (bitField0_ & ~0x00000100);
        batchSize_ = 0;
        onChanged();
        return this;
      }

      // optional uint64 max_result_size = 10;
      private long maxResultSize_ ;
      /**
       * <code>optional uint64 max_result_size = 10;</code>
       */
      public boolean hasMaxResultSize() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional uint64 max_result_size = 10;</code>
       */
      public long getMaxResultSize() {
        return maxResultSize_;
      }
      /**
       * <code>optional uint64 max_result_size = 10;</code>
       */
      public Builder setMaxResultSize(long value) {
        bitField0_ |= 0x00000200;
        maxResultSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 max_result_size = 10;</code>
       */
      public Builder clearMaxResultSize() {
        bitField0_ = (bitField0_ & ~0x00000200);
        maxResultSize_ = 0L;
        onChanged();
        return this;
      }

      // optional uint32 store_limit = 11;
      private int storeLimit_ ;
      /**
       * <code>optional uint32 store_limit = 11;</code>
       */
      public boolean hasStoreLimit() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional uint32 store_limit = 11;</code>
       */
      public int getStoreLimit() {
        return storeLimit_;
      }
      /**
       * <code>optional uint32 store_limit = 11;</code>
       */
      public Builder setStoreLimit(int value) {
        bitField0_ |= 0x00000400;
        storeLimit_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 store_limit = 11;</code>
       */
      public Builder clearStoreLimit() {
        bitField0_ = (bitField0_ & ~0x00000400);
        storeLimit_ = 0;
        onChanged();
        return this;
      }

      // optional uint32 store_offset = 12;
      private int storeOffset_ ;
      /**
       * <code>optional uint32 store_offset = 12;</code>
       */
      public boolean hasStoreOffset() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional uint32 store_offset = 12;</code>
       */
      public int getStoreOffset() {
        return storeOffset_;
      }
      /**
       * <code>optional uint32 store_offset = 12;</code>
       */
      public Builder setStoreOffset(int value) {
        bitField0_ |= 0x00000800;
        storeOffset_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 store_offset = 12;</code>
       */
      public Builder clearStoreOffset() {
        bitField0_ = (bitField0_ & ~0x00000800);
        storeOffset_ = 0;
        onChanged();
        return this;
      }

      // optional bool load_column_families_on_demand = 13;
      private boolean loadColumnFamiliesOnDemand_ ;
      /**
       * <code>optional bool load_column_families_on_demand = 13;</code>
       *
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       */
      public boolean hasLoadColumnFamiliesOnDemand() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional bool load_column_families_on_demand = 13;</code>
       *
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       */
      public boolean getLoadColumnFamiliesOnDemand() {
        return loadColumnFamiliesOnDemand_;
      }
      /**
       * <code>optional bool load_column_families_on_demand = 13;</code>
       *
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       */
      public Builder setLoadColumnFamiliesOnDemand(boolean value) {
        bitField0_ |= 0x00001000;
        loadColumnFamiliesOnDemand_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool load_column_families_on_demand = 13;</code>
       *
       * <pre>
       * DO NOT add defaults to load_column_families_on_demand. 
       * </pre>
       */
      public Builder clearLoadColumnFamiliesOnDemand() {
        bitField0_ = (bitField0_ & ~0x00001000);
        loadColumnFamiliesOnDemand_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:Scan)
    }

    static {
      defaultInstance = new Scan(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:Scan)
  }

  public interface ScanRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .RegionSpecifier region = 1;
    /**
     * <code>optional .RegionSpecifier region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>optional .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>optional .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    // optional .Scan scan = 2;
    /**
     * <code>optional .Scan scan = 2;</code>
     */
    boolean hasScan();
    /**
     * <code>optional .Scan scan = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan getScan();
    /**
     * <code>optional .Scan scan = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder();

    // optional uint64 scanner_id = 3;
    /**
     * <code>optional uint64 scanner_id = 3;</code>
     */
    boolean hasScannerId();
    /**
     * <code>optional uint64 scanner_id = 3;</code>
     */
    long getScannerId();

    // optional uint32 number_of_rows = 4;
    /**
     * <code>optional uint32 number_of_rows = 4;</code>
     */
    boolean hasNumberOfRows();
    /**
     * <code>optional uint32 number_of_rows = 4;</code>
     */
    int getNumberOfRows();

    // optional bool close_scanner = 5;
    /**
     * <code>optional bool close_scanner = 5;</code>
     */
    boolean hasCloseScanner();
    /**
     * <code>optional bool close_scanner = 5;</code>
     */
    boolean getCloseScanner();

    // optional uint64 next_call_seq = 6;
    /**
     * <code>optional uint64 next_call_seq = 6;</code>
     */
    boolean hasNextCallSeq();
    /**
     * <code>optional uint64 next_call_seq = 6;</code>
     */
    long getNextCallSeq();
  }
  /**
   * Protobuf type {@code ScanRequest}
   *
   * <pre>
   **
   * A scan request. Initially, it should specify a scan. Later on, you
   * can use the scanner id returned to fetch result batches with a different
   * scan request.
   *
   * The scanner will remain open if there are more results, and it's not
   * asked to be closed explicitly.
   *
   * You can fetch the results and ask the scanner to be closed to save
   * a trip if you are not interested in remaining results.
   * </pre>
   */
  public static final class ScanRequest extends
      com.google.protobuf.GeneratedMessage
      implements ScanRequestOrBuilder {
    // Use ScanRequest.newBuilder() to construct.
    private ScanRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ScanRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ScanRequest defaultInstance;
    public static ScanRequest getDefaultInstance() {
      return defaultInstance;
    }

    public ScanRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ScanRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = scan_.toBuilder();
              }
              scan_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(scan_);
                scan_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              scannerId_ = input.readUInt64();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              numberOfRows_ = input.readUInt32();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              closeScanner_ = input.readBool();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              nextCallSeq_ = input.readUInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<ScanRequest> PARSER =
        new com.google.protobuf.AbstractParser<ScanRequest>() {
      public ScanRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ScanRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ScanRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>optional .RegionSpecifier region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    /**
     * <code>optional .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }

    // optional .Scan scan = 2;
    public static final int SCAN_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan scan_;
    /**
     * <code>optional .Scan scan = 2;</code>
     */
    public boolean hasScan() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .Scan scan = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan getScan() {
      return scan_;
    }
    /**
     * <code>optional .Scan scan = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder() {
      return scan_;
    }

    // optional uint64 scanner_id = 3;
    public static final int SCANNER_ID_FIELD_NUMBER = 3;
    private long scannerId_;
    /**
     * <code>optional uint64 scanner_id = 3;</code>
     */
    public boolean hasScannerId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional uint64 scanner_id = 3;</code>
     */
    public long getScannerId() {
      return scannerId_;
    }

    // optional uint32 number_of_rows = 4;
    public static final int NUMBER_OF_ROWS_FIELD_NUMBER = 4;
    private int numberOfRows_;
    /**
     * <code>optional uint32 number_of_rows = 4;</code>
     */
    public boolean hasNumberOfRows() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional uint32 number_of_rows = 4;</code>
     */
    public int getNumberOfRows() {
      return numberOfRows_;
    }

    // optional bool close_scanner = 5;
    public static final int CLOSE_SCANNER_FIELD_NUMBER = 5;
    private boolean closeScanner_;
    /**
     * <code>optional bool close_scanner = 5;</code>
     */
    public boolean hasCloseScanner() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool close_scanner = 5;</code>
     */
    public boolean getCloseScanner() {
      return closeScanner_;
    }

    // optional uint64 next_call_seq = 6;
    public static final int NEXT_CALL_SEQ_FIELD_NUMBER = 6;
    private long nextCallSeq_;
    /**
     * <code>optional uint64 next_call_seq = 6;</code>
     */
    public boolean hasNextCallSeq() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional uint64 next_call_seq = 6;</code>
     */
    public long getNextCallSeq() {
      return nextCallSeq_;
    }

    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      scan_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
      scannerId_ = 0L;
      numberOfRows_ = 0;
      closeScanner_ = false;
      nextCallSeq_ = 0L;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasRegion()) {
        if (!getRegion().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasScan()) {
        if (!getScan().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, scan_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt64(3, scannerId_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeUInt32(4, numberOfRows_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(5, closeScanner_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeUInt64(6, nextCallSeq_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, scan_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(3, scannerId_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, numberOfRows_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, closeScanner_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(6, nextCallSeq_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasScan() == other.hasScan());
      if (hasScan()) {
        result = result && getScan()
            .equals(other.getScan());
      }
      result = result && (hasScannerId() == other.hasScannerId());
      if (hasScannerId()) {
        result = result && (getScannerId()
            == other.getScannerId());
      }
      result = result && (hasNumberOfRows() == other.hasNumberOfRows());
      if (hasNumberOfRows()) {
        result = result && (getNumberOfRows()
            == other.getNumberOfRows());
      }
      result = result && (hasCloseScanner() == other.hasCloseScanner());
      if (hasCloseScanner()) {
        result = result && (getCloseScanner()
            == other.getCloseScanner());
      }
      result = result && (hasNextCallSeq() == other.hasNextCallSeq());
      if (hasNextCallSeq()) {
        result = result && (getNextCallSeq()
            == other.getNextCallSeq());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasScan()) {
        hash = (37 * hash) + SCAN_FIELD_NUMBER;
        hash = (53 * hash) + getScan().hashCode();
      }
      if (hasScannerId()) {
        hash = (37 * hash) + SCANNER_ID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getScannerId());
      }
      if (hasNumberOfRows()) {
        hash = (37 * hash) + NUMBER_OF_ROWS_FIELD_NUMBER;
        hash = (53 * hash) + getNumberOfRows();
      }
      if (hasCloseScanner()) {
        hash = (37 * hash) + CLOSE_SCANNER_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getCloseScanner());
      }
      if (hasNextCallSeq()) {
        hash = (37 * hash) + NEXT_CALL_SEQ_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getNextCallSeq());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code ScanRequest}
     *
     * <pre>
     **
     * A scan request. Initially, it should specify a scan. Later on, you
     * can use the scanner id returned to fetch result batches with a different
     * scan request.
     *
     * The scanner will remain open if there are more results, and it's not
     * asked to be closed explicitly.
     *
     * You can fetch the results and ask the scanner to be closed to save
     * a trip if you are not interested in remaining results.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getScanFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (scanBuilder_ == null) {
          scan_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
        } else {
          scanBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        scannerId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        numberOfRows_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        closeScanner_ = false;
        bitField0_ = (bitField0_ & ~0x00000010);
        nextCallSeq_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (scanBuilder_ == null) {
          result.scan_ = scan_;
        } else {
          result.scan_ = scanBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.scannerId_ = scannerId_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.numberOfRows_ = numberOfRows_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.closeScanner_ = closeScanner_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.nextCallSeq_ = nextCallSeq_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasScan()) {
          mergeScan(other.getScan());
        }
        if (other.hasScannerId()) {
          setScannerId(other.getScannerId());
        }
        if (other.hasNumberOfRows()) {
          setNumberOfRows(other.getNumberOfRows());
        }
        if (other.hasCloseScanner()) {
          setCloseScanner(other.getCloseScanner());
        }
        if (other.hasNextCallSeq()) {
          setNextCallSeq(other.getNextCallSeq());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasRegion()) {
          if (!getRegion().isInitialized()) {
            
            return false;
          }
        }
        if (hasScan()) {
          if (!getScan().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      /**
       * <code>optional .RegionSpecifier region = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      // optional .Scan scan = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan scan_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder> scanBuilder_;
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      public boolean hasScan() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan getScan() {
        if (scanBuilder_ == null) {
          return scan_;
        } else {
          return scanBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      public Builder setScan(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan value) {
        if (scanBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          scan_ = value;
          onChanged();
        } else {
          scanBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      public Builder setScan(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder builderForValue) {
        if (scanBuilder_ == null) {
          scan_ = builderForValue.build();
          onChanged();
        } else {
          scanBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      public Builder mergeScan(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan value) {
        if (scanBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              scan_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance()) {
            scan_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.newBuilder(scan_).mergeFrom(value).buildPartial();
          } else {
            scan_ = value;
          }
          onChanged();
        } else {
          scanBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      public Builder clearScan() {
        if (scanBuilder_ == null) {
          scan_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.getDefaultInstance();
          onChanged();
        } else {
          scanBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder getScanBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getScanFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder getScanOrBuilder() {
        if (scanBuilder_ != null) {
          return scanBuilder_.getMessageOrBuilder();
        } else {
          return scan_;
        }
      }
      /**
       * <code>optional .Scan scan = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder> 
          getScanFieldBuilder() {
        if (scanBuilder_ == null) {
          scanBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Scan.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanOrBuilder>(
                  scan_,
                  getParentForChildren(),
                  isClean());
          scan_ = null;
        }
        return scanBuilder_;
      }

      // optional uint64 scanner_id = 3;
      private long scannerId_ ;
      /**
       * <code>optional uint64 scanner_id = 3;</code>
       */
      public boolean hasScannerId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional uint64 scanner_id = 3;</code>
       */
      public long getScannerId() {
        return scannerId_;
      }
      /**
       * <code>optional uint64 scanner_id = 3;</code>
       */
      public Builder setScannerId(long value) {
        bitField0_ |= 0x00000004;
        scannerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 scanner_id = 3;</code>
       */
      public Builder clearScannerId() {
        bitField0_ = (bitField0_ & ~0x00000004);
        scannerId_ = 0L;
        onChanged();
        return this;
      }

      // optional uint32 number_of_rows = 4;
      private int numberOfRows_ ;
      /**
       * <code>optional uint32 number_of_rows = 4;</code>
       */
      public boolean hasNumberOfRows() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional uint32 number_of_rows = 4;</code>
       */
      public int getNumberOfRows() {
        return numberOfRows_;
      }
      /**
       * <code>optional uint32 number_of_rows = 4;</code>
       */
      public Builder setNumberOfRows(int value) {
        bitField0_ |= 0x00000008;
        numberOfRows_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 number_of_rows = 4;</code>
       */
      public Builder clearNumberOfRows() {
        bitField0_ = (bitField0_ & ~0x00000008);
        numberOfRows_ = 0;
        onChanged();
        return this;
      }

      // optional bool close_scanner = 5;
      private boolean closeScanner_ ;
      /**
       * <code>optional bool close_scanner = 5;</code>
       */
      public boolean hasCloseScanner() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool close_scanner = 5;</code>
       */
      public boolean getCloseScanner() {
        return closeScanner_;
      }
      /**
       * <code>optional bool close_scanner = 5;</code>
       */
      public Builder setCloseScanner(boolean value) {
        bitField0_ |= 0x00000010;
        closeScanner_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool close_scanner = 5;</code>
       */
      public Builder clearCloseScanner() {
        bitField0_ = (bitField0_ & ~0x00000010);
        closeScanner_ = false;
        onChanged();
        return this;
      }

      // optional uint64 next_call_seq = 6;
      private long nextCallSeq_ ;
      /**
       * <code>optional uint64 next_call_seq = 6;</code>
       */
      public boolean hasNextCallSeq() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional uint64 next_call_seq = 6;</code>
       */
      public long getNextCallSeq() {
        return nextCallSeq_;
      }
      /**
       * <code>optional uint64 next_call_seq = 6;</code>
       */
      public Builder setNextCallSeq(long value) {
        bitField0_ |= 0x00000020;
        nextCallSeq_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 next_call_seq = 6;</code>
       */
      public Builder clearNextCallSeq() {
        bitField0_ = (bitField0_ & ~0x00000020);
        nextCallSeq_ = 0L;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:ScanRequest)
    }

    static {
      defaultInstance = new ScanRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:ScanRequest)
  }

  public interface ScanResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated uint32 cells_per_result = 1;
    /**
     * <code>repeated uint32 cells_per_result = 1;</code>
     *
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     */
    java.util.List<java.lang.Integer> getCellsPerResultList();
    /**
     * <code>repeated uint32 cells_per_result = 1;</code>
     *
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     */
    int getCellsPerResultCount();
    /**
     * <code>repeated uint32 cells_per_result = 1;</code>
     *
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     */
    int getCellsPerResult(int index);

    // optional uint64 scanner_id = 2;
    /**
     * <code>optional uint64 scanner_id = 2;</code>
     */
    boolean hasScannerId();
    /**
     * <code>optional uint64 scanner_id = 2;</code>
     */
    long getScannerId();

    // optional bool more_results = 3;
    /**
     * <code>optional bool more_results = 3;</code>
     */
    boolean hasMoreResults();
    /**
     * <code>optional bool more_results = 3;</code>
     */
    boolean getMoreResults();

    // optional uint32 ttl = 4;
    /**
     * <code>optional uint32 ttl = 4;</code>
     */
    boolean hasTtl();
    /**
     * <code>optional uint32 ttl = 4;</code>
     */
    int getTtl();

    // repeated .Result results = 5;
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> 
        getResultsList();
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResults(int index);
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    int getResultsCount();
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
        getResultsOrBuilderList();
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code ScanResponse}
   *
   * <pre>
   **
   * The scan response. If there are no more results, more_results will
   * be false.  If it is not specified, it means there are more.
   * </pre>
   */
  public static final class ScanResponse extends
      com.google.protobuf.GeneratedMessage
      implements ScanResponseOrBuilder {
    // Use ScanResponse.newBuilder() to construct.
    private ScanResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ScanResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ScanResponse defaultInstance;
    public static ScanResponse getDefaultInstance() {
      return defaultInstance;
    }

    public ScanResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ScanResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                cellsPerResult_ = new java.util.ArrayList<java.lang.Integer>();
                mutable_bitField0_ |= 0x00000001;
              }
              cellsPerResult_.add(input.readUInt32());
              break;
            }
            case 10: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001) && input.getBytesUntilLimit() > 0) {
                cellsPerResult_ = new java.util.ArrayList<java.lang.Integer>();
                mutable_bitField0_ |= 0x00000001;
              }
              while (input.getBytesUntilLimit() > 0) {
                cellsPerResult_.add(input.readUInt32());
              }
              input.popLimit(limit);
              break;
            }
            case 16: {
              bitField0_ |= 0x00000001;
              scannerId_ = input.readUInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              moreResults_ = input.readBool();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000004;
              ttl_ = input.readUInt32();
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                results_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result>();
                mutable_bitField0_ |= 0x00000010;
              }
              results_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          cellsPerResult_ = java.util.Collections.unmodifiableList(cellsPerResult_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          results_ = java.util.Collections.unmodifiableList(results_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<ScanResponse> PARSER =
        new com.google.protobuf.AbstractParser<ScanResponse>() {
      public ScanResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ScanResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ScanResponse> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // repeated uint32 cells_per_result = 1;
    public static final int CELLS_PER_RESULT_FIELD_NUMBER = 1;
    private java.util.List<java.lang.Integer> cellsPerResult_;
    /**
     * <code>repeated uint32 cells_per_result = 1;</code>
     *
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     */
    public java.util.List<java.lang.Integer>
        getCellsPerResultList() {
      return cellsPerResult_;
    }
    /**
     * <code>repeated uint32 cells_per_result = 1;</code>
     *
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     */
    public int getCellsPerResultCount() {
      return cellsPerResult_.size();
    }
    /**
     * <code>repeated uint32 cells_per_result = 1;</code>
     *
     * <pre>
     * This field is filled in if we are doing cellblocks.  A cellblock is made up
     * of all Cells serialized out as one cellblock BUT responses from a server
     * have their Cells grouped by Result.  So we can reconstitute the
     * Results on the client-side, this field is a list of counts of Cells
     * in each Result that makes up the response.  For example, if this field
     * has 3, 3, 3 in it, then we know that on the client, we are to make
     * three Results each of three Cells each.
     * </pre>
     */
    public int getCellsPerResult(int index) {
      return cellsPerResult_.get(index);
    }

    // optional uint64 scanner_id = 2;
    public static final int SCANNER_ID_FIELD_NUMBER = 2;
    private long scannerId_;
    /**
     * <code>optional uint64 scanner_id = 2;</code>
     */
    public boolean hasScannerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional uint64 scanner_id = 2;</code>
     */
    public long getScannerId() {
      return scannerId_;
    }

    // optional bool more_results = 3;
    public static final int MORE_RESULTS_FIELD_NUMBER = 3;
    private boolean moreResults_;
    /**
     * <code>optional bool more_results = 3;</code>
     */
    public boolean hasMoreResults() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool more_results = 3;</code>
     */
    public boolean getMoreResults() {
      return moreResults_;
    }

    // optional uint32 ttl = 4;
    public static final int TTL_FIELD_NUMBER = 4;
    private int ttl_;
    /**
     * <code>optional uint32 ttl = 4;</code>
     */
    public boolean hasTtl() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional uint32 ttl = 4;</code>
     */
    public int getTtl() {
      return ttl_;
    }

    // repeated .Result results = 5;
    public static final int RESULTS_FIELD_NUMBER = 5;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> results_;
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> getResultsList() {
      return results_;
    }
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
        getResultsOrBuilderList() {
      return results_;
    }
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    public int getResultsCount() {
      return results_.size();
    }
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResults(int index) {
      return results_.get(index);
    }
    /**
     * <code>repeated .Result results = 5;</code>
     *
     * <pre>
     * If cells are not carried in an accompanying cellblock, then they are pb'd here.
     * This field is mutually exclusive with cells_per_result (since the Cells will
     * be inside the pb'd Result)
     * </pre>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultsOrBuilder(
        int index) {
      return results_.get(index);
    }

    private void initFields() {
      cellsPerResult_ = java.util.Collections.emptyList();
      scannerId_ = 0L;
      moreResults_ = false;
      ttl_ = 0;
      results_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < cellsPerResult_.size(); i++) {
        output.writeUInt32(1, cellsPerResult_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeUInt64(2, scannerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(3, moreResults_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeUInt32(4, ttl_);
      }
      for (int i = 0; i < results_.size(); i++) {
        output.writeMessage(5, results_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < cellsPerResult_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeUInt32SizeNoTag(cellsPerResult_.get(i));
        }
        size += dataSize;
        size += 1 * getCellsPerResultList().size();
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, scannerId_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, moreResults_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, ttl_);
      }
      for (int i = 0; i < results_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, results_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse) obj;

      boolean result = true;
      result = result && getCellsPerResultList()
          .equals(other.getCellsPerResultList());
      result = result && (hasScannerId() == other.hasScannerId());
      if (hasScannerId()) {
        result = result && (getScannerId()
            == other.getScannerId());
      }
      result = result && (hasMoreResults() == other.hasMoreResults());
      if (hasMoreResults()) {
        result = result && (getMoreResults()
            == other.getMoreResults());
      }
      result = result && (hasTtl() == other.hasTtl());
      if (hasTtl()) {
        result = result && (getTtl()
            == other.getTtl());
      }
      result = result && getResultsList()
          .equals(other.getResultsList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getCellsPerResultCount() > 0) {
        hash = (37 * hash) + CELLS_PER_RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getCellsPerResultList().hashCode();
      }
      if (hasScannerId()) {
        hash = (37 * hash) + SCANNER_ID_FIELD_NUMBER;
        hash = (53 * hash) + hashLong(getScannerId());
      }
      if (hasMoreResults()) {
        hash = (37 * hash) + MORE_RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getMoreResults());
      }
      if (hasTtl()) {
        hash = (37 * hash) + TTL_FIELD_NUMBER;
        hash = (53 * hash) + getTtl();
      }
      if (getResultsCount() > 0) {
        hash = (37 * hash) + RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + getResultsList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code ScanResponse}
     *
     * <pre>
     **
     * The scan response. If there are no more results, more_results will
     * be false.  If it is not specified, it means there are more.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultsFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        cellsPerResult_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        scannerId_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        moreResults_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        ttl_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ScanResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          cellsPerResult_ = java.util.Collections.unmodifiableList(cellsPerResult_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.cellsPerResult_ = cellsPerResult_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.scannerId_ = scannerId_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.moreResults_ = moreResults_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000004;
        }
        result.ttl_ = ttl_;
        if (resultsBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010)) {
            results_ = java.util.Collections.unmodifiableList(results_);
            bitField0_ = (bitField0_ & ~0x00000010);
          }
          result.results_ = results_;
        } else {
          result.results_ = resultsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance()) return this;
        if (!other.cellsPerResult_.isEmpty()) {
          if (cellsPerResult_.isEmpty()) {
            cellsPerResult_ = other.cellsPerResult_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureCellsPerResultIsMutable();
            cellsPerResult_.addAll(other.cellsPerResult_);
          }
          onChanged();
        }
        if (other.hasScannerId()) {
          setScannerId(other.getScannerId());
        }
        if (other.hasMoreResults()) {
          setMoreResults(other.getMoreResults());
        }
        if (other.hasTtl()) {
          setTtl(other.getTtl());
        }
        if (resultsBuilder_ == null) {
          if (!other.results_.isEmpty()) {
            if (results_.isEmpty()) {
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000010);
            } else {
              ensureResultsIsMutable();
              results_.addAll(other.results_);
            }
            onChanged();
          }
        } else {
          if (!other.results_.isEmpty()) {
            if (resultsBuilder_.isEmpty()) {
              resultsBuilder_.dispose();
              resultsBuilder_ = null;
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000010);
              resultsBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getResultsFieldBuilder() : null;
            } else {
              resultsBuilder_.addAllMessages(other.results_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated uint32 cells_per_result = 1;
      private java.util.List<java.lang.Integer> cellsPerResult_ = java.util.Collections.emptyList();
      private void ensureCellsPerResultIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          cellsPerResult_ = new java.util.ArrayList<java.lang.Integer>(cellsPerResult_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <code>repeated uint32 cells_per_result = 1;</code>
       *
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       */
      public java.util.List<java.lang.Integer>
          getCellsPerResultList() {
        return java.util.Collections.unmodifiableList(cellsPerResult_);
      }
      /**
       * <code>repeated uint32 cells_per_result = 1;</code>
       *
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       */
      public int getCellsPerResultCount() {
        return cellsPerResult_.size();
      }
      /**
       * <code>repeated uint32 cells_per_result = 1;</code>
       *
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       */
      public int getCellsPerResult(int index) {
        return cellsPerResult_.get(index);
      }
      /**
       * <code>repeated uint32 cells_per_result = 1;</code>
       *
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       */
      public Builder setCellsPerResult(
          int index, int value) {
        ensureCellsPerResultIsMutable();
        cellsPerResult_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated uint32 cells_per_result = 1;</code>
       *
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       */
      public Builder addCellsPerResult(int value) {
        ensureCellsPerResultIsMutable();
        cellsPerResult_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated uint32 cells_per_result = 1;</code>
       *
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       */
      public Builder addAllCellsPerResult(
          java.lang.Iterable<? extends java.lang.Integer> values) {
        ensureCellsPerResultIsMutable();
        super.addAll(values, cellsPerResult_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated uint32 cells_per_result = 1;</code>
       *
       * <pre>
       * This field is filled in if we are doing cellblocks.  A cellblock is made up
       * of all Cells serialized out as one cellblock BUT responses from a server
       * have their Cells grouped by Result.  So we can reconstitute the
       * Results on the client-side, this field is a list of counts of Cells
       * in each Result that makes up the response.  For example, if this field
       * has 3, 3, 3 in it, then we know that on the client, we are to make
       * three Results each of three Cells each.
       * </pre>
       */
      public Builder clearCellsPerResult() {
        cellsPerResult_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }

      // optional uint64 scanner_id = 2;
      private long scannerId_ ;
      /**
       * <code>optional uint64 scanner_id = 2;</code>
       */
      public boolean hasScannerId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional uint64 scanner_id = 2;</code>
       */
      public long getScannerId() {
        return scannerId_;
      }
      /**
       * <code>optional uint64 scanner_id = 2;</code>
       */
      public Builder setScannerId(long value) {
        bitField0_ |= 0x00000002;
        scannerId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint64 scanner_id = 2;</code>
       */
      public Builder clearScannerId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        scannerId_ = 0L;
        onChanged();
        return this;
      }

      // optional bool more_results = 3;
      private boolean moreResults_ ;
      /**
       * <code>optional bool more_results = 3;</code>
       */
      public boolean hasMoreResults() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bool more_results = 3;</code>
       */
      public boolean getMoreResults() {
        return moreResults_;
      }
      /**
       * <code>optional bool more_results = 3;</code>
       */
      public Builder setMoreResults(boolean value) {
        bitField0_ |= 0x00000004;
        moreResults_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool more_results = 3;</code>
       */
      public Builder clearMoreResults() {
        bitField0_ = (bitField0_ & ~0x00000004);
        moreResults_ = false;
        onChanged();
        return this;
      }

      // optional uint32 ttl = 4;
      private int ttl_ ;
      /**
       * <code>optional uint32 ttl = 4;</code>
       */
      public boolean hasTtl() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional uint32 ttl = 4;</code>
       */
      public int getTtl() {
        return ttl_;
      }
      /**
       * <code>optional uint32 ttl = 4;</code>
       */
      public Builder setTtl(int value) {
        bitField0_ |= 0x00000008;
        ttl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional uint32 ttl = 4;</code>
       */
      public Builder clearTtl() {
        bitField0_ = (bitField0_ & ~0x00000008);
        ttl_ = 0;
        onChanged();
        return this;
      }

      // repeated .Result results = 5;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> results_ =
        java.util.Collections.emptyList();
      private void ensureResultsIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          results_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result>(results_);
          bitField0_ |= 0x00000010;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> resultsBuilder_;

      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> getResultsList() {
        if (resultsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(results_);
        } else {
          return resultsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public int getResultsCount() {
        if (resultsBuilder_ == null) {
          return results_.size();
        } else {
          return resultsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getResults(int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);
        } else {
          return resultsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder setResults(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.set(index, value);
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder setResults(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder addResults(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder addResults(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(index, value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder addResults(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder addResults(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder addAllResults(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result> values) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          super.addAll(values, results_);
          onChanged();
        } else {
          resultsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder clearResults() {
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000010);
          onChanged();
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public Builder removeResults(int index) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.remove(index);
          onChanged();
        } else {
          resultsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder getResultsBuilder(
          int index) {
        return getResultsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getResultsOrBuilder(
          int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);  } else {
          return resultsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
           getResultsOrBuilderList() {
        if (resultsBuilder_ != null) {
          return resultsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(results_);
        }
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder addResultsBuilder() {
        return getResultsFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance());
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder addResultsBuilder(
          int index) {
        return getResultsFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance());
      }
      /**
       * <code>repeated .Result results = 5;</code>
       *
       * <pre>
       * If cells are not carried in an accompanying cellblock, then they are pb'd here.
       * This field is mutually exclusive with cells_per_result (since the Cells will
       * be inside the pb'd Result)
       * </pre>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder> 
           getResultsBuilderList() {
        return getResultsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getResultsFieldBuilder() {
        if (resultsBuilder_ == null) {
          resultsBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  results_,
                  ((bitField0_ & 0x00000010) == 0x00000010),
                  getParentForChildren(),
                  isClean());
          results_ = null;
        }
        return resultsBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:ScanResponse)
    }

    static {
      defaultInstance = new ScanResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:ScanResponse)
  }

  public interface BulkLoadHFileRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier region = 1;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    // repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> 
        getFamilyPathList();
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index);
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    int getFamilyPathCount();
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
        getFamilyPathOrBuilderList();
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
        int index);

    // optional bool assign_seq_num = 3;
    /**
     * <code>optional bool assign_seq_num = 3;</code>
     */
    boolean hasAssignSeqNum();
    /**
     * <code>optional bool assign_seq_num = 3;</code>
     */
    boolean getAssignSeqNum();
  }
  /**
   * Protobuf type {@code BulkLoadHFileRequest}
   *
   * <pre>
   **
   * Atomically bulk load multiple HFiles (say from different column families)
   * into an open region.
   * </pre>
   */
  public static final class BulkLoadHFileRequest extends
      com.google.protobuf.GeneratedMessage
      implements BulkLoadHFileRequestOrBuilder {
    // Use BulkLoadHFileRequest.newBuilder() to construct.
    private BulkLoadHFileRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private BulkLoadHFileRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final BulkLoadHFileRequest defaultInstance;
    public static BulkLoadHFileRequest getDefaultInstance() {
      return defaultInstance;
    }

    public BulkLoadHFileRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private BulkLoadHFileRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                familyPath_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath>();
                mutable_bitField0_ |= 0x00000002;
              }
              familyPath_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.PARSER, extensionRegistry));
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              assignSeqNum_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          familyPath_ = java.util.Collections.unmodifiableList(familyPath_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<BulkLoadHFileRequest> PARSER =
        new com.google.protobuf.AbstractParser<BulkLoadHFileRequest>() {
      public BulkLoadHFileRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BulkLoadHFileRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<BulkLoadHFileRequest> getParserForType() {
      return PARSER;
    }

    public interface FamilyPathOrBuilder
        extends com.google.protobuf.MessageOrBuilder {

      // required bytes family = 1;
      /**
       * <code>required bytes family = 1;</code>
       */
      boolean hasFamily();
      /**
       * <code>required bytes family = 1;</code>
       */
      com.google.protobuf.ByteString getFamily();

      // required string path = 2;
      /**
       * <code>required string path = 2;</code>
       */
      boolean hasPath();
      /**
       * <code>required string path = 2;</code>
       */
      java.lang.String getPath();
      /**
       * <code>required string path = 2;</code>
       */
      com.google.protobuf.ByteString
          getPathBytes();
    }
    /**
     * Protobuf type {@code BulkLoadHFileRequest.FamilyPath}
     */
    public static final class FamilyPath extends
        com.google.protobuf.GeneratedMessage
        implements FamilyPathOrBuilder {
      // Use FamilyPath.newBuilder() to construct.
      private FamilyPath(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
        super(builder);
        this.unknownFields = builder.getUnknownFields();
      }
      private FamilyPath(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

      private static final FamilyPath defaultInstance;
      public static FamilyPath getDefaultInstance() {
        return defaultInstance;
      }

      public FamilyPath getDefaultInstanceForType() {
        return defaultInstance;
      }

      private final com.google.protobuf.UnknownFieldSet unknownFields;
      @java.lang.Override
      public final com.google.protobuf.UnknownFieldSet
          getUnknownFields() {
        return this.unknownFields;
      }
      private FamilyPath(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        initFields();
        int mutable_bitField0_ = 0;
        com.google.protobuf.UnknownFieldSet.Builder unknownFields =
            com.google.protobuf.UnknownFieldSet.newBuilder();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!parseUnknownField(input, unknownFields,
                                       extensionRegistry, tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                bitField0_ |= 0x00000001;
                family_ = input.readBytes();
                break;
              }
              case 18: {
                bitField0_ |= 0x00000002;
                path_ = input.readBytes();
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e.getMessage()).setUnfinishedMessage(this);
        } finally {
          this.unknownFields = unknownFields.build();
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder.class);
      }

      public static com.google.protobuf.Parser<FamilyPath> PARSER =
          new com.google.protobuf.AbstractParser<FamilyPath>() {
        public FamilyPath parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return new FamilyPath(input, extensionRegistry);
        }
      };

      @java.lang.Override
      public com.google.protobuf.Parser<FamilyPath> getParserForType() {
        return PARSER;
      }

      private int bitField0_;
      // required bytes family = 1;
      public static final int FAMILY_FIELD_NUMBER = 1;
      private com.google.protobuf.ByteString family_;
      /**
       * <code>required bytes family = 1;</code>
       */
      public boolean hasFamily() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes family = 1;</code>
       */
      public com.google.protobuf.ByteString getFamily() {
        return family_;
      }

      // required string path = 2;
      public static final int PATH_FIELD_NUMBER = 2;
      private java.lang.Object path_;
      /**
       * <code>required string path = 2;</code>
       */
      public boolean hasPath() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required string path = 2;</code>
       */
      public java.lang.String getPath() {
        java.lang.Object ref = path_;
        if (ref instanceof java.lang.String) {
          return (java.lang.String) ref;
        } else {
          com.google.protobuf.ByteString bs = 
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            path_ = s;
          }
          return s;
        }
      }
      /**
       * <code>required string path = 2;</code>
       */
      public com.google.protobuf.ByteString
          getPathBytes() {
        java.lang.Object ref = path_;
        if (ref instanceof java.lang.String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          path_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      private void initFields() {
        family_ = com.google.protobuf.ByteString.EMPTY;
        path_ = "";
      }
      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized != -1) return isInitialized == 1;

        if (!hasFamily()) {
          memoizedIsInitialized = 0;
          return false;
        }
        if (!hasPath()) {
          memoizedIsInitialized = 0;
          return false;
        }
        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          output.writeBytes(1, family_);
        }
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          output.writeBytes(2, getPathBytes());
        }
        getUnknownFields().writeTo(output);
      }

      private int memoizedSerializedSize = -1;
      public int getSerializedSize() {
        int size = memoizedSerializedSize;
        if (size != -1) return size;

        size = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(1, family_);
        }
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          size += com.google.protobuf.CodedOutputStream
            .computeBytesSize(2, getPathBytes());
        }
        size += getUnknownFields().getSerializedSize();
        memoizedSerializedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @java.lang.Override
      protected java.lang.Object writeReplace()
          throws java.io.ObjectStreamException {
        return super.writeReplace();
      }

      @java.lang.Override
      public boolean equals(final java.lang.Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath)) {
          return super.equals(obj);
        }
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath) obj;

        boolean result = true;
        result = result && (hasFamily() == other.hasFamily());
        if (hasFamily()) {
          result = result && getFamily()
              .equals(other.getFamily());
        }
        result = result && (hasPath() == other.hasPath());
        if (hasPath()) {
          result = result && getPath()
              .equals(other.getPath());
        }
        result = result &&
            getUnknownFields().equals(other.getUnknownFields());
        return result;
      }

      private int memoizedHashCode = 0;
      @java.lang.Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        if (hasFamily()) {
          hash = (37 * hash) + FAMILY_FIELD_NUMBER;
          hash = (53 * hash) + getFamily().hashCode();
        }
        if (hasPath()) {
          hash = (37 * hash) + PATH_FIELD_NUMBER;
          hash = (53 * hash) + getPath().hashCode();
        }
        hash = (29 * hash) + getUnknownFields().hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return PARSER.parseFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseFrom(input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return PARSER.parseDelimitedFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseDelimitedFrom(input, extensionRegistry);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return PARSER.parseFrom(input);
      }
      public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return PARSER.parseFrom(input, extensionRegistry);
      }

      public static Builder newBuilder() { return Builder.create(); }
      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath prototype) {
        return newBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() { return newBuilder(this); }

      @java.lang.Override
      protected Builder newBuilderForType(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * Protobuf type {@code BulkLoadHFileRequest.FamilyPath}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessage.Builder<Builder>
         implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_descriptor;
        }

        protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
            internalGetFieldAccessorTable() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder.class);
        }

        // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            com.google.protobuf.GeneratedMessage.BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          }
        }
        private static Builder create() {
          return new Builder();
        }

        public Builder clear() {
          super.clear();
          family_ = com.google.protobuf.ByteString.EMPTY;
          bitField0_ = (bitField0_ & ~0x00000001);
          path_ = "";
          bitField0_ = (bitField0_ & ~0x00000002);
          return this;
        }

        public Builder clone() {
          return create().mergeFrom(buildPartial());
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_FamilyPath_descriptor;
        }

        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getDefaultInstanceForType() {
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance();
        }

        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath build() {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath buildPartial() {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
            to_bitField0_ |= 0x00000001;
          }
          result.family_ = family_;
          if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
            to_bitField0_ |= 0x00000002;
          }
          result.path_ = path_;
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath) {
            return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath other) {
          if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance()) return this;
          if (other.hasFamily()) {
            setFamily(other.getFamily());
          }
          if (other.hasPath()) {
            bitField0_ |= 0x00000002;
            path_ = other.path_;
            onChanged();
          }
          this.mergeUnknownFields(other.getUnknownFields());
          return this;
        }

        public final boolean isInitialized() {
          if (!hasFamily()) {
            
            return false;
          }
          if (!hasPath()) {
            
            return false;
          }
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath) e.getUnfinishedMessage();
            throw e;
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        // required bytes family = 1;
        private com.google.protobuf.ByteString family_ = com.google.protobuf.ByteString.EMPTY;
        /**
         * <code>required bytes family = 1;</code>
         */
        public boolean hasFamily() {
          return ((bitField0_ & 0x00000001) == 0x00000001);
        }
        /**
         * <code>required bytes family = 1;</code>
         */
        public com.google.protobuf.ByteString getFamily() {
          return family_;
        }
        /**
         * <code>required bytes family = 1;</code>
         */
        public Builder setFamily(com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
          family_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>required bytes family = 1;</code>
         */
        public Builder clearFamily() {
          bitField0_ = (bitField0_ & ~0x00000001);
          family_ = getDefaultInstance().getFamily();
          onChanged();
          return this;
        }

        // required string path = 2;
        private java.lang.Object path_ = "";
        /**
         * <code>required string path = 2;</code>
         */
        public boolean hasPath() {
          return ((bitField0_ & 0x00000002) == 0x00000002);
        }
        /**
         * <code>required string path = 2;</code>
         */
        public java.lang.String getPath() {
          java.lang.Object ref = path_;
          if (!(ref instanceof java.lang.String)) {
            java.lang.String s = ((com.google.protobuf.ByteString) ref)
                .toStringUtf8();
            path_ = s;
            return s;
          } else {
            return (java.lang.String) ref;
          }
        }
        /**
         * <code>required string path = 2;</code>
         */
        public com.google.protobuf.ByteString
            getPathBytes() {
          java.lang.Object ref = path_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b = 
                com.google.protobuf.ByteString.copyFromUtf8(
                    (java.lang.String) ref);
            path_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <code>required string path = 2;</code>
         */
        public Builder setPath(
            java.lang.String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
          path_ = value;
          onChanged();
          return this;
        }
        /**
         * <code>required string path = 2;</code>
         */
        public Builder clearPath() {
          bitField0_ = (bitField0_ & ~0x00000002);
          path_ = getDefaultInstance().getPath();
          onChanged();
          return this;
        }
        /**
         * <code>required string path = 2;</code>
         */
        public Builder setPathBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
          path_ = value;
          onChanged();
          return this;
        }

        // @@protoc_insertion_point(builder_scope:BulkLoadHFileRequest.FamilyPath)
      }

      static {
        defaultInstance = new FamilyPath(true);
        defaultInstance.initFields();
      }

      // @@protoc_insertion_point(class_scope:BulkLoadHFileRequest.FamilyPath)
    }

    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }

    // repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;
    public static final int FAMILY_PATH_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> familyPath_;
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> getFamilyPathList() {
      return familyPath_;
    }
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
        getFamilyPathOrBuilderList() {
      return familyPath_;
    }
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    public int getFamilyPathCount() {
      return familyPath_.size();
    }
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index) {
      return familyPath_.get(index);
    }
    /**
     * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
        int index) {
      return familyPath_.get(index);
    }

    // optional bool assign_seq_num = 3;
    public static final int ASSIGN_SEQ_NUM_FIELD_NUMBER = 3;
    private boolean assignSeqNum_;
    /**
     * <code>optional bool assign_seq_num = 3;</code>
     */
    public boolean hasAssignSeqNum() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool assign_seq_num = 3;</code>
     */
    public boolean getAssignSeqNum() {
      return assignSeqNum_;
    }

    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      familyPath_ = java.util.Collections.emptyList();
      assignSeqNum_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getFamilyPathCount(); i++) {
        if (!getFamilyPath(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      for (int i = 0; i < familyPath_.size(); i++) {
        output.writeMessage(2, familyPath_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(3, assignSeqNum_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      for (int i = 0; i < familyPath_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, familyPath_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, assignSeqNum_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && getFamilyPathList()
          .equals(other.getFamilyPathList());
      result = result && (hasAssignSeqNum() == other.hasAssignSeqNum());
      if (hasAssignSeqNum()) {
        result = result && (getAssignSeqNum()
            == other.getAssignSeqNum());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (getFamilyPathCount() > 0) {
        hash = (37 * hash) + FAMILY_PATH_FIELD_NUMBER;
        hash = (53 * hash) + getFamilyPathList().hashCode();
      }
      if (hasAssignSeqNum()) {
        hash = (37 * hash) + ASSIGN_SEQ_NUM_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getAssignSeqNum());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code BulkLoadHFileRequest}
     *
     * <pre>
     **
     * Atomically bulk load multiple HFiles (say from different column families)
     * into an open region.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getFamilyPathFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (familyPathBuilder_ == null) {
          familyPath_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          familyPathBuilder_.clear();
        }
        assignSeqNum_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (familyPathBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            familyPath_ = java.util.Collections.unmodifiableList(familyPath_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.familyPath_ = familyPath_;
        } else {
          result.familyPath_ = familyPathBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.assignSeqNum_ = assignSeqNum_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (familyPathBuilder_ == null) {
          if (!other.familyPath_.isEmpty()) {
            if (familyPath_.isEmpty()) {
              familyPath_ = other.familyPath_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureFamilyPathIsMutable();
              familyPath_.addAll(other.familyPath_);
            }
            onChanged();
          }
        } else {
          if (!other.familyPath_.isEmpty()) {
            if (familyPathBuilder_.isEmpty()) {
              familyPathBuilder_.dispose();
              familyPathBuilder_ = null;
              familyPath_ = other.familyPath_;
              bitField0_ = (bitField0_ & ~0x00000002);
              familyPathBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getFamilyPathFieldBuilder() : null;
            } else {
              familyPathBuilder_.addAllMessages(other.familyPath_);
            }
          }
        }
        if (other.hasAssignSeqNum()) {
          setAssignSeqNum(other.getAssignSeqNum());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        for (int i = 0; i < getFamilyPathCount(); i++) {
          if (!getFamilyPath(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      // repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> familyPath_ =
        java.util.Collections.emptyList();
      private void ensureFamilyPathIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          familyPath_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath>(familyPath_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> familyPathBuilder_;

      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> getFamilyPathList() {
        if (familyPathBuilder_ == null) {
          return java.util.Collections.unmodifiableList(familyPath_);
        } else {
          return familyPathBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public int getFamilyPathCount() {
        if (familyPathBuilder_ == null) {
          return familyPath_.size();
        } else {
          return familyPathBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath getFamilyPath(int index) {
        if (familyPathBuilder_ == null) {
          return familyPath_.get(index);
        } else {
          return familyPathBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder setFamilyPath(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.set(index, value);
          onChanged();
        } else {
          familyPathBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder setFamilyPath(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.set(index, builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addFamilyPath(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.add(value);
          onChanged();
        } else {
          familyPathBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addFamilyPath(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath value) {
        if (familyPathBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureFamilyPathIsMutable();
          familyPath_.add(index, value);
          onChanged();
        } else {
          familyPathBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addFamilyPath(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.add(builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addFamilyPath(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder builderForValue) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.add(index, builderForValue.build());
          onChanged();
        } else {
          familyPathBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder addAllFamilyPath(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath> values) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          super.addAll(values, familyPath_);
          onChanged();
        } else {
          familyPathBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder clearFamilyPath() {
        if (familyPathBuilder_ == null) {
          familyPath_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          familyPathBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public Builder removeFamilyPath(int index) {
        if (familyPathBuilder_ == null) {
          ensureFamilyPathIsMutable();
          familyPath_.remove(index);
          onChanged();
        } else {
          familyPathBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder getFamilyPathBuilder(
          int index) {
        return getFamilyPathFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder getFamilyPathOrBuilder(
          int index) {
        if (familyPathBuilder_ == null) {
          return familyPath_.get(index);  } else {
          return familyPathBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
           getFamilyPathOrBuilderList() {
        if (familyPathBuilder_ != null) {
          return familyPathBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(familyPath_);
        }
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder addFamilyPathBuilder() {
        return getFamilyPathFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance());
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder addFamilyPathBuilder(
          int index) {
        return getFamilyPathFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.getDefaultInstance());
      }
      /**
       * <code>repeated .BulkLoadHFileRequest.FamilyPath family_path = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder> 
           getFamilyPathBuilderList() {
        return getFamilyPathFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder> 
          getFamilyPathFieldBuilder() {
        if (familyPathBuilder_ == null) {
          familyPathBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPath.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.FamilyPathOrBuilder>(
                  familyPath_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          familyPath_ = null;
        }
        return familyPathBuilder_;
      }

      // optional bool assign_seq_num = 3;
      private boolean assignSeqNum_ ;
      /**
       * <code>optional bool assign_seq_num = 3;</code>
       */
      public boolean hasAssignSeqNum() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bool assign_seq_num = 3;</code>
       */
      public boolean getAssignSeqNum() {
        return assignSeqNum_;
      }
      /**
       * <code>optional bool assign_seq_num = 3;</code>
       */
      public Builder setAssignSeqNum(boolean value) {
        bitField0_ |= 0x00000004;
        assignSeqNum_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool assign_seq_num = 3;</code>
       */
      public Builder clearAssignSeqNum() {
        bitField0_ = (bitField0_ & ~0x00000004);
        assignSeqNum_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:BulkLoadHFileRequest)
    }

    static {
      defaultInstance = new BulkLoadHFileRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:BulkLoadHFileRequest)
  }

  public interface BulkLoadHFileResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bool loaded = 1;
    /**
     * <code>required bool loaded = 1;</code>
     */
    boolean hasLoaded();
    /**
     * <code>required bool loaded = 1;</code>
     */
    boolean getLoaded();
  }
  /**
   * Protobuf type {@code BulkLoadHFileResponse}
   */
  public static final class BulkLoadHFileResponse extends
      com.google.protobuf.GeneratedMessage
      implements BulkLoadHFileResponseOrBuilder {
    // Use BulkLoadHFileResponse.newBuilder() to construct.
    private BulkLoadHFileResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private BulkLoadHFileResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final BulkLoadHFileResponse defaultInstance;
    public static BulkLoadHFileResponse getDefaultInstance() {
      return defaultInstance;
    }

    public BulkLoadHFileResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private BulkLoadHFileResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              loaded_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<BulkLoadHFileResponse> PARSER =
        new com.google.protobuf.AbstractParser<BulkLoadHFileResponse>() {
      public BulkLoadHFileResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new BulkLoadHFileResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<BulkLoadHFileResponse> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bool loaded = 1;
    public static final int LOADED_FIELD_NUMBER = 1;
    private boolean loaded_;
    /**
     * <code>required bool loaded = 1;</code>
     */
    public boolean hasLoaded() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bool loaded = 1;</code>
     */
    public boolean getLoaded() {
      return loaded_;
    }

    private void initFields() {
      loaded_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasLoaded()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBool(1, loaded_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, loaded_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse) obj;

      boolean result = true;
      result = result && (hasLoaded() == other.hasLoaded());
      if (hasLoaded()) {
        result = result && (getLoaded()
            == other.getLoaded());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasLoaded()) {
        hash = (37 * hash) + LOADED_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getLoaded());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code BulkLoadHFileResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        loaded_ = false;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_BulkLoadHFileResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.loaded_ = loaded_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance()) return this;
        if (other.hasLoaded()) {
          setLoaded(other.getLoaded());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasLoaded()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bool loaded = 1;
      private boolean loaded_ ;
      /**
       * <code>required bool loaded = 1;</code>
       */
      public boolean hasLoaded() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bool loaded = 1;</code>
       */
      public boolean getLoaded() {
        return loaded_;
      }
      /**
       * <code>required bool loaded = 1;</code>
       */
      public Builder setLoaded(boolean value) {
        bitField0_ |= 0x00000001;
        loaded_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bool loaded = 1;</code>
       */
      public Builder clearLoaded() {
        bitField0_ = (bitField0_ & ~0x00000001);
        loaded_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:BulkLoadHFileResponse)
    }

    static {
      defaultInstance = new BulkLoadHFileResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:BulkLoadHFileResponse)
  }

  public interface CoprocessorServiceCallOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required bytes row = 1;
    /**
     * <code>required bytes row = 1;</code>
     */
    boolean hasRow();
    /**
     * <code>required bytes row = 1;</code>
     */
    com.google.protobuf.ByteString getRow();

    // required string service_name = 2;
    /**
     * <code>required string service_name = 2;</code>
     */
    boolean hasServiceName();
    /**
     * <code>required string service_name = 2;</code>
     */
    java.lang.String getServiceName();
    /**
     * <code>required string service_name = 2;</code>
     */
    com.google.protobuf.ByteString
        getServiceNameBytes();

    // required string method_name = 3;
    /**
     * <code>required string method_name = 3;</code>
     */
    boolean hasMethodName();
    /**
     * <code>required string method_name = 3;</code>
     */
    java.lang.String getMethodName();
    /**
     * <code>required string method_name = 3;</code>
     */
    com.google.protobuf.ByteString
        getMethodNameBytes();

    // required bytes request = 4;
    /**
     * <code>required bytes request = 4;</code>
     */
    boolean hasRequest();
    /**
     * <code>required bytes request = 4;</code>
     */
    com.google.protobuf.ByteString getRequest();
  }
  /**
   * Protobuf type {@code CoprocessorServiceCall}
   */
  public static final class CoprocessorServiceCall extends
      com.google.protobuf.GeneratedMessage
      implements CoprocessorServiceCallOrBuilder {
    // Use CoprocessorServiceCall.newBuilder() to construct.
    private CoprocessorServiceCall(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private CoprocessorServiceCall(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final CoprocessorServiceCall defaultInstance;
    public static CoprocessorServiceCall getDefaultInstance() {
      return defaultInstance;
    }

    public CoprocessorServiceCall getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private CoprocessorServiceCall(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              bitField0_ |= 0x00000001;
              row_ = input.readBytes();
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              serviceName_ = input.readBytes();
              break;
            }
            case 26: {
              bitField0_ |= 0x00000004;
              methodName_ = input.readBytes();
              break;
            }
            case 34: {
              bitField0_ |= 0x00000008;
              request_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder.class);
    }

    public static com.google.protobuf.Parser<CoprocessorServiceCall> PARSER =
        new com.google.protobuf.AbstractParser<CoprocessorServiceCall>() {
      public CoprocessorServiceCall parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CoprocessorServiceCall(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<CoprocessorServiceCall> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required bytes row = 1;
    public static final int ROW_FIELD_NUMBER = 1;
    private com.google.protobuf.ByteString row_;
    /**
     * <code>required bytes row = 1;</code>
     */
    public boolean hasRow() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required bytes row = 1;</code>
     */
    public com.google.protobuf.ByteString getRow() {
      return row_;
    }

    // required string service_name = 2;
    public static final int SERVICE_NAME_FIELD_NUMBER = 2;
    private java.lang.Object serviceName_;
    /**
     * <code>required string service_name = 2;</code>
     */
    public boolean hasServiceName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required string service_name = 2;</code>
     */
    public java.lang.String getServiceName() {
      java.lang.Object ref = serviceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          serviceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string service_name = 2;</code>
     */
    public com.google.protobuf.ByteString
        getServiceNameBytes() {
      java.lang.Object ref = serviceName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        serviceName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // required string method_name = 3;
    public static final int METHOD_NAME_FIELD_NUMBER = 3;
    private java.lang.Object methodName_;
    /**
     * <code>required string method_name = 3;</code>
     */
    public boolean hasMethodName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>required string method_name = 3;</code>
     */
    public java.lang.String getMethodName() {
      java.lang.Object ref = methodName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          methodName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>required string method_name = 3;</code>
     */
    public com.google.protobuf.ByteString
        getMethodNameBytes() {
      java.lang.Object ref = methodName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        methodName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    // required bytes request = 4;
    public static final int REQUEST_FIELD_NUMBER = 4;
    private com.google.protobuf.ByteString request_;
    /**
     * <code>required bytes request = 4;</code>
     */
    public boolean hasRequest() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>required bytes request = 4;</code>
     */
    public com.google.protobuf.ByteString getRequest() {
      return request_;
    }

    private void initFields() {
      row_ = com.google.protobuf.ByteString.EMPTY;
      serviceName_ = "";
      methodName_ = "";
      request_ = com.google.protobuf.ByteString.EMPTY;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRow()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasServiceName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasMethodName()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasRequest()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, getServiceNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeBytes(3, getMethodNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeBytes(4, request_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(1, row_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, getServiceNameBytes());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(3, getMethodNameBytes());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(4, request_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall) obj;

      boolean result = true;
      result = result && (hasRow() == other.hasRow());
      if (hasRow()) {
        result = result && getRow()
            .equals(other.getRow());
      }
      result = result && (hasServiceName() == other.hasServiceName());
      if (hasServiceName()) {
        result = result && getServiceName()
            .equals(other.getServiceName());
      }
      result = result && (hasMethodName() == other.hasMethodName());
      if (hasMethodName()) {
        result = result && getMethodName()
            .equals(other.getMethodName());
      }
      result = result && (hasRequest() == other.hasRequest());
      if (hasRequest()) {
        result = result && getRequest()
            .equals(other.getRequest());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRow()) {
        hash = (37 * hash) + ROW_FIELD_NUMBER;
        hash = (53 * hash) + getRow().hashCode();
      }
      if (hasServiceName()) {
        hash = (37 * hash) + SERVICE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getServiceName().hashCode();
      }
      if (hasMethodName()) {
        hash = (37 * hash) + METHOD_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getMethodName().hashCode();
      }
      if (hasRequest()) {
        hash = (37 * hash) + REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getRequest().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code CoprocessorServiceCall}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        row_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        serviceName_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        methodName_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        request_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceCall_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.row_ = row_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.serviceName_ = serviceName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.methodName_ = methodName_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.request_ = request_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance()) return this;
        if (other.hasRow()) {
          setRow(other.getRow());
        }
        if (other.hasServiceName()) {
          bitField0_ |= 0x00000002;
          serviceName_ = other.serviceName_;
          onChanged();
        }
        if (other.hasMethodName()) {
          bitField0_ |= 0x00000004;
          methodName_ = other.methodName_;
          onChanged();
        }
        if (other.hasRequest()) {
          setRequest(other.getRequest());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRow()) {
          
          return false;
        }
        if (!hasServiceName()) {
          
          return false;
        }
        if (!hasMethodName()) {
          
          return false;
        }
        if (!hasRequest()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required bytes row = 1;
      private com.google.protobuf.ByteString row_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes row = 1;</code>
       */
      public boolean hasRow() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public com.google.protobuf.ByteString getRow() {
        return row_;
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public Builder setRow(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        row_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes row = 1;</code>
       */
      public Builder clearRow() {
        bitField0_ = (bitField0_ & ~0x00000001);
        row_ = getDefaultInstance().getRow();
        onChanged();
        return this;
      }

      // required string service_name = 2;
      private java.lang.Object serviceName_ = "";
      /**
       * <code>required string service_name = 2;</code>
       */
      public boolean hasServiceName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required string service_name = 2;</code>
       */
      public java.lang.String getServiceName() {
        java.lang.Object ref = serviceName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          serviceName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string service_name = 2;</code>
       */
      public com.google.protobuf.ByteString
          getServiceNameBytes() {
        java.lang.Object ref = serviceName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          serviceName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string service_name = 2;</code>
       */
      public Builder setServiceName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        serviceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string service_name = 2;</code>
       */
      public Builder clearServiceName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        serviceName_ = getDefaultInstance().getServiceName();
        onChanged();
        return this;
      }
      /**
       * <code>required string service_name = 2;</code>
       */
      public Builder setServiceNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        serviceName_ = value;
        onChanged();
        return this;
      }

      // required string method_name = 3;
      private java.lang.Object methodName_ = "";
      /**
       * <code>required string method_name = 3;</code>
       */
      public boolean hasMethodName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>required string method_name = 3;</code>
       */
      public java.lang.String getMethodName() {
        java.lang.Object ref = methodName_;
        if (!(ref instanceof java.lang.String)) {
          java.lang.String s = ((com.google.protobuf.ByteString) ref)
              .toStringUtf8();
          methodName_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>required string method_name = 3;</code>
       */
      public com.google.protobuf.ByteString
          getMethodNameBytes() {
        java.lang.Object ref = methodName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          methodName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>required string method_name = 3;</code>
       */
      public Builder setMethodName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        methodName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required string method_name = 3;</code>
       */
      public Builder clearMethodName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        methodName_ = getDefaultInstance().getMethodName();
        onChanged();
        return this;
      }
      /**
       * <code>required string method_name = 3;</code>
       */
      public Builder setMethodNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        methodName_ = value;
        onChanged();
        return this;
      }

      // required bytes request = 4;
      private com.google.protobuf.ByteString request_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>required bytes request = 4;</code>
       */
      public boolean hasRequest() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>required bytes request = 4;</code>
       */
      public com.google.protobuf.ByteString getRequest() {
        return request_;
      }
      /**
       * <code>required bytes request = 4;</code>
       */
      public Builder setRequest(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        request_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>required bytes request = 4;</code>
       */
      public Builder clearRequest() {
        bitField0_ = (bitField0_ & ~0x00000008);
        request_ = getDefaultInstance().getRequest();
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:CoprocessorServiceCall)
    }

    static {
      defaultInstance = new CoprocessorServiceCall(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:CoprocessorServiceCall)
  }

  public interface CoprocessorServiceRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier region = 1;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    // required .CoprocessorServiceCall call = 2;
    /**
     * <code>required .CoprocessorServiceCall call = 2;</code>
     */
    boolean hasCall();
    /**
     * <code>required .CoprocessorServiceCall call = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall();
    /**
     * <code>required .CoprocessorServiceCall call = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder();
  }
  /**
   * Protobuf type {@code CoprocessorServiceRequest}
   */
  public static final class CoprocessorServiceRequest extends
      com.google.protobuf.GeneratedMessage
      implements CoprocessorServiceRequestOrBuilder {
    // Use CoprocessorServiceRequest.newBuilder() to construct.
    private CoprocessorServiceRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private CoprocessorServiceRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final CoprocessorServiceRequest defaultInstance;
    public static CoprocessorServiceRequest getDefaultInstance() {
      return defaultInstance;
    }

    public CoprocessorServiceRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private CoprocessorServiceRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = call_.toBuilder();
              }
              call_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(call_);
                call_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<CoprocessorServiceRequest> PARSER =
        new com.google.protobuf.AbstractParser<CoprocessorServiceRequest>() {
      public CoprocessorServiceRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CoprocessorServiceRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<CoprocessorServiceRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }

    // required .CoprocessorServiceCall call = 2;
    public static final int CALL_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall call_;
    /**
     * <code>required .CoprocessorServiceCall call = 2;</code>
     */
    public boolean hasCall() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .CoprocessorServiceCall call = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall() {
      return call_;
    }
    /**
     * <code>required .CoprocessorServiceCall call = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder() {
      return call_;
    }

    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasCall()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getCall().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, call_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, call_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasCall() == other.hasCall());
      if (hasCall()) {
        result = result && getCall()
            .equals(other.getCall());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasCall()) {
        hash = (37 * hash) + CALL_FIELD_NUMBER;
        hash = (53 * hash) + getCall().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code CoprocessorServiceRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getCallFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (callBuilder_ == null) {
          call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
        } else {
          callBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (callBuilder_ == null) {
          result.call_ = call_;
        } else {
          result.call_ = callBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasCall()) {
          mergeCall(other.getCall());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasCall()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getCall().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      // required .CoprocessorServiceCall call = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder> callBuilder_;
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      public boolean hasCall() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall getCall() {
        if (callBuilder_ == null) {
          return call_;
        } else {
          return callBuilder_.getMessage();
        }
      }
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      public Builder setCall(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall value) {
        if (callBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          call_ = value;
          onChanged();
        } else {
          callBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      public Builder setCall(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder builderForValue) {
        if (callBuilder_ == null) {
          call_ = builderForValue.build();
          onChanged();
        } else {
          callBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      public Builder mergeCall(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall value) {
        if (callBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              call_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance()) {
            call_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.newBuilder(call_).mergeFrom(value).buildPartial();
          } else {
            call_ = value;
          }
          onChanged();
        } else {
          callBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      public Builder clearCall() {
        if (callBuilder_ == null) {
          call_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.getDefaultInstance();
          onChanged();
        } else {
          callBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder getCallBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCallFieldBuilder().getBuilder();
      }
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder getCallOrBuilder() {
        if (callBuilder_ != null) {
          return callBuilder_.getMessageOrBuilder();
        } else {
          return call_;
        }
      }
      /**
       * <code>required .CoprocessorServiceCall call = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder> 
          getCallFieldBuilder() {
        if (callBuilder_ == null) {
          callBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCall.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceCallOrBuilder>(
                  call_,
                  getParentForChildren(),
                  isClean());
          call_ = null;
        }
        return callBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:CoprocessorServiceRequest)
    }

    static {
      defaultInstance = new CoprocessorServiceRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:CoprocessorServiceRequest)
  }

  public interface CoprocessorServiceResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier region = 1;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    // required .NameBytesPair value = 2;
    /**
     * <code>required .NameBytesPair value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>required .NameBytesPair value = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue();
    /**
     * <code>required .NameBytesPair value = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder();
  }
  /**
   * Protobuf type {@code CoprocessorServiceResponse}
   */
  public static final class CoprocessorServiceResponse extends
      com.google.protobuf.GeneratedMessage
      implements CoprocessorServiceResponseOrBuilder {
    // Use CoprocessorServiceResponse.newBuilder() to construct.
    private CoprocessorServiceResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private CoprocessorServiceResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final CoprocessorServiceResponse defaultInstance;
    public static CoprocessorServiceResponse getDefaultInstance() {
      return defaultInstance;
    }

    public CoprocessorServiceResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private CoprocessorServiceResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = value_.toBuilder();
              }
              value_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(value_);
                value_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<CoprocessorServiceResponse> PARSER =
        new com.google.protobuf.AbstractParser<CoprocessorServiceResponse>() {
      public CoprocessorServiceResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new CoprocessorServiceResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<CoprocessorServiceResponse> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }

    // required .NameBytesPair value = 2;
    public static final int VALUE_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value_;
    /**
     * <code>required .NameBytesPair value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>required .NameBytesPair value = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
      return value_;
    }
    /**
     * <code>required .NameBytesPair value = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
      return value_;
    }

    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!hasValue()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getValue().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, value_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, value_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code CoprocessorServiceResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getValueFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_CoprocessorServiceResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!hasValue()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        if (!getValue().isInitialized()) {
          
          return false;
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      // required .NameBytesPair value = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> valueBuilder_;
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getValue() {
        if (valueBuilder_ == null) {
          return value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      public Builder setValue(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      public Builder setValue(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      public Builder mergeValue(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              value_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getValueBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_;
        }
      }
      /**
       * <code>required .NameBytesPair value = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  value_,
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:CoprocessorServiceResponse)
    }

    static {
      defaultInstance = new CoprocessorServiceResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:CoprocessorServiceResponse)
  }

  public interface MultiActionOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .MutationProto mutation = 1;
    /**
     * <code>optional .MutationProto mutation = 1;</code>
     */
    boolean hasMutation();
    /**
     * <code>optional .MutationProto mutation = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto getMutation();
    /**
     * <code>optional .MutationProto mutation = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder();

    // optional .Get get = 2;
    /**
     * <code>optional .Get get = 2;</code>
     */
    boolean hasGet();
    /**
     * <code>optional .Get get = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet();
    /**
     * <code>optional .Get get = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder();
  }
  /**
   * Protobuf type {@code MultiAction}
   *
   * <pre>
   **
   * An action that is part of MultiRequest.
   * This is a union type - exactly one of the fields will be set.
   * </pre>
   */
  public static final class MultiAction extends
      com.google.protobuf.GeneratedMessage
      implements MultiActionOrBuilder {
    // Use MultiAction.newBuilder() to construct.
    private MultiAction(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MultiAction(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MultiAction defaultInstance;
    public static MultiAction getDefaultInstance() {
      return defaultInstance;
    }

    public MultiAction getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MultiAction(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = mutation_.toBuilder();
              }
              mutation_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(mutation_);
                mutation_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = get_.toBuilder();
              }
              get_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(get_);
                get_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder.class);
    }

    public static com.google.protobuf.Parser<MultiAction> PARSER =
        new com.google.protobuf.AbstractParser<MultiAction>() {
      public MultiAction parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MultiAction(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MultiAction> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .MutationProto mutation = 1;
    public static final int MUTATION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto mutation_;
    /**
     * <code>optional .MutationProto mutation = 1;</code>
     */
    public boolean hasMutation() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .MutationProto mutation = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto getMutation() {
      return mutation_;
    }
    /**
     * <code>optional .MutationProto mutation = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder() {
      return mutation_;
    }

    // optional .Get get = 2;
    public static final int GET_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get get_;
    /**
     * <code>optional .Get get = 2;</code>
     */
    public boolean hasGet() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .Get get = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet() {
      return get_;
    }
    /**
     * <code>optional .Get get = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
      return get_;
    }

    private void initFields() {
      mutation_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
      get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasMutation()) {
        if (!getMutation().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasGet()) {
        if (!getGet().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, mutation_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, get_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, mutation_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, get_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction) obj;

      boolean result = true;
      result = result && (hasMutation() == other.hasMutation());
      if (hasMutation()) {
        result = result && getMutation()
            .equals(other.getMutation());
      }
      result = result && (hasGet() == other.hasGet());
      if (hasGet()) {
        result = result && getGet()
            .equals(other.getGet());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasMutation()) {
        hash = (37 * hash) + MUTATION_FIELD_NUMBER;
        hash = (53 * hash) + getMutation().hashCode();
      }
      if (hasGet()) {
        hash = (37 * hash) + GET_FIELD_NUMBER;
        hash = (53 * hash) + getGet().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MultiAction}
     *
     * <pre>
     **
     * An action that is part of MultiRequest.
     * This is a union type - exactly one of the fields will be set.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getMutationFieldBuilder();
          getGetFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (mutationBuilder_ == null) {
          mutation_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
        } else {
          mutationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (getBuilder_ == null) {
          get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
        } else {
          getBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiAction_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (mutationBuilder_ == null) {
          result.mutation_ = mutation_;
        } else {
          result.mutation_ = mutationBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (getBuilder_ == null) {
          result.get_ = get_;
        } else {
          result.get_ = getBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDefaultInstance()) return this;
        if (other.hasMutation()) {
          mergeMutation(other.getMutation());
        }
        if (other.hasGet()) {
          mergeGet(other.getGet());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasMutation()) {
          if (!getMutation().isInitialized()) {
            
            return false;
          }
        }
        if (hasGet()) {
          if (!getGet().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .MutationProto mutation = 1;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto mutation_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder> mutationBuilder_;
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      public boolean hasMutation() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto getMutation() {
        if (mutationBuilder_ == null) {
          return mutation_;
        } else {
          return mutationBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      public Builder setMutation(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto value) {
        if (mutationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          mutation_ = value;
          onChanged();
        } else {
          mutationBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      public Builder setMutation(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder builderForValue) {
        if (mutationBuilder_ == null) {
          mutation_ = builderForValue.build();
          onChanged();
        } else {
          mutationBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      public Builder mergeMutation(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto value) {
        if (mutationBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              mutation_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance()) {
            mutation_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.newBuilder(mutation_).mergeFrom(value).buildPartial();
          } else {
            mutation_ = value;
          }
          onChanged();
        } else {
          mutationBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      public Builder clearMutation() {
        if (mutationBuilder_ == null) {
          mutation_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.getDefaultInstance();
          onChanged();
        } else {
          mutationBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder getMutationBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getMutationFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder getMutationOrBuilder() {
        if (mutationBuilder_ != null) {
          return mutationBuilder_.getMessageOrBuilder();
        } else {
          return mutation_;
        }
      }
      /**
       * <code>optional .MutationProto mutation = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder> 
          getMutationFieldBuilder() {
        if (mutationBuilder_ == null) {
          mutationBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProto.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutationProtoOrBuilder>(
                  mutation_,
                  getParentForChildren(),
                  isClean());
          mutation_ = null;
        }
        return mutationBuilder_;
      }

      // optional .Get get = 2;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> getBuilder_;
      /**
       * <code>optional .Get get = 2;</code>
       */
      public boolean hasGet() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get getGet() {
        if (getBuilder_ == null) {
          return get_;
        } else {
          return getBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .Get get = 2;</code>
       */
      public Builder setGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          get_ = value;
          onChanged();
        } else {
          getBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .Get get = 2;</code>
       */
      public Builder setGet(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder builderForValue) {
        if (getBuilder_ == null) {
          get_ = builderForValue.build();
          onChanged();
        } else {
          getBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .Get get = 2;</code>
       */
      public Builder mergeGet(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get value) {
        if (getBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              get_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance()) {
            get_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.newBuilder(get_).mergeFrom(value).buildPartial();
          } else {
            get_ = value;
          }
          onChanged();
        } else {
          getBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .Get get = 2;</code>
       */
      public Builder clearGet() {
        if (getBuilder_ == null) {
          get_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.getDefaultInstance();
          onChanged();
        } else {
          getBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder getGetBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getGetFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .Get get = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder getGetOrBuilder() {
        if (getBuilder_ != null) {
          return getBuilder_.getMessageOrBuilder();
        } else {
          return get_;
        }
      }
      /**
       * <code>optional .Get get = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder> 
          getGetFieldBuilder() {
        if (getBuilder_ == null) {
          getBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Get.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetOrBuilder>(
                  get_,
                  getParentForChildren(),
                  isClean());
          get_ = null;
        }
        return getBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:MultiAction)
    }

    static {
      defaultInstance = new MultiAction(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MultiAction)
  }

  public interface ActionResultOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // optional .Result value = 1;
    /**
     * <code>optional .Result value = 1;</code>
     */
    boolean hasValue();
    /**
     * <code>optional .Result value = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getValue();
    /**
     * <code>optional .Result value = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getValueOrBuilder();

    // optional .NameBytesPair exception = 2;
    /**
     * <code>optional .NameBytesPair exception = 2;</code>
     */
    boolean hasException();
    /**
     * <code>optional .NameBytesPair exception = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getException();
    /**
     * <code>optional .NameBytesPair exception = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder();
  }
  /**
   * Protobuf type {@code ActionResult}
   *
   * <pre>
   **
   * An individual action result. The result will in the
   * same order as the action in the request. If an action
   * returns a value, it is set in value field. If it doesn't
   * return anything, the result will be empty. If an action
   * fails to execute due to any exception, the exception
   * is returned as a stringified parameter.
   * </pre>
   */
  public static final class ActionResult extends
      com.google.protobuf.GeneratedMessage
      implements ActionResultOrBuilder {
    // Use ActionResult.newBuilder() to construct.
    private ActionResult(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private ActionResult(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final ActionResult defaultInstance;
    public static ActionResult getDefaultInstance() {
      return defaultInstance;
    }

    public ActionResult getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private ActionResult(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = value_.toBuilder();
              }
              value_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(value_);
                value_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = exception_.toBuilder();
              }
              exception_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(exception_);
                exception_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder.class);
    }

    public static com.google.protobuf.Parser<ActionResult> PARSER =
        new com.google.protobuf.AbstractParser<ActionResult>() {
      public ActionResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new ActionResult(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<ActionResult> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // optional .Result value = 1;
    public static final int VALUE_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value_;
    /**
     * <code>optional .Result value = 1;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .Result value = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getValue() {
      return value_;
    }
    /**
     * <code>optional .Result value = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getValueOrBuilder() {
      return value_;
    }

    // optional .NameBytesPair exception = 2;
    public static final int EXCEPTION_FIELD_NUMBER = 2;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair exception_;
    /**
     * <code>optional .NameBytesPair exception = 2;</code>
     */
    public boolean hasException() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .NameBytesPair exception = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getException() {
      return exception_;
    }
    /**
     * <code>optional .NameBytesPair exception = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder() {
      return exception_;
    }

    private void initFields() {
      value_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      exception_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (hasException()) {
        if (!getException().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, value_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, exception_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, value_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, exception_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult) obj;

      boolean result = true;
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result && (hasException() == other.hasException());
      if (hasException()) {
        result = result && getException()
            .equals(other.getException());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      if (hasException()) {
        hash = (37 * hash) + EXCEPTION_FIELD_NUMBER;
        hash = (53 * hash) + getException().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code ActionResult}
     *
     * <pre>
     **
     * An individual action result. The result will in the
     * same order as the action in the request. If an action
     * returns a value, it is set in value field. If it doesn't
     * return anything, the result will be empty. If an action
     * fails to execute due to any exception, the exception
     * is returned as a stringified parameter.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getValueFieldBuilder();
          getExceptionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (exceptionBuilder_ == null) {
          exception_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
        } else {
          exceptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_ActionResult_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (exceptionBuilder_ == null) {
          result.exception_ = exception_;
        } else {
          result.exception_ = exceptionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDefaultInstance()) return this;
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        if (other.hasException()) {
          mergeException(other.getException());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (hasException()) {
          if (!getException().isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // optional .Result value = 1;
      private org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> valueBuilder_;
      /**
       * <code>optional .Result value = 1;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .Result value = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result getValue() {
        if (valueBuilder_ == null) {
          return value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .Result value = 1;</code>
       */
      public Builder setValue(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result value = 1;</code>
       */
      public Builder setValue(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result value = 1;</code>
       */
      public Builder mergeValue(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              value_ != org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .Result value = 1;</code>
       */
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.getDefaultInstance();
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .Result value = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder getValueBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .Result value = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_;
        }
      }
      /**
       * <code>optional .Result value = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.Result.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ResultOrBuilder>(
                  value_,
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }

      // optional .NameBytesPair exception = 2;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair exception_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> exceptionBuilder_;
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      public boolean hasException() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair getException() {
        if (exceptionBuilder_ == null) {
          return exception_;
        } else {
          return exceptionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      public Builder setException(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (exceptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          exception_ = value;
          onChanged();
        } else {
          exceptionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      public Builder setException(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder builderForValue) {
        if (exceptionBuilder_ == null) {
          exception_ = builderForValue.build();
          onChanged();
        } else {
          exceptionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      public Builder mergeException(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair value) {
        if (exceptionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              exception_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance()) {
            exception_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.newBuilder(exception_).mergeFrom(value).buildPartial();
          } else {
            exception_ = value;
          }
          onChanged();
        } else {
          exceptionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      public Builder clearException() {
        if (exceptionBuilder_ == null) {
          exception_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.getDefaultInstance();
          onChanged();
        } else {
          exceptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder getExceptionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getExceptionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder getExceptionOrBuilder() {
        if (exceptionBuilder_ != null) {
          return exceptionBuilder_.getMessageOrBuilder();
        } else {
          return exception_;
        }
      }
      /**
       * <code>optional .NameBytesPair exception = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder> 
          getExceptionFieldBuilder() {
        if (exceptionBuilder_ == null) {
          exceptionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPair.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.NameBytesPairOrBuilder>(
                  exception_,
                  getParentForChildren(),
                  isClean());
          exception_ = null;
        }
        return exceptionBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:ActionResult)
    }

    static {
      defaultInstance = new ActionResult(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:ActionResult)
  }

  public interface MultiRequestOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // required .RegionSpecifier region = 1;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    boolean hasRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion();
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder();

    // repeated .MultiAction action = 2;
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> 
        getActionList();
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction getAction(int index);
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    int getActionCount();
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> 
        getActionOrBuilderList();
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder getActionOrBuilder(
        int index);

    // optional bool atomic = 3;
    /**
     * <code>optional bool atomic = 3;</code>
     */
    boolean hasAtomic();
    /**
     * <code>optional bool atomic = 3;</code>
     */
    boolean getAtomic();
  }
  /**
   * Protobuf type {@code MultiRequest}
   *
   * <pre>
   **
   * You can execute a list of actions on a given region in order.
   *
   * If it is a list of mutate actions, atomic can be set
   * to make sure they can be processed atomically, just like
   * RowMutations.
   * </pre>
   */
  public static final class MultiRequest extends
      com.google.protobuf.GeneratedMessage
      implements MultiRequestOrBuilder {
    // Use MultiRequest.newBuilder() to construct.
    private MultiRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MultiRequest(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MultiRequest defaultInstance;
    public static MultiRequest getDefaultInstance() {
      return defaultInstance;
    }

    public MultiRequest getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MultiRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = region_.toBuilder();
              }
              region_ = input.readMessage(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(region_);
                region_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction>();
                mutable_bitField0_ |= 0x00000002;
              }
              action_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.PARSER, extensionRegistry));
              break;
            }
            case 24: {
              bitField0_ |= 0x00000002;
              atomic_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          action_ = java.util.Collections.unmodifiableList(action_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.Builder.class);
    }

    public static com.google.protobuf.Parser<MultiRequest> PARSER =
        new com.google.protobuf.AbstractParser<MultiRequest>() {
      public MultiRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MultiRequest(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MultiRequest> getParserForType() {
      return PARSER;
    }

    private int bitField0_;
    // required .RegionSpecifier region = 1;
    public static final int REGION_FIELD_NUMBER = 1;
    private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_;
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public boolean hasRegion() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
      return region_;
    }
    /**
     * <code>required .RegionSpecifier region = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
      return region_;
    }

    // repeated .MultiAction action = 2;
    public static final int ACTION_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> action_;
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> getActionList() {
      return action_;
    }
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> 
        getActionOrBuilderList() {
      return action_;
    }
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    public int getActionCount() {
      return action_.size();
    }
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction getAction(int index) {
      return action_.get(index);
    }
    /**
     * <code>repeated .MultiAction action = 2;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder getActionOrBuilder(
        int index) {
      return action_.get(index);
    }

    // optional bool atomic = 3;
    public static final int ATOMIC_FIELD_NUMBER = 3;
    private boolean atomic_;
    /**
     * <code>optional bool atomic = 3;</code>
     */
    public boolean hasAtomic() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bool atomic = 3;</code>
     */
    public boolean getAtomic() {
      return atomic_;
    }

    private void initFields() {
      region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      action_ = java.util.Collections.emptyList();
      atomic_ = false;
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      if (!hasRegion()) {
        memoizedIsInitialized = 0;
        return false;
      }
      if (!getRegion().isInitialized()) {
        memoizedIsInitialized = 0;
        return false;
      }
      for (int i = 0; i < getActionCount(); i++) {
        if (!getAction(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, region_);
      }
      for (int i = 0; i < action_.size(); i++) {
        output.writeMessage(2, action_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBool(3, atomic_);
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, region_);
      }
      for (int i = 0; i < action_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, action_.get(i));
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, atomic_);
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest) obj;

      boolean result = true;
      result = result && (hasRegion() == other.hasRegion());
      if (hasRegion()) {
        result = result && getRegion()
            .equals(other.getRegion());
      }
      result = result && getActionList()
          .equals(other.getActionList());
      result = result && (hasAtomic() == other.hasAtomic());
      if (hasAtomic()) {
        result = result && (getAtomic()
            == other.getAtomic());
      }
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasRegion()) {
        hash = (37 * hash) + REGION_FIELD_NUMBER;
        hash = (53 * hash) + getRegion().hashCode();
      }
      if (getActionCount() > 0) {
        hash = (37 * hash) + ACTION_FIELD_NUMBER;
        hash = (53 * hash) + getActionList().hashCode();
      }
      if (hasAtomic()) {
        hash = (37 * hash) + ATOMIC_FIELD_NUMBER;
        hash = (53 * hash) + hashBoolean(getAtomic());
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MultiRequest}
     *
     * <pre>
     **
     * You can execute a list of actions on a given region in order.
     *
     * If it is a list of mutate actions, atomic can be set
     * to make sure they can be processed atomically, just like
     * RowMutations.
     * </pre>
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getRegionFieldBuilder();
          getActionFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (actionBuilder_ == null) {
          action_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          actionBuilder_.clear();
        }
        atomic_ = false;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiRequest_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (regionBuilder_ == null) {
          result.region_ = region_;
        } else {
          result.region_ = regionBuilder_.build();
        }
        if (actionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            action_ = java.util.Collections.unmodifiableList(action_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.action_ = action_;
        } else {
          result.action_ = actionBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000002;
        }
        result.atomic_ = atomic_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance()) return this;
        if (other.hasRegion()) {
          mergeRegion(other.getRegion());
        }
        if (actionBuilder_ == null) {
          if (!other.action_.isEmpty()) {
            if (action_.isEmpty()) {
              action_ = other.action_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureActionIsMutable();
              action_.addAll(other.action_);
            }
            onChanged();
          }
        } else {
          if (!other.action_.isEmpty()) {
            if (actionBuilder_.isEmpty()) {
              actionBuilder_.dispose();
              actionBuilder_ = null;
              action_ = other.action_;
              bitField0_ = (bitField0_ & ~0x00000002);
              actionBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getActionFieldBuilder() : null;
            } else {
              actionBuilder_.addAllMessages(other.action_);
            }
          }
        }
        if (other.hasAtomic()) {
          setAtomic(other.getAtomic());
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        if (!hasRegion()) {
          
          return false;
        }
        if (!getRegion().isInitialized()) {
          
          return false;
        }
        for (int i = 0; i < getActionCount(); i++) {
          if (!getAction(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // required .RegionSpecifier region = 1;
      private org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> regionBuilder_;
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public boolean hasRegion() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier getRegion() {
        if (regionBuilder_ == null) {
          return region_;
        } else {
          return regionBuilder_.getMessage();
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          region_ = value;
          onChanged();
        } else {
          regionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder setRegion(
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder builderForValue) {
        if (regionBuilder_ == null) {
          region_ = builderForValue.build();
          onChanged();
        } else {
          regionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder mergeRegion(org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier value) {
        if (regionBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              region_ != org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance()) {
            region_ =
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.newBuilder(region_).mergeFrom(value).buildPartial();
          } else {
            region_ = value;
          }
          onChanged();
        } else {
          regionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public Builder clearRegion() {
        if (regionBuilder_ == null) {
          region_ = org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.getDefaultInstance();
          onChanged();
        } else {
          regionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder getRegionBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getRegionFieldBuilder().getBuilder();
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder getRegionOrBuilder() {
        if (regionBuilder_ != null) {
          return regionBuilder_.getMessageOrBuilder();
        } else {
          return region_;
        }
      }
      /**
       * <code>required .RegionSpecifier region = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder> 
          getRegionFieldBuilder() {
        if (regionBuilder_ == null) {
          regionBuilder_ = new com.google.protobuf.SingleFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifier.Builder, org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.RegionSpecifierOrBuilder>(
                  region_,
                  getParentForChildren(),
                  isClean());
          region_ = null;
        }
        return regionBuilder_;
      }

      // repeated .MultiAction action = 2;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> action_ =
        java.util.Collections.emptyList();
      private void ensureActionIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          action_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction>(action_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> actionBuilder_;

      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> getActionList() {
        if (actionBuilder_ == null) {
          return java.util.Collections.unmodifiableList(action_);
        } else {
          return actionBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public int getActionCount() {
        if (actionBuilder_ == null) {
          return action_.size();
        } else {
          return actionBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction getAction(int index) {
        if (actionBuilder_ == null) {
          return action_.get(index);
        } else {
          return actionBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder setAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.set(index, value);
          onChanged();
        } else {
          actionBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder setAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.set(index, builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder addAction(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.add(value);
          onChanged();
        } else {
          actionBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder addAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction value) {
        if (actionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureActionIsMutable();
          action_.add(index, value);
          onChanged();
        } else {
          actionBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder addAction(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.add(builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder addAction(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder builderForValue) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.add(index, builderForValue.build());
          onChanged();
        } else {
          actionBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder addAllAction(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction> values) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          super.addAll(values, action_);
          onChanged();
        } else {
          actionBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder clearAction() {
        if (actionBuilder_ == null) {
          action_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          actionBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public Builder removeAction(int index) {
        if (actionBuilder_ == null) {
          ensureActionIsMutable();
          action_.remove(index);
          onChanged();
        } else {
          actionBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder getActionBuilder(
          int index) {
        return getActionFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder getActionOrBuilder(
          int index) {
        if (actionBuilder_ == null) {
          return action_.get(index);  } else {
          return actionBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> 
           getActionOrBuilderList() {
        if (actionBuilder_ != null) {
          return actionBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(action_);
        }
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder addActionBuilder() {
        return getActionFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDefaultInstance());
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder addActionBuilder(
          int index) {
        return getActionFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.getDefaultInstance());
      }
      /**
       * <code>repeated .MultiAction action = 2;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder> 
           getActionBuilderList() {
        return getActionFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder> 
          getActionFieldBuilder() {
        if (actionBuilder_ == null) {
          actionBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiAction.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiActionOrBuilder>(
                  action_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          action_ = null;
        }
        return actionBuilder_;
      }

      // optional bool atomic = 3;
      private boolean atomic_ ;
      /**
       * <code>optional bool atomic = 3;</code>
       */
      public boolean hasAtomic() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional bool atomic = 3;</code>
       */
      public boolean getAtomic() {
        return atomic_;
      }
      /**
       * <code>optional bool atomic = 3;</code>
       */
      public Builder setAtomic(boolean value) {
        bitField0_ |= 0x00000004;
        atomic_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool atomic = 3;</code>
       */
      public Builder clearAtomic() {
        bitField0_ = (bitField0_ & ~0x00000004);
        atomic_ = false;
        onChanged();
        return this;
      }

      // @@protoc_insertion_point(builder_scope:MultiRequest)
    }

    static {
      defaultInstance = new MultiRequest(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MultiRequest)
  }

  public interface MultiResponseOrBuilder
      extends com.google.protobuf.MessageOrBuilder {

    // repeated .ActionResult result = 1;
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> 
        getResultList();
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult getResult(int index);
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    int getResultCount();
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> 
        getResultOrBuilderList();
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder getResultOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code MultiResponse}
   */
  public static final class MultiResponse extends
      com.google.protobuf.GeneratedMessage
      implements MultiResponseOrBuilder {
    // Use MultiResponse.newBuilder() to construct.
    private MultiResponse(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
      super(builder);
      this.unknownFields = builder.getUnknownFields();
    }
    private MultiResponse(boolean noInit) { this.unknownFields = com.google.protobuf.UnknownFieldSet.getDefaultInstance(); }

    private static final MultiResponse defaultInstance;
    public static MultiResponse getDefaultInstance() {
      return defaultInstance;
    }

    public MultiResponse getDefaultInstanceForType() {
      return defaultInstance;
    }

    private final com.google.protobuf.UnknownFieldSet unknownFields;
    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
      return this.unknownFields;
    }
    private MultiResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      initFields();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(input, unknownFields,
                                     extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                result_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult>();
                mutable_bitField0_ |= 0x00000001;
              }
              result_.add(input.readMessage(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e.getMessage()).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          result_ = java.util.Collections.unmodifiableList(result_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.Builder.class);
    }

    public static com.google.protobuf.Parser<MultiResponse> PARSER =
        new com.google.protobuf.AbstractParser<MultiResponse>() {
      public MultiResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return new MultiResponse(input, extensionRegistry);
      }
    };

    @java.lang.Override
    public com.google.protobuf.Parser<MultiResponse> getParserForType() {
      return PARSER;
    }

    // repeated .ActionResult result = 1;
    public static final int RESULT_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> result_;
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> getResultList() {
      return result_;
    }
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> 
        getResultOrBuilderList() {
      return result_;
    }
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    public int getResultCount() {
      return result_.size();
    }
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult getResult(int index) {
      return result_.get(index);
    }
    /**
     * <code>repeated .ActionResult result = 1;</code>
     */
    public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder getResultOrBuilder(
        int index) {
      return result_.get(index);
    }

    private void initFields() {
      result_ = java.util.Collections.emptyList();
    }
    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized != -1) return isInitialized == 1;

      for (int i = 0; i < getResultCount(); i++) {
        if (!getResult(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      for (int i = 0; i < result_.size(); i++) {
        output.writeMessage(1, result_.get(i));
      }
      getUnknownFields().writeTo(output);
    }

    private int memoizedSerializedSize = -1;
    public int getSerializedSize() {
      int size = memoizedSerializedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < result_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, result_.get(i));
      }
      size += getUnknownFields().getSerializedSize();
      memoizedSerializedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    protected java.lang.Object writeReplace()
        throws java.io.ObjectStreamException {
      return super.writeReplace();
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse)) {
        return super.equals(obj);
      }
      org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse other = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse) obj;

      boolean result = true;
      result = result && getResultList()
          .equals(other.getResultList());
      result = result &&
          getUnknownFields().equals(other.getUnknownFields());
      return result;
    }

    private int memoizedHashCode = 0;
    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResultCount() > 0) {
        hash = (37 * hash) + RESULT_FIELD_NUMBER;
        hash = (53 * hash) + getResultList().hashCode();
      }
      hash = (29 * hash) + getUnknownFields().hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseDelimitedFrom(input, extensionRegistry);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return PARSER.parseFrom(input);
    }
    public static org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return PARSER.parseFrom(input, extensionRegistry);
    }

    public static Builder newBuilder() { return Builder.create(); }
    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse prototype) {
      return newBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() { return newBuilder(this); }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code MultiResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessage.Builder<Builder>
       implements org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.class, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.Builder.class);
      }

      // Construct using org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessage.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
          getResultFieldBuilder();
        }
      }
      private static Builder create() {
        return new Builder();
      }

      public Builder clear() {
        super.clear();
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resultBuilder_.clear();
        }
        return this;
      }

      public Builder clone() {
        return create().mergeFrom(buildPartial());
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.internal_static_MultiResponse_descriptor;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse getDefaultInstanceForType() {
        return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse build() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse buildPartial() {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse result = new org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse(this);
        int from_bitField0_ = bitField0_;
        if (resultBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            result_ = java.util.Collections.unmodifiableList(result_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.result_ = result_;
        } else {
          result.result_ = resultBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse) {
          return mergeFrom((org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse other) {
        if (other == org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance()) return this;
        if (resultBuilder_ == null) {
          if (!other.result_.isEmpty()) {
            if (result_.isEmpty()) {
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultIsMutable();
              result_.addAll(other.result_);
            }
            onChanged();
          }
        } else {
          if (!other.result_.isEmpty()) {
            if (resultBuilder_.isEmpty()) {
              resultBuilder_.dispose();
              resultBuilder_ = null;
              result_ = other.result_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultBuilder_ = 
                com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders ?
                   getResultFieldBuilder() : null;
            } else {
              resultBuilder_.addAllMessages(other.result_);
            }
          }
        }
        this.mergeUnknownFields(other.getUnknownFields());
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getResultCount(); i++) {
          if (!getResult(i).isInitialized()) {
            
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse) e.getUnfinishedMessage();
          throw e;
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      // repeated .ActionResult result = 1;
      private java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> result_ =
        java.util.Collections.emptyList();
      private void ensureResultIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          result_ = new java.util.ArrayList<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult>(result_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> resultBuilder_;

      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> getResultList() {
        if (resultBuilder_ == null) {
          return java.util.Collections.unmodifiableList(result_);
        } else {
          return resultBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public int getResultCount() {
        if (resultBuilder_ == null) {
          return result_.size();
        } else {
          return resultBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult getResult(int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);
        } else {
          return resultBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder setResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.set(index, value);
          onChanged();
        } else {
          resultBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder setResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder addResult(org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(value);
          onChanged();
        } else {
          resultBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder addResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult value) {
        if (resultBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultIsMutable();
          result_.add(index, value);
          onChanged();
        } else {
          resultBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder addResult(
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder addResult(
          int index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder builderForValue) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder addAllResult(
          java.lang.Iterable<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult> values) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          super.addAll(values, result_);
          onChanged();
        } else {
          resultBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder clearResult() {
        if (resultBuilder_ == null) {
          result_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public Builder removeResult(int index) {
        if (resultBuilder_ == null) {
          ensureResultIsMutable();
          result_.remove(index);
          onChanged();
        } else {
          resultBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder getResultBuilder(
          int index) {
        return getResultFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder getResultOrBuilder(
          int index) {
        if (resultBuilder_ == null) {
          return result_.get(index);  } else {
          return resultBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> 
           getResultOrBuilderList() {
        if (resultBuilder_ != null) {
          return resultBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(result_);
        }
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder addResultBuilder() {
        return getResultFieldBuilder().addBuilder(
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDefaultInstance());
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder addResultBuilder(
          int index) {
        return getResultFieldBuilder().addBuilder(
            index, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.getDefaultInstance());
      }
      /**
       * <code>repeated .ActionResult result = 1;</code>
       */
      public java.util.List<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder> 
           getResultBuilderList() {
        return getResultFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilder<
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder> 
          getResultFieldBuilder() {
        if (resultBuilder_ == null) {
          resultBuilder_ = new com.google.protobuf.RepeatedFieldBuilder<
              org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResult.Builder, org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ActionResultOrBuilder>(
                  result_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          result_ = null;
        }
        return resultBuilder_;
      }

      // @@protoc_insertion_point(builder_scope:MultiResponse)
    }

    static {
      defaultInstance = new MultiResponse(true);
      defaultInstance.initFields();
    }

    // @@protoc_insertion_point(class_scope:MultiResponse)
  }

  /**
   * Protobuf service {@code ClientService}
   */
  public static abstract class ClientService
      implements com.google.protobuf.Service {
    protected ClientService() {}

    public interface Interface {
      /**
       * <code>rpc Get(.GetRequest) returns (.GetResponse);</code>
       */
      public abstract void get(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse> done);

      /**
       * <code>rpc MultiGet(.MultiGetRequest) returns (.MultiGetResponse);</code>
       */
      public abstract void multiGet(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse> done);

      /**
       * <code>rpc Mutate(.MutateRequest) returns (.MutateResponse);</code>
       */
      public abstract void mutate(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse> done);

      /**
       * <code>rpc Scan(.ScanRequest) returns (.ScanResponse);</code>
       */
      public abstract void scan(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse> done);

      /**
       * <code>rpc BulkLoadHFile(.BulkLoadHFileRequest) returns (.BulkLoadHFileResponse);</code>
       */
      public abstract void bulkLoadHFile(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done);

      /**
       * <code>rpc ExecService(.CoprocessorServiceRequest) returns (.CoprocessorServiceResponse);</code>
       */
      public abstract void execService(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done);

      /**
       * <code>rpc Multi(.MultiRequest) returns (.MultiResponse);</code>
       */
      public abstract void multi(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse> done);

    }

    public static com.google.protobuf.Service newReflectiveService(
        final Interface impl) {
      return new ClientService() {
        @java.lang.Override
        public  void get(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse> done) {
          impl.get(controller, request, done);
        }

        @java.lang.Override
        public  void multiGet(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse> done) {
          impl.multiGet(controller, request, done);
        }

        @java.lang.Override
        public  void mutate(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse> done) {
          impl.mutate(controller, request, done);
        }

        @java.lang.Override
        public  void scan(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse> done) {
          impl.scan(controller, request, done);
        }

        @java.lang.Override
        public  void bulkLoadHFile(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done) {
          impl.bulkLoadHFile(controller, request, done);
        }

        @java.lang.Override
        public  void execService(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done) {
          impl.execService(controller, request, done);
        }

        @java.lang.Override
        public  void multi(
            com.google.protobuf.RpcController controller,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request,
            com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse> done) {
          impl.multi(controller, request, done);
        }

      };
    }

    public static com.google.protobuf.BlockingService
        newReflectiveBlockingService(final BlockingInterface impl) {
      return new com.google.protobuf.BlockingService() {
        public final com.google.protobuf.Descriptors.ServiceDescriptor
            getDescriptorForType() {
          return getDescriptor();
        }

        public final com.google.protobuf.Message callBlockingMethod(
            com.google.protobuf.Descriptors.MethodDescriptor method,
            com.google.protobuf.RpcController controller,
            com.google.protobuf.Message request)
            throws com.google.protobuf.ServiceException {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.callBlockingMethod() given method descriptor for " +
              "wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return impl.get(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest)request);
            case 1:
              return impl.multiGet(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest)request);
            case 2:
              return impl.mutate(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest)request);
            case 3:
              return impl.scan(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest)request);
            case 4:
              return impl.bulkLoadHFile(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest)request);
            case 5:
              return impl.execService(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest)request);
            case 6:
              return impl.multi(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest)request);
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final com.google.protobuf.Message
            getRequestPrototype(
            com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getRequestPrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
            case 5:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
            case 6:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

        public final com.google.protobuf.Message
            getResponsePrototype(
            com.google.protobuf.Descriptors.MethodDescriptor method) {
          if (method.getService() != getDescriptor()) {
            throw new java.lang.IllegalArgumentException(
              "Service.getResponsePrototype() given method " +
              "descriptor for wrong service type.");
          }
          switch(method.getIndex()) {
            case 0:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
            case 1:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.getDefaultInstance();
            case 2:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
            case 3:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
            case 4:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
            case 5:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
            case 6:
              return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
            default:
              throw new java.lang.AssertionError("Can't get here.");
          }
        }

      };
    }

    /**
     * <code>rpc Get(.GetRequest) returns (.GetResponse);</code>
     */
    public abstract void get(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse> done);

    /**
     * <code>rpc MultiGet(.MultiGetRequest) returns (.MultiGetResponse);</code>
     */
    public abstract void multiGet(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse> done);

    /**
     * <code>rpc Mutate(.MutateRequest) returns (.MutateResponse);</code>
     */
    public abstract void mutate(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse> done);

    /**
     * <code>rpc Scan(.ScanRequest) returns (.ScanResponse);</code>
     */
    public abstract void scan(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse> done);

    /**
     * <code>rpc BulkLoadHFile(.BulkLoadHFileRequest) returns (.BulkLoadHFileResponse);</code>
     */
    public abstract void bulkLoadHFile(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done);

    /**
     * <code>rpc ExecService(.CoprocessorServiceRequest) returns (.CoprocessorServiceResponse);</code>
     */
    public abstract void execService(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done);

    /**
     * <code>rpc Multi(.MultiRequest) returns (.MultiResponse);</code>
     */
    public abstract void multi(
        com.google.protobuf.RpcController controller,
        org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request,
        com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse> done);

    public static final
        com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptor() {
      return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.getDescriptor().getServices().get(0);
    }
    public final com.google.protobuf.Descriptors.ServiceDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }

    public final void callMethod(
        com.google.protobuf.Descriptors.MethodDescriptor method,
        com.google.protobuf.RpcController controller,
        com.google.protobuf.Message request,
        com.google.protobuf.RpcCallback<
          com.google.protobuf.Message> done) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.callMethod() given method descriptor for wrong " +
          "service type.");
      }
      switch(method.getIndex()) {
        case 0:
          this.get(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse>specializeCallback(
              done));
          return;
        case 1:
          this.multiGet(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse>specializeCallback(
              done));
          return;
        case 2:
          this.mutate(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse>specializeCallback(
              done));
          return;
        case 3:
          this.scan(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse>specializeCallback(
              done));
          return;
        case 4:
          this.bulkLoadHFile(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse>specializeCallback(
              done));
          return;
        case 5:
          this.execService(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse>specializeCallback(
              done));
          return;
        case 6:
          this.multi(controller, (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest)request,
            com.google.protobuf.RpcUtil.<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse>specializeCallback(
              done));
          return;
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final com.google.protobuf.Message
        getRequestPrototype(
        com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getRequestPrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest.getDefaultInstance();
        case 5:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest.getDefaultInstance();
        case 6:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public final com.google.protobuf.Message
        getResponsePrototype(
        com.google.protobuf.Descriptors.MethodDescriptor method) {
      if (method.getService() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "Service.getResponsePrototype() given method " +
          "descriptor for wrong service type.");
      }
      switch(method.getIndex()) {
        case 0:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance();
        case 1:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.getDefaultInstance();
        case 2:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance();
        case 3:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance();
        case 4:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance();
        case 5:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance();
        case 6:
          return org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance();
        default:
          throw new java.lang.AssertionError("Can't get here.");
      }
    }

    public static Stub newStub(
        com.google.protobuf.RpcChannel channel) {
      return new Stub(channel);
    }

    public static final class Stub extends org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ClientService implements Interface {
      private Stub(com.google.protobuf.RpcChannel channel) {
        this.channel = channel;
      }

      private final com.google.protobuf.RpcChannel channel;

      public com.google.protobuf.RpcChannel getChannel() {
        return channel;
      }

      public  void get(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance()));
      }

      public  void multiGet(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.getDefaultInstance()));
      }

      public  void mutate(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance()));
      }

      public  void scan(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance()));
      }

      public  void bulkLoadHFile(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance()));
      }

      public  void execService(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance()));
      }

      public  void multi(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request,
          com.google.protobuf.RpcCallback<org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse> done) {
        channel.callMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance(),
          com.google.protobuf.RpcUtil.generalizeCallback(
            done,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.class,
            org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance()));
      }
    }

    public static BlockingInterface newBlockingStub(
        com.google.protobuf.BlockingRpcChannel channel) {
      return new BlockingStub(channel);
    }

    public interface BlockingInterface {
      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse get(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse multiGet(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse mutate(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse scan(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse bulkLoadHFile(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse execService(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request)
          throws com.google.protobuf.ServiceException;

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse multi(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request)
          throws com.google.protobuf.ServiceException;
    }

    private static final class BlockingStub implements BlockingInterface {
      private BlockingStub(com.google.protobuf.BlockingRpcChannel channel) {
        this.channel = channel;
      }

      private final com.google.protobuf.BlockingRpcChannel channel;

      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse get(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(0),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.GetResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse multiGet(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(1),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiGetResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse mutate(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(2),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MutateResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse scan(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(3),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.ScanResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse bulkLoadHFile(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(4),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.BulkLoadHFileResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse execService(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(5),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.CoprocessorServiceResponse.getDefaultInstance());
      }


      public org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse multi(
          com.google.protobuf.RpcController controller,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiRequest request)
          throws com.google.protobuf.ServiceException {
        return (org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse) channel.callBlockingMethod(
          getDescriptor().getMethods().get(6),
          controller,
          request,
          org.apache.hadoop.hbase.protobuf.generated.ClientProtos.MultiResponse.getDefaultInstance());
      }

    }

    // @@protoc_insertion_point(class_scope:ClientService)
  }

  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Column_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Column_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Get_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Get_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Result_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Result_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MultiGetRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MultiGetRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_GetResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_GetResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MultiGetResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MultiGetResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Condition_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Condition_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MutationProto_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MutationProto_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MutationProto_ColumnValue_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MutationProto_ColumnValue_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MutationProto_ColumnValue_QualifierValue_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MutationProto_ColumnValue_QualifierValue_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MutateRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MutateRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MutateResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MutateResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_Scan_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_Scan_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ScanRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ScanRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ScanResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ScanResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_BulkLoadHFileRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_BulkLoadHFileRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_BulkLoadHFileRequest_FamilyPath_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_BulkLoadHFileResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_BulkLoadHFileResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_CoprocessorServiceCall_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_CoprocessorServiceCall_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_CoprocessorServiceRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_CoprocessorServiceRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_CoprocessorServiceResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_CoprocessorServiceResponse_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MultiAction_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MultiAction_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_ActionResult_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_ActionResult_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MultiRequest_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MultiRequest_fieldAccessorTable;
  private static com.google.protobuf.Descriptors.Descriptor
    internal_static_MultiResponse_descriptor;
  private static
    com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internal_static_MultiResponse_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\014Client.proto\032\013hbase.proto\032\014Filter.prot" +
      "o\032\nCell.proto\032\020Comparator.proto\"+\n\006Colum" +
      "n\022\016\n\006family\030\001 \002(\014\022\021\n\tqualifier\030\002 \003(\014\"\347\001\n" +
      "\003Get\022\013\n\003row\030\001 \002(\014\022\027\n\006column\030\002 \003(\0132\007.Colu" +
      "mn\022!\n\tattribute\030\003 \003(\0132\016.NameBytesPair\022\027\n" +
      "\006filter\030\004 \001(\0132\007.Filter\022\036\n\ntime_range\030\005 \001" +
      "(\0132\n.TimeRange\022\027\n\014max_versions\030\006 \001(\r:\0011\022" +
      "\032\n\014cache_blocks\030\007 \001(\010:\004true\022\023\n\013store_lim" +
      "it\030\010 \001(\r\022\024\n\014store_offset\030\t \001(\r\"<\n\006Result" +
      "\022\023\n\004cell\030\001 \003(\0132\005.Cell\022\035\n\025associated_cell",
      "_count\030\002 \001(\005\"u\n\nGetRequest\022 \n\006region\030\001 \002" +
      "(\0132\020.RegionSpecifier\022\021\n\003get\030\002 \002(\0132\004.Get\022" +
      "\032\n\022closest_row_before\030\003 \001(\010\022\026\n\016existence" +
      "_only\030\004 \001(\010\"z\n\017MultiGetRequest\022 \n\006region" +
      "\030\001 \002(\0132\020.RegionSpecifier\022\021\n\003get\030\002 \003(\0132\004." +
      "Get\022\032\n\022closest_row_before\030\003 \001(\010\022\026\n\016exist" +
      "ence_only\030\004 \001(\010\"6\n\013GetResponse\022\027\n\006result" +
      "\030\001 \001(\0132\007.Result\022\016\n\006exists\030\002 \001(\010\";\n\020Multi" +
      "GetResponse\022\027\n\006result\030\001 \003(\0132\007.Result\022\016\n\006" +
      "exists\030\002 \003(\010\"\200\001\n\tCondition\022\013\n\003row\030\001 \002(\014\022",
      "\016\n\006family\030\002 \002(\014\022\021\n\tqualifier\030\003 \002(\014\022\"\n\014co" +
      "mpare_type\030\004 \002(\0162\014.CompareType\022\037\n\ncompar" +
      "ator\030\005 \002(\0132\013.Comparator\"\227\006\n\rMutationProt" +
      "o\022\013\n\003row\030\001 \001(\014\0220\n\013mutate_type\030\002 \001(\0162\033.Mu" +
      "tationProto.MutationType\0220\n\014column_value" +
      "\030\003 \003(\0132\032.MutationProto.ColumnValue\022\021\n\tti" +
      "mestamp\030\004 \001(\004\022!\n\tattribute\030\005 \003(\0132\016.NameB" +
      "ytesPair\022:\n\ndurability\030\006 \001(\0162\031.MutationP" +
      "roto.Durability:\013USE_DEFAULT\022\036\n\ntime_ran" +
      "ge\030\007 \001(\0132\n.TimeRange\022\035\n\025associated_cell_",
      "count\030\010 \001(\005\032\330\001\n\013ColumnValue\022\016\n\006family\030\001 " +
      "\002(\014\022B\n\017qualifier_value\030\002 \003(\0132).MutationP" +
      "roto.ColumnValue.QualifierValue\032u\n\016Quali" +
      "fierValue\022\021\n\tqualifier\030\001 \001(\014\022\r\n\005value\030\002 " +
      "\001(\014\022\021\n\ttimestamp\030\003 \001(\004\022.\n\013delete_type\030\004 " +
      "\001(\0162\031.MutationProto.DeleteType\"W\n\nDurabi" +
      "lity\022\017\n\013USE_DEFAULT\020\000\022\014\n\010SKIP_WAL\020\001\022\r\n\tA" +
      "SYNC_WAL\020\002\022\014\n\010SYNC_WAL\020\003\022\r\n\tFSYNC_WAL\020\004\"" +
      ">\n\014MutationType\022\n\n\006APPEND\020\000\022\r\n\tINCREMENT" +
      "\020\001\022\007\n\003PUT\020\002\022\n\n\006DELETE\020\003\"p\n\nDeleteType\022\026\n",
      "\022DELETE_ONE_VERSION\020\000\022\034\n\030DELETE_MULTIPLE" +
      "_VERSIONS\020\001\022\021\n\rDELETE_FAMILY\020\002\022\031\n\025DELETE" +
      "_FAMILY_VERSION\020\003\"r\n\rMutateRequest\022 \n\006re" +
      "gion\030\001 \002(\0132\020.RegionSpecifier\022 \n\010mutation" +
      "\030\002 \002(\0132\016.MutationProto\022\035\n\tcondition\030\003 \001(" +
      "\0132\n.Condition\"<\n\016MutateResponse\022\027\n\006resul" +
      "t\030\001 \001(\0132\007.Result\022\021\n\tprocessed\030\002 \001(\010\"\325\002\n\004" +
      "Scan\022\027\n\006column\030\001 \003(\0132\007.Column\022!\n\tattribu" +
      "te\030\002 \003(\0132\016.NameBytesPair\022\021\n\tstart_row\030\003 " +
      "\001(\014\022\020\n\010stop_row\030\004 \001(\014\022\027\n\006filter\030\005 \001(\0132\007.",
      "Filter\022\036\n\ntime_range\030\006 \001(\0132\n.TimeRange\022\027" +
      "\n\014max_versions\030\007 \001(\r:\0011\022\032\n\014cache_blocks\030" +
      "\010 \001(\010:\004true\022\022\n\nbatch_size\030\t \001(\r\022\027\n\017max_r" +
      "esult_size\030\n \001(\004\022\023\n\013store_limit\030\013 \001(\r\022\024\n" +
      "\014store_offset\030\014 \001(\r\022&\n\036load_column_famil" +
      "ies_on_demand\030\r \001(\010\"\236\001\n\013ScanRequest\022 \n\006r" +
      "egion\030\001 \001(\0132\020.RegionSpecifier\022\023\n\004scan\030\002 " +
      "\001(\0132\005.Scan\022\022\n\nscanner_id\030\003 \001(\004\022\026\n\016number" +
      "_of_rows\030\004 \001(\r\022\025\n\rclose_scanner\030\005 \001(\010\022\025\n" +
      "\rnext_call_seq\030\006 \001(\004\"y\n\014ScanResponse\022\030\n\020",
      "cells_per_result\030\001 \003(\r\022\022\n\nscanner_id\030\002 \001" +
      "(\004\022\024\n\014more_results\030\003 \001(\010\022\013\n\003ttl\030\004 \001(\r\022\030\n" +
      "\007results\030\005 \003(\0132\007.Result\"\263\001\n\024BulkLoadHFil" +
      "eRequest\022 \n\006region\030\001 \002(\0132\020.RegionSpecifi" +
      "er\0225\n\013family_path\030\002 \003(\0132 .BulkLoadHFileR" +
      "equest.FamilyPath\022\026\n\016assign_seq_num\030\003 \001(" +
      "\010\032*\n\nFamilyPath\022\016\n\006family\030\001 \002(\014\022\014\n\004path\030" +
      "\002 \002(\t\"\'\n\025BulkLoadHFileResponse\022\016\n\006loaded" +
      "\030\001 \002(\010\"a\n\026CoprocessorServiceCall\022\013\n\003row\030" +
      "\001 \002(\014\022\024\n\014service_name\030\002 \002(\t\022\023\n\013method_na",
      "me\030\003 \002(\t\022\017\n\007request\030\004 \002(\014\"d\n\031Coprocessor" +
      "ServiceRequest\022 \n\006region\030\001 \002(\0132\020.RegionS" +
      "pecifier\022%\n\004call\030\002 \002(\0132\027.CoprocessorServ" +
      "iceCall\"]\n\032CoprocessorServiceResponse\022 \n" +
      "\006region\030\001 \002(\0132\020.RegionSpecifier\022\035\n\005value" +
      "\030\002 \002(\0132\016.NameBytesPair\"B\n\013MultiAction\022 \n" +
      "\010mutation\030\001 \001(\0132\016.MutationProto\022\021\n\003get\030\002" +
      " \001(\0132\004.Get\"I\n\014ActionResult\022\026\n\005value\030\001 \001(" +
      "\0132\007.Result\022!\n\texception\030\002 \001(\0132\016.NameByte" +
      "sPair\"^\n\014MultiRequest\022 \n\006region\030\001 \002(\0132\020.",
      "RegionSpecifier\022\034\n\006action\030\002 \003(\0132\014.MultiA" +
      "ction\022\016\n\006atomic\030\003 \001(\010\".\n\rMultiResponse\022\035" +
      "\n\006result\030\001 \003(\0132\r.ActionResult2\342\002\n\rClient" +
      "Service\022 \n\003Get\022\013.GetRequest\032\014.GetRespons" +
      "e\022/\n\010MultiGet\022\020.MultiGetRequest\032\021.MultiG" +
      "etResponse\022)\n\006Mutate\022\016.MutateRequest\032\017.M" +
      "utateResponse\022#\n\004Scan\022\014.ScanRequest\032\r.Sc" +
      "anResponse\022>\n\rBulkLoadHFile\022\025.BulkLoadHF" +
      "ileRequest\032\026.BulkLoadHFileResponse\022F\n\013Ex" +
      "ecService\022\032.CoprocessorServiceRequest\032\033.",
      "CoprocessorServiceResponse\022&\n\005Multi\022\r.Mu" +
      "ltiRequest\032\016.MultiResponseBB\n*org.apache" +
      ".hadoop.hbase.protobuf.generatedB\014Client" +
      "ProtosH\001\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
      new com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner() {
        public com.google.protobuf.ExtensionRegistry assignDescriptors(
            com.google.protobuf.Descriptors.FileDescriptor root) {
          descriptor = root;
          internal_static_Column_descriptor =
            getDescriptor().getMessageTypes().get(0);
          internal_static_Column_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Column_descriptor,
              new java.lang.String[] { "Family", "Qualifier", });
          internal_static_Get_descriptor =
            getDescriptor().getMessageTypes().get(1);
          internal_static_Get_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Get_descriptor,
              new java.lang.String[] { "Row", "Column", "Attribute", "Filter", "TimeRange", "MaxVersions", "CacheBlocks", "StoreLimit", "StoreOffset", });
          internal_static_Result_descriptor =
            getDescriptor().getMessageTypes().get(2);
          internal_static_Result_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Result_descriptor,
              new java.lang.String[] { "Cell", "AssociatedCellCount", });
          internal_static_GetRequest_descriptor =
            getDescriptor().getMessageTypes().get(3);
          internal_static_GetRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetRequest_descriptor,
              new java.lang.String[] { "Region", "Get", "ClosestRowBefore", "ExistenceOnly", });
          internal_static_MultiGetRequest_descriptor =
            getDescriptor().getMessageTypes().get(4);
          internal_static_MultiGetRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MultiGetRequest_descriptor,
              new java.lang.String[] { "Region", "Get", "ClosestRowBefore", "ExistenceOnly", });
          internal_static_GetResponse_descriptor =
            getDescriptor().getMessageTypes().get(5);
          internal_static_GetResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_GetResponse_descriptor,
              new java.lang.String[] { "Result", "Exists", });
          internal_static_MultiGetResponse_descriptor =
            getDescriptor().getMessageTypes().get(6);
          internal_static_MultiGetResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MultiGetResponse_descriptor,
              new java.lang.String[] { "Result", "Exists", });
          internal_static_Condition_descriptor =
            getDescriptor().getMessageTypes().get(7);
          internal_static_Condition_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Condition_descriptor,
              new java.lang.String[] { "Row", "Family", "Qualifier", "CompareType", "Comparator", });
          internal_static_MutationProto_descriptor =
            getDescriptor().getMessageTypes().get(8);
          internal_static_MutationProto_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MutationProto_descriptor,
              new java.lang.String[] { "Row", "MutateType", "ColumnValue", "Timestamp", "Attribute", "Durability", "TimeRange", "AssociatedCellCount", });
          internal_static_MutationProto_ColumnValue_descriptor =
            internal_static_MutationProto_descriptor.getNestedTypes().get(0);
          internal_static_MutationProto_ColumnValue_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MutationProto_ColumnValue_descriptor,
              new java.lang.String[] { "Family", "QualifierValue", });
          internal_static_MutationProto_ColumnValue_QualifierValue_descriptor =
            internal_static_MutationProto_ColumnValue_descriptor.getNestedTypes().get(0);
          internal_static_MutationProto_ColumnValue_QualifierValue_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MutationProto_ColumnValue_QualifierValue_descriptor,
              new java.lang.String[] { "Qualifier", "Value", "Timestamp", "DeleteType", });
          internal_static_MutateRequest_descriptor =
            getDescriptor().getMessageTypes().get(9);
          internal_static_MutateRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MutateRequest_descriptor,
              new java.lang.String[] { "Region", "Mutation", "Condition", });
          internal_static_MutateResponse_descriptor =
            getDescriptor().getMessageTypes().get(10);
          internal_static_MutateResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MutateResponse_descriptor,
              new java.lang.String[] { "Result", "Processed", });
          internal_static_Scan_descriptor =
            getDescriptor().getMessageTypes().get(11);
          internal_static_Scan_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_Scan_descriptor,
              new java.lang.String[] { "Column", "Attribute", "StartRow", "StopRow", "Filter", "TimeRange", "MaxVersions", "CacheBlocks", "BatchSize", "MaxResultSize", "StoreLimit", "StoreOffset", "LoadColumnFamiliesOnDemand", });
          internal_static_ScanRequest_descriptor =
            getDescriptor().getMessageTypes().get(12);
          internal_static_ScanRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ScanRequest_descriptor,
              new java.lang.String[] { "Region", "Scan", "ScannerId", "NumberOfRows", "CloseScanner", "NextCallSeq", });
          internal_static_ScanResponse_descriptor =
            getDescriptor().getMessageTypes().get(13);
          internal_static_ScanResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ScanResponse_descriptor,
              new java.lang.String[] { "CellsPerResult", "ScannerId", "MoreResults", "Ttl", "Results", });
          internal_static_BulkLoadHFileRequest_descriptor =
            getDescriptor().getMessageTypes().get(14);
          internal_static_BulkLoadHFileRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_BulkLoadHFileRequest_descriptor,
              new java.lang.String[] { "Region", "FamilyPath", "AssignSeqNum", });
          internal_static_BulkLoadHFileRequest_FamilyPath_descriptor =
            internal_static_BulkLoadHFileRequest_descriptor.getNestedTypes().get(0);
          internal_static_BulkLoadHFileRequest_FamilyPath_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_BulkLoadHFileRequest_FamilyPath_descriptor,
              new java.lang.String[] { "Family", "Path", });
          internal_static_BulkLoadHFileResponse_descriptor =
            getDescriptor().getMessageTypes().get(15);
          internal_static_BulkLoadHFileResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_BulkLoadHFileResponse_descriptor,
              new java.lang.String[] { "Loaded", });
          internal_static_CoprocessorServiceCall_descriptor =
            getDescriptor().getMessageTypes().get(16);
          internal_static_CoprocessorServiceCall_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_CoprocessorServiceCall_descriptor,
              new java.lang.String[] { "Row", "ServiceName", "MethodName", "Request", });
          internal_static_CoprocessorServiceRequest_descriptor =
            getDescriptor().getMessageTypes().get(17);
          internal_static_CoprocessorServiceRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_CoprocessorServiceRequest_descriptor,
              new java.lang.String[] { "Region", "Call", });
          internal_static_CoprocessorServiceResponse_descriptor =
            getDescriptor().getMessageTypes().get(18);
          internal_static_CoprocessorServiceResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_CoprocessorServiceResponse_descriptor,
              new java.lang.String[] { "Region", "Value", });
          internal_static_MultiAction_descriptor =
            getDescriptor().getMessageTypes().get(19);
          internal_static_MultiAction_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MultiAction_descriptor,
              new java.lang.String[] { "Mutation", "Get", });
          internal_static_ActionResult_descriptor =
            getDescriptor().getMessageTypes().get(20);
          internal_static_ActionResult_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_ActionResult_descriptor,
              new java.lang.String[] { "Value", "Exception", });
          internal_static_MultiRequest_descriptor =
            getDescriptor().getMessageTypes().get(21);
          internal_static_MultiRequest_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MultiRequest_descriptor,
              new java.lang.String[] { "Region", "Action", "Atomic", });
          internal_static_MultiResponse_descriptor =
            getDescriptor().getMessageTypes().get(22);
          internal_static_MultiResponse_fieldAccessorTable = new
            com.google.protobuf.GeneratedMessage.FieldAccessorTable(
              internal_static_MultiResponse_descriptor,
              new java.lang.String[] { "Result", });
          return null;
        }
      };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.hbase.protobuf.generated.HBaseProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.FilterProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.CellProtos.getDescriptor(),
          org.apache.hadoop.hbase.protobuf.generated.ComparatorProtos.getDescriptor(),
        }, assigner);
  }

  // @@protoc_insertion_point(outer_class_scope)
}

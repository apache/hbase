<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
   <title>2.3.&nbsp;Configuration Files</title><link rel="stylesheet" type="text/css" href="../css/freebsd_docbook.css"><meta name="generator" content="DocBook XSL-NS Stylesheets V1.76.1"><link rel="home" href="book.html" title="The Apache HBase&#153; Reference Guide"><link rel="up" href="configuration.html" title="Chapter&nbsp;2.&nbsp;Apache HBase (TM) Configuration"><link rel="prev" href="standalone_dist.html" title="2.2.&nbsp;HBase run modes: Standalone and Distributed"><link rel="next" href="example_config.html" title="2.4.&nbsp;Example Configurations"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">2.3.&nbsp;Configuration Files</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="standalone_dist.html">Prev</a>&nbsp;</td><th width="60%" align="center">Chapter&nbsp;2.&nbsp;Apache HBase (TM) Configuration</th><td width="20%" align="right">&nbsp;<a accesskey="n" href="example_config.html">Next</a></td></tr></table><hr></div><div class="section" title="2.3.&nbsp;Configuration Files"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="config.files"></a>2.3.&nbsp;Configuration Files</h2></div></div></div><div class="section" title="2.3.1.&nbsp;hbase-site.xml and hbase-default.xml"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.site"></a>2.3.1.&nbsp;<code class="filename">hbase-site.xml</code> and <code class="filename">hbase-default.xml</code></h3></div></div></div><p>Just as in Hadoop where you add site-specific HDFS configuration
    to the <code class="filename">hdfs-site.xml</code> file,
    for HBase, site specific customizations go into
    the file <code class="filename">conf/hbase-site.xml</code>.
    For the list of configurable properties, see
    <a class="xref" href="config.files.html#hbase_default_configurations" title="2.3.1.1.&nbsp;HBase Default Configuration">Section&nbsp;2.3.1.1, &#8220;HBase Default Configuration&#8221;</a>
    below or view the raw <code class="filename">hbase-default.xml</code>
    source file in the HBase source code at
    <code class="filename">src/main/resources</code>.
    </p><p>
    Not all configuration options make it out to
    <code class="filename">hbase-default.xml</code>.  Configuration
    that it is thought rare anyone would change can exist only
    in code; the only way to turn up such configurations is
    via a reading of the source code itself.
    </p><p>
      Currently, changes here will require a cluster restart for HBase to notice the change.
      </p><div class="section" title="2.3.1.1.&nbsp;HBase Default Configuration"><div class="titlepage"><div><div><h4 class="title"><a name="hbase_default_configurations"></a>2.3.1.1.&nbsp;HBase Default Configuration</h4></div></div></div><p></p><div class="glossary" title="HBase Default Configuration"><div class="titlepage"><div><div><h5 class="title"><a name="hbase.default.configuration"></a>HBase Default Configuration</h5></div></div></div><p>
The documentation below is generated using the default hbase configuration file,
<code class="filename">hbase-default.xml</code>, as source.
</p><dl><dt><a name="hbase.rootdir"></a><code class="varname">hbase.rootdir</code></dt><dd><p>The directory shared by region servers and into
    which HBase persists.  The URL should be 'fully-qualified'
    to include the filesystem scheme.  For example, to specify the
    HDFS directory '/hbase' where the HDFS instance's namenode is
    running at namenode.example.org on port 9000, set this value to:
    hdfs://namenode.example.org:9000/hbase.  By default HBase writes
    into /tmp.  Change this configuration else all data will be lost
    on machine restart.
    </p><p>Default: <code class="varname">file:///tmp/hbase-${user.name}/hbase</code></p></dd><dt><a name="hbase.master.port"></a><code class="varname">hbase.master.port</code></dt><dd><p>The port the HBase Master should bind to.</p><p>Default: <code class="varname">60000</code></p></dd><dt><a name="hbase.cluster.distributed"></a><code class="varname">hbase.cluster.distributed</code></dt><dd><p>The mode the cluster will be in. Possible values are
      false for standalone mode and true for distributed mode.  If
      false, startup will run all HBase and ZooKeeper daemons together
      in the one JVM.
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.tmp.dir"></a><code class="varname">hbase.tmp.dir</code></dt><dd><p>Temporary directory on the local filesystem.
    Change this setting to point to a location more permanent
    than '/tmp' (The '/tmp' directory is often cleared on
    machine restart).
    </p><p>Default: <code class="varname">/tmp/hbase-${user.name}</code></p></dd><dt><a name="hbase.master.info.port"></a><code class="varname">hbase.master.info.port</code></dt><dd><p>The port for the HBase Master web UI.
    Set to -1 if you do not want a UI instance run.
    </p><p>Default: <code class="varname">60010</code></p></dd><dt><a name="hbase.master.info.bindAddress"></a><code class="varname">hbase.master.info.bindAddress</code></dt><dd><p>The bind address for the HBase Master web UI
    </p><p>Default: <code class="varname">0.0.0.0</code></p></dd><dt><a name="hbase.client.write.buffer"></a><code class="varname">hbase.client.write.buffer</code></dt><dd><p>Default size of the HTable clien write buffer in bytes.
    A bigger buffer takes more memory -- on both the client and server
    side since server instantiates the passed write buffer to process
    it -- but a larger buffer size reduces the number of RPCs made.
    For an estimate of server-side memory-used, evaluate
    hbase.client.write.buffer * hbase.regionserver.handler.count
    </p><p>Default: <code class="varname">2097152</code></p></dd><dt><a name="hbase.regionserver.port"></a><code class="varname">hbase.regionserver.port</code></dt><dd><p>The port the HBase RegionServer binds to.
    </p><p>Default: <code class="varname">60020</code></p></dd><dt><a name="hbase.regionserver.info.port"></a><code class="varname">hbase.regionserver.info.port</code></dt><dd><p>The port for the HBase RegionServer web UI
    Set to -1 if you do not want the RegionServer UI to run.
    </p><p>Default: <code class="varname">60030</code></p></dd><dt><a name="hbase.regionserver.info.port.auto"></a><code class="varname">hbase.regionserver.info.port.auto</code></dt><dd><p>Whether or not the Master or RegionServer
    UI should search for a port to bind to. Enables automatic port
    search if hbase.regionserver.info.port is already in use.
    Useful for testing, turned off by default.
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.regionserver.info.bindAddress"></a><code class="varname">hbase.regionserver.info.bindAddress</code></dt><dd><p>The address for the HBase RegionServer web UI
    </p><p>Default: <code class="varname">0.0.0.0</code></p></dd><dt><a name="hbase.client.pause"></a><code class="varname">hbase.client.pause</code></dt><dd><p>General client pause value.  Used mostly as value to wait
    before running a retry of a failed get, region lookup, etc.</p><p>Default: <code class="varname">1000</code></p></dd><dt><a name="hbase.client.retries.number"></a><code class="varname">hbase.client.retries.number</code></dt><dd><p>Maximum retries.  Used as maximum for all retryable
    operations such as fetching of the root region from root region
    server, getting a cell's value, starting a row update, etc.
    Default: 10.
    </p><p>Default: <code class="varname">10</code></p></dd><dt><a name="hbase.bulkload.retries.number"></a><code class="varname">hbase.bulkload.retries.number</code></dt><dd><p>Maximum retries.  This is maximum number of iterations
    to atomic bulk loads are attempted in the face of splitting operations
    0 means never give up.  Default: 0.
    </p><p>Default: <code class="varname">0</code></p></dd><dt><a name="hbase.client.scanner.caching"></a><code class="varname">hbase.client.scanner.caching</code></dt><dd><p>Number of rows that will be fetched when calling next
    on a scanner if it is not served from (local, client) memory. Higher
    caching values will enable faster scanners but will eat up more memory
    and some calls of next may take longer and longer times when the cache is empty.
    Do not set this value such that the time between invocations is greater
    than the scanner timeout; i.e. hbase.client.scanner.timeout.period
    </p><p>Default: <code class="varname">100</code></p></dd><dt><a name="hbase.client.keyvalue.maxsize"></a><code class="varname">hbase.client.keyvalue.maxsize</code></dt><dd><p>Specifies the combined maximum allowed size of a KeyValue
    instance. This is to set an upper boundary for a single entry saved in a
    storage file. Since they cannot be split it helps avoiding that a region
    cannot be split any further because the data is too large. It seems wise
    to set this to a fraction of the maximum region size. Setting it to zero
    or less disables the check.
    </p><p>Default: <code class="varname">10485760</code></p></dd><dt><a name="hbase.client.scanner.timeout.period"></a><code class="varname">hbase.client.scanner.timeout.period</code></dt><dd><p>Client scanner lease period in milliseconds. Default is
    60 seconds. </p><p>Default: <code class="varname">60000</code></p></dd><dt><a name="hbase.regionserver.rowlock.timeout.period"></a><code class="varname">hbase.regionserver.rowlock.timeout.period</code></dt><dd><p>Row lock time out period in milliseconds. Default is
    60 seconds. </p><p>Default: <code class="varname">60000</code></p></dd><dt><a name="hbase.regionserver.handler.count"></a><code class="varname">hbase.regionserver.handler.count</code></dt><dd><p>Count of RPC Listener instances spun up on RegionServers.
    Same property is used by the Master for count of master handlers.
    Default is 10.
    </p><p>Default: <code class="varname">10</code></p></dd><dt><a name="hbase.regionserver.msginterval"></a><code class="varname">hbase.regionserver.msginterval</code></dt><dd><p>Interval between messages from the RegionServer to Master
    in milliseconds.
    </p><p>Default: <code class="varname">3000</code></p></dd><dt><a name="hbase.regionserver.optionallogflushinterval"></a><code class="varname">hbase.regionserver.optionallogflushinterval</code></dt><dd><p>Sync the HLog to the HDFS after this interval if it has not
    accumulated enough entries to trigger a sync. Default 1 second. Units:
    milliseconds.
    </p><p>Default: <code class="varname">1000</code></p></dd><dt><a name="hbase.regionserver.regionSplitLimit"></a><code class="varname">hbase.regionserver.regionSplitLimit</code></dt><dd><p>Limit for the number of regions after which no more region
    splitting should take place. This is not a hard limit for the number of
    regions but acts as a guideline for the regionserver to stop splitting after
    a certain limit. Default is set to MAX_INT; i.e. do not block splitting.
    </p><p>Default: <code class="varname">2147483647</code></p></dd><dt><a name="hbase.regionserver.logroll.period"></a><code class="varname">hbase.regionserver.logroll.period</code></dt><dd><p>Period at which we will roll the commit log regardless
    of how many edits it has.</p><p>Default: <code class="varname">3600000</code></p></dd><dt><a name="hbase.regionserver.logroll.errors.tolerated"></a><code class="varname">hbase.regionserver.logroll.errors.tolerated</code></dt><dd><p>The number of consecutive WAL close errors we will allow
    before triggering a server abort.  A setting of 0 will cause the
    region server to abort if closing the current WAL writer fails during
    log rolling.  Even a small value (2 or 3) will allow a region server
    to ride over transient HDFS errors.</p><p>Default: <code class="varname">2</code></p></dd><dt><a name="hbase.regionserver.hlog.reader.impl"></a><code class="varname">hbase.regionserver.hlog.reader.impl</code></dt><dd><p>The HLog file reader implementation.</p><p>Default: <code class="varname">org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogReader</code></p></dd><dt><a name="hbase.regionserver.hlog.writer.impl"></a><code class="varname">hbase.regionserver.hlog.writer.impl</code></dt><dd><p>The HLog file writer implementation.</p><p>Default: <code class="varname">org.apache.hadoop.hbase.regionserver.wal.SequenceFileLogWriter</code></p></dd><dt><a name="hbase.regionserver.nbreservationblocks"></a><code class="varname">hbase.regionserver.nbreservationblocks</code></dt><dd><p>The number of resevoir blocks of memory release on
    OOME so we can cleanup properly before server shutdown.
    </p><p>Default: <code class="varname">4</code></p></dd><dt><a name="hbase.zookeeper.dns.interface"></a><code class="varname">hbase.zookeeper.dns.interface</code></dt><dd><p>The name of the Network Interface from which a ZooKeeper server
      should report its IP address.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.zookeeper.dns.nameserver"></a><code class="varname">hbase.zookeeper.dns.nameserver</code></dt><dd><p>The host name or IP address of the name server (DNS)
      which a ZooKeeper server should use to determine the host name used by the
      master for communication and display purposes.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.regionserver.dns.interface"></a><code class="varname">hbase.regionserver.dns.interface</code></dt><dd><p>The name of the Network Interface from which a region server
      should report its IP address.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.regionserver.dns.nameserver"></a><code class="varname">hbase.regionserver.dns.nameserver</code></dt><dd><p>The host name or IP address of the name server (DNS)
      which a region server should use to determine the host name used by the
      master for communication and display purposes.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.master.dns.interface"></a><code class="varname">hbase.master.dns.interface</code></dt><dd><p>The name of the Network Interface from which a master
      should report its IP address.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.master.dns.nameserver"></a><code class="varname">hbase.master.dns.nameserver</code></dt><dd><p>The host name or IP address of the name server (DNS)
      which a master should use to determine the host name used
      for communication and display purposes.
    </p><p>Default: <code class="varname">default</code></p></dd><dt><a name="hbase.balancer.period%0A    "></a><code class="varname">hbase.balancer.period
    </code></dt><dd><p>Period at which the region balancer runs in the Master.
    </p><p>Default: <code class="varname">300000</code></p></dd><dt><a name="hbase.regions.slop"></a><code class="varname">hbase.regions.slop</code></dt><dd><p>Rebalance if any regionserver has average + (average * slop) regions.
    Default is 20% slop.
    </p><p>Default: <code class="varname">0.2</code></p></dd><dt><a name="hbase.master.logcleaner.ttl"></a><code class="varname">hbase.master.logcleaner.ttl</code></dt><dd><p>Maximum time a HLog can stay in the .oldlogdir directory,
    after which it will be cleaned by a Master thread.
    </p><p>Default: <code class="varname">600000</code></p></dd><dt><a name="hbase.master.logcleaner.plugins"></a><code class="varname">hbase.master.logcleaner.plugins</code></dt><dd><p>A comma-separated list of LogCleanerDelegate invoked by
    the LogsCleaner service. These WAL/HLog cleaners are called in order,
    so put the HLog cleaner that prunes the most HLog files in front. To
    implement your own LogCleanerDelegate, just put it in HBase's classpath
    and add the fully qualified class name here. Always add the above
    default log cleaners in the list.
    </p><p>Default: <code class="varname">org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner</code></p></dd><dt><a name="hbase.regionserver.global.memstore.upperLimit"></a><code class="varname">hbase.regionserver.global.memstore.upperLimit</code></dt><dd><p>Maximum size of all memstores in a region server before new
      updates are blocked and flushes are forced. Defaults to 40% of heap.
      Updates are blocked and flushes are forced until size of all memstores
      in a region server hits hbase.regionserver.global.memstore.lowerLimit.
    </p><p>Default: <code class="varname">0.4</code></p></dd><dt><a name="hbase.regionserver.global.memstore.lowerLimit"></a><code class="varname">hbase.regionserver.global.memstore.lowerLimit</code></dt><dd><p>Maximum size of all memstores in a region server before
      flushes are forced. Defaults to 35% of heap.
      This value equal to hbase.regionserver.global.memstore.upperLimit causes
      the minimum possible flushing to occur when updates are blocked due to
      memstore limiting.
    </p><p>Default: <code class="varname">0.35</code></p></dd><dt><a name="hbase.server.thread.wakefrequency"></a><code class="varname">hbase.server.thread.wakefrequency</code></dt><dd><p>Time to sleep in between searches for work (in milliseconds).
    Used as sleep interval by service threads such as log roller.
    </p><p>Default: <code class="varname">10000</code></p></dd><dt><a name="hbase.server.versionfile.writeattempts"></a><code class="varname">hbase.server.versionfile.writeattempts</code></dt><dd><p>
    How many time to retry attempting to write a version file
    before just aborting. Each attempt is seperated by the
    hbase.server.thread.wakefrequency milliseconds.
    </p><p>Default: <code class="varname">3</code></p></dd><dt><a name="hbase.hregion.memstore.flush.size"></a><code class="varname">hbase.hregion.memstore.flush.size</code></dt><dd><p>
    Memstore will be flushed to disk if size of the memstore
    exceeds this number of bytes.  Value is checked by a thread that runs
    every hbase.server.thread.wakefrequency.
    </p><p>Default: <code class="varname">134217728</code></p></dd><dt><a name="hbase.hregion.preclose.flush.size"></a><code class="varname">hbase.hregion.preclose.flush.size</code></dt><dd><p>
      If the memstores in a region are this size or larger when we go
      to close, run a "pre-flush" to clear out memstores before we put up
      the region closed flag and take the region offline.  On close,
      a flush is run under the close flag to empty memory.  During
      this time the region is offline and we are not taking on any writes.
      If the memstore content is large, this flush could take a long time to
      complete.  The preflush is meant to clean out the bulk of the memstore
      before putting up the close flag and taking the region offline so the
      flush that runs under the close flag has little to do.
    </p><p>Default: <code class="varname">5242880</code></p></dd><dt><a name="hbase.hregion.memstore.block.multiplier"></a><code class="varname">hbase.hregion.memstore.block.multiplier</code></dt><dd><p>
    Block updates if memstore has hbase.hregion.block.memstore
    time hbase.hregion.flush.size bytes.  Useful preventing
    runaway memstore during spikes in update traffic.  Without an
    upper-bound, memstore fills such that when it flushes the
    resultant flush files take a long time to compact or split, or
    worse, we OOME.
    </p><p>Default: <code class="varname">2</code></p></dd><dt><a name="hbase.hregion.memstore.mslab.enabled"></a><code class="varname">hbase.hregion.memstore.mslab.enabled</code></dt><dd><p>
      Enables the MemStore-Local Allocation Buffer,
      a feature which works to prevent heap fragmentation under
      heavy write loads. This can reduce the frequency of stop-the-world
      GC pauses on large heaps.
    </p><p>Default: <code class="varname">true</code></p></dd><dt><a name="hbase.hregion.max.filesize"></a><code class="varname">hbase.hregion.max.filesize</code></dt><dd><p>
    Maximum HStoreFile size. If any one of a column families' HStoreFiles has
    grown to exceed this value, the hosting HRegion is split in two.
    Default: 10G.
    </p><p>Default: <code class="varname">10737418240</code></p></dd><dt><a name="hbase.hstore.compactionThreshold"></a><code class="varname">hbase.hstore.compactionThreshold</code></dt><dd><p>
    If more than this number of HStoreFiles in any one HStore
    (one HStoreFile is written per flush of memstore) then a compaction
    is run to rewrite all HStoreFiles files as one.  Larger numbers
    put off compaction but when it runs, it takes longer to complete.
    </p><p>Default: <code class="varname">3</code></p></dd><dt><a name="hbase.hstore.blockingStoreFiles"></a><code class="varname">hbase.hstore.blockingStoreFiles</code></dt><dd><p>
    If more than this number of StoreFiles in any one Store
    (one StoreFile is written per flush of MemStore) then updates are
    blocked for this HRegion until a compaction is completed, or
    until hbase.hstore.blockingWaitTime has been exceeded.
    </p><p>Default: <code class="varname">7</code></p></dd><dt><a name="hbase.hstore.blockingWaitTime"></a><code class="varname">hbase.hstore.blockingWaitTime</code></dt><dd><p>
    The time an HRegion will block updates for after hitting the StoreFile
    limit defined by hbase.hstore.blockingStoreFiles.
    After this time has elapsed, the HRegion will stop blocking updates even
    if a compaction has not been completed.  Default: 90 seconds.
    </p><p>Default: <code class="varname">90000</code></p></dd><dt><a name="hbase.hstore.compaction.max"></a><code class="varname">hbase.hstore.compaction.max</code></dt><dd><p>Max number of HStoreFiles to compact per 'minor' compaction.
    </p><p>Default: <code class="varname">10</code></p></dd><dt><a name="hbase.hregion.majorcompaction"></a><code class="varname">hbase.hregion.majorcompaction</code></dt><dd><p>The time (in miliseconds) between 'major' compactions of all
    HStoreFiles in a region.  Default: 1 day.
    Set to 0 to disable automated major compactions.
    </p><p>Default: <code class="varname">86400000</code></p></dd><dt><a name="hbase.mapreduce.hfileoutputformat.blocksize"></a><code class="varname">hbase.mapreduce.hfileoutputformat.blocksize</code></dt><dd><p>The mapreduce HFileOutputFormat writes storefiles/hfiles.
    This is the minimum hfile blocksize to emit.  Usually in hbase, writing
    hfiles, the blocksize is gotten from the table schema (HColumnDescriptor)
    but in the mapreduce outputformat context, we don't have access to the
    schema so get blocksize from Configuration.  The smaller you make
    the blocksize, the bigger your index and the less you fetch on a
    random-access.  Set the blocksize down if you have small cells and want
    faster random-access of individual cells.
    </p><p>Default: <code class="varname">65536</code></p></dd><dt><a name="hfile.block.cache.size"></a><code class="varname">hfile.block.cache.size</code></dt><dd><p>
        Percentage of maximum heap (-Xmx setting) to allocate to block cache
        used by HFile/StoreFile. Default of 0.25 means allocate 25%.
        Set to 0 to disable but it's not recommended.
    </p><p>Default: <code class="varname">0.25</code></p></dd><dt><a name="hbase.hash.type"></a><code class="varname">hbase.hash.type</code></dt><dd><p>The hashing algorithm for use in HashFunction. Two values are
    supported now: murmur (MurmurHash) and jenkins (JenkinsHash).
    Used by bloom filters.
    </p><p>Default: <code class="varname">murmur</code></p></dd><dt><a name="hfile.block.index.cacheonwrite"></a><code class="varname">hfile.block.index.cacheonwrite</code></dt><dd><p>
          This allows to put non-root multi-level index blocks into the block
          cache at the time the index is being written.
      </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hfile.index.block.max.size"></a><code class="varname">hfile.index.block.max.size</code></dt><dd><p>
          When the size of a leaf-level, intermediate-level, or root-level
          index block in a multi-level block index grows to this size, the
          block is written out and a new block is started.
      </p><p>Default: <code class="varname">131072</code></p></dd><dt><a name="hfile.format.version"></a><code class="varname">hfile.format.version</code></dt><dd><p>
          The HFile format version to use for new files. Set this to 1 to test
          backwards-compatibility. The default value of this option should be
          consistent with FixedFileTrailer.MAX_VERSION.
      </p><p>Default: <code class="varname">2</code></p></dd><dt><a name="io.storefile.bloom.block.size"></a><code class="varname">io.storefile.bloom.block.size</code></dt><dd><p>
          The size in bytes of a single block ("chunk") of a compound Bloom
          filter. This size is approximate, because Bloom blocks can only be
          inserted at data block boundaries, and the number of keys per data
          block varies.
      </p><p>Default: <code class="varname">131072</code></p></dd><dt><a name="hfile.block.bloom.cacheonwrite"></a><code class="varname">hfile.block.bloom.cacheonwrite</code></dt><dd><p>
          Enables cache-on-write for inline blocks of a compound Bloom filter.
      </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.rs.cacheblocksonwrite"></a><code class="varname">hbase.rs.cacheblocksonwrite</code></dt><dd><p>
          Whether an HFile block should be added to the block cache when the
          block is finished.
      </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.rpc.engine"></a><code class="varname">hbase.rpc.engine</code></dt><dd><p>Implementation of org.apache.hadoop.hbase.ipc.RpcEngine to be
    used for client / server RPC call marshalling.
    </p><p>Default: <code class="varname">org.apache.hadoop.hbase.ipc.ProtobufRpcEngine</code></p></dd><dt><a name="hbase.ipc.client.tcpnodelay"></a><code class="varname">hbase.ipc.client.tcpnodelay</code></dt><dd><p>Set no delay on rpc socket connections.  See
    http://docs.oracle.com/javase/1.5.0/docs/api/java/net/Socket.html#getTcpNoDelay()
    </p><p>Default: <code class="varname">true</code></p></dd><dt><a name="hbase.master.keytab.file"></a><code class="varname">hbase.master.keytab.file</code></dt><dd><p>Full path to the kerberos keytab file to use for logging in
    the configured HMaster server principal.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.master.kerberos.principal"></a><code class="varname">hbase.master.kerberos.principal</code></dt><dd><p>Ex. "hbase/_HOST@EXAMPLE.COM".  The kerberos principal name
    that should be used to run the HMaster process.  The principal name should
    be in the form: user/hostname@DOMAIN.  If "_HOST" is used as the hostname
    portion, it will be replaced with the actual hostname of the running
    instance.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.regionserver.keytab.file"></a><code class="varname">hbase.regionserver.keytab.file</code></dt><dd><p>Full path to the kerberos keytab file to use for logging in
    the configured HRegionServer server principal.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.regionserver.kerberos.principal"></a><code class="varname">hbase.regionserver.kerberos.principal</code></dt><dd><p>Ex. "hbase/_HOST@EXAMPLE.COM".  The kerberos principal name
    that should be used to run the HRegionServer process.  The principal name
    should be in the form: user/hostname@DOMAIN.  If "_HOST" is used as the
    hostname portion, it will be replaced with the actual hostname of the
    running instance.  An entry for this principal must exist in the file
    specified in hbase.regionserver.keytab.file
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hadoop.policy.file"></a><code class="varname">hadoop.policy.file</code></dt><dd><p>The policy configuration file used by RPC servers to make
      authorization decisions on client requests.  Only used when HBase
      security is enabled.
    </p><p>Default: <code class="varname">hbase-policy.xml</code></p></dd><dt><a name="hbase.superuser"></a><code class="varname">hbase.superuser</code></dt><dd><p>List of users or groups (comma-separated), who are allowed
    full privileges, regardless of stored ACLs, across the cluster.
    Only used when HBase security is enabled.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.auth.key.update.interval"></a><code class="varname">hbase.auth.key.update.interval</code></dt><dd><p>The update interval for master key for authentication tokens 
    in servers in milliseconds.  Only used when HBase security is enabled.
    </p><p>Default: <code class="varname">86400000</code></p></dd><dt><a name="hbase.auth.token.max.lifetime"></a><code class="varname">hbase.auth.token.max.lifetime</code></dt><dd><p>The maximum lifetime in milliseconds after which an
    authentication token expires.  Only used when HBase security is enabled.
    </p><p>Default: <code class="varname">604800000</code></p></dd><dt><a name="zookeeper.session.timeout"></a><code class="varname">zookeeper.session.timeout</code></dt><dd><p>ZooKeeper session timeout.
      HBase passes this to the zk quorum as suggested maximum time for a
      session (This setting becomes zookeeper's 'maxSessionTimeout').  See
      http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions
      "The client sends a requested timeout, the server responds with the
      timeout that it can give the client. " In milliseconds.
    </p><p>Default: <code class="varname">180000</code></p></dd><dt><a name="zookeeper.znode.parent"></a><code class="varname">zookeeper.znode.parent</code></dt><dd><p>Root ZNode for HBase in ZooKeeper. All of HBase's ZooKeeper
      files that are configured with a relative path will go under this node.
      By default, all of HBase's ZooKeeper file path are configured with a
      relative path, so they will all go under this directory unless changed.
    </p><p>Default: <code class="varname">/hbase</code></p></dd><dt><a name="zookeeper.znode.rootserver"></a><code class="varname">zookeeper.znode.rootserver</code></dt><dd><p>Path to ZNode holding root region location. This is written by
      the master and read by clients and region servers. If a relative path is
      given, the parent folder will be ${zookeeper.znode.parent}. By default,
      this means the root location is stored at /hbase/root-region-server.
    </p><p>Default: <code class="varname">root-region-server</code></p></dd><dt><a name="zookeeper.znode.acl.parent"></a><code class="varname">zookeeper.znode.acl.parent</code></dt><dd><p>Root ZNode for access control lists.</p><p>Default: <code class="varname">acl</code></p></dd><dt><a name="hbase.coprocessor.region.classes"></a><code class="varname">hbase.coprocessor.region.classes</code></dt><dd><p>A comma-separated list of Coprocessors that are loaded by
    default on all tables. For any override coprocessor method, these classes
    will be called in order. After implementing your own Coprocessor, just put
    it in HBase's classpath and add the fully qualified class name here.
    A coprocessor can also be loaded on demand by setting HTableDescriptor.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.coprocessor.master.classes"></a><code class="varname">hbase.coprocessor.master.classes</code></dt><dd><p>A comma-separated list of
    org.apache.hadoop.hbase.coprocessor.MasterObserver coprocessors that are
    loaded by default on the active HMaster process. For any implemented
    coprocessor methods, the listed classes will be called in order. After
    implementing your own MasterObserver, just put it in HBase's classpath
    and add the fully qualified class name here.
    </p><p>Default: <code class="varname"></code></p></dd><dt><a name="hbase.zookeeper.quorum"></a><code class="varname">hbase.zookeeper.quorum</code></dt><dd><p>Comma separated list of servers in the ZooKeeper Quorum.
    For example, "host1.mydomain.com,host2.mydomain.com,host3.mydomain.com".
    By default this is set to localhost for local and pseudo-distributed modes
    of operation. For a fully-distributed setup, this should be set to a full
    list of ZooKeeper quorum servers. If HBASE_MANAGES_ZK is set in hbase-env.sh
    this is the list of servers which we will start/stop ZooKeeper on.
    </p><p>Default: <code class="varname">localhost</code></p></dd><dt><a name="hbase.zookeeper.peerport"></a><code class="varname">hbase.zookeeper.peerport</code></dt><dd><p>Port used by ZooKeeper peers to talk to each other.
    See http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper
    for more information.
    </p><p>Default: <code class="varname">2888</code></p></dd><dt><a name="hbase.zookeeper.leaderport"></a><code class="varname">hbase.zookeeper.leaderport</code></dt><dd><p>Port used by ZooKeeper for leader election.
    See http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper
    for more information.
    </p><p>Default: <code class="varname">3888</code></p></dd><dt><a name="hbase.zookeeper.property.initLimit"></a><code class="varname">hbase.zookeeper.property.initLimit</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    The number of ticks that the initial synchronization phase can take.
    </p><p>Default: <code class="varname">10</code></p></dd><dt><a name="hbase.zookeeper.property.syncLimit"></a><code class="varname">hbase.zookeeper.property.syncLimit</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    The number of ticks that can pass between sending a request and getting an
    acknowledgment.
    </p><p>Default: <code class="varname">5</code></p></dd><dt><a name="hbase.zookeeper.property.dataDir"></a><code class="varname">hbase.zookeeper.property.dataDir</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    The directory where the snapshot is stored.
    </p><p>Default: <code class="varname">${hbase.tmp.dir}/zookeeper</code></p></dd><dt><a name="hbase.zookeeper.property.clientPort"></a><code class="varname">hbase.zookeeper.property.clientPort</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    The port at which the clients will connect.
    </p><p>Default: <code class="varname">2181</code></p></dd><dt><a name="hbase.zookeeper.property.maxClientCnxns"></a><code class="varname">hbase.zookeeper.property.maxClientCnxns</code></dt><dd><p>Property from ZooKeeper's config zoo.cfg.
    Limit on number of concurrent connections (at the socket level) that a
    single client, identified by IP address, may make to a single member of
    the ZooKeeper ensemble. Set high to avoid zk connection issues running
    standalone and pseudo-distributed.
    </p><p>Default: <code class="varname">300</code></p></dd><dt><a name="hbase.rest.port"></a><code class="varname">hbase.rest.port</code></dt><dd><p>The port for the HBase REST server.</p><p>Default: <code class="varname">8080</code></p></dd><dt><a name="hbase.rest.readonly"></a><code class="varname">hbase.rest.readonly</code></dt><dd><p>
    Defines the mode the REST server will be started in. Possible values are:
    false: All HTTP methods are permitted - GET/PUT/POST/DELETE.
    true: Only the GET method is permitted.
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.defaults.for.version.skip"></a><code class="varname">hbase.defaults.for.version.skip</code></dt><dd><p>
    Set to true to skip the 'hbase.defaults.for.version' check.
    Setting this to true can be useful in contexts other than
    the other side of a maven generation; i.e. running in an
    ide.  You'll want to set this boolean to true to avoid
    seeing the RuntimException complaint: "hbase-default.xml file
    seems to be for and old version of HBase (\${hbase.version}), this
    version is X.X.X-SNAPSHOT"
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.coprocessor.abortonerror"></a><code class="varname">hbase.coprocessor.abortonerror</code></dt><dd><p>
      Set to true to cause the hosting server (master or regionserver) to
      abort if a coprocessor throws a Throwable object that is not IOException or
      a subclass of IOException. Setting it to true might be useful in development
      environments where one wants to terminate the server as soon as possible to
      simplify coprocessor failure analysis.
      </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.online.schema.update.enable"></a><code class="varname">hbase.online.schema.update.enable</code></dt><dd><p>
    Set true to enable online schema changes.  This is an experimental feature.  
    There are known issues modifying table schemas at the same time a region
    split is happening so your table needs to be quiescent or else you have to
    be running with splits disabled.
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="dfs.support.append"></a><code class="varname">dfs.support.append</code></dt><dd><p>Does HDFS allow appends to files?
    This is an hdfs config. set in here so the hdfs client will do append support.
    You must ensure that this config. is true serverside too when running hbase
    (You will have to restart your cluster after setting it).
    </p><p>Default: <code class="varname">true</code></p></dd><dt><a name="hbase.thrift.minWorkerThreads"></a><code class="varname">hbase.thrift.minWorkerThreads</code></dt><dd><p>
    The "core size" of the thread pool. New threads are created on every
    connection until this many threads are created.
    </p><p>Default: <code class="varname">16</code></p></dd><dt><a name="hbase.thrift.maxWorkerThreads"></a><code class="varname">hbase.thrift.maxWorkerThreads</code></dt><dd><p>
    The maximum size of the thread pool. When the pending request queue
    overflows, new threads are created until their number reaches this number.
    After that, the server starts dropping connections.
    </p><p>Default: <code class="varname">1000</code></p></dd><dt><a name="hbase.thrift.maxQueuedRequests"></a><code class="varname">hbase.thrift.maxQueuedRequests</code></dt><dd><p>
     The maximum number of pending Thrift connections waiting in the queue. If
     there are no idle threads in the pool, the server queues requests. Only
     when the queue overflows, new threads are added, up to
     hbase.thrift.maxQueuedRequests threads.
     </p><p>Default: <code class="varname">1000</code></p></dd><dt><a name="hbase.offheapcache.percentage"></a><code class="varname">hbase.offheapcache.percentage</code></dt><dd><p>
     The amount of off heap space to be allocated towards the experimental
     off heap cache. If you desire the cache to be disabled, simply set this
     value to 0.
     </p><p>Default: <code class="varname">0</code></p></dd><dt><a name="hbase.data.umask.enable"></a><code class="varname">hbase.data.umask.enable</code></dt><dd><p>Enable, if true, that file permissions should be assigned
      to the files written by the regionserver
    </p><p>Default: <code class="varname">false</code></p></dd><dt><a name="hbase.data.umask"></a><code class="varname">hbase.data.umask</code></dt><dd><p>File permissions that should be used to write data
      files when hbase.data.umask.enable is true
    </p><p>Default: <code class="varname">000</code></p></dd><dt><a name="hbase.metrics.showTableName"></a><code class="varname">hbase.metrics.showTableName</code></dt><dd><p>Whether to include the prefix "tbl.tablename" in per-column family metrics.
	If true, for each metric M, per-cf metrics will be reported for tbl.T.cf.CF.M, if false,
	per-cf metrics will be aggregated by column-family across tables, and reported for cf.CF.M.
	In both cases, the aggregated metric M across tables and cfs will be reported.
    </p><p>Default: <code class="varname">true</code></p></dd><dt><a name="hbase.metrics.exposeOperationTimes"></a><code class="varname">hbase.metrics.exposeOperationTimes</code></dt><dd><p>Whether to report metrics about time taken performing an
      operation on the region server.  Get, Put, Delete, Increment, and Append can all
      have their times exposed through Hadoop metrics per CF and per region.
	</p><p>Default: <code class="varname">true</code></p></dd><dt><a name="hbase.table.archive.directory"></a><code class="varname">hbase.table.archive.directory</code></dt><dd><p>Per-table directory name under which to backup files for a
      table. Files are moved to the same directories as they would be under the
      table directory, but instead are just one level lower (under
      table/.archive/... rather than table/...). Currently only applies to HFiles.</p><p>Default: <code class="varname">.archive</code></p></dd><dt><a name="hbase.master.hfilecleaner.plugins"></a><code class="varname">hbase.master.hfilecleaner.plugins</code></dt><dd><p>A comma-separated list of HFileCleanerDelegate invoked by
    the HFileCleaner service. These HFiles cleaners are called in order,
    so put the cleaner that prunes the most files in front. To
    implement your own HFileCleanerDelegate, just put it in HBase's classpath
    and add the fully qualified class name here. Always add the above
    default log cleaners in the list as they will be overwritten in hbase-site.xml.
    </p><p>Default: <code class="varname">org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner</code></p></dd><dt><a name="hbase.regionserver.catalog.timeout"></a><code class="varname">hbase.regionserver.catalog.timeout</code></dt><dd><p>Timeout value for the Catalog Janitor from the regionserver to META.</p><p>Default: <code class="varname">600000</code></p></dd><dt><a name="hbase.master.catalog.timeout"></a><code class="varname">hbase.master.catalog.timeout</code></dt><dd><p>Timeout value for the Catalog Janitor from the master to META.</p><p>Default: <code class="varname">600000</code></p></dd><dt><a name="hbase.config.read.zookeeper.config"></a><code class="varname">hbase.config.read.zookeeper.config</code></dt><dd><p>
        Set to true to allow HBaseConfiguration to read the
        zoo.cfg file for ZooKeeper properties. Switching this to true
        is not recommended, since the functionality of reading ZK
        properties from a zoo.cfg file has been deprecated.
    </p><p>Default: <code class="varname">false</code></p></dd></dl></div></div></div><div class="section" title="2.3.2.&nbsp;hbase-env.sh"><div class="titlepage"><div><div><h3 class="title"><a name="hbase.env.sh"></a>2.3.2.&nbsp;<code class="filename">hbase-env.sh</code></h3></div></div></div><p>Set HBase environment variables in this file.
      Examples include options to pass the JVM on start of
      an HBase daemon such as heap size and garbarge collector configs.
      You can also set configurations for HBase configuration, log directories,
      niceness, ssh options, where to locate process pid files,
      etc. Open the file at
      <code class="filename">conf/hbase-env.sh</code> and peruse its content.
      Each option is fairly well documented.  Add your own environment
      variables here if you want them read by HBase daemons on startup.</p><p>
      Changes here will require a cluster restart for HBase to notice the change.
      </p></div><div class="section" title="2.3.3.&nbsp;log4j.properties"><div class="titlepage"><div><div><h3 class="title"><a name="log4j"></a>2.3.3.&nbsp;<code class="filename">log4j.properties</code></h3></div></div></div><p>Edit this file to change rate at which HBase files
      are rolled and to change the level at which HBase logs messages.
      </p><p>
      Changes here will require a cluster restart for HBase to notice the change
      though log levels can be changed for particular daemons via the HBase UI.
      </p></div><div class="section" title="2.3.4.&nbsp;Client configuration and dependencies connecting to an HBase cluster"><div class="titlepage"><div><div><h3 class="title"><a name="client_dependencies"></a>2.3.4.&nbsp;Client configuration and dependencies connecting to an HBase cluster</h3></div></div></div><p>
          Since the HBase Master may move around, clients bootstrap by looking to ZooKeeper for
          current critical locations.  ZooKeeper is where all these values are kept.  Thus clients
          require the location of the ZooKeeper ensemble information before they can do anything else.
          Usually this the ensemble location is kept out in the <code class="filename">hbase-site.xml</code> and
          is picked up by the client from the <code class="varname">CLASSPATH</code>.</p><p>If you are configuring an IDE to run a HBase client, you should
            include the <code class="filename">conf/</code> directory on your classpath so
            <code class="filename">hbase-site.xml</code> settings can be found (or
            add <code class="filename">src/test/resources</code> to pick up the hbase-site.xml
            used by tests).
      </p><p>
          Minimally, a client of HBase needs several libraries in its <code class="varname">CLASSPATH</code> when connecting to a cluster, including:
          </p><pre class="programlisting">
commons-configuration (commons-configuration-1.6.jar)
commons-lang (commons-lang-2.5.jar)
commons-logging (commons-logging-1.1.1.jar)
hadoop-core (hadoop-core-1.0.0.jar)
hbase (hbase-0.92.0.jar)
log4j (log4j-1.2.16.jar)
slf4j-api (slf4j-api-1.5.8.jar)
slf4j-log4j (slf4j-log4j12-1.5.8.jar)
zookeeper (zookeeper-3.4.2.jar)</pre><p>
      </p><p>
          An example basic <code class="filename">hbase-site.xml</code> for client only
          might look as follows:
          </p><pre class="programlisting">
&lt;?xml version="1.0"?&gt;
&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;
&lt;configuration&gt;
  &lt;property&gt;
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;
    &lt;value&gt;example1,example2,example3&lt;/value&gt;
    &lt;description&gt;The directory shared by region servers.
    &lt;/description&gt;
  &lt;/property&gt;
&lt;/configuration&gt;
</pre><p>
        </p><div class="section" title="2.3.4.1.&nbsp;Java client configuration"><div class="titlepage"><div><div><h4 class="title"><a name="java.client.config"></a>2.3.4.1.&nbsp;Java client configuration</h4></div></div></div><p>The configuration used by a Java client is kept
        in an <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/HBaseConfiguration" target="_top">HBaseConfiguration</a> instance.
        The factory method on HBaseConfiguration, <code class="code">HBaseConfiguration.create();</code>,
        on invocation, will read in the content of the first <code class="filename">hbase-site.xml</code> found on
        the client's <code class="varname">CLASSPATH</code>, if one is present
        (Invocation will also factor in any <code class="filename">hbase-default.xml</code> found;
        an hbase-default.xml ships inside the <code class="filename">hbase.X.X.X.jar</code>).
        It is also possible to specify configuration directly without having to read from a
        <code class="filename">hbase-site.xml</code>.  For example, to set the ZooKeeper
        ensemble for the cluster programmatically do as follows:
        </p><pre class="programlisting">Configuration config = HBaseConfiguration.create();
config.set("hbase.zookeeper.quorum", "localhost");  // Here we are running zookeeper locally</pre><p>
        If multiple ZooKeeper instances make up your ZooKeeper ensemble,
        they may be specified in a comma-separated list (just as in the <code class="filename">hbase-site.xml</code> file).
        This populated <code class="classname">Configuration</code> instance can then be passed to an
        <a class="link" href="http://hbase.apache.org/apidocs/org/apache/hadoop/hbase/client/HTable.html" target="_top">HTable</a>,
        and so on.
        </p></div></div></div><div id="disqus_thread"></div><script type="text/javascript">
    var disqus_shortname = 'hbase'; // required: replace example with your forum shortname
    var disqus_url = 'http://hbase.apache.org/book';
    var disqus_identifier = 'config.files';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a><div class="navfooter"><hr><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="standalone_dist.html">Prev</a>&nbsp;</td><td width="20%" align="center"><a accesskey="u" href="configuration.html">Up</a></td><td width="40%" align="right">&nbsp;<a accesskey="n" href="example_config.html">Next</a></td></tr><tr><td width="40%" align="left" valign="top">2.2.&nbsp;HBase run modes: Standalone and Distributed&nbsp;</td><td width="20%" align="center"><a accesskey="h" href="book.html">Home</a></td><td width="40%" align="right" valign="top">&nbsp;2.4.&nbsp;Example Configurations</td></tr></table></div></body></html>